Job Title,Salary Estimate,Job Description,Rating,Company Name,Location,Headquarters,Size,Founded,Type of ownership,Industry,Sector,Revenue,Competitors
Data Scientist,-1,"Position Description The data scientist will work in teams addressing statistical, Machine Learning and data understanding problems. In this role they will contribute to the development and deployment of Machine Learning, Operational Research, Semantic Analysis and statistical methods for finding structure in large data sets. Key responsibilities • Analysis of huge data set • Application of statistical methods for problem solving /analysis • Predictive modelling and supervise learning • Operational Research • Development of Unit Tests Other Responsibilities Analytical skills for problem solvingCommunication - Communicates clearly and concisely on a routine basis (verbally and in writing)Collaboration & Team Work - Works collaboratively with other members of the team by sharing ideas and informationExcellence in Execution - Works hard to meets the goals/ targets given, and is motivated by opportunities for reward and recognitionInnovation - Explores alternative approaches to achieving objectivesLearning & Applying - Focusses on learning and development as per the feedback provided for enhancing one's own performance",3.4,"UnitedHealth Group
3.4",Bengaluru,"Minnetonka, MN",10000+ employees,1977,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"Aetna, Humana, WellPoint"
Data Scientist,-1,"Position: Data Scientist

Location: Pune, India

NICE Actimize is comprised of talented, creative and dedicated individuals with a passion for delivering innovative solutions to the market. At NICE Actimize, we recognize that every employee’s contributions are integral to our company’s growth and success. To find and acquire the best and brightest talent around the globe, we offer a challenging work environment, competitive compensation and benefits, and rewarding career opportunities. Come share, grow and learn with us – you’ll be challenged, you’ll have fun and you’ll be part of a fast growing, highly respected organization.

NICE Actimize is currently seeking an experienced Data Scientist to join our dynamic and growing Fraud & AML Analytics Services team.

Responsibilities
Perform analysis to support the deployment of fraud prevention analytical models
Analyze fraud cases obtained from clients
Research data patterns in order to find patterns predictive of fraud
Improve the quality and actual implementation of computational algorithms and tools
Optimize the detection performance of NICE Actimize Fraud products and improve customers’ experience with our Fraud solutions
Define product requirements for analytics and provide feedback to the product team on ways in which product may be improved
Develop and enhance our solution-specific risk scores
Measure the quality of the analytical performance of Fraud Products
Develop tools to support model tuning, performance tracking and automation
Develop custom detection logic for specific clients
Help maintain and improve model development methodologies/practices.
Experience: 3 to 6 Years

Qualifications:
Advanced degree in a quantitative area (statistics, mathematics, physics, computer science, engineering)
Strong general analytical skills, Experience with statistical model development. Deep and diverse experience with multiple statistical procedures and data mining algorithms.
Strong experience with using SQL and EXCEL.
Strong programming skills in Python and ability to rapidly learn new programming tools.
Exposure to other programming languages: R, SAS, Scala, Java, Python, Matlab, SPSS, VBA, including procedures, macros, and scripting.
Experience of building and deploying classification and regression machine learning models at an enterprise level.
Good oral and written communications skills, and ability to interact with engineers, software developers, project managers, business analysts, product managers and with clients.
Ability to work in multi-disciplinary agile teams.
Strong commitment to quality
Customer facing experience – a plus
Innovative aptitude.
Additional Desired Qualifications:
Experience in development of risk management models, particularly in the fraud, AML, or financial trade compliance areas.
Knowledge of national and international financial systems and data standards.
Experience with Business Intelligence platforms, methodologies (e.g. OLAP), and tools.",4.0,"NICE Actimize
4.0",Pune,"Hoboken, NJ",501 to 1000 employees,1999,Subsidiary or Business Segment,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"SAS, Feedzai"
Data Scientist,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities
As a Data Scientist, you will be part of our growing team of data scientists and experts. You will be responsible for expanding and optimizing our data models, prediction algorithms correlation algorithms as well as text analytics models. You will support our software developers, data engineers on building and enhancing models. You must be self- directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re- designing our real time anomaly detection, correlation and forecasting models. You will be working on as a Data Scientist. The solutions developed by you would be highly scalable leveraging that needs to be run in Kubernetes Container environment.

Responsibilities:

Some of the Solutions we work involve the following
Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.
Natural Language Processing for entity, topic clusters and relationship extraction
Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets
Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing
Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts
Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.
Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.
Required Technical and Professional Expertise
Degree in Statistics, Mathematics, Computer Science or another quantitative field with 6 to 8 years of experience in manipulating data sets and building statistical models
Experience in using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets
Experience in creating and using advanced machine learning algorithms and statistics such as regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
Experience in visualizing or presenting data for stakeholders using Excel, PowerBI, Tableau etc.
Experience with distributed data or computing tools such as Hive, Spark, MySQL, etc
Experience creating and using advanced machine learning algorithms and statistics:
regression, simulation, scenario analysis, modelling, clustering, decision trees, etc.
Strong knowledge of Java or Python and general software development skills
(source code management, debugging, testing, deployment, etc.)
Preferred Technical and Professional Expertise
Bachelors degree in Computer Science, Mathematics, Physics, Computational Linguistics, or related field
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Scientist,-1,"Amazon strives to be Earth's most customer-centric company where people can find and discover anything they want to buy online. We hire the world's brightest minds, offering them a fast paced, technologically sophisticated, and friendly work environment.

The FinAuto Data Engineering and Analytics team, part of Finance Automation Org focuses on the application of machine learning methods designed to enable Amazon to increase free cash flow by optimizing spend, expense, payroll defects. All of this work is performed in close coordination with senior business leaders. These are exciting fast-paced businesses in which we get to work on extremely interesting analytical problems, in an environment where you get to learn from other data engineers and apply econometric, statistics, and machine learning at massive scale.
As a member of the FinAuto Data Engineering and Analytics team, you will partner closely with a team of stake holders, payment teams, data engineers and software engineers.
In this role you will:
· Work with data engineers to design and implement machine learning applications and solutions.
· Implement and maintain a high-volume, highly available, hybrid (SQL + No SQL) data processing solutions that consists of structured and semi-structured data.
· Design and implement a very large distributed data warehousing and reporting solution and integrate it with business intelligence tools



Basic Qualifications

· 5+ years of experience in software development of large-scale data infrastructure and distributed systems
· 5+ years of experience in data extraction, transformation, statistical analysis and data modeling
· 5+ years of experience developing enterprise software using Java or Python
· 3+ years of experience in applying Data Mining and Machine Learning techniques to solve business problems
· 3+ years of experience using major RDBMS, Hadoop, Spark, Elasticsearch, or similar technologies
· 3+ years of experience with statistical modeling tools such as R, SAS, SciKit-learn, or TensorFlow
· Bachelors degree in Computer Science, Computer Engineering, Machine Learning, or related field or equivalent experience.

Preferred Qualifications

· Masters degree in Computer Science, Computer Engineering, Machine Learning, or related field; PhD a plus
· Deep expertise in Statistics, Machine Learning or related disciplines
· Advanced knowledge in performance, scalability, numerical accuracy, enterprise system architecture, best practices.
· Experience building solutions using AWS big data and machine learning services
· Ability to communicate complex technical concepts and solutions to all levels of the organization",4.3,"Amazon
4.3",Hyderabad,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Scientist,-1,"If you are a data junkie who would like to wrangle through huge data sets of usage, stats, clickstreams, free text feedbacks and more to predict the user experience, adoption and retention. You like to solve complex and challenging problems and articulate the results in a lucid manner. Then we’ve got the problem for you and the data to solve it.

In your role as data scientist you will :
Select features, building and optimizing classifiers using machine learning techniques
Build statistical/machine learning models to extract insights
Create automated anomaly detection systems and constant tracking of its performance
Collaborate with subject matter experts to determine relevant data sources
Communicate the insights/recommendations to a wide spectrum of stake holder
Act as a mentor to guide/train less experienced folks
Desired Skills and experience:
B.E/Masters in Computer science/Statistics or equivalent
At least 5 years of experience in predictive modelling, strong knowledge of machine learning algorithms.
Strong in R,Python (numpy, scipy etc)
Very strong SQL and data visualization
Exposure to Big Data platforms such as Spark, Mahout, Scala, AWS machine learning is a plus
Great communications skills
Verizon recently acquired BlueJeans and plans to integrate BlueJeans employees into Verizon, including its compensation and benefits programs, in due course. This position will be part of that planned integration.",3.0,"BlueJeans
3.0",Bengaluru,"San Jose, CA",201 to 500 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Provide analytical insights into emerging problems, trends and portfolios
Work closely with business partners and stakeholders to determine how to design analysis and measurement approaches that will significantly improve our ability to understand and address emerging business issues
Bringing data to life and making it actionable and relevant to stakeholders through exploratory analysis of internal and external data sources using advanced and innovative analytical techniques, algorithms, and tools
Identifying present or future gaps in the teams existing reporting and tools suite and managing portfolio monitoring, dashboards and reporting
Providing regular updates to leadership, product and other stakeholders that will simplify and clarify complex concepts and the results of analyses effectively with emphasis on the actionable outcomes and impact to business
Experience with standard statistical techniques and tools a plus
Required Qualifications
Bachelor's Degree in a quantitative discipline (Economics, Engineering, Computer Science, Math, Statistics)
1-2 years experience in analytics or management consulting
Proficiency using SQL and querying relational databases
Experience in at least one statistical programming language (SAS, R, Python)
Experience in at least one data visualization tool (Tableau, Qlikview)
Experience with project management
Preferred Skills:
Strong communication skills
Quick learning
Out-of-box Problem Solving",3.7,"PayPal
3.7",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Data Scientist,-1,"Are you looking at developing future leaders? Come join us at Siemens.

At our Bengaluru Hub nearly 1100 employees provide various types of services – Finance, HR, IT, Supply Chain, Customer Care - to more than 60 Siemens entities across the world, We are global business solutions, that supports Siemens companies worldwide to achieve perfection in their internal process allowing our colleagues to fully focus on their business.

Change the future with us
You Work with large, data sets and applying sophisticated analytical methods as needed!
You should Develop custom data models and algorithms to apply to data sets.
You Should Know-how on Extract, Transform and Load (ETL) of Big Data in enterprise environments (e.g., SAP, Oracle), cloud infrastructure (e.g., AWS, Azure), as well as familiarity of data architecture requirements and conceptual approaches for deploying algorithmic solutions
You Should Interact with multiple partners (from various levels) and optimal present findings by exploiting visual displays of sophisticated quantity information in a simplified way
You will Identify and develop intelligent and innovative data analytics use cases to optimize business processes
We don’t need superheroes, just super minds
Bachelor’s degree in a quantitative field (e.g., Statistics, Operations Research, Bioinformatics, Economics, Computational Biology, Computer Science, Mathematics, Physics, Electrical Engineering, Industrial Engineering) or related field
Skilled in applying algorithmic models and are well acquainted with the properties and limits of a diverse set of established as well as state-of-the-art models, as well as validating the model results against the stated business objectives
Should be Comfortable working in programming languages like SQL, Python and R, as well as with frameworks like Tensorflow and Keras; experience designing solutions in distributed teams using Version Control tools like GIT
Experience with cloud technologies: Amazon Web Services and/or Microsoft Azure
Experience on collecting business requirements and traduce it into solution designs!
We’ve got quite a lot to offer. How about you?

This role is based in Bangalore. But you’ll also get to visit other locations in India and globe, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we encourage applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and creativity and help us craft tomorrow.

Find out more about Siemens at: www.siemens.com/careers

Organization: Global Business Services

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.0,"Siemens Healthineers
4.0",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Scientist,-1,"Overview


We have an exciting opportunity for a Data Scientist to join our dynamic AI Development team. This permanent position is well suited to an individual that is looking to advance their career in Python / R / Java Programming and gain hands-on experience in a thriving and supportive workplace.

Responsibilities


Objectives: 
Primary focus on applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.
Ability to manage time and follow guidelines and processes.
Procedures: 
Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
 Selecting features, building and optimizing classifiers using machine learning techniques
 Once the data source has been identified, mine and analyse data to drive optimization and improvement of product development, marketing techniques and business strategies.
 Enhancing data collection procedures to include information that is relevant for building analytic systems
 Design and review data collection procedures for regulatory compliance.
 Develop custom data models and algorithms to apply to data sets.
 Present information using data visualization techniques
 Propose solutions and strategies to business challenges
 Collaborate with SAS programming and Statistics teams
 Develop company A/B testing framework and test model quality.
 Develop processes and tools to monitor and analyse model performance and data accuracy.
 Raise awareness with other team on Data Science techniques and approaches.
 Have a good understanding of ICH/GCP guidelines.
 Follow appropriate Project Management procedures.
 Communicate effectively with project team.
Key Contacts/Relationships (Internal & External):

Internal:Work closely with other project team members, mentor and line manager.

External:Under supervision, may have limited interaction with internal clients to complete various programming activities. To fulfil this role, the Data Scientist supported by AI team members, may be required to participate in project team meetings and be responsive on an ad-hoc basis.

Qualifications
Qualified to degree level or equivalent, preferably in a numerate discipline
Good knowledge on statistics.
5 years of experience on Programming / Data Science Industry and minimum 2 year as Data Scientist",3.8,"Quanticate
3.8",Bengaluru,"Hitchin, United Kingdom",201 to 500 employees,1995,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹1 to ₹5 billion (INR),"GCE Solutions, Parexel, IQVIA"
Data Scientist,-1,"Site Name: India - Karnataka - Bangalore
Posted Date: Jul 28 2020
GSK is one of the worlds foremost pharmaceutical and healthcare companies and we are proud to be leading a healthcare revolution.

By disrupting our approaches to R&D and commercial business processes, D&A is allowing us to integrate, simplify and unlock all our data to drive innovation, decision making and enable our transformation in servicing our patients, healthcare professionals and consumers.

YOU would be responsible for the following:
Demonstrate specialization in AI/ML and Cognitive technology, process automation and process mining.
A strong business architecture foundation combined with technical skills background.
Deliver key analytics projects in an agile methodology.
Lead the investigation and detailed analysis of Cognitive ML/AI Incidents and process exceptions including a strategic approach to root cause analysis.
Provide accurate specifications and timely deliverance of all our products which need a good foundation of Data analytics, ML algorithm, python and other related coding experience
Follow proper DevOps methodologies, CI/CD pipelines, change and release management controls.
We are looking for professionals with these skills to achieve our goals. If YOU have these skills, we would like to speak to you.
MS/BS degree in Computer Science, Engineering, Design
Experience in Advanced analytics systems including but not limited to Apache, Hadoop, or any other Hadoop systems, HDFS, Graph and other non-relational databases.
Experience with in cloud or on-premise environment.
Experience on Azure ML, Azure Cognitive services is preferred.
Technical expert in AI/ML algorithms who can take these algorithms developed in Python, Scala, spark etc.
Experience in deploying AI/ML algorithms. Expert understanding of performance evaluation of the models.
Extensive experience in UAT, SAT and UX for adv analytics.
Why GSK?


Our values and expectations are at the heart of everything we do and form an important part of our culture. These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance and trust, the successful candidate will demonstrate the following capabilities.

GSKIndia_DA

*LI-GSK

Our goal is to be one of the worlds most innovative, best performing and trusted healthcare companies. We believe that we all bring something unique to GSK and when we combine our knowledge, experiences and styles together, the impact is incredible. Come join our adventure at GSK where you will be inspired to do your best work for our patients and consumers. A place where you can be you, feel good and keep growing.

Important notice to Employment businesses/ Agencies

GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.

It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.

GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKilne (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.

If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in gsk.com, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine.",3.9,"GSK
3.9",Bengaluru,"Brentford, United Kingdom",10000+ employees,1830,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Pfizer, AstraZeneca, Merck"
Data Scientist,-1,"When everything's connected, how we connect is everything… and we'd like to connect with you too! We are looking for you to help us deliver exceptional customer experiences as a Data Scientist.
At TTEC Digital, we combine human insight and the speed of technology to transform our clients’ interactions with their customers. Advanced analytics of the customer experience and customer interactions is our expertise.
Check out our website below to learn more about what we do and how we help our clients.
What you’ll be doing
This person will be a part of our Global Data Science Center focused on helping our clients find and seize opportunities in their markets.

Support the development of consulting products such as proprietary customer experience scores and marketing optimization solutions
Maintain our stellar reputation with our clients and drive >80 client NPS
Leverage a mixture of data science methods such as SVM, neural nets, decision trees, and regression models to deliver proprietary uplift model solutions
Support the introduction and advancement of decision science throughout our contact center engagement
Recommend and introduce new methods where relevant
Resource Planning
Recommend required resources to managers
Align required resources to client schedules
Mentor data engineers and architects on requirements
Develop requirements and technical specifications documents for use by engineers

Delivery
Recommend project timelines to managers
Drive on-time delivery and identify and escalate risks to managers
Support attainment of annual goals for client satisfaction
Deliver your own solutions while collaborating on other projects

What you’ll bring to the role
Masters in Statistics, Economics, IE/OR, Computer Science, Applied Mathematics or related field is required; PhD is a plus
1-5 years' experience delivering advanced analytics solutions since graduate program
Ability to translate client requests into approach statements and project plans
Ability to work in a highly collaborative, team-oriented environment
Ability to identify effective, relevant statistical and/or mathematical methods to solve complex business problems
Expert at data wrangling both structured and unstructured data
Experience delivering solutions using regression modeling or machine learning techniques; experience with both is desired
Expert in developing and implementing predictive analytics solutions in one or more of the following languages: R or Python experience with SAS is desired
Experience delivering solutions using large datasets (multi-Gb or larger)
Experience in MS Office suite of products, especially Excel and Powerpoint
Ability to work within any modern big data environment (AWS, MS Azure, SAP Hana, etc.) is desired
Experience with text analytic or speech analytic is desired.
Experience with one or more modern social listening tools (Crimson Hexagon, TheySay, etc.) is desired
What skills you’ll need:
Excellent analytic and data-driven thinking skills
Strong communication skills and an ability to work successfully in a distributed workforce
Creative problem solving and an understanding of analytics workflows
Strong background in consulting a plus

About TTEC
We help global brands provide a great experience to their customers, build customer loyalty, and grow their business. We were founded on one guiding principle: customer experiences that are simple, inspired, and more human deliver lasting value for everyone. Your role brings that principle to life.",3.4,"TTEC
3.4",Hyderabad,"Englewood, CO",10000+ employees,1982,Company - Public,Staffing & Outsourcing,Business Services,₹100 to ₹500 billion (INR),"Teleperformance, TaskUs, Convergys"
Data Scientist,-1,"Hitachi Vantara combines technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers’ experiences, develop new revenue streams, and lower the costs of business. Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. Come join our team and our employee-focused culture, and help drive our customers’ data to meaningful customer outcomes.

Responsibilities:
Lead data science and machine learning efforts in products and solutions involving IoT, Big Data, Cloud and microservices

The products and solutions are being designed using artificial intelligence and analytics into problems involving management and root cause analysis for IT operations, manufacturing and data centers to provide valuable insights and quantifiable RoI to end users
Mentor and guide data science team members as well as developers and QA engineers working on the products
Work with business managers to frame a problem, both mathematically and within the business context
Perform exploratory data analysis to gain a deeper understanding of the problem
Understand business data and how to use it appropriately in data analysis
Construct and fit statistical, machine learning, or optimization models using Spark and TensorFlow
Apply and develop appropriate advanced statistical, machine learning, and/or deep learning models and algorithms to classify structured or unstructured data
Collaborate with internal stakeholders to understand business challenges and develop analytical solutions to optimize business processes
Test performance of machine learning and deep learning models

Qualifications:
10 to 15 years’ overall experience designing, implementing and successfully delivering enterprise/SAAS product with analytics features
10+ years of experience in analytics, data science, data mining, machine learning or comparable product/consumer analytics role
Bachelor's degree in Computer Science, Operations Research or Math/Statistics
Experience in working with multi-dimensional data
Top notch communication skills to convey key insights from complex analysis, both oral and written
Experience in Spark MLLib, PySpark, NumPy/SciPy, TidyData
Experience with agile and Scrum
Ability to work with distributed teams in a collaborative and productive manner
Self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities

Desired Skills:
Experience working with TensorFlow, Open CV, Deep learning experience and time series analysis
Exposure or experience in IoT/Industrial automation and/or DevOps experience",2.7,"Hitachi Vantara
2.7",Bengaluru,"Santa Clara, CA",5001 to 10000 employees,1989,Subsidiary or Business Segment,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist Intern,-1,"Amazon Internet Services Private Limited (AISPL), is seeking a talented, self-directed Intern Data Scientist to help use massive amounts of data to develop Machine Learning (ML) and Deep Learning (DL). The role will focus on public sector and healthcare, to derive business value through the adoption of Artificial Intelligence (AI). If you have experience with AI/ML-Data Science, including building ML or DL models, wed like to have you join our team. You will get to work with an innovative company, with great teammates, and have a lot of fun helping our customers.

At Amazon Web Services (AWS), we are helping public sector healthcare build ML and DL models on the AWS Cloud. We are applying predictive technology to large volumes of data and against a wide spectrum of problems. Our AI/ML and Analytics team works together with our AWS customers to address their business needs using AI.

This role will support the public sector AI/ML & Analytics team of AISPL and contribute to creation of healthcare data models for programs categorized as high impact by AISPL.

We are looking for a talented individual who is capable of using ML and other techniques to design, evangelize, and implement state-of-the-art solutions for never-before-solved problems.


Roles & Responsibilities:
· Design data architectures and data lakes
· Provide expertise in the development of ETL solutions on AWS
· Use ML tools, such as Amazon SageMaker Ground Truth (GT) to annotate data. Work with the team on designing workflow and user interface for GT annotation.
· Collaborate with our data scientists to create scalable ML solutions for business problems
· Interact with customer directly to understand the business problem, help and aid them in implementation of their ML ecosystem
· Analyze and extract relevant information from large amounts of historical data - provide hands-on data wrangling expertise
· Work closely with account team, research scientist teams and product engineering teams to drive model implementations and new algorithms
Basic Qualifications
· BS in computer science, or related technical, math, or scientific field
· Working knowledge of deep learning, machine learning and statistics
· User interface experience with Javascript, HTML
· Knowledge of ETL tools and databases (both SQL-based, NoSQL)
· Experience in using Python, R or Matlab or other statistical/machine learning software
· Strong communication and data presentation skills

Preferred Qualifications
· The motivation to achieve results in a fast-paced environment
· Comfortable working in a fast paced, highly collaborative, dynamic work environment
· Professional oral and written communication skills in English
· Publications or presentation in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
· Experience with AWS technologies like Redshift, S3, EC2, Data Pipeline, & EMR



Basic Qualifications

Basic Qualifications
· BS in computer science, or related technical, math, or scientific field
· Working knowledge of deep learning, machine learning and statistics
· User interface experience with Javascript, HTML
· Knowledge of ETL tools and databases (both SQL-based, NoSQL)
· Experience in using Python, R or Matlab or other statistical/machine learning software
· Strong communication and data presentation skills


Preferred Qualifications

Preferred Qualifications
· The motivation to achieve results in a fast-paced environment
· Comfortable working in a fast paced, highly collaborative, dynamic work environment
· Professional oral and written communication skills in English
· Publications or presentation in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
· Experience with AWS technologies like Redshift, S3, EC2, Data Pipeline, & EMR",4.3,"Amazon
4.3",Gurgaon,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Scientist,-1,"Job Description:


Job Title - Data Scientist

Location- Pune

Role Description


Within the HR function, we are looking for a Data Scientist who will help discover information hidden in the data available and help the business to drive the strategy with data-based insights. Data scientist must be able to apply their analytical, statistical and programming skills to collect, analyze and interpret large data sets and present the outcomes using various data visualization techniques apt for different kind of stakeholders. Data scientist then should use such outcomes to develop data driven solutions and support stakeholders to improve business outcomes.

What we’ll offer you

As part of our flexible scheme, here are just some of the benefits that you’ll enjoy

· Best in class leave policy

· Gender neutral parental leaves

· 100% reimbursement under child care assistance benefit (gender neutral)

· Flexible working arrangements

· Sponsorship for Industry relevant certifications and education

· Employee Assistance Program for you and your family members

· Comprehensive Hospitalization Insurance for you and your dependents

· Accident and Term life Insurance

Complementary Health screening for 35 yrs. and above

Areas of Specialty
Data Mining: Ability to perform statistical analysis, prepare forecasting and predictive models etc.
AI & Machine Learning: Ability to build AI Models/Machine Learning models to automate the processes and continuously enhance the model based on data changes
Programming Skills: Ability to write programs/scripts in popular scripting and programming languages
Data Profiling & Quality: Ability to perform data quality checks on the source data ensuring good data quality for the model inputs
Data Visualization: Ability to present the outcomes in the most effective way
Responsibilities
Work continuously with stakeholders to identify opportunities of leveraging data to help in business solutions and driving business strategy; in this case it will be for the HR function of a large European bank
Analyze data to find patterns by applying data mining techniques and performing statistical analysis
Build AI tools to automate the processes; create machine learning based tools or processes
Develop high quality predictive modeling systems to provide HR with crucial results helping business to take smart decisions around workforce planning e.g. identification of potential leavers/movers
Develop data collection processes from a wide variety of sources including the data verification steps to ensure bringing the right quality of data and continuous monitoring of data performance
Use third party data in collaboration with organization’s data to have better insights and comparison with industry parameters
Develop and automate testing & verification framework for testing the quality of the various models being developed or already in production
Develop smart data visualization techniques/approaches conveying the outcomes in a clear and intuitive manner
Recruit, train and lead a team of data scientists
Evaluate new and emerging technologies
Skills & Qualifications
Excellent understanding and experience with common data science tools and data mining technologies
Exposure of AI & Machine Learning techniques and algorithms
Good demonstrable experience with data visualization tools and reporting technologies
Good experience with different databases including RDBMS, NoSQL databases and formats like JSON, XML etc.
Excellent scripting and programming skills like Python, R, Java, Scala etc.
Strong analytical and problem solving skills
Proficient written and verbal communication skills
Exposure to Big Data and Business Analytics technologies
Experience with cloud technologies
Data oriented personality with a drive to learn and master new technologies
Education/Certification


Graduation/Post-graduation from an accredited college or university with a concentration in Statistics or Computer Science (or equivalent)

Deutsche Bank is an equal opportunity employer who seeks to recruit and appoint the best available person for a job regardless of marital / civil partnership status, sex (including pregnancy), age, religion, belief, race, nationality and ethnic or national origin, colour, sexual orientation or disability.

How we’ll support you

· Training and development to help you excel in your career

· Flexible working to assist you balance your personal priorities

· Coaching and support from experts in your team

· A culture of continuous learning to aid progression

· A range of flexible benefits that you can tailor to suit your needs

About us and our teams

Please visit our company website for further information:

https://www.db.com/company/company.html

Our values define the working environment we strive to create – diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer.

We promote good working relationships and encourage high standards of conduct and work performance. We welcome applications from talented people from all cultures, countries, races, genders, sexual orientations, disabilities, beliefs and generations and are committed to providing a working environment free from harassment, discrimination and retaliation.

Click here to find out more about our diversity and inclusion policy and initiatives.",3.5,"Deutsche Bank
3.5",Pune,"Frankfurt am Main, Germany",10000+ employees,1870,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),-1
Data Scientist Sales & Channel,-1,"HP is the worlds leading personal systems and printing company, we create technology that makes life better for everyone, everywhere. Our innovation springs from a team of individuals, each collaborating and contributing their own perspectives, knowledge, and experience to advance the way the world works and lives.
We are looking for visionaries, like you, who are ready to make a purposeful impact on the way the world works.
At HP, the future is yours to create!
If you are our Data Scientist in India, you will get an opportunity to work on below.

o Mines data using modern tools and programming languages.
o Defines and implements models to uncover patterns and predictions creating business value and innovation.
o Works with the business to understand the business domain perspective.
o Effectively tells stories with the data using visualization tools/methods to demonstrate insight impact and business value.
o Assures accuracy, integrity, and compliance of cleansed data.
o Maintains proficiency within the data science domain by keeping up with technology and trend shifts.
o Leads a project team of data science professionals
o Collaborates and communicates with project team regarding project progress and issue resolution.
o Represents the data science team for all phases of larger and more-complex development projects.
o Provides guidance, training and mentoring to less experienced staff members.

Are you a high-performer? We are looking for an individual with:

o Using statistics, mathematics, algorithms and programming languages.
o Understanding of how to manage disparate unstructured and structured data in a distributed environment.
o Fluent in structured and unstructured data and modern data transformation methodologies.
o Ability to create models to pull valuable insights from data.
o Create stories and visualizations to describe and communicate data insights.
o Ability to use creativity to spot trends and tease out patterns in large datasets.

#LIPOST",4.1,"HP Inc.
4.1",Bengaluru,"Palo Alto, CA",10000+ employees,1939,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Analytics
Data Scientist - QuantumBlack

Gurugram

Apply Now

Qualifications

Masters or PhD level in the computer science, machine learning, applied statistics, mathematics
Experience in statistical modelling and machine learning techniques
Programming experience in at least two of the following languages: R, Python, Scala, SQL
Experience in applying data science methods to business problems
Experience in applying advanced analytical and statistical methods in the commercial world
Good presentation and communication skills, with the ability to explain complex analytical concepts to people from other fields

Who You'll Work With

You will join the Gurgaon office and be part of QuantumBlack. You will work with other data scientists, data engineers, machine learning engineers, designers and project managers on interdisciplinary projects, using maths, stats and machine learning to derive structure and knowledge from raw data across various industry sectors.

Who you are

You are a highly collaborative individual who is capable of laying aside your own agenda, listening to and learning from colleagues, challenging thoughtfully and prioritising impact. You search for ways to improve things and work collaboratively with colleagues. You believe in iterative change, experimenting with new approaches, learning and improving to move forward quickly.

What You'll Do

As a data scientist at QuantumBlack:

You will work in multi-disciplinary environments harnessing data to provide real-world impact for organisations globally. You will influence many of the recommendations our clients need to positively change their businesses and enhance performance.

Role responsibilities
Work on complex and extremely varied data sets from some of the world’s largest organisations to solve real world problems
Develop data science products and solutions for clients as well as for our data science team
Write highly optimized code to advance our internal Data Science Toolbox
Work in a multi-disciplinary environment with specialists in machine learning, engineering and design
Add real-world impact to your academic expertise; you will be encouraged to write ‘black’ papers and present at meetings and conferences should you wish
Attend conferences such as NIPS and ICML as one global team and data science retrospectives where you will have the opportunity to share and learn from your colleagues
Work within one of the largest and most advanced data science teams in London, and support the lead data scientists to develop data science products
What you’ll learn
How successful projections on real world problems across a variety of industries are completed through referencing past deliveries of end to end machine learning pipelines
Build products alongside the core engineering team and evolve the engineering process to scale with data, handling complex problems and advanced client situations
Be able to focus on modelling by working alongside the Data Engineering team which focuses on the wrangling, clean-up and transformation of data.
Best practices in software development and productionise machine learning by working with our Machine Learning Engineering teams which optimise code for model development and scale it
Work with our UX and Visual Design teams to interpret your complex models into stunning and user-focused visualisations
Using new technologies and problem-solving skills in a multicultural and creative environment
You will work on the frameworks and libraries that our teams of Data Scientists and Data Engineers use to progress from data to impact. You will guide global companies through data science solutions to transform their businesses and enhance performance across industries including healthcare, automotive, energy and elite sport.
Real-World Impact – No project is ever the same; we work across multiple sectors, providing unique learning and development opportunities internationally.
Fusing Tech & Leadership – We work with the latest technologies and methodologies and offer first class learning programmes at all levels.
Multidisciplinary Teamwork - Our teams include data scientists, engineers, project managers, UX and visual designers who work collaboratively to enhance performance.
Innovative Work Culture – Creativity, insight and passion come from being balanced. We cultivate a modern work environment through an emphasis on wellness, insightful talks and training sessions.
Striving for Diversity – With colleagues from over 40 nationalities, we recognise the benefits of working with people from all walks of life.
Our projects range from helping pharmaceutical companies bring lifesaving drugs to market quicker to optimising a Formula1 car’s performance. At QuantumBlack you have the best of both worlds; all the benefits of being part of one of the leading management consultancies globally and the autonomy to thrive in a fast growth tech culture:
Healthcare Efficiency – We helped a healthcare provider improve their clinical trial practices by identifying congestion in diagnostic testing as a key indicator of admissions breaches.
Environmental Impact – We designed and built the first data-driven application for a state of the art centre of excellence in urban innovation by collecting real-time data from environmental sensors across London and deploying proprietary analytics to find unexpected patterns in air pollution.
Product Development – We worked with the CEO of an elite automotive organisation to reduce the 18-month car development timeframe by improving processes, designs and team structures.
Visit our Careers site to watch our video and read about our interview processes and benefits

As an equal opportunity employer, QuantumBlack encourages applications from all backgrounds regardless of gender, race, disability, pregnancy, marital status, age, sexual orientation, gender reassignment, religion or belief. We maintain a sense of community rooted in respect and consideration for all employees where any evaluation is based simply upon individual work and team performance.

Industries
High Tech

Functions
Technology

Apply Now
FOR U.S. APPLICANTS: McKinsey & Company is an Equal Opportunity/Affirmative Action employer.
All qualified applicants will receive consideration for employment without regard to sex, gender
identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran
status, age, or any other characteristic protected by applicable law.

FOR NON-U.S. APPLICANTS: McKinsey & Company is an Equal Opportunity employer. For additional details
regarding our global EEO policy and diversity initiatives, please visit our
McKinsey Careers and
Diversity & Inclusion sites.",4.5,"QuantumBlack
4.5",Gurgaon,"London, United Kingdom",501 to 1000 employees,2009,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Palantir Technologies, Google, Microsoft"
Data Scientist,-1,"Are you looking at developing future leaders? Come join us at Siemens.

At our Bengaluru Hub nearly 1100 employees provide various types of services Finance, HR, IT, Supply Chain, Customer Care - to more than 60 Siemens entities across the world, We are global business solutions, that supports Siemens companies worldwide to achieve perfection in their internal process allowing our colleagues to fully focus on their business.

Change the future with us
You Work with large, data sets and applying sophisticated analytical methods as needed!
You should Develop custom data models and algorithms to apply to data sets.
You Should Know-how on Extract, Transform and Load (ETL) of Big Data in enterprise environments (e.g., SAP, Oracle), cloud infrastructure (e.g., AWS, Azure), as well as familiarity of data architecture requirements and conceptual approaches for deploying algorithmic solutions
You Should Interact with multiple partners (from various levels) and optimal present findings by exploiting visual displays of sophisticated quantity information in a simplified way
You will Identify and develop intelligent and innovative data analytics use cases to optimize business processes
We dont need superheroes, just super minds
Bachelors degree in a quantitative field (e.g., Statistics, Operations Research, Bioinformatics, Economics, Computational Biology, Computer Science, Mathematics, Physics, Electrical Engineering, Industrial Engineering) or related field
Skilled in applying algorithmic models and are well acquainted with the properties and limits of a diverse set of established as well as state-of-the-art models, as well as validating the model results against the stated business objectives
Should be Comfortable working in programming languages like SQL, Python and R, as well as with frameworks like Tensorflow and Keras; experience designing solutions in distributed teams using Version Control tools like GIT
Experience with cloud technologies: Amazon Web Services and/or Microsoft Azure
Experience on collecting business requirements and traduce it into solution designs!
Weve got quite a lot to offer. How about you?

This role is based in Bangalore. But youll also get to visit other locations in India and globe, so youll need to go where this journey takes you. In return, youll get the chance to work with teams impacting entire cities, countries and the shape of things to come.

Were Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we encourage applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and creativity and help us craft tomorrow.

Find out more about Siemens at: www.siemens.com/careers

Organization: Global Business Services

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.0,"Siemens
4.0",Bengaluru,"Munich, Germany",10000+ employees,1843,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),"GE, ABB, Philips"
Data Scientist,-1,"Title
Data Scientist


27-Jul-2020

Job Description
Required skill sets:

1. Data Scientist - Time series
2.Python
3.Predictive Analytics and maintenance
4.Machine Learning
5. Deep Learning

Auto req ID
17299BR

Job Type
Full Time-Regular

Assignment Country
India

Total Years of Exp
5

Education Type
BE

Assignment State
Karnataka

Assignment Location
Bangalore (Bengaluru)

Experience Level
Senior Level",3.1,"QuEST Global
3.1",Bengaluru,"Singapore, Singapore",10000+ employees,1997,Company - Private,Aerospace & Defence,Aerospace & Defence,₹10 to ₹50 billion (INR),-1
Data Scientist,-1,"Data Scientist

Munich Re, Bombay, India

Entry level

Graduate and entry level positions

Type of job

Full-time

Area of Expertise

Data Analytics/Engineering

Your job


Job Purpose
We are looking for an experienced Data Scientist to join our growing Data Analytics team. The role will be responsible for advising the business on the potential of data, to provide new insights into the business's mission, and through t...
Apply now
Open job details

Published on 07/22/2020",3.3,"ERGO Group
3.3",Mumbai,"Dublin, Ireland",201 to 500 employees,1993,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1
Associate Data Analyst,-1,"Associate Data Analyst

Full Time
Bangalore, IN

Innovate with Gensuite as an Associate Data Analyst

Do you want to innovate the future? At Gensuite we innovate the future every day! From working with incredible team members, innovative subscribers and new technology like Artificial Intelligence, a career at Gensuite means using your skills to develop fresh ideas and innovative initiatives. Our employees work together seamlessly, combining our collective creativity and passion to meet and exceed the expectations of our customers.

We work with incredible brands like Amazon Fulfillment, General Electric and NBC Universal among many, that trust our solution, inspired by users and created for leaders.

Gensuite Benefits

We offer all our full-time employees a competitive package of compensation and benefits, including vacation; Company-sponsored group healthcare and life insurance plans. We also pride ourselves on our friendly, accepting work atmosphere. Plus, our team events and office-wide initiatives keep us feeling invigorated and ready to tackle any challenge.

About Gensuite LLC

Gensuite LLC develops and deploys innovative software solutions for companies in every industry and corner of the globe. Our varied and powerful web-based applications are developed to help our customers turn complex compliance requirements into a manageable, digitized and actionable processes. Our comprehensive cloud software suite features intuitive, best-practice process functionality, flexible configurations and powerful extensions. For over two decades, weve helped companies manage safe & sustainable operations worldwide, with a focus on fast return on investment (ROI), service excellence and continuous innovation. Over 1 million users trust Gensuite with their compliance and Environmental, Health and Safety software system needs, and we are proud to offer solutions inspired by our users and created for worldwide leaders.

Gensuite Subscribers

Worldwide: Access Midstream, Amazon Fulfillment, AngloGold Ashanti, Cactus Wellhead, Comcast, Dubois Chemicals, General Electric, Grainger, Hill-Rom, Ingersoll Rand, Luxottica, NBCUniversal, Perrigo, US Silica and more.

Responsibilities
Working in Tableau to create customer facing reports on Gensuite application data and scoping said reports.
Working with customer services team to finalize efforts for proposal creation.
Working with Application DEV teams to finalize data models to bring into the Tableau reports.
Entail ongoing maintenance to these reports as well and investigating if there are data accuracy concerns.
Qualifications & Experience:

Bachelors degree in information systems/computer science, with course work in database management, and computer-related training. 1-3 years of relevant experience in data analysis.

Skills:

Must be able to clearly understand and articulate a data science problem and work on it independently.
Experience in implementing and optimizing various algorithms of big data analytics, machine learning and statistical algorithms using computer languages such as SQL, R, Python.
Extensive background in data mining and statistical analysis.
Able to understand various data structures and common methods in data transformation.
Excellent pattern recognition, natural language processing (NLP), predictive and machine learning modeling.
Advanced skills in Excel as well as any data visualization tools like Tableau or similar BI tools (familiarity with Tableau preferred).
Advanced ability to draw insights from data and clearly communicate them (verbal/written) to the stakeholders and senior management as required.
An ability and interest in working in a fast-paced and rapidly changing environment.
Excellent communication skills.
Ability to work effectively with a variety of personality styles.
Strong commitment to results.
Sense of urgency; responsive.
Questions about the position? Please contact our HR Specialist, Arjun Krishnan at arjun.krishnan@gensuitellc.com",3.4,"Gensuite LLC
3.4",Bengaluru,"Mason, OH",201 to 500 employees,2008,Company - Private,Computer Hardware & Software,Information Technology,₹1 to ₹5 billion (INR),"Intelex Technologies, VelocityEHS"
Data Scientist,-1,"Location
Bombay , India

Your job

Job Purpose

We are looking for an experienced Data Scientist to join our growing Data Analytics team. The role will be responsible for advising the business on the potential of data, to provide new insights into the business's mission, and through the use of advanced statistical analysis, data mining, and data visualization techniques, to create solutions that enable enhanced business performance.

Key Responsibilities

Construct statistical and probabilistic models to advance mortality and morbidity research.
Develop models of policyholder behaviour (lapse, anti-selection, fraud) based on available data and judgement.
Develop models based on advanced machine learning techniques like deep learning, neural network etc
Develop and recommend solutions to improve efficiency
Inform management or internal client of results and make recommendations as appropriate

Your profile

Master Degree or Ph. D. in mathematics, Operational Research, Statistics, Computer science or engineering with 2+ years of experience in advanced data analytics and machine learning projects.
Exceptional skills in coding with R and/or Python.
Sound knowledge of Big Data platforms (e.g. Hadoop) and cloud and streaming technology (AWS, Kafka, Microsoft Azure).
Sound knowledge of machine learning algorithms (e.g. GLM, GBM, Random Forest).
Proven experience in data visualisation tools (e.g. RShiny, Tableau, SAS VA, Power BI).
Outstanding skills in presenting results to internal and external clients
Experience in managing complex project with international and multi-cultural stakeholders.
Self-motivating, preparedness to take ownership
Actuarial / insurance domain knowledge (preferred)

About us

Our business model is based on the combination of primary insurance and reinsurance under one roof. We take on risks worldwide of every type and complexity, and our experience, financial strength, efficiency and first-class service make us the first choice for all matters relating to risk. Our client relationships are built on trust and cooperation. If you would be interested in helping shape the future as part of one of our teams, we look forward to hearing from you.

Apply now! Apply for this Job!",3.7,"Munich Re
3.7",Mumbai,"Munich, Germany",5001 to 10000 employees,1880,Company - Public,Insurance Operators,Insurance,₹500+ billion (INR),-1
Data Scientist,-1,"Description
We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.
You will be responsible for researching, innovate and implementing state-of-the-art algorithms using deep learning, reinforcement learning techniques in Natural Language Processing task, Machine Reading Comprehension, Recognizing Textual Entailment, Document Classification, Text Analytics, Sentiment Analysis, recommendation engine, A/B testing and more.
Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
research and innovation of state-of-the-art papers in NLP problems
Working with Backend Engineers to ship your models to production and publish research in top journals e.g.: NIPS, Arxiv and Nature
Skills and Qualifications
Proficiency in Python, R or Java and data science tools.
Experience in modern Deep Learning and Natural Language Processing / Natural Language Understanding (NLP, NLU), including Neural Networks, RNNs, seq2seq+attention models, and real world machine learning in TensorFlow.
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive or Pig.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Experience building production-ready NLP systems
Familiarity with non-standard machine intelligence models (Reinforcement Learning, Hierarchical Temporal Memory, Capsule Networks) is a plus
Familiarity with Distributed systems (Docker, Kubernetes, Kafka, Spark, Redis, AWS S3/EC2/RDS/KMS, MongoDB, or Lucene) is a plus
Proficient understanding of code versioning tools such as Git, Mercurial or SVN, continuous integration tool like Jenkins.
Bachelor’s degree or higher in a technical field of study
Job Location: Indore | Openings",4.6,"GenieTalk
4.6",Indore,"Mumbai, India",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Data Science @ Tookitaki

The data science team is responsible for solving business problems with complex data. Data
complexity could be characterized in terms of volume, dimensionality and multiple
touchpoints/sources. We understand the data, ask fundamental-first-principle questions,
apply our analytical and machine learning skills to solve the problem in the best way
possible. We also encourage participation in competitions like Kaggle.

Our ideal candidate

We are looking for a junior data scientist who has a deep interest in theoretical and applied
machine learning and loves working in a fast-paced environment.
He/she should have 3-5 years’ work experience in predictive analytics/forecasting space and
have solved real-world problems. Candidates with experience in transactional anomaly
prediction, operational risk modelling would be given preference.

The role would be a client-facing one, hence good communication skills are a must. The
candidate should have the ability to communicate complex models and analysis in a clear

and a precise manner. The candidate would be responsible for:
Comprehending business problems properly – what to predict, how to build DV, what
value addition he/she is bringing to the client, etc.
Understanding and analyzing large, complex, multi-dimensional datasets and build
features relevant for business
Understanding the math behind algorithms and choosing one over another
Understanding approaches like stacking, ensemble and applying them correctly to
increase accuracy

Desired technical requirements

Proficiency with Python and the ability to write production-ready codes. Experience
in Scala would be a plus
Big data experience, e.g. familiarity with Spark, Hadoop, is highly preferred
Familiarity with SQL or other databases.

Desired Non-technical Requirements

Very strong communication skills both written and verbal
Strong desire to work with start-ups

Job Perks

Attractive variable compensation package
Opportunity to work with an award-winning organization in the hottest space in tech –
artificial intelligence and advanced machine learning",4.8,"Tookitaki
4.8",India,"Singapore, Singapore",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Science-Python Programming Language,-1,"Job Skill: Python Programming Language
Designation: Career Level - 11-Analyst
Job Location: Mumbai
Qualifications: Any Graduation
Years of Experience: 3-5 years
About Accenture


Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions underpinned by the worlds largest delivery network Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com



Job Summary


You will be aligned with our Insights & Intelligence vertical and help us generate insights by leveraging different analytics tools and techniques to deliver value to our clients. You will also help us apply your expertise in building world class solutions, conquering the business problems, addressing technical challenges using AI Platforms and technologies. You will be required to utilize the existing frameworks, standards, patterns to create architectural foundation and services necessary for AI applications that scale from multi-user to enterprise class and demonstrate self as an expert by actively blogging, publishing research papers and creating awareness in this emerging area.

In the Data Science team, you will manage and analyze data in order to build data driven business insights and high impact data models to generate significant business value. This will involve creating models and processes to collect, distill and interpret data with a view to aid more informed decision making, examine and explore data from multiple sources with the goal of discovering insights which in turn can provide competitive advantage for our client.

You will be primarily using Python Programming Language to help build multiple programming paradigms including procedural, object-oriented and functional programming. You will have to write logical code for different projects and take a constructive and object orientated approach.

Roles and Responsibilities


In this role you are required to do analysis and solving of lower-complexity problems. Interaction is with peers within Accenture before updating supervisors. Likely has limited exposure with clients and/or Accenture management. Moderate level instruction on daily work tasks and detailed instructions on new assignments would be provided. Decisions impact own work and may impact the work of others . Individual contributor as a part of a team, with a focused scope of work. Please note that this role may require you to work in rotational shifts.",3.9,"Accenture
3.9",Mumbai,"Dublin, Ireland",10000+ employees,1989,Company - Public,Consulting,Business Services,₹500+ billion (INR),"Cognizant Technology Solutions, EY, McKinsey & Company"
"Consultant, Data Science and Analytics",-1,"What We'll Bring:

TransUnion, a global information and insights company, is seeking a highly-skilled Consultant for its Data Science & Analytics team.

You will apply your analytical skills to work on all aspects of the account lifecycle in the consumer credit domain on behalf of a diverse set of clients, ranging from marketing and propensity models for customer acquisition and retention, fraud detection solutions, credit risk models for acquisition and account management, cross-sell applications, portfolio models for regulatory applications, event-based trigger solutions, and strategy analyses of various kinds. You will also develop complex analytic solutions to help streamline Transunion’s IT operations, improve data quality and customer experience partnering with other departments.

Advancement opportunities exist in both a technical and managerial track depending on the candidate’s desires and aptitudes.

What You'll Bring:

Protecting the health and wellness of our associates and candidates considering a career at TransUnion is our highest priority. In supporting this vision, our recruitment and new hire experience for this role is fully virtual for the time being. Candidates interviewing will get to know our team over the phone and video, and this role will operate virtually upon hire until we return to the office. Even though we’re not physically together right now, our goal is to provide you a supportive candidate and new hire experience that will immerse you in our culture and set you up for success at TransUnion.

Dynamics of the Role

TransUnion, a global information and insights company, is seeking a highly-skilled Consultant for its Data Science & Analytics team.

You will apply your analytical skills to work on all aspects of the account lifecycle in the consumer credit domain on behalf of a diverse set of clients, ranging from marketing and propensity models for customer acquisition and retention, fraud detection solutions, credit risk models for acquisition and account management, cross-sell applications, portfolio models for regulatory applications, event-based trigger solutions, and strategy analyses of various kinds. You will also develop complex analytic solutions to help streamline Transunion’s IT operations, improve data quality and customer experience partnering with other departments.

Advancement opportunities exist in both a technical and managerial track depending on the candidate’s desires and aptitudes.

The Team’s Focus

The Data Science & Analytics team is an industry-recognized, client-facing department that rewards an entrepreneurial spirit. We have deep technical expertise and an established reputation as an analytic solutions provider in the consumer identity and credit information space. We have a wealth of data and industry experience within our large group of highly-trained analysts, Data Scientists, engineers, and economists. We also have a modern computing environment based on best-in-class “big data” technologies and the freedom to explore new data sources and statistical and machine learning methodologies. All of these resources will enable you to help us deliver next-generation analytic solutions for our customers.

How You’ll Contribute

This position is responsible for developing data-driven solutions to challenging and complex problems related to IT infrastructure/ operations, data ingestion and quality control, and enhancing customer experience. You will also be responsible for consumer credit models, strategies, and business intelligence solutions through consulting engagements and research serving TransUnion and its clients. This position requires an understanding of consumer lending, credit risk management practices, IT operations and process engineering.

You will partner with internal and external cross-functional teams to drive new business initiatives and deliver long term value-added product propositions for B2B customers in the US financial services segment at TransUnion. This includes but is not limited to the development of predictive risk management and business intelligence solutions for credit card issuers, auto & mortgage lenders, collections agencies and retail banks.
You will lead analytic client engagements involving descriptive, predictive, and prescriptive leveraging a variety of techniques (e.g., segmentation, logistic regression, survival analysis, principal component analysis, Monte Carlo simulation, scenario and sensitivity analysis).
You will design and write programs for data extraction, segmentation and statistical analysis on large population datasets using languages such as R, SAS, Python, SQL, Hive, and Pig on Linux, PC, and mainframe computing platforms.
You will deliver analytic insights and recommendations in succinct and compelling presentations for internal and external customers and an executive audience.
You will develop project proposals, sales presentations, and promotional collateral to enable the adoption of integrated customer solutions supported by TransUnion.
You will identify strategies and opportunities for customers to test and adopt TransUnion’s analytic products and services.
You will provide mentorship and training to junior colleagues and maintain progress on all initiatives under limited direct supervision.
You will foster a high-performance culture and cultivate an environment that promotes excellence and reflects the TransUnion brand.

What You’ll Bring

Master’s or PhD degree in statistics, applied mathematics, financial mathematics, engineering, operations research, or another highly quantitative field. A track record of academic excellence
At least two (2) years of professional experience performing analytic work in Financial Services, Technology, or related industries. Experience applying advanced analytics to planning and infrastructure problems is preferred.
Multiple examples of demonstrated success in client-facing roles over a period of at least two (2) years
Ability to travel 10-20%
Strong analytical, critical thinking, and creative problem-solving skills
Advanced programming skills; mastery of a statistical language such as R or SAS; experience using other programming and data manipulation languages (SQL, Hive, Pig, Python, C/C++, Java); proficiency with Microsoft Office tools
Versatile interpersonal and communication style with the ability to effectively communicate at multiple levels within and outside the organization; ability to work in a collaborative, fast-paced environment
Strong project management skills with the ability to manage multiple assignments effectively
An understanding of current industry challenges and trends at the level needed to proactively identify customers’ analytical needs and related business opportunities

Impact You'll Make:

What We Offer

We aim high — and are reaching for new heights every day. This is a terrific time to join our team as we build on our commitment to integrity, service, reliability, and innovation. These values stand behind the decisions we make every day, as well as our relationships at work and with the customers we serve. We believe in the power to achieve and are taking it in bold new directions.

Who We Are

A global leader in credit information and information management services, TransUnion gives businesses, consumers and the global community the power to achieve their goals. Businesses count on us to better manage risk and customer relationships. Consumers are able to better manage credit to achieve their financial goals. And in communities around the world, we help build strong economies and give people the power to achieve their dreams.

Exceptional opportunities are coming as we build on this strong foundation. Our ambitious growth strategy includes substantial new investment worldwide, a wide range of new solutions to help our customers succeed like never before, and new ideas for expanding our reach in every part of our dynamic and fast-moving industry. We’re on an exciting journey and you can be a part of it.

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.

TransUnion Job Title

Consultant, Data Science and Analytics",4.0,"TransUnion
4.0",Chennai,"Chicago, IL",5001 to 10000 employees,1968,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),-1
Data Scientist,-1,"What it’s like to work with the world’s fastest-growing Healthcare Technology Company


At Innovaccer, we go beyond the normal. We believe in doing things differently. So don’t expect - old-school cubicles, slow pace, and anything remotely dull.

What you can expect is plenty of support and guidance from your colleagues, freedom to take risks, and opportunities to learn from each other.

The healthcare industry is witnessing a transformational shift and we are committed to helping healthcare work as one. Taking on new challenges head-on and building something that can create a huge impact is a part of our culture.

We love organized chaos. So, if you are looking for a typical 9 to 5 job where you are told what to do, this may not be for you. When you work with Innovaccer, you are your own boss.

Your Role


Marketing Operations is a critically important department, enabling the leadership to grow and run the business more effectively. A Marketing Operations associate would be an individual with a strong interest in learning how a business is run, how the growth is tracked. Therefore, has the required technical know-how to build intelligent processes, create a live dashboard, and develop algorithms to assist decision making. You will be working closely with the Director Marketing and Operations Team. This role requires a highly resourceful individual with emotional intelligence, analytical skills, strong ML Knowledge, and expertise in coding.

A Day in the Life
Working closely with the leadership to devise data-driven strategies and improve process efficiency.
Leading an analytic solution module, or working as part of a larger team in data science projects.
Driving data-derived insights across a wide range of divisions by developing advanced statistical models, machine learning algorithms, and computational algorithms based on business initiatives.
Creating and Integrating Databases and from multiple sources and helping Analytics and Operation vertical with decision making and predictive abilities.
Directing the gathering of data, assessing data validity, and synthesizing data into large analytics datasets to support project goals.
Liaise with department heads and their reportees to discuss the progress on their goals, highlight the deviations, prepare solutions, and monitor progress on next steps
Understanding business objectives and developing models that help to achieve them, along with metrics to track their progress. Automation Engineering
Integrate multiple data sources and databases into one system using Python
Develop live dashboards using SQL and NoSQL databases like MySQL, MongoDB, Elastic search
Develop algorithms to boost Marketing and Sales Activities
Help in general automation and integration of different tools.
Skills Required
Self-starter, curious, accountable, enjoys a healthy level of autonomy, strong work ethic, able
to succeed in a fast-paced, high-intensity startup environment
Highly-developed communication skills (written/verbal) and interpersonal savvy
Strong knowledge of Data Structures and Algorithms.
Proven experience of writing modular and reusable code using JavaScript/Python frameworks
Proven experience with Git
Proficiency with Python and basic libraries for machine learning such as scikit-learn and
pandas
Experience with BI Tools is a plus
What You Need
B.Tech in quantitative discipline
0-12 months of experience in a software engineering/Data Science profile
What We Offer
Industry-focused Certifications: We want you to be a subject matter expert in what you do. So, whether it’s our product or our domain, you will dive straight in and be certified by the best in the world.
Quarterly Rewards and Recognition Programs: We foster learning and encourage people to take moonshots. When you achieve your goals, we recognize and reward your hard work.
Health Benefits: We cover health insurance for you and your loved ones.
Sabbatical Policy: We encourage people to take time off and rejuvenate, upskill and pursue their interests so that they can generate new ideas for innovating at Innovaccer.
Pet-friendly office and open floor plan. No mundane cubicles.


Apply Here


Job Title

Data Scientist


Department

Marketing & Partnerships


Employment Type

Full-Time


Location

Noida",3.6,"InnovAccer
3.6",Noida,"San Francisco, CA",501 to 1000 employees,2014,Company - Private,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),Health Catalyst
Data Scientist,-1,"JOB DESCRIPTION – Data Scientist
LTI (NSE: LTI) is a global technology consulting and digital solutions company helping more than 300 clients succeed in a converging world. With operations in 30 countries, we go the extra mile for our clients and accelerate their digital transformation with LTI’s Mosaic platform enabling their mobile, social, analytics, IoT and cloud journeys

Social Report:

LTI Wins the 2018 Stevie® Awards for Great Employers in Two Categories

LTI Recognized as the Winner of 2018 Microsoft App Innovation Award

TM 2019"">LTI Tops ITS Challengers List for the second consecutive year in Everest Group’s PEAK Matrix IT Service Provider of the Year 2019
Your Role

Data Scientist
Your Team
Your day at work will be like (Roles & Responsibilities)
Analyze raw data: assessing quality, cleansing, structuring for downstream processing
Applies intellectual curiosity and deep analytical thinking to mine large data sets for hidden gems of insight and correlation.
Design and implement high performance, accurate, scalable and robust analytical models in support of product and project objectives
Evolve the approach for the application of machine learning/deep learning to existing program and project disciplines
Collaborate with engineering team to bring analytical prototypes to production
Work experience in TAX domain is plus
Generate actionable insights for business improvements
Lead development and implementation of scalable algorithmic solutions for real-time operations and information flow systems
Ensure advanced agile standards are maintained in research, development, QA, and implementation phases
Ensure excellence in delivery to internal and external customers
Help establish standards in machine learning and statistical analysis to ensure consistency in quality across projects and teams and identify relevant process efficiencies

This job might be for you if you have the following skills (Skills, Experience)

Required Skills & Competencies
Advanced level proficiency with statistical, machine learning modelling techniques such as regression, decision trees, neural networks, support vector machines, supervised/unsupervised clustering techniques, experimental test design, etc.
Expert theoretical knowledge of machine learning modelling techniques and advanced applied skills in developing predictive targeting models within distributed computing platforms such as Hadoop, AWS, Azure, GCP using one or more tools like Spark, Scala, SAS, R, Python, Bayesian, H2O, Storm, Yarn, Kafka
Must have experience in statistical programming in R, Python, TensorFlow. SAS/SPSS/MATLAB are plus
Experience in Text Analytics
Experience working in a Unix/Linux environment for automating processes with shell scripting
Superior analytical skill combined with business discipline. Ability to perform insightful and actionable quantitative and qualitative analysis of the business.
Strong verbal and written communication skills coupled with demonstrated prior leadership within large teams
SQL: Data Warehouse, Teradata SQL
Big Data: Azure Storage, experience in any one flavor – Cloudera/Hortonwork/MapR
Reporting: Power BI, Excel
Additional Qualifications
5 to 10 years of experience
Full Time Bachelor's / Master's degree in Statistics, Applied Mathematics or Computer Science
Extensive experience applying machine learning algorithms, predictive modeling, data mining, and statistical analysis to solve business problems..

You will stand out if you have the following

(Good to have)
Your Place of work

Shivajinagar, Pune

Job Segment:
Database, Scientific, Engineer, Warehouse, Developer, Engineering, Technology, Manufacturing",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
Data Scientist,-1,"Data Scientist-832760

At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.

What is the Data Scientist – Client Analytics group responsible for?

Works with their team in support of a single business unit, providing support for solving more complex problems for their domain by developing a variety of models and statistical techniques. They also perform ad hoc statistical and data mining analysis as required
What are the ongoing responsibilities of a Data Scientist?

Data Preparation, Gathering and Analysis Collects data from disparate systems, analyzes it, and delivers the data as intelligence that is actionable Analyzes and interprets the results of research experiments through statistical models Solves analytical problems utilizing large structured, semi-structured and un-structured data in a distributed processing environment (Required)
Statistical Analysis - Data Mining and Advanced Analytic Techniques Develops predictive, statistical, behavioral, or other models using supervised and un-supervised machine learning / statistical modeling techniques Performs ad hoc statistical and data mining analyses (Required)
Training, Research and Development Conducts research on various advanced statistical techniques to apply to appropriate analytical problems (Required)

Skills:
Ability to translate business challenges into analytical problems
Ability to articulate and explain statistical / machine learning techniques to business partners
Proven experience in telling stories using data
Ability to handle large datasets for building Statistical/Machine learning models which includes hands on experience working on data cleansing, manipulation and data mining
Proven ability to work with ambiguous (not well defined) challenges
Displays curiosity to learn and learns independently
Excellent written and verbal communication skills
Excellent organizational and planning skills
Proven ability to take initiative and work under pressure in a changing/growing environment
Ability to work individually or as a team as task requires
Able to cultivate interpersonal customer and co-worker relationships

What ideal qualifications, skills & experience would help someone to be Successful?

Master’s / Bachelor’s degree in Statistics, Mathematics, Econometrics, Computer Science, Engineering or related disciplines, preferably from premier Institutes
3-5 years of experience in advanced analytics
Proven Experience in Statistical and Machine learning techniques
Desirable to have experience in Time Series modelling as well
Experience in SAS or R or Python
Experience in SQL
What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:
Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.

JOB FUNCTION: Data Science and Analytics

PRIMARY LOCATION: India-Andhra Pradesh-Hyderabad

SCHEDULE: Full-time

JOB POSTING DATE: Jul 21, 2020, 9:52:30 AM",3.8,"Franklin Templeton Investments
3.8",Andhra Pradesh,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
Data Scientist,-1,"Experience working on Advanced Analytics and Machine Learning (ML) as well as on Business Analytics More than two years of industry experience, of which least one year of strong experience working on predictive analytics, machine learning and other domains in advanced data analytics.

Responsibilities:
Leverage process/enterprise data to build statistical/mathematical models
Produce business-relevant insights from all available data sets
Implement scalable Data Science solutions on a suitable technology stack for enterprise deployment
Integrate new ML modules to existing data collection
Create insightful and actionable reports and visualizations with conclusions derived from data
Technical skills:
Exploratory data analysis skills
Knowledge and experience with machine learning algorithms (supervised and unsupervised).
Knowledge of statistical techniques to support exploratory findings and conclusions
Strong experience in one of the programming languages used in data science (Python, R, MATLAB or similar)
Good to have experience with some of the related packages Numpy, Pandas, Matplotlib, sci-kit-learn, etc.
Experience working on Cloud technologies preferably on Azure.
Experience in deploying machine solutions at a proof of concept and industry scale
Job Type: Full-time

Salary: ₹450,000.00 - ₹850,000.00 per year

Experience:
total work: 2 years (Required)
Python: 1 year (Required)
Education:
Bachelor's (Required)
Location:
Kochi, Kerala (Required)
Work Remotely:
Temporarily due to COVID-19",4.3,"MariApps Marine Solutions
4.3",Kochi,"Singapore, Singapore",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Title
Data Scientist

20-Jul-2020

No. of Positions
2

Job Description
General Position Definition
Incumbent is responsible for developing analytical models for projects collaborating with different business stakeholders & other partners and working across a range of technologies and tools.
The ideal candidate has strong background in quantitative skills (like statistics, mathematics, advanced computing, machine learning) and has applied those skills in solving real world problems across different businesses / functions.
Purpose
Develops analytics models using specialized tools based on the business problem and data available
Identifies the right set of models and develops the right code / package to execute them
Evaluates the validity of the model (both scientifically as well as from a business perspective)
Support the Data Science Team Lead in design and execution of analytics projects
Work with Shell stakeholders and subject matter experts to complete tasks and deliverables on projects
Skills
Stakeholder Engagement Skills
Working collaboratively across multiple sets of stakeholders – business SMEs, IT, Data teams, Analytics resources, etc. to deliver on project deliverables and tasks
Identify actionable insights that directly address challenges / opportunities
Articulate business insights and recommendations (based on model output) to respective stakeholders
Understanding business KPI's, frameworks and drivers for performance
Proficiency Level: Skill
Auto req ID
141665BR

Country of Work Location
India

Employment Type
Full Time

Company Description
The aim of the Shell Business Operations, Chennai is to provide the Group with operational excellence through highlighting and utilizing process improvements and functional efficiencies as well as by leveraging economies of scale. Currently, the Chennai centre provides a wide range of finance, accounting and business services to Shell operating companies across several business sectors globally.

Set up in September 2007, the Chennai centre has grown rapidly and now , in its fourth year of operations , it has crossed the 1600 staff mark. The centre is located in the RMZ Millennia Business Park, where the Shell campus is a LEED Platinum building with world class infrastructure. The business is expected to grow further over the next two years and infrastructural additions to support this have been planned.

The main focus in Chennai is on Finance Operations which supports delivery of the global Finance functional plan. There is also a ‘Downstream India’ - Customer Services Team that handles lubricant depot ordering within the country. The Shell Business Operations (SBO Team) manages the centre facilities and supports business partners’ operations on site. There is a strong focus at SBO on safety & well being of staff and on its three core values: Compliance, Intervention & Respect.

Disclaimer
Please note: We occasionally amend or withdraw Shell jobs and reserve the right to do so at any time, including prior to the advertised closing date.

Before applying, you are advised to read our data protection policy. This policy describes the processing that may be associated with your personal data and informs you that your personal data may be transferred to Royal Dutch/Shell Group companies around the world.

The Shell Group and its approved recruitment consultants will never ask you for a fee to process or consider your application for a career with Shell. Anyone who demands such a fee is not an authorised Shell representative and you are strongly advised to refuse any such demand.

Shell is an Equal Opportunity Employer.

Work Location
Chennai - RMZ Millenia

Requirements
Industry / Functional Expertise
Provide deep business expertise preferably Oil & Gas - Upstream or Downstream businesses. (If these are not available, willing to consider other industries that are similar or related - manufacturing, mining, power generation, etc.)
functional expertise in any one or more of the following industry / functional areas
Customer / Marketing – pricing analytics, churn prediction, cross-sell / up-sell, Market Basket Analysis, Product Recommendation, Marketing Mix Modeling, Campaign design and effectiveness testing, Network Modeling, Customer segmentation, propensity analysis, customer lifetime value, profitability analysis, Customer experience (incl. voice of customer), CRM, Loyalty program management,
Online & Offline –Strong Campaign Analyses experience in both online & offline. Should have worked with multiple social media data, understands campaign effectiveness study and experienced in planning/targeting for CRM activities based on learning from previous activities, strong knowledge of all kinds of marketing data
Proficiency Level: Mastery
Modeling and Technology Skills
Deep expertise in machine learning techniques (supervised and unsupervised) statistics / mathematics / operations research including (but not limited to):
Advanced Machine learning techniques: Decision Trees, Neural Networks, Deep Learning, Support Vector Machines, Clustering, Bayesian Networks, Reinforcement Learning, Feature Reduction / engineering, Anomaly deduction, Natural Language Processing (incl. Theme deduction, sentiment analysis, Topic Modeling), Natural Language Generation
Statistics / Mathematics: Data Quality Analysis, Data identification, Hypothesis testing, Univariate / Multivariate Analysis, Cluster Analysis, Classification/PCA, Factor Analysis, Linear Modeling, Logit/Probit Model, Affinity & Association, Time Series, DoE, distribution / probability theory
Strong experience in specialized analytics tools and technologies (including, but not limited to)
Python, Azure Analysis Services
Spotfire, PowerBI
Awareness of Data Bricks, Apache Spark, Hadoop
Awareness of Agile / Scrum ways of working
Identify the right modeling approach(es) for given scenario and articulate why the approach fits
Assess data availability and modeling feasibility
Review interpretation of models results
Evaluate model fit and based on business / function scenario
Proficiency Level: Skill-to-Mastery
Special Challenges
Rapid onboarding on projects, understanding analytics goal and working with ill-defined datasets
Communicating technical jargon in plain English to colleagues within Data Science team and outside
Virtual working with network of colleagues located throughout the globe
Dimensions
Support design and delivery of analytics projects, within or cutting across upstream and downstream business units in Shell
Experience
5+ years of relevant experience in Retail domain
Advanced university degree in Mathematics, Statistics, Engineering, Economics, Quantitative Finance, OR, etc.
Good interpersonal communication skills and influencing skills
Eagerness to learn and ability to work with limited supervision
SBO Location
Chennai

City, State (if applicable)
Chennai",4.0,"Shell
4.0",Chennai,"Houston, TX",10000+ employees,1907,Company - Public,Oil & Gas Exploration & Production,"Oil, Gas, Energy & Utilities",₹500+ billion (INR),"ExxonMobil, BP, Chevron"
Data Scientist,-1,"Positions in Pune, India.

PharmaACE is a growing Global Healthcare Consulting Firm, headquartered in Princeton, New Jersey. Our expert teams of Business Analysts, based across the US, Canada, Europe, and India, provide Analytics and Business Solutions using our worldwide delivery models for a wide range of clients. Our clients include established, multinational BioPharma leaders and innovators, as well as entrepreneurial firms on the cutting edge of science. We have deep expertise in Forecasting, Business Analytics, Competitive Intelligence, Sales Analytics, and the Analytics Center of Excellence Model. Our wealth of therapeutic area experience cuts across Oncology, Immuno-science, CNS, CV-Met, and Rare Diseases. We support our clients’ needs in Primary Care, Specialty Care, and Hospital business units, and we have managed portfolios in the Biologics space, Branded Pharmaceuticals, Generics, APIs, Diagnostics, and Packaging & Delivery Systems.

Brief introduction :
If you are keen to work on analytical database problem solving, then work in the area of advance data analytics to provide consulting to pharmaceutical clients

Designation name & Description :
As a Data Scientist, you are expected to develop and implement AI/ML techniques to help client business needs.

Advance data analytics team designs and implements analyses in SQL or Redshift or Python or excel based on patient level data or similar datasets to address business problems for our clients and engage with onshore team / client to help them understand the analysis and lead to data driven decision making.

Job Responsibilities:
Understanding business objectives and developing models that help to achieve them, along with metrics to track their progress
Managing available resources such as hardware, data, and personnel so that deadlines are met
Analyzing the AI/ML algorithms that could be used to solve a given problem and ranking them by their success probability
Exploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world
Verifying data quality, and/or ensuring it via data cleaning
Supervising the data acquisition process if more data is needed
Finding available datasets online that could be used for training
Defining validation strategies
Defining the preprocessing or feature engineering to be done on a given dataset
Defining data augmentation pipelines
Training models and tuning their hyperparameters
Analyzing the errors of the model and designing strategies to overcome them
Knowledge on Deep learning techniques is added advantage
Deploying models to production

Qualifications :
Bachelor’s/Masters Degree
1-2 years of functionally related professional experience in software development is required
Having work experience in Pharma/Life sciences background is advantage
Experience of Data Science, Business Analytics, Predictive Analytics, NLP, Machine Learning and Cognitive Computing is required
Proficiency with Python and basic libraries for AI/ML
Expertise in visualizing and manipulating big datasets
Experience of programming languages Like R, Python, MySQL, NodeJS is required
Experience developing new applications within an agile environment preferred

Connect with PharmaACE in India on social media:
Follow PharmaACE on LinkedIn and Twitter for more job opportunities
Read our blogs for latest news and information from the Pharma world
To know more about us visit our website
Advanced Analytics Statistician – Consultant / Sr. Consultant
Data Scientist
Consultant / Senior Consultant
Consultant - Business Intelligence
Associate Consultant/ Consultant - Forecasting
Associate Consultant - Consultant Commercial Analytics
Analyst - Chart Audit
Associate Consultant /Consultant – Chart Audit
Associate Consultant(Epidemiologist)
Consultant/Senior Consultant- Forecasting
Consultant Forecasting (WFH)",3.8,"Shell
4.0",Pune,"Princeton, NJ",51 to 200 employees,2013,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹100 to ₹500 million (INR),-1
Data Scientist,-1,"Eyeota is looking for an exceptional Data Scientist who is passionate about data and motivated to build large scale machine learning solutions to shine our data products. This person will be contributing to the analytics of data for insight discovery and development of machine learning pipeline to support modeling of terabytes of daily data for various use cases.

Qualifications:
2+ years relevant working experience
Master/Bachelors in computer science or engineering
Working knowledge of Python and SQL
Experience in time series data, data manipulation, analytics and visualization
Experience working with large-scale data
Proficiency of various ML algorithms for supervised and unsupervised learning
Experience working in Agile/Lean model
Experience with Java and Golang is a plus
Experience with BI toolkit such as Tableau, Superset, Quicksight, etc is a plus
Exposure to building large-scale ML models using one or more of modern tools and libraries such as AWS Sagemaker, Spark ML-Lib, Dask, Tensorflow, PyTorch, Keras, GCP ML Stack
Exposure to modern Big Data tech such as Cassandra/Scylla, Kafka, Ceph, Hadoop, Spark
Exposure to IAAS platforms such as AWS, GCP, Azure

About Eyeota

Eyeota provides a dynamic, fun workplace filled with passionate individuals. We are at the cutting edge of advertising technology and there is never a dull moment at work.

We have a truly global footprint, with our headquarters in Singapore and offices in Australia, United States, United Kingdom and India

At Eyeota you will gain work experience in a global startup. We speak over 20 different languages, from more than 16 different nationalities and over 42% of our staff are multilingual.

Eyeota is an Equal Opportunity Employer.

Powered by JazzHR

S6QaWf82ez",3.2,"Eyeota
3.2",Pune,"Singapore, Singapore",51 to 200 employees,2010,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,"Lotame, Krux"
"Research Scientist, Google Research",-1,"Due to the current health crisis related to COVID-19 and the escalating visa/travel restrictions in place, we're currently unable to extend offers to anyone who cannot work from India due to lockdown visa/travel restrictions, or other restrictive measures until further notice. Consequently, we will be prioritizing candidates who can start in this location by set date as expected. We're keeping the situation under review and would adjust our position should the restrictive measures be removed later on.

Minimum qualifications:
PhD in Computer Science, related technical field, or equivalent practical experience
Experience in Machine Learning, NLP/NLU, Computer Vision, Optimization,
Game Theory, Computer Systems, Market Algorithms
Experience with general purpose programming languages e.g., C/C++ or Python
Contributions to research communities including publishing in top forums (e.g: NeurIPS, ICML, ACL, CVPR, KDD, AAMAS)
Preferred qualifications:
Strong publication record
About the job


As an organization, Google maintains a portfolio of research projects driven by fundamental research, new product innovation, product contribution and infrastructure goals, while providing individuals and teams the freedom to emphasize specific types of work.

As a Research Scientist, you'll setup large-scale tests and deploy promising ideas quickly and broadly, managing deadlines and deliverables while applying the latest theories to develop new and improved products, processes, or technologies. From creating experiments and prototyping implementations to designing new architectures, our research scientists work on real-world problems that span the breadth of computer science, such as machine (and deep) learning, data mining, natural language processing, hardware and software performance analysis, improving compilers for mobile platforms, as well as core search and much more.

You'll also actively contribute to the wider research community by sharing and publishing your findings, with ideas inspired by internal projects as well as from collaborations with research programs at partner universities and technical institutes all over the world.

Research in machine intelligence has already impacted Google services including Search, Maps, Android, YouTube, and Photos. Our researchers have a never-ending quest to find more information and make it accessible.

Google Research India is the latest addition to Google’s global research labs with the mission to advance fundamental Computer Science Research by building strong teams, and by partnering with the academic research community.

Applying research to solve big problems in fields like healthcare, agriculture, or education while also using it to make Google’s products more helpful for billions of users.

Google Research is building the next generation of intelligent systems for all Google products. To achieve this, we’re working on projects that utilize the latest computer science techniques developed by the best and brightest software engineers and research scientists in the world. Google Research teams collaborate closely with other teams across Google, maintaining the flexibility and versatility required to adapt new projects and foci that meet the demands of the world's fast-paced business needs.
Responsibilities
Undertake cutting edge research in the above mentioned areas.
Develop solutions for real-world, large-scale problems.

Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form.",4.4,"Google
4.4",Bengaluru,"Mountain View, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Microsoft, Apple, Facebook"
Data Scientist,-1,"Bottomline is at the forefront of digital transformation. We are a growing global market leader uniquely equipped to address the changing needs of how businesses pay and get paid. Our culture of Working with and for each other enables us to delight our customers. We empower our teams to think like owners driving customer delight, helping them grow their business and win in their markets.

We are looking for Data Scientist to innovate, win, and grow with us in Bangalore, India.

As a member of Central Data & Analytics Team, you will be developing software to be used for a range of machine learning and data mining techniques, including predictive modeling, anomaly detection, customer profiling and segmentation, recommendations, text analytics, and big data analytics in solving our business problems. You will take an idea from conception and experimentation to design and implementation to deployment and production. In this role, you will interact with a team of experts in Machine Learning and Data Mining.

How you'll contribute:
Exposure to the sate-of-the-art of data analytics products and solutions.
Ability to prototype statistical analysis algorithms
Experience in coding structures for storing and processing complex, high volume, and multi-dimensional data
Experience in optimizing space/time tradeoffs for computationally expensive processes
Exposure to different Machine Learning techniques
Familiar with Agile software development process.
What will make you successful:
At least 2 years' professional experience in with major programming languages such as Java, Python, Scala
A completed graduate degree in Computer Science, Engineering or any other heavily numerate subject
Understanding of the full software development lifecycle (conduct data analysis and build large-scale machine-learning models/pipelines)
Experience in Big Data technologies (Hadoop, Spark), large relational and NoSQL databases
Experience in data pre-processing, Machine Learning, and data visualization
Experience in quantitative analysis and translation of findings into actionable insights
Outstanding communication and presentational skills
You'll love Botttomline because in everything we do we seek to delight our customers and we are passionate about building a company of which we can all be proud, and this starts with building amazing teams filled with team members that challenge you every day.

Start your #LifeAtBT

Public cloud AWS, ML, DL, NPL, Python, Java, Scala, Hadoop, Spark, Docker, Kubernetes, Agile, Scrum",3.7,"Bottomline Technologies
3.7",Bengaluru,"Portsmouth, NH",1001 to 5000 employees,1989,Company - Public,Computer Hardware & Software,Information Technology,₹10 to ₹50 billion (INR),-1
Machine Learning Engineer,-1,"JOB DESCRIPTION

Job Requirements
Design and implement machine learning, information extraction, probabilistic matching algorithms and models
Research and develop innovative, scalable and dynamic solutions to hard problems
Work closely with Machine Learning Scientists (PhDs), ML engineers, data scientists and data engineers to address challenges head on
Use the latest advances in NLP, data science and machine leaning to enhance our products and create new experiences
Scale machine learning algorithm that powers our platform to support our growing customer base and increasing data volume
Be a valued contributor in shaping the future of our products and services
You will be part of our Data Science & Algorithms team and collaborate product management and other team members
Be part of a fast pace, fun focused, agile team
Work Experience
3+ years of industry experience
PhD/MS/BTech in computer science, information systems, or similar technical field
Strong mathematics, statistics, and data analytics
Solid coding and engineering skills preferably in Machine Learning (not mandatory)
Proficient in Java, Python, and Scala
Industry experience building and productionizing end-to-end systems
Knowledge of Information Extraction, NLP algorithms coupled with Deep Learning
Experience with data processing and storage frameworks like Hadoop, Spark, Kafka etc.",4.3,"Phenom People
4.3",Hyderabad,"Ambler, PA",501 to 1000 employees,2011,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Location:
Defence Colony, New Delhi

Job Purpose Summary:
Responsible for driving Mahajan Imaging's new focus on medical informatics and data analytics:
Preferably well aquainted with SQL based PACS and Hospital Information Systems.
Putting medical reports and images into an easily searchable structured format for clinical research and scientific purposes.
Responsible for pulling relevant information from company databases.
Would have access to high-end servers and other equipment.
Would have opportunity to work with leading medical imaging companies and universities.",4.0,"Mahajan Imaging
4.0",New Delhi,"New Delhi , India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"COMPANY OVERVIEW
Tata Group is an Indian multinational conglomerate company headquartered in Mumbai, India. It encompasses seven business sectors: communications and information technology, engineering, materials, services, energy, consumer products and chemicals. Tata Group was founded in 1868 by Jamsetji Tata as a trading company. It has operations in more than 80 countries across six continents. Tata Group has over 100 operating companies with each of them operating independently.
Tata Sons is the promoter of all key Tata companies and holds the bulk of shareholding in these companies.

BACKGROUND The Tata companies together serve over million consumer and commercial customers today across several products and services. In order for the Tata companies to better understand customer and client needs and preferences, action life stages, needs, value, and potential, and enhance value and experience; the Tata companies need to develop robust data and information management capability and customer analytics. The vision is to eventually create the best in-house capability for data analytics amongst any large corporate. To achieve the above aims, it has been decided to establish an independent Tata company focused on building a common data analytics platform and help Tata Group companies. This company is being incubated in the initial phase as a division of Tata Industries and will subsequently be structured as a separate company to build Big Data Analytics and Data Science capabilities catering to but not limited to the ‘Consumer’ brands of the group.

Tata Insights and Quants – Journey to Date
Company: Tata - Insights and Quants – A Newly started division by Tata Industries.
http://www.livemint.com/Companies/PCgvCZILuJKV68UKVHZRJO/With-new-analytics-arm-Tata-aims-to-make-better-sense-of-da.html
Employer Brand: Tata iQ in 18 months of its inception was recognized in the list of Analytics India Magazine’s (AIM)
Top 10 most desirable Analytics Indian Firms to work for in 2016:
http://analyticsindiamag.com/top-10-analytics-firm-wish-worked-2016/
Generating Value for Customer: Fourteen Tata companies are partnering Tata Insights and Quants (Tata iQ), a Big Data firm, to analyse data collected from users, consumers and make sense of it to put changes in place http://www.livemint.com/Companies/5om8ebrv6p02jGCcRB3j3K/Tata-companies-use-Big-Data-to-craft-strategies.html https://cio.economictimes.indiatimes.com/news/strategy-and-management/how-ranjit-satyanath-plugs-into-it-to-power-up-croma-for-the-digital-era/65050926

Contributing to Community through big data:
In line with the Tata group’s philosophy of giving back more to the society than what it takes, Tata iQ, Tata group’s big data and decision Sciences Company.
Okhai partners with Tata iQ to deliver big impact through big data

Company : Tata Insights and Quants
Role : Data Scientist
Level : Analyst – Associate - Senior Associate
Role Type : Individual Contributor
Location : Mumbai | Bangalore | Jamshedpur | Kalinga Nagar – All Options open

Job Description The incumbent will be part of the Predictive Analytics, Digital Analytics, Data Sciences, Advanced Visualization, Insights & Experimentation team and will report to the Manager/Senior Manager. He/she will be an individual contributor working on multiple data sciences, advanced visualization and data management initiatives across multiple companies and industries leveraging traditional and big data. The incumbent will have the unique opportunity to witness the application of analytics across multiple industry verticals. Close partnership with business and the senior leadership of multiple Tata Companies will enable a clear understanding of the business perspectives and the application of analytics for solving real business problems.

Key Responsibilities:
Apply Data Mining/ Data Analysis methods using a variety of data tools, building and implementing models using algorithms and creating/ running simulations to drive optimisation and improvement across business functions
Assess accuracy of new data sources and data gathering techniques
Perform Exploratory Data Analysis, detailed analysis of business problems and technical environments in designing the solution
Apply Supervised, Unsupervised, Reinforcement Learning and Deep Learning algorithms
Apply advanced Machine Learning Algorithms and Statistics:
o Regression, Simulation, Scenario Analysis
o Time Series Modelling
o Classification - Logistic Regression, Decision Trees, SVM, KNN, Naive Bayes
o Clustering, K-Means
o Ensemble Models - Random Forest, Boosting, Bagging
o Neural Networks
Lead and manage Proof of Concepts and demonstrate the outcomes quickly
Document use cases, solutions and recommendations
Work analytically in a problem-solving environment
Work in a fast-paced agile development environment
Coordinate with different functional teams to implement models and monitor outcomes
Work with stakeholders throughout the organization to identify opportunities for leveraging organisation data and apply Predictive Modelling techniques to gain insights across business functions - Operations, Products, Sales, Marketing, HR and Finance teams
Help program and project managers in the design, planning and governance of implementing Data Science solutions
Experience and Skills:
2-7 years of professional working experience in Analytics
Experience in Retail, Financial Services and Manufacturing
Experience using statistical packages of R, Python and Spark ML to work with data and draw insights from large data sets
Experience with distributed data/ computing tools: Hadoop, Hive, Spark, Python
Experience with SQL
Experience visualizing/ presenting data for stakeholders using matplot, ggplot or Excel or Tableau
Excellent written and verbal communication skills for coordinating across teams
Education qualification:
Bachelors/ Masters in a quantitative discipline (Statistics, Econometrics, Mathematics, Engineering and Science)
Reach us on careers@tataiq.com",3.9,"Tata Insights and Quants
3.9",Mumbai,"Zug, Switzerland",10000+ employees,1980,Unknown,Architectural & Engineering Services,Business Services,Unknown / Non-Applicable,-1
Data Scientist,-1,"As a Data Science Associate Manager at PayPal, you will apply your leadership, strategic and analytical skills to major company challenges. You will act as a business consultant to drive recommendations and implement solutions that ultimately impact the bottom line. And you will do it all by collaborating with a global team of colleagues across sales, operations, product, data science, and finance in an environment that values your insight, encourages you to take on new responsibility, promotes continuous learning, and rewards innovation.",3.0,"Tata Insights and Quants
3.9",Mumbai,"Cambridge, MA",1001 to 5000 employees,1973,Non-profit Organisation,Aerospace & Defence,Aerospace & Defence,₹50 to ₹100 billion (INR),"BAE Systems USA, MITRE, Raytheon Technologies"
Senior Data Scientist,-1,"Location:
Chennai, Mumbai, New Delhi

Geography:
Asia Pacific

Capabilities:
Big data & advanced analytics

Industries:
Technology industries

About Us


Boston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.

To succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.

Practice Area Profile

BCG GAMMA combines innovative skills in computer science, artificial intelligence, statistics, and machine learning with deep industry expertise. The BCG GAMMA team is comprised of world-class data scientists and business consultants who specialize in the use of advanced analytics to get breakthrough business results. Our teams own the full analytics value-chain end to end: framing new business challenges, building fact-bases, designing innovative algorithms, creating scale through designing tools and apps, and training colleagues and clients in new solutions. Here at BCG GAMMA, you’ll have the chance to work with clients in every BCG region and every industry area. We are also a core member of a rapidly growing analytics enterprise at BCG - a constellation of teams focused on driving practical results for BCG clients by applying leading edge analytics approaches, data, and technology.

Role Profile

POSITION PROFILE:
We are seeking a strong candidate with advanced analytics experience to fill an exciting Senior Data
Scientist (SDS) position within BCG Gamma. The SDS is a valuable expert in Data Science and Analytics
and will design and build analytics methodologies, solutions, and products to deliver value to BCG's clients
in collaboration with case teams. Exceptional candidates will also show an analytical curiosity, going
beyond the immediate requirements of the project to find deep insights that others have missed. They will
ask questions about outliers, seek to understand the fundamental drivers of advantage and look for clues
that may change the basis of competition.

As a Senior Data Scientist you design and build analytics solutions for our clients where data and
analytics are at the heart of the question. The team interaction centers on use of statistical programs and
others tools to conduct intensive analysis of objective data and open discussion, complemented by
objective research into the competitive environment. Responsibilities / duties to include: understand
problems from the client’s point of view, build and execute solid analytics work plans, gather and organize
large and complex data assets, perform relevant analyses (data exploration and statistical modeling),
manage priorities and deadlines, foster teamwork in interactions, develop client relationships with client
counterparts, and communicate hypotheses and findings in a structured way.

As the field of advanced analytics is rapidly evolving, the SDS is responsible for staying current on
leading-edge business applications, tools and approaches, proactively working with the Analytics
Leadership to enhance offerings that deliver competitive advantage to BCG.

Your Qualifications

JOB REQUIREMENTS:
PhD and 1-2 years of relevant industry work experience or a Masters Degree with significant relevant experience providing advanced analytics solutions is required. The degree should be in computer science, applied mathematics, statistics, machine learning, or a related data centric field.
Looking for individuals with deep technical and data science expertise, acute strategic and analytical skills, ability to lead and persuade, drive and energy, and desire to work in a project based environment on strategic issues.
Strong record of professional accomplishment and leadership.

Date Posted:
13-Feb-2019

Boston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.
BCG is an E-Verify Employer. Click here for more information on E-Verify.",4.0,"Boston Consulting Group
4.0",Mumbai,"Boston, MA",10000+ employees,1963,Company - Private,Consulting,Business Services,₹500 million to ₹1 billion (INR),"McKinsey & Company, Bain & Company, Accenture"
Senior Data Scientist,-1,"About the Group:

The mission of the Juniper Digital Experience and Automation (DEA) team (part of the Juniper Global Services (GS) Organization) is to delight external and internal customers by delivering efficient, innovative solutions that are proactive, easy to use and self-service focused.

DEA is at the heart of the Global Services digital strategy. We buy, build and integrate innovative technologies that enables the Global Services business with a focus on business agility and efficiency. Through partnerships with business subject matter experts we identify need, ideate, determine idea value (ROI) and ultimately realize new capabilities. Automation, Data Science / Machine Learning and Advanced Analytics are critical components of that innovation work.

About the position:

We are seeking a talented Data Scientist with a passion to research and devise innovative statistical models for data analysis. In this role, you will coordinate with product design and engineering to develop an understanding of needs, enable smarter business processes, and implement analytics for meaningful insights and communicate your findings to stakeholders. Keep current with technical and industry developments.

Responsibilities:
Using machine learning techniques to select features, build, and optimize classifiers
Performing data mining by utilizing latest state-of-the-art processes
Proven experience as an NLP Engineer or similar role
Understanding of NLP techniques for text representation, semantic extraction techniques, data structures and modeling
Deep understanding of text representation techniques (such as n-grams, bag of words, sentiment analysis etc.), statistics and classification algorithms
Experience with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Strong communication skills
An analytical mind with problem-solving abilities
Required Qualifications:
7+ years related professional data science experience.
Bachelor’s degree in Statistics, Mathematics, Computer Science, Machine Learning, Economics, or any other related quantitative field
Superb understanding of machine learning tools and algorithms including k-NN, SVM, Decision Forests, Naive Bayes, etc.
Adequate work experience with common data science languages such as Python, R etc.
Strong familiarity and hands-on experience with statistical software packages (Python, R, SAS)
Experience using business intelligence tools (e.g. Tableau) or anything equivalent
Experience with distributed data/computing tools: Hive, Spark, MySQL, etc.
Good to have experience in solving customer support related use case
Comfort working in a dynamic, research-oriented group with several ongoing concurrent projects
Preferred Qualifications
Master’s degree in Mathematics, Statistics, Physics, Computer Science, or related fields
Familiarity with deep neural networks and frameworks (like Tensorflow or PyTorch)
Professional certifications
Juniper Networks is an Equal Opportunity/Affirmative Action Employer.

ABOUT JUNIPER NETWORKS

Juniper Networks is in the business of network innovation. From devices to data centers, from consumers to cloud providers, Juniper Networks delivers the software, silicon and systems that transform the experience and economics of networking. Our products and technology run the world’s largest and most demanding networks today, enabling service providers, enterprises, and governments to create value and accelerate business success. Everyday our 9,000+ colleagues come together across 46 countries to realize our company vision – Connect Everything, Empower Everyone. We are innovating in ways that empower our customers, our partners and ultimately, everyone, in a connected world. These customers include the top 130 global service providers, 96 of the Fortune 100 and hundreds of public sector organizations.

WHERE WILL YOU DO YOUR BEST WORK?

Wherever you are in the world, whether it’s downtown Sunnyvale or London, Westford or Bangalore, Juniper is a place that was founded on disruptive thinking – where colleague innovation is not only valued, but expected. We believe that the great task of delivering a new network for the next decade is delivered through the creativity and commitment of our people. The Juniper Way is the commitment to all our colleagues that the culture and company inspire their best work—their life’s work. At Juniper we believe this is more than a job - it is an opportunity to help change the world...",3.8,"Juniper Networks
3.8",Bengaluru,"Sunnyvale, CA",5001 to 10000 employees,1996,Company - Public,Telecommunications Services,Telecommunications,₹100 to ₹500 billion (INR),-1
Data Scientist,-1,"DMI (Digital Management, LLC.), the world’s first end-to-end mobility company, combines all the skills and services necessary to deliver mobile enterprise solutions. Built to reinvent business through mobility, DMI has expertise in mobile strategy, UX, web, and app development, omni-channel commerce, brand and marketing, IoT and big data analytics, and secure device and app management. The company’s unique, integrated approach to mobility has resulted in dramatic growth as well as an expanding client base, which includes hundreds of Fortune 1000 commercial clients and all fifteen U.S. Federal Departments. DMI is headquartered in Bethesda, MD, with satellite offices around the world. The company was named one of the 2018 Top Workplaces in the Washington, DC area by The Washington Post and received Inc. Magazine’s Hire Power Award as one of the top 100 Private Job Creators in the US. Additional information is available at www.dminc.com and on LinkedIn, Twitter, Facebook, and Instagram.

You have a strong academic background in statistics and machine learning. The typical candidate has a Bachelor’s or Master’s degree in Math, Statistics, Computer Science, Physics or such quantitative fields.
Overall 10+ years with atleast 5 years of your experience were related to data and data analysis. You have worked on a variety of complex data analysis and modeling problems, gathering a great deal of practical wisdom on how to apply these techniques to real world scenarios.
For atleast 2 years, you have been in a technical leadership position responsible for the output of a team. The team(s) you were leading successfully executed and delivered multiple data science projects end to end under your leadership.
You are competent enough to roll up your sleeves and get things done as a data scientist when the situation demands. You have a wide range of statistical and machine-learning tools under your belt. These include linear models for regression and classification, multi-level models, factor analysis & PCA, discriminant analysis, support vector machine, decision tree ensembles & bootstrap, neural networks, mixture models & clustering algorithms, and so on. You are proficient in at least one programming language commonly used for data analysis (like R/Python), and you are comfortable with SQL.

Additional Preferred qualifications:
Masters or Doctorate in relevant domain.
Previously worked on business analytics problems like customer churn, lifetime value estimation, targeted marketing, personalized offers, etc.
Experienced in designing and analyzing A/B tests.
Experienced in working with large data sets, with big data processing tools like MapReduce, Spark, Hive, etc. Have data engineering skills to do basic preprocessing, cleaning and transformations.
Possesses data visualization skills using programmatic tools and tools like Tableau",3.4,"DMI
3.4",Bengaluru,"Bethesda, MD",1001 to 5000 employees,2002,Company - Private,Consulting,Business Services,₹10 to ₹50 billion (INR),"Deloitte, IBM, Accenture"
Data Scientist,-1,"Data Scientist


You will discover the information hidden in vast amounts of data, and help clients make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities
– Selecting features, building and optimizing classifiers using machine learning techniques
– Data mining using state-of-the-art methods
– Extending company’s data with third party sources of information when needed
– Enhancing data collection procedures to include information that is relevant for building analytic systems
– Processing, cleansing, and verifying the integrity of data used for analysis
– Doing ad-hoc analysis and presenting results in a clear manner
– Creating automated anomaly detection systems and constant tracking of its performance
Skills And Qualifications
– Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
– Experience with common data science toolkits. Excellence in at least one of these is highly desirable
– Great communication skills
– Experience with data visualisation tools, such as D3.js, GGplot, etc.
– Proficiency in using query languages
– Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
– Good applied statistics skills, such as distributions, statistical testing, regression, etc.
– Good scripting and programming skills
– Data-oriented personality
Education
UG:Any Graduate – Any Specialization
PG:Any Postgraduate – Any Specialization",-1,Acies,Chennai,"Chicago, IL",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Summary:
Provide strong analytical, advanced Data Science and Machine Learning expertise as a key member of our specialized science-based team focused on the research, development, and deployment of Manhattan Associates’ next-generation cloud-native Machine Learning platform
Experience in most big data and statistical analytic tools: Python, Hadoop (Hive), Elastic Search DB Familiar with machine learning algorithms/concepts
Work with our product management and application development teams to identify, prototype, develop and deploy ML-empowered solutions
Knowledge on Apache Spark, Kafka, and other data platform technologies
Assist product teams with deployment and lifecycle oversight, performance analysis, issue troubleshooting, tuning and refreshing of production models/pipelines within our Kibana ML platform
Work with large, complex data sets to extract, analyze, visualize, and infer meaningful insights
Stay current with state-of-the-art techniques and technologies in the field
Research, experiment, and benchmark new ML use cases, methods, and technologies
Communicate and document effectively, especially when communicating with non-technical business partners and customers
Experience working on Spark Streaming applications is an advantage
Why ColorTokens is the place to advance your career?

ColorTokens is a Silicon Valley company located in Santa Clara that is redefining Enterprise and Cloud Security. We are a product company in the Network and Cyber Security space. We are building a product team in India that rivals the best minds in the world and delivers products that are Novel, Refreshing and Insightful (NRI).ColorTokens core team represents deep industry experience across hardware, software and cloud technologies.

An enterprise-class technology takes time to bring to market. During this time, we do not want to expose our product and approach to competitors, experts, analysts, and the world at large. Our mission is to deliver the next generation Cyber Security platform.

At ColorTokens you will collaborate and exchange ideas and best practices with an amazing set of high skilled. ColorTokens encompasses from business strategy, user experience to technology direction.

You work in an autonomous and collaborative environment with your team in creating solutions that solve real-world challenges for your customers and together.",4.1,"ColorTokens
4.1",Hyderabad,"Santa Clara, CA",51 to 200 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Data Sciences team at Priority Vendor uses data and algorithms to build large scale systems to enable better decision making for the invoice discounting as well as render better customer experience to suppliers. Some of the areas of our focus are Rate Determination, Demand Sensing, Recommendation Systems, etc.

Some of the things we are working on:
Daily Rate Determination

Building algorithms to predict supplier expectation on discount amount

Building prediction models to improve on invoice discounting%

Role & Responsibilities

As a data scientist, he/she will have the opportunity to leverage Priority Vendor 3 year old rich data to develop data products that are used by millions of suppliers (end user) and propel the growth of our business. He/she will collaborate with a strong team of engineers, product managers in defining the frontier of data products. Data scientists will work on how to evaluate potential approaches, build features, statistical/machine learning models and determine metrics. He/she will communicate insights/recommendations to a wide spectrum of stakeholders across the company.

Qualification & Skillset

Advanced degree in the quantitative field preferred.

3+ year’s industry experience developing machine learning models at scale from inception to business impact.

Deep understanding of modern machine learning techniques and their mathematical underpinnings such as classification, recommendation systems, and natural language processing.

Proven ability to tailor machine learning solutions to business problems in a cross-functional team.

Experience with distributed machine learning and computing framework (Spark, Hadoop, Mahout or equivalent). Applied experience preferred.

Strong programming skill (Python, R, or Scala preferred).

Experience productionizing machine learning model is a plus.

High proficiency in at least one of the following broad areas:

Machine learning

Statistical modeling/inference

Information retrieval,

Data mining

NLP",4.0,"Priority Vendor
4.0",Noida,"Noida, India",51 to 200 employees,2014,Company - Private,-1,Finance,Unknown / Non-Applicable,-1
"Data Scientist II, Consumer Payments",-1,"The Amazon Payments Team manages all Amazon branded payment offerings, globally. These offerings are growing rapidly and we are continuously adding new market-leading features and launching new products. Our payments products (Amazon Co-Branded Credit Cards, Gift Cards, Points, Shop with Points and Installments ) provide the most innovative payment experience on and off Amazon. We manage a financial services ad serving platform (billions of impressions per year) through Amazons purchase path where we offer Amazon branded and non-branded payment products and services. Our team of high caliber software developers, statisticians, analysts and product managers use rigorous quantitative approaches to ensure that we target the right product to the right customer at the right moment, managing tradeoffs between click through rate, approval rates and lifetime value. We leverage the wealth of Amazons information to build a wide range of probabilistic models, set up experiments that ensure that we are thriving to reach global optimums and leverage Amazons technological infrastructure to display the right offerings in real time. We work closely with product managers to understand their business, collect requirements and deliver high value analytics and insights for the Amazon Payments team that drive acquisition, usage and loyalty. Our petabytes of data has the ability to improve the shopping experience for hundreds of millions of consumers worldwide. Our goal is to delight our customers with their purchasing experience. Those of us who love to work with data see this as the pinnacle of opportunities that you cannot find anywhere else in the world.

We are looking for an outstanding Data Scientist that is able to comprehend the details behind the Amazon Payments Products business, understand/clarify business requirements, transform volumes of data into actionable insights, serve as the technical/statistics SME, help us improve our targeting methods/models by initiating innovative/creative projects, lead analytical discussions and road map, work across teams and influence the analytical direction of external teams, combine expert statistical/modeling knowledge with programming skills to manage and deliver on complex/critical analysis projects, independently identify and resolve business/technical issues, develop best practices and support our product managers across the world. Amazon.com has a culture of data-driven decision-making, and demands business intelligence that is timely, accurate, innovative and actionable.

Basic Qualifications

· Bachelor's degree in a quantitative field (i.e. math, engineering, statistics, finance, or similar)
· 4+ years of relevant work experience in data science, business analytics, business intelligence, or comparable experience
· Strong proficiency in MS Excel and relational databases - e.g. Redshift, SQL, ETL, Data Warehouse, etc.
· Deep understanding of common business metrics and the ability to generate new ones as needed
· Strong verbal/written communication & data presentation skills, including an ability to effectively communicate with both business and technical teams
· An ability to thrive in a highly ambiguous, fast-paced and rapidly-changing environment
· Ability to lead large projects and drive through completion

Preferred Qualifications

· Masters degree in an analytical field (or equivalent experience)
· 2+ years of relevant work experience in data science, business analytics, business intelligence (BI), or comparable experience
· Practical experience in programing or scripting languages like Python, VBA, etc.
· Familiarity with AWS solutions such as EC2, DynamoDB, and S3
· Financial service experience is a plus",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Scientist,-1,"This position requires a person to design, implement and processes large data sets used for modeling, data mining.

Responsibilities :
Develop and plan required analytic projects in response to business needs.
In conjunction with data owners and department managers, contribute to the development of data models and protocols for mining production databases.
Develop new analytical methods and/or tools as required.
Contribute to data mining architectures, modeling standards, reporting, and data analysis methodologies.
Conduct research and make recommendations on data mining products, services, protocols, and standards in support of procurement and development efforts.
Work with application developers to extract data relevant for analysis.
Collaborate with unit managers, end users, development staff, and other stakeholders to integrate data mining results with existing systems.
Provide and apply quality assurance best practices for data mining/analysis services.
Adhere to change control and testing processes for modifications to analytical models.
Create data definitions for new database file/table development and/or changes to existing ones as needed for analysis.
Determine required network components to ensure data access, as well as data consistency and integrity.
Respond to and resolve data mining performance issues. Monitor data mining system performance and implement efficiency improvements.
Manage and/or provide guidance to junior members of the team.

Send us the Resume at info@zettamine.com",3.8,"ZettaMine
3.8",Hyderabad,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"We are looking for a data scientist with an experience of 3+ years in deriving insights using analytical models handling vast amounts of data available across multiple platforms. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products. Experience in social media analytics is a must.

RESPONSIBILITIES
Data mining using state-of-the-art methods
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Selecting features, building and optimizing models using machine learning techniques
Doing ad-hoc analysis and presenting results in a clear manner
Creating proposals and presentations
SKILLS
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests etc.
Experience in Predictive modelling, ensemble modelling, sentiment analysis, NLP, Time-Series Analysis, Deep Learning, Reinforcement learning, Recommender Systems
Experience with common data science toolkits, such as R, Python etc.
Experience with data visualisation tools, such as Tableau, Power BI, Qlikview etc.
Proficiency in using query languages such as SQL and HQL
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Great communication skills
Benefits and Perks
Working with smart, young, mission-driven people
Approachable management team
Mobile allowance
Travel allowance
Regular team outings
Flexible Schedules",1.0,"Emerging India Group
1.0",India,"Noida, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"About Mindcurv

We help our customers rethink their digital business, experiences, and technology to navigate the new digital reality. We do this by designing sustainable and accountable solutions for humans living in a digital world. Mindcurv holistically covers the market’s need to digitize business processes and customer experiences and take advantage of the cloud following DevOps and agile principles.

Within Digital Platforms & Experiences we design and fully craft tailored solutions for our customers enabling them to get the most out of their business. We design and build a solid foundation in commerce, marketplace, responsive design, DXP and order management to name a few.

Your Role :
Be part of Big Data and Advanced analytics project team’s in the Data Science domain and as a trusted advisor to the VP of Data Science department on technology, configuration and delivery of projects undertaken by Mindcurv. You need to be hands-on to deliver end to end vis a vis projects undertaken in the Analytics space. Need to have a proven ability to drive business results with your data-based insights. You must be comfortable working with a wide range of stakeholders and functional teams. You should have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.

What you will do :
Identify valuable data sources and collection processes
Supervise preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns for insurance industry.
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Collaborate with engineering and product development teams
Hands-on knowledge of implementing various AI algorithms and best-fit scenarios.

Who you are :
4+ years’ experience in Analytics systems/program delivery. At least 2 Big Data or Advanced Analytics project implementation experience
Experience using statistical computer languages (R, Python, SQL, Pyspark, etc.) to manipulate data and draw insights from large data sets; familiarity with Scala, Java or C++
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Hands on experience in Azure/AWS analytics platform (3+ years).
Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop)
Strong math skills (e.g. statistics, algebra)
Excellent communication and presentation skills
Deploying data pipelines in production based on Continuous Delivery practices.
Experience using variations of Databricks or similar analytical applications in AWS/Azure
Fluent in English (verbal and written). German/Dutch language familiarity will be a plus
Interpersonal and Team skills should be top notch

Why join Mindcurv?

We believe that the most important aspect of a job is being excited about it, having growth opportunities and working in a team you really like. We’re always on the lookout for people who know their stuff and want to collaborate on tomorrow’s digital solutions. Our workplaces feel good, because they’re filled with good people.

Join a collaborative environment and work with the latest technologies. We’ll grow your career and provide a great workplace with flexible hours.

If you agree with our philosophy and share our values, we are looking forward to meeting you as soon as possible!",4.8,"Mindcurv
4.8",Kochi,"Essen, Germany",201 to 500 employees,2011,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Your Profile
Will demonstrate cross functional interactions with big data engineering, product and reporting teams.
Work on building intelligence to solve business problems on customer engagement & customer experience across BookMyShow applications.
Will Perform data analysis by integrating different data sources
Will participate and add value throughout data lifecycle - data capturing, model inputs, format and API handshake required
Will develop deployable models that can be integrated with production systems
Should understand business and customer challenges and create models to support decision making
Will be developing advanced statistical models, machine learning methods, data mining ,HDFS MR jobs, Big data streaming, deploying high-end real time solutions,analysing and reporting on various datasets.
Your Checklist
Passionate about everything around data
Understanding business problems and addressing them by leveraging BIG data
Ability to communicate data models in a clear and precise manner
Building predictive statistics, user behaviour models, supervised & unsupervised machine learning.
Programming ability using R/Octave/Python or equivalent tools
Hands on SQL experience
Experience with Map Reduce , Apache streaming, HDFS and NoSQL is a plus.
Working knowledge of technology stack - HDFS, Spark, Flink, NoSQL, AWS, Docker
3 - 6 years of relevant experience.
Prior expereince of digital analytics/ fraud analytics/ forecast and personalisation is a must.
Statistics majors or equivalent in Operations Research, Applied Mathematics, Physics, Computer science is a MUST.",3.7,"BookMyShow
3.7",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
Data Scientist,-1,"You will be designing and operationalize various kinds of descriptive, predictive and prescriptive analytics relevant in the planning space. While the analysis can happen in R, Python, Excel, SQL or o9’s tool, ensure the results are presented in a usable fashion for consumption in the o9 platform.

Who is o9?
Smart. Simple. Fun. All words to describe our environment at o9 Solutions. An exciting and high energy environment that drives us to grow and AIM 10x. The perfect place to be innovative, collaborative and dynamic as an organization. We’re always looking for great talent to join our o9 team.

Company Overview
o9 is the premier AI-powered platform for driving digital transformations of integrated planning and operations capabilities. We help enterprises to digitally transform their supply chain with a cloud-based platform that connects the supply chain end-to-end. Whether it is driving demand, aligning demand and supply, or managing P&L, any process can be made faster and smarter with o9’s AI-powered digital solutions.

Our headquarters is located in Dallas, and we currently have offices in Amsterdam, Barcelona, Bangalore, Tokyo, and Seoul. We expanded our value-adding activities to companies including Google, Nike, Walmart, Starbucks, Bridgestone, Caterpillar, Pirelli, General Electric, etc.

Job description:
What you will be doing:
Experience using statistical computer languages (R, Python, SQL, SAS, etc.) to manipulate data and draw insights from large data sets.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Exposure to distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
Experience in genetic algorithms, logistic and linear regression, PCA, decision tree analysis and statistical methods
Deep understanding of common business metrics and the ability to generate new ones as needed
Improve upon existing methodologies by developing new data sources, testing model enhancements, and fine-tuning model parameters.
What you need:
4+ years of experience in implementing ML algorithms using R and/or Python, preferably in the planning domain. (Hiring for both junior and senior roles based on the relevant experience).
Ability to analyze problems by synthesizing complex information, evaluating alternate methods and articulating the result with the relevant assumptions/reasons
Knowledge of statistical and machine learning algorithms
Experience of applying analytics in the field of planning, using advanced ML algorithms like demand planning, market intelligence, optimal assortments/pricing/inventory levels, etc.
Experience in implementing planning applications will be a plus
Knowledge of SQL, experience with ETL tools like Informatica/SSIS will be a plus
Having an educational background in Operations Research/Industrial Engineering/Business Analytics will be a plus.

What you get:
Competitive compensation and benefits
Flexible working schedule
Extended possibilities to travel
Exposure to the biggest brands in the world
A very strong entrepreneurial culture
A great team to support you and you can support
Possibility to really make a difference in a scale-up environment
International working environment

o9 is an equal opportunity employer and seeks applicants of diverse backgrounds and hires without regard to race, colour, gender, religion, national origin, citizenship, age, sexual orientation or any other characteristic protected by law.",3.2,"o9 Solutions, Inc.
3.2",Bengaluru,"Dallas, TX",501 to 1000 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹5 to ₹10 billion (INR),-1
Data Scientist,-1,"The Opportunity


This mid-level Data scientist role provides an opportunity to be a part of the Near’s Data Science team. You’ll join a team of experts in application of data science models for a location intelligence platform. They carry out R&D, prototyping, development and deployment of best-in-class AdTech and MarTech data science solutions. The role requires to partner with key decision makers in business, product and engineering teams within the company. You will design, develop and craft narratives that help us understand the user base and pitch the product to our clients.

You will be part of one of the fastest growing Enterprise SaaS companies, where you are given the freedom to experiment and innovate new winning ways – a great opportunity for people who can work independently and are self-driven.

Tasks include
Developing core data science models and capabilities that power the Near Location Intelligence Platform and associated products.
Applying various data science methods such as time series, causal inference, experiments, machine learning, modeling, and forecasting to understand the most important aspects of our product, users, and business.
Use advanced data analytics including processing structured (payments, telecom, page clicks etc) and unstructured data in multiple formats (text, audio, video) spanning multiple domains including user profile data, geo-spatial data, network data and retail data.
Research and create intellectual property for the company that will benefit Near and its partners.
Use nonparametric and probabilistic models to generate insights keeping in mind the bias- variance trade-off.
Work closely with the Engineering team to operationalize and deploy the models.
Partner with technology and the business team to build a superior data quality pipeline that will feed the models.
Understand and prioritize the data science work based on cost effectiveness and leverage time management skills.
Attend conferences and organize workshops/meet-ups to be in touch with the data science community.

Skills and Requirements
You should hold a degree in M.Tech/MS/PhD in quantitative field (e.g. Computer Science, Econometrics, STEM fields) a plus.
Overall 3-6 years of experience with at least 3 years of working experience in any data driven company/platform, developing data science models and quantitative models.
Must have thorough mathematical knowledge of correlation/causation, decision trees, classification and regression models, recommenders, probability and stochastic processes, distributions, priors and posteriors.
Understand the model lifecycle of cleansing/standardizing raw data, feature creation/selection.
Write complex transformation logic to generate independent and dependent variables, model selection, tuning, A/B testing and generating production ready code.
Knowledge of Numerical optimization, Linear/Non-linear/Integer programming, Statistics, Combinatorial optimization is a plus.
Familiarity with R, Apache Spark (Java, Scala, Python), PrestoDB, AWS Cloud, PyMC3/theano/tensorflow and other scientific python/R modules is a plus.
Need to be comfortable writing code for model building and bootstrap, test and own models through their lifecycle including devops and deploying into cloud.
Candidate is expected to have exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Must have completed academic projects in data science experimenting with raw data and generating insights, publications are a plus.",4.6,"Near.co
4.6",Bengaluru,"Singapore, Singapore",51 to 200 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"The Company

Talentica Software is a boutique software development company started by ex-IITB grads and industry veterans. It is a privately held company. The company is 16 years old and 400+ employees work exclusively for startups as Tech Partners taking them from a Series-A position to Series-B position and possible acquisition (for example Citrus Pay). We have built products for over 125 startups, most of them are based in the Bay Area or Europe. These startups come to us primarily because we know the issues that plague startup product development and the solutions for the same, thereby improving their success chances. Owing to the unique space we are in, we deal extensively with cutting edge technology. The data science team works under the purview of the Technology Excellence Group at Talentica Software. The goal of this team is to solve problems and build algorithms that are typically data driven. Hence, problems involving statistics, optimization, computer vision, machine learning, and natural language processing are of interest to this group.

We are looking to hire a Data Scientist with Computer Vision and Machine Learning experience.

Here is what we are looking for in prospective candidates: Mandatory
Has completed his/her PhD from one of the old IITs or IISc-Bangalore
Should have completed full-time PhD degree
Graduated from IIT or IISc or IIIT-Hyderabad or ISI-Kolkata with a Master’s degree
Should have at least one published full paper in CVPR or ECCV or ICML or NIPS
Excellent programming skills and must be able to implement complex algorithms in Python
Hands-on experience with use of standard image processing and machine learning libraries such as OpenCV, Tensorflow, Keras
Here is what we are looking for in prospective candidates: Good to have
Graduated from IIT-Bombay or IISc-Bangalore or IIT-Delhi
Not required for the current role but it is good to have worked with Mongo/Cassandra/PostgreSQL/Neo4J
Credited courses focused on linear algebra, stochastic models, pattern recognition, design and analysis of algorithms, machine learning
Interest in applications of computer vision algorithms for video, shape recognition, matching & retrieval

Experience:
Should have worked in the industry for at least 2 years.
Should like to work in a startup environment.
Should be capable of converting theory to practice by reading relevant papers.
Should be capable of conceiving original ideas and coding them as working algorithms.",4.1,"Talentica Software India
4.1",Pune,"Pune, India",201 to 500 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"JOB DESCRIPTION

Data Scientist

Role : Data Scientist

Experience : 5+ years

Education

Graduation / Post Graduation : Specialization in Computer Science, Software Engineering, Business Analytics etc.

Role Background

Inteliment is looking for people who aspire to solve real and complex business problems with their Data Science expertise. You will be a part of our Data Science Centre of Excellence that implements Inteliment’s Data Science Platform as well as on other industry leading platforms.

Key Responsibilities

Work closely with product engineering, client and project teams and align them with respect to your focus area.

Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner.

Enhancing data collection, processing, cleansing and verifying the integrity of data used for advance analytics

Be a subject matter expert in Data Science Platform Data Science & Analytics products and offerings.

Selecting features, building and optimizing classifiers using machine learning techniques, understand and work around possible limitations in models.

To develop hypothesis and test them with careful experiments.

Aid in project planning to determine effort and time estimations.

Contributing to creation of knowledgebase for Technology platform & practise and related KMS initiatives.

Required Skills

Data-oriented personality with a good scripting and programming skills and hands-on expertise on data science toolkits, such as R, MatLab, SAS, SPSS

Hands-on expertise and exposure in NLP, machine & deep learning algorithms, model building, statistical modelling, predictive modelling environments

Excellent track record of delivery using languages like Python, R, Java and technologies like Hadoop, Git / Stash, JIRA / Rally etc.

Desired Skills

Demonstrated clear and thorough logical and analytical thinking, as well as problem solving skills

Self-directed, ability to work independently and research innovative solutions to business problems

Must be flexible to travel onsite if required.

Effective interpersonal communication across various levels of the organization.

Ability to interpret, evaluate and communicate detailed information in a manner that is appropriate to the audience.

Ability to conduct root cause analysis and performance tuning for complex business processes and functionality.

Ability to interact with IT and business users across the organization to resolve issues and provide solutions in a timely manner.

Should be proactive & transparent in the in the deliverables & critical thinker while designing the solutions.

Team oriented and enjoys working in a collaborative development environment.

Tools & Technologies

Excellent track record of delivery using languages like Python, R, Java and technologies like Hadoop, Git / Stash, JIRA / Rally, SAS, SPSS, Statistic etc.

Experience with NoSQL databases (MongoDB, Cassandra, HBase) and SQL, Hive, Pig.

Experience with data-viz tools to present trends, forecasts, patters Tools & Technologies

If you have got it all.. What are you waiting for?",4.1,"inteliment
4.1",Pune,"Pune, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Data Scientist,-1,"Company overview

American multinational manufacturer and marketer of branded consumer foods sold through retail stores
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Requirements

Machine Learning Algorithms, Python",3.8,"RGF Professional Recruitment
3.8",Mumbai,"Tokyo, Japan",10000+ employees,1960,Company - Public,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Data Scientist

Job Description:
Expertise or extensive experience with Python/ R -programming
· A thorough understanding of SQL databases
· Excellent technical abilities
statistics and machine-learning optimization skills;
knowledge of big data
insightful data visualization capability
to use algorithms and programming to efficiently go through large datasets
Define unstructured data needs, evaluate data quality, and extract/transform data
data science programming languages and big data tools including R, Python, Spark, SQL, Hadoop
Development and deployment of an advanced solution in a Big Data

Experience Range:

4 - 8 years

Educational Qualifications:

Any graduation,

Skills Required :

data scientist,

data analyst,

Candidate Attributes :

Should be good at R Python and Big Data",3.1,"Angel Broking
3.1",Andheri,"Mumbai, India",1001 to 5000 employees,1987,Company - Private,Brokerage Services,Finance,Unknown / Non-Applicable,-1
Data Scientist,-1,"Click to Apply

Company Description

Entytle is at the perfect intersection of big data analysis, predictive analytics, machine learning and sales automation.

We are revolutionizing the way industrial OEM manufacturers can leverage existing information to make highly profitable data driven decisions and increase recurring revenue from their customer installed base.

Our highly satisfied customers have derived tremendous ROI from our cutting edge software.

Mission

Deliver innovative but pragmatic solutions to help our customers drive recurring revenue sales, increase loyalty and capture lifetime value from their customers.

Outcomes

Work collaboratively with Entytle stakeholders to create AI and Machine Learning algorithms that address recurring revenue sales
Utilize our data science platform to research and generate new insights into customer loyalty and lifetime value
Provide our internal teams and customers a clear understanding of the models and research generated

Position Description

The position reports to the Head of Data Science. You will work with other data scientists, engineers and product management team members in developing insights and innovative data science models (e.g. AI, ML) in support of our installed base sales automation application. Your communication skills will allow you to work with internal teams and, as needed, our manufacturing-based customers. You will use your agile experience to work with our geographically dispersed teams.

Responsibilities

Work with, as needed, customers to understand business challenges and propose new modeling and algorithmic solutions that leverage the latest in statistical and machine learning techniques.
Work collaboratively with the rest of the data science team, data engineers, developers and product management to translate business requirements into technical requirements that can be addressed with statistical and machine learning techniques.
Study data sources and find insights/correlation to investigate how data science can be used to solve existing and new business challenges.
Apply statistical analysis and modeling techniques on small and large datasets to solve specific business problems in the installed base sales automation domain.
Use best practices in applying and deploying data science at scale.

Competencies

Strong sense of and an ability to cultivate an environment of teamwork, and a willingness to help others.
Ability to effectively communicate technical concepts to both technical and non-technical staff members and customers.
Proficiency in data analysis and programming languages such as SQL, Python, and R.
2-4 years hands-on experience in machine learning, statistics or experiment design.
Master’s Degree required in Statistics, Mathematics, Econometrics, Operations Research, Computer Science, Physics or a related field with focus on data analysis.
Expertise in machine learning, statistics, data analysis. Must have an excellent knowledge of advanced methods, and experience in applying those methods to a variety of problems.
Solid grasp of probability, statistical or mathematical modeling with analytical and quantitative problem-solving ability. Experience with time-series analysis would be a plus.
Demonstrated experience in applying machine learning to real-world problems
Familiarity with software development cycles, source control systems (including Git), databases, and cloud computing platforms such as AWS.
Knowledge of large equipment manufacturing, installed base sales, recurring revenue, and equipment service would be a plus.",4.6,"Entytle
4.6",Pune,"Palo Alto, CA",1 to 50 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Description – Data Scientist
Roles & Responsibilities:
Ability to understand a problem statement and implement solutions & techniques for solving natural language processing, text analytics, and information extraction problems, as well as structured data problems.
Work and collaborate with other teams to deliver and create value for clients
Fast learner: ability to learn and pick up a new language/tool/ platform quickly
Conceptualize, design and deliver high-quality solutions and insightful analysis
Conduct research and prototyping innovations; data and requirements gathering; solution scoping and architecture; consulting clients and client facing teams on advanced statistical and machine learning problems.
Come up with actionable ideas to solve problems and implement those ideas.
Communicate context, data, solution and implications to the team, senior leaders and stakeholders.


Skills:
Intermediate to expert level proficiency in at least one of Python and R
Ability to discover effective solutions to complex problems. Strong skills in data-structures and algorithms.
Experience of working on a project end-to-end: problem scoping, data gathering, EDA, modeling, insights, and visualizations
Problem-solving: Ability to break the problem into small problems and think of relevant techniques which can be explored & used to cater to those
Intermediate to advanced knowledge of regular expressions, machine learning, probability theory, information theory, statistics, and algorithms. Discuss and use various algorithms and approaches on a daily basis.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, MySQL, etc.


Qualifications & Experience :
Bachelor's or Master's degree in engineering.
Good knowledge of Basic Statistics (Hypothesis testing, probability, distributions, etc.)
Exposure towards multivariate statistical Analysis (such as PCA, PLS, etc.).
Strong in Machine learning and supervised Learning techniques such as ANN, Decision Trees, SVM, Naïve Bayes etc.
Knowledge on Unsupervised learning techniques such as k-means, hierarchical clustering etc.",3.5,"CoStrategix Technologies
3.5",Bengaluru,"Cincinnati, OH",51 to 200 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Do you feel passionately about solving problems through data? Have you spent 2+ years solving business problems through data?

Do you aspire to take data science to millions of people out there? Can the leader in you make people follow data science out of sheer passion? Would you enjoy helping people solve problems with out expecting any thing in return?

If the answer to all the questions is yes – look no more. Analytics Vidhya is looking for evangelists who can carry and deliver their baton to the world.

What should you expect?
A team of best data scientists and thought leaders from industry.
Disciplined entrepreneurship within team. Each person is owner of his own work – you set the milestones, the pace and the achievements.
High standards, deep passion for data science and a commitment to find out ways to make things work.

Who can fill in the shoes?

This role is best suited for:
Person with 2+ years of experience in data science. The person should have prior experience with practical data science applications and use cases.
Person who loves problem solving through data. She/He should be able to do things hands on by himself or guide a team of data scientists to solve a problem.
A person with deep experience in tools like SAS / R / Python / Julia / Matlab and machine learning / predictive modeling techniques/ Machine Learning Algorithms.
Strong problem solving and communication skills (English).
An avid reader.

What is the role?

Being a startup, the role would evolve over time. But, here are a few things you can expect:

Creating problems for our hackathons by working closely with the clients
Continuously learning new skills and evangelizing them with in our community
Defining and leading our strategy in making data science easy and accessible to all
Leading industry events, meetups, webinars and competitions
Develop custom data models and algorithms to apply to data problems
Use predictive modeling to increase and optimize customer experiences and other business outcomes.

Where is the role based?

We would love to have you in our office in Gurgaon.

If the role excites you, drop an email to hiring@analyticsvidhya.com with your CV, mentioning “Why do you think you are the perfect fit for this role”.",4.2,"Analytics Vidhya
4.2",Gurgaon,"Gurgaon, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"About Us
Established in May 2015, Indus OS is a homebred system apps company, building India’s only content and commerce platform for users to discover and consume digital content & services in the language of their choice. With a vision of digitally connecting 1 Billion Indians, Indus OS is constantly striving to adapt its existing portfolio (App Store, Minus One Screen, Keyboard, Messenger, etc) by introducing new features to enrich the user experience in their native language.
Currently, Indus OS has a user base of over 60+ Million on the back of 10+ smartphone brand partnerships with leading OEMs such as Samsung, Gionee, iTel, Micromax, Intex, Karbonn and others. The Indus platform is available in English & 23 Indian regional languages and is intended to digitally connect the next 1 billion people in the emerging markets.

Indus App Bazaar:
India’s Largest Indigenous App Store with more than 60mn users.
Indus App Bazaar is an offering from Indus OS, a home-grown technology brand building content and commerce platform for users to discover and consume digital content & amp; services in the language of their choice. Indus App Bazaar is an alternative Android based app store designed with innovations in localization, simplicity, user personalization and performance optimization. The platform provides multi-lingual support for users, in English as well as 12 Indian languages – Hindi, Gujarati, Marathi, Tamil, Telugu, Urdu, Malayalam, Kannada, Punjabi, Odia, Assamese, and Bengali.
With an AI driven user experience, Indus App Bazaar offers targeted content to their users based on their interest, location, and language. The browse-based discovery platform is easy to use and does not require an email address for users to download apps. Indus App Bazaar offers over 400,000 apps and has over 60 million users. It also has a strategic partnership with Samsung to power its Galaxy Store, across all Samsung devices in India. It is the preferred app distribution channel for top developers like TikTok, Likee, Helo, Paytm, Phonepe, Xender, Shareit, Vmate, Amazon, Meesho.
Indus OS in news
Yourstory: https://bit.ly/34ZqWGs
FirstPost: http://bit.ly/2s1GURE
The Asian Age: http://bit.ly/2OboBSW
Indian Television: https://bit.ly/2OT01q8
Inc42: https://bit.ly/2Lulkfw

What we do:
To create the mobile ecosystem for the next billion smartphone users from emerging markets in their native language.
What you’ll be doing

Actively monitor all data stack at Indus OS.
Leverage all the data to build best in class products to enhance Indus' product offerings.
You’ll be responsible for designing, implementation & maintenance of various data and machine learning-based
components and applications for mobile platforms.
Communicate often & effectively about the status of new & ongoing development efforts within the company. This will
help in understanding as well as evangelizing how data can be used more & more effectively.
Represent the Data Science engineering team at high-level meetings.
Motivate, mentor and lead other team members by rolling up your sleeves and offering technical insights into data science and AI
Work closely with various teams to create exciting mobile user experiences while leveraging data
You’ll be continuously keeping an eye on the latest cutting-edge Data Science, ML & AI technologies and leveraging
these in one’s own and the team’s work as necessary

Your Profile

1+ Experience of working on large data stacks
Complete end to end exposure of first-time training and system set up to deliver a product which leverages trained
models to feedback collection and retraining
Strong knowledge of Spark
Deep learning using Tensorflow/CNTK
Command over programming in Python/Scala/R but we generally like people who are programming language agnostic
Working over the large quantum of data using HBase/MapR/Cassandra etc
Must have set up data pipelines to move data across systems
Exposure over working with Audio (speech), Image, Video or any other non-textual data would be a huge plus
Knowledge of working in the cloud
Experience of working with version control, bug tracking, continuous integration, and other productivity enhancement
software like SVN, Bugzilla, Jira, etc.
Prior experience in implementing Agile software methodologies
The ability to effectively manage technical people (internal & external development resources) and projects
Taking responsibility and ownership in the team’s work

Additional Requirements:
B-Tech/BS/BE/BS/MS/M.Tech/MS in Electronics or Computer Science from a premier institute in India (IITs, BITS, NITs, etc) or abroad.

Our Offering:
True start-up experience – no bureaucracy and a ton of tough decisions that have a real impact on the business from day one.
The camaraderie of an amazingly talented team that is working tirelessly to build a great OS for India and surrounding markets.

Perks:
Awesome benefits, social gatherings, etc.
Work with intelligent, fun and interesting people in a dynamic start-up environment.

Catch up with us on Social Media:
Visit www.indusos.com for detailed information.
Facebook – https://www.facebook.com/indusos/
Twitter – https://twitter.com/indusos
LinkedIn – https://www.linkedin.com/company/indusos",4.3,"Indus OS
4.3",Mumbai,"Mumbai, India",51 to 200 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Chief Data Scientist - ML/AI,-1,"Icertis, the leading enterprise contract management platform in the cloud, helps companies unlock the full business value of their contracts to increase revenue, reduce cost, accelerate cash flow and minimize risk. The adaptable, AI-infused Icertis Contract Management (ICM) platform quickly turns contracts from static documents into strategic assets. Today, Icertis, the analyst-validated industry leader, is used by innovative companies like Airbus, BASF, Cognizant, Daimler, Johnson & Johnson, Microsoft and Sanofi across 90+ countries to manage 7.5 million contracts governing more than $1 trillion.

Contracts have always been the foundation of commerce - determining, influencing and guarding the balance between risk and reward. This is the first time in history that almost all contracts have been digitized and the risks and rewards expressed in legal language can now potentially be enshrined in computer readable logic. This role at Icertis is to bring thought leadership to computational law and its journey towards autonomous contracts. With insights into the contracting processes of some of the largest organizations in the world, this role will be responsible for evolving new tenets of contracting and reinforcing existing ones. The Chief Data Scientist will study current trends and data, evolve new methodologies and platform features to set the direction of Icertis enterprise contract management intelligence. The role reports to the CTO.
Role Requirements
You have demonstrated skills to go deep into a domain and transform business processes in that domain by applying the right AI techniques. You are a respected and recognized leader in the field, and have deep knowledge of machine learning and NLP techniques. You bring teams together, break new ground and provide thought leadership in areas that have the potential to make deep impact to how we live and work. Research or application background in computational law or related domains is a big plus. You bring the right values and team work to build a world class analytics team
Responsibilities
Deeply understand the mechanics of the enterprise contract management lifecycle
Help define and own the direction of the Icertis platform for applying AI to contracting processes
Establish Icertis’ s thought leadership in this area
Build a strong team of data scientists and engineers to help realize the Icertis vision of transforming the foundation of commerce through AI/ML
Provide pragmatic solutions to tough contracting problems using AI working with a team of data scientists and engineers
Qualifications
Holds a PhD degree in a quantitative discipline: computer science, applied mathematics, statistics, engineering or equivalent
15+ years of industry experience
Hands-on data science and NLP experience
Knowledge of machine learning techniques (regression, classification, clustering, dimension reduction, etc.) and their real-world advantages/drawbacks
Deep knowledge of Machine Learning, NLP related mathematical domains such as statistics (distributions, tests), calculus, linear algebra, probability, etc.
Icertis is not open to 3rd party solicitation or resumes for our posted FTE positions. Resumes received from 3rd party agencies that are unsolicited will be considered complimentary.

Icertis, Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.",4.3,"Icertis
4.3",Pune,"Bellevue, WA",1001 to 5000 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Selectica, SAP Ariba"
Data Scientist,-1,"Currently we are looking for a Senior Computer Vision Engineer who is passionate about the sphere of Big Data, Data Science and AI.

Responsibilities:
Creating solutions and products for leading representatives of different industries;
Analysing business problems, looking for better technical solutions and their implementation;
Expanding company’s expertise in the field of Computer Vision;
Management of the direction of the company in the future.",-1,Exeliq Consulting,Maharashtra,"Schaumburg, IL",1 to 50 employees,2019,Company - Public,-1,-1,₹10 to ₹50 million (INR),-1
Data Scientist,-1,"Qualification: BS/MS/MCA, BCA in Computer Science or equivalent Experience: 3+ Years

Key Responsibilities:
Dive into the data and identify patterns
Development of end-to-end models and policy for our existing products
Development of Fraud models and fraud rule engine
Collaborate with various stakeholders (e.g. tech, product) to understand and design best solutions which can be implemented
Work on cutting-edge techniques e.g. machine learning and deep learning models

Skills Required:
Strong Mathematics Basics
Proficiency in Python, Matlab, C++ or any other AI language of choice
Demonstrated expertise in solving Data Science problems from first principles
Familiarity with relational and NoSQL databases
Experience with Unix/Linux
Good Problem solving & Analytical Skills",3.9,"Redian Software
3.9",Gurgaon,"Noida, India",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"We are looking for strong Data Scientists/Analysts, who will be problem solvers, using predictive modelling techniques and machine learning algorithms, to solve complex business problems in credit and risk domains, and also provide business strategies.

Roles and Responsibilities:
Use of cutting edge machine learning techniques for solving supervised and unsupervised learning problems
Design analytical solutions for complex business problems
Dig deep into data, understand characteristics, evaluate and validate hypotheses through empirical approaches
Recommend and implement best practices around application of statistical modelling
Develop and implement predictive models solving business problems and recommend actionable insights
Mentor and train new recruits
Qualification & Experience
2+ years of experience in the field of analytics, predictive modeling or data science
Strong with programming languages like Python and data processing using SQL or equivalent
Strong with analytical and statistical packages like R, Python Scikit-Learn
Additional familiarity with C/C++ welcome
Experience with the following machine learning algorithms desirable: Gradient Boosting, Decision Trees, Logistic Regression, Random Forests, Deep Neural Networks, Ensemble methods
Experience with NoSQL and distributed data processing technologies such as Hadoop is also desirable
Bachelor or Master in Operations Research, Computer Engineering or in closely related Quantitative Disciplines from a premier institution.
Interested? Please send your resume to careersindia@applieddatafinance.com.",4.5,"Applied Data Finance
4.5",Chennai,"San Diego, CA",51 to 200 employees,2014,Company - Private,Lending,Finance,Unknown / Non-Applicable,Avant
Data Scientist,-1,"Candidate should be able to analyse data and discover information, with high level inputs from the functional team. Understanding of data mining techniques and statistical analysis is important.",3.5,"Pattern Effects Labs
3.5",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"About the Company

Meesho is India’s top reselling platform, used by more than 1 million resellers across the country. Resellers are small business owners and home entrepreneurs who sell stuff using Meesho, within their extended social circles. Meesho is reimagining e-commerce for India, and building a platform for the next 20 million entrepreneurs in the country.

Meesho is one of the fastest growing startups in the world, and is backed by top investors globally, including DST Global, YCombinator and Sequoia. You can read more about Meesho’s journey on TechCrunch.

About the role

As a data driven organisation with the core mission of empowering 20 million entrepreneurs throughout the country, Data scientists are an integral part of the Meesho team. You'll develop models and run experiments to infer insights from hard data that meaningfully impacts our 1Million+ resellers. From improving our product usability to identifying new growth opportunities data scientists help all teams within Meesho develop effective solutions.

Here are some of the problems you'll be working on: -

- Understanding reseller preferences to provide them with the most relevant products

- Modelling which resellers will be the most impacted by changes in our incentive structures

- Designing discount programs to help our resellers sell more

- Inferring insights from our existing data to identify new growth opportunities

- Designing experiments to improve usability across our product suite

- How can you help resellers better recognise end customer preferences to improve their revenue?

- Using data to identify bottlenecks that helps our suppliers meet their SLA requirements

- What frontend visualisations will best help category managers understand the current demand for products?

- Modelling seasonal demand to predict key organisational metrics

Mandatory Requirements:-
Bachelor’s Degree from a Tier 1 school (IIT, NIT, IIIT, BITS, DCE)
1-3 years of experience as a Data Scientist
Familiarity with concepts like Neural Networks, Machine Learning etc and tools like SQL, R, Python
Capabilities The ideal candidate for this role has:-
A good understanding of and belief in Meesho’s business model and product
Strong understanding of Statistics and Linear Algebra
Strong understanding of hypothesis/model testing and ability to identify common model testing errors like overfitting, underfitting, type I and type II errors
Experience designing and running A/B tests and drawing insights from them
Familiarity with Python or R, proficiency with SQL
Strong communication skills to explain your analysis
Bonus points We will prefer candidates who have:-
A Computer Science degree
Experience in working on personalization or other ML problems
Familiarity with Big Data tech stack like Apache Spark, Hadoop, Redshift",3.9,"Meesho
3.9",Bengaluru,"Bengaluru, India",501 to 1000 employees,2015,Company - Private,"Department, Clothing, & Shoe Shops",Retail,Unknown / Non-Applicable,"GlowRoad, Shop101, Wooplr"
Data Scientist,-1,"About us & Vision

Sequretek is an Indian MNC focused on Information Security and Information Management space. The company is backed by industry veterans who have come together with a vision to build India’s leading Information Security company.
Sequretek’s customers have appreciated its solution offerings, and within a short span the company has acquired marquee clientele in Financial, Pharmaceutical, IT/ITES, and Retail and Logistics sectors.
Sequretek probably is the one of the very few companies that offers a blend of its own core threat intelligence products along with both on-premise and cloud solutions. Our end point detection, protection, and response technology – EDPR is the industry’s only product that replaces up to six different endpoint technologies for our customers.
Our vision is to establish and sustain Sequretek as a Global Leader in terms of the ‘Security’ of Enterprise-level Information-Assets through the consistent delivery of world-class products and solutions that leverage state-of-the-art technologies relevant to the contemporary digital economy.

Why Sequretek?

You will be part of an award winning ""Security Product Company of the Year – 2019” announced by Data Security Council of India (A NASSCOM Initiative).
The team is highly visible, agile, and working on critical problems that directly affect the company’s success.
Our researchers regularly appear at various global conferences and are some of the most sought-after thought leaders in the security industry.
Our ML Engine was certified by ICSA Labs for its detection against unknown / little known malwares.
As part of the research group, you will leverage your problem-solving and analytical skills to further our capabilities, as well as publish and present new and novel research.

Education & Experience

Education:The candidate must have any of the below:
BE/B.Tech/MTech in Computer Science, Statistics, or Data Science.
Experience:
Minimum 1-2 years of experience in applying ML/Deep Learning algorithms and
techniques to real-world data sets.

Key Responsibilities

Skills:
Knowledge of Core Python
Proficiency in Machine learning algorithms (SVM, Decision Trees, PCA, Clustering etc.).
Knowledge and Experience of Deep Learning Algorithms (CNN, RNN, LSTM etc.)
Knowledge of major ML frameworks such as TensorFlow, PyTorch, Keras, and Scikit-Learn.
Strong analytical thinking and problem solving.
Designs scalable processes to collect, manipulate, present, and analyze large datasets in a production-ready environment
Demonstrated participation on platforms like Kaggle is a plus
Prefer great appreciation or expertise in Security products such as End point detection, protection and response, Managed detection and response etc
Must be proactive and flexible and have the ability to work under pressure and possess good follow-through skills.
Must possess excellent written and verbal communication and a quick learner.
Responsibilities:
Wants to build and develop innovative intellectual property through the research and implementation of new approaches in machine learning and simplifying security
Approaches problems from an adversarial mindset in an effort to circumvent prediction systems
Works with internal product and engineering teams to drive development of new products
Has the capability to translate and implement newly published research on specific datasets and problems to validate approaches and potentially improve
Experienced wrangling large volumes of data and applying machine learning techniques towards real product and business problems
Invests time in research including publications, and is committed to keeping up with AI trends
Develop working prototypes of algorithms and evaluate and compare metrics based on large, real-world data sets",4.0,"Sequretek
4.0",Bengaluru,"Mumbai, India",201 to 500 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Data Scientist Bangalore As a fully functioning analytics team member, applies best practices to analytics solutions and contributes to the development of improved best practices. Below are the MUST HAVES: • Experience as Data Scientist - Fortune 100 Clients - Prefer Product Base. • Data analysis experience working with large-scale data. • Strong experience using Python & SQL for analysis, modeling, and data visualization.
Advanced statistics, data mining and modeling knowledge. Requirements: • Advanced Python for Data Science (descriptive / predictive models) + Strong Stats background Own the end to end data science process, from initiation to deployment, and through ongoing communication and collaboration. • Drive personalization, real-time decision-making, causal inference, and predictive analytics capabilities through the application of Machine Learning, Deep Learning, NLP, and Simulation in an agile development framework. • Conduct quantitative analysis of experimental, and textual data to generate insights and drive decision making (ANOVA, Regression, Chi-Sq, AB, pre-post etc..) Working knowledge of SQL, Tableau, Hadoop, BigQuery, Presto, Vertica Write well documented code that can be shared and used across teams, and can scale to be used in existing products",3.3,"Calsoft Labs
3.3",Bengaluru,"Bengaluru, India",1001 to 5000 employees,1992,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,"Mindtree, Happiest Minds Technologies, Altran Americas"
Data Scientist,-1,"NLP, ML, Python/R, Hadoop, strong mathematical bacground
If you are intrested, please send us your resume at hr@teqnirvana.com",4.2,"TEQNirvana
4.2",Mumbai,"Bengaluru, India",1 to 50 employees,2005,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Scientist,-1,"Required Experience, Skills and Qualifications :
Basic understanding of statistics, linear algebra and calculus.

Good understanding of data structures.

Proficient in Python and should have worked on statistical packages

Good understanding of AI and ML technology

Working with big data sets; data extraction, data mining, visualization, storytelling

Comfortable working on both supervised and unsupervised machine learning problems.

Worked on (at-least one of) the specialized packages pertaining to textual data like nltk and image data like pil, opencv, etc.

Worked on deep learning frameworks like tensorflow, etc

Hands-on experience in dealing with text and/or image data

Knowledge of distributed and parallel processing frameworks like Spark.

Understanding of search platforms like Solr/Elastic Search.

Qualification : Bachelor of Computer Application Bachelor of Engineering/ Bachelor of Technology Master of Computer Application Masters of Engineering/ Masters of Technology
Working Days : 5 Days a Week ( to )
Job Nature : Full Time

Experience 5 - 12 Years
Salary 15 Lac To 25 Lac P.A.
Industry IT Software - Application Programming / Maintenance
Qualification Professional Degree
Key Skills Data Science Data Analysis AI Python IT linear algebra calculus big data

About Company

Email ID getintouch@saffroncareers.in",-1,Saffron Consultancy Services,New Delhi,"Gurgaon, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"FiFyles is changing lives!

As Data Scientist eager to jump into brand new learning experiences, you’ll have fun analyzing complex, massive data sets. If this sounds like you, please read on!

Who You Are

You cut your baby teeth on Bayesian modeling and Markov chains
You love the idea of working at a startup-within-a-startup
You are curious enough to always want to dig deeper
You dream of applying machine learning to everyday tasks
You never wait for someone else to ask “why?”
You drive others crazy with how open-minded you are
Your imagination knows no bounds when it comes to slicing and dicing complex problems and data sets
You are strongly opinionated on what makes for great software skills, and love playing devil’s advocate
You believe every experience, good or bad, is an opportunity to grow
You are convinced that the best use of experience is to leverage it to learn more
You are a natural-born leader
You know how to prioritize
You are analytically curious
You still like to play “Where’s Waldo?” on occasion to test your awesome pattern-recognition skills
There’s always methodology to your madness
You know that numbers tell a good story
Spock is your favorite Star Trek character

What You Want From Your Next Career Move

To change the world using your skills in solving analytical problems. To learn. To perform data analyses on massive data sets, at scale. To manage the data demands of a company with a heart.

Why We Need You

FitFyles is a company that saves lives. A company that is going to change the face of health care for good. We need someone to administer the flow of ideas regarding data and make recommendations to influence the direction of our business by communicating results to numerous stakeholder groups. You’ll work with the massive datasets, information, and knowledge that we’re collecting and organizing, and help to drive innovation in our product and enhance user experiences. We need your unique skills to:

Help manage our intense growth by developing and executing data analyses to manage the growth demands of FitFyles
Develop, implement and maintain robust reporting methodologies and tool to support mission-critical business objectives
Pioneer new uses of data to help save lives by enhancing user growth and engagement

How You’ll Change Global Healthcare

You’ll help millions live longer, healthier, happier lives through your ability to exercise creativity in addition to your analytic skills.

What you’ve achieved

BS / MS / PhD in a quantitative discipline (applied mathematics, statistics, CS, OR, or related field)
5+ years of experience using quantitative approaches to solve challenging and meaningful analytical problems (or equivalent)
Proficiency in programming and the use of analytic tools to perform rapid design, prototyping, analysis, simulation of, and experimentation with, advanced algorithms and applications (such as Matlab / Mathematica, Java, Ruby, Python, and experience in various relational and non-relational databases)
Solid grounding in applied mathematics and statistics including expertise in Bayesian modeling, multivariate regression, logistic regression, machine learning, cluster analysis, decision analysis, time series analysis and forecasting, factor analysis, structural equation modeling, item response theory, Markov chains, and data visualization (preferred)
Startup or equivalent experience (preferred) and the drive to live the dream (required)",-1,Fitfyles,New Delhi,"New Delhi, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"LocationIndia / US / EuropeExperience2 YearsAcademic Qualification:B.S, B.E., B.Tech/MBA from top-tier Engineering /B-School ORMasters in Statistics/Economics from leading UniversityOverviewContinuous, growth opportunities for career progression and personal developmentProfessional, stimulating, continuous learning, work environment based on camaraderie, individual mentorship, on-the-job and corporate trainingCompetitive and performance-oriented compensation and employee benefits packageIndustry benchmarked HR policies and practices, particularly in areas such as Performance Management, Learning and Professional Development, Career Planning and Compensation and Rewards.Roles and responsibilitiesWill involve teamwork as well as work in which individual contribution will be needed.Clear, articulate and confident written and verbal communication skills.Working experience in Advanced Analytics Techniques Predictive modelling Time series forecasting Machine Learning etc.The role will require a sound understanding of business functions, statistical concepts and algorithm design/implementation skills.Core responsibilities include leveraging data science to solve business cases, training other team members, and contributing to pre-sales through quick execution of PoCs. Typical activities will include:Interacting with business stake holders for gathering requirementsAnalysing data to develop key insights on business trends and performanceApplying statistical/mathematical algorithms as needed to address specific business problemsProficiency in using query languages such as SQL(preferable), Hive, Pig, R, SAS, PythonAdditional Skills (preferred)Will involve teamwork as well as work in which individual contribution will be needed.Intermediate querying and scripting skills in SQLExperience in relevant field such as Statistics, Computer Science or Applied Math.SPOCBuddhadeb BhattacharjeeMail toBuddhadeb.bhattacharjee@tcg-digital.com",3.0,"TCG Digital
3.0",India,"Somerset, NJ",201 to 500 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"About us

nurture.farm aspires to bring technology, digitization and best scientific practices to all farmers, big and small. We believe in bringing the best talent together, to create a team passionate for transforming the farming ecosystem. Our software engineers develop technologies that strengthen the hands of millions of farmers, making farming more profitable and sustainable. Our products need to handle information at a massive scale. We are looking for engineers who bring expertise in distributed and scalable computing, easy-to-use consumer products, UI design and mobile, machine learning, data science, networking, storage, security and much more. We’re a team that values versatility, self-motivated drive and a passion to create an impact on millions of farmers.

We’re looking for ..

builders and tinkerers, who derive pleasure from creating something from scratch,

dreamers, who are passionate about creating something that touches millions of people, and transforms lives,

sculptors, who take pride in simplicity of design, and have the keenest eye for detail when it comes to quality,

learners, who look forward to continuing to grow everyday.

If that’s you, we should chat.

Machine Learning Engineer

Minimum qualifications

BTech Computer Science, or similar field of study, or equivalent practical experience.

Software development experience in one or more general purpose programming languages.

Experience working with the following: Machine Learning Frameworks (Tensorflow, PyTorch, etc), Data Science toolkits

Conversant with Model Training, Feature Engineering, setting up training pipelines as well as bringing models into production

Familiarity with real time streaming, distributed computing

Working proficiency and communication skills in verbal and written English.

Preferred qualifications

Master’s degree, further education or experience in AI/ML, computer science or other technical related field.

Understanding of agriTech domain and application of technology in farming

Interest and ability to learn other coding languages as needed.

Responsibilities

Understand the agriculture and agtech domain and come up with concrete problem definitions based on observations from the field.

Design AI solutions to help farming, working with GIS and Remote Sensing data, and combining it with ground truth collected from the farms.

Design, develop, test, deploy, maintain and improve ML models.

Manage individual project priorities, deadlines and deliverables.

Enthusiastic to take on problems across the full-stack.",3.8,"UPL ltd
3.8",Bengaluru,"Mumbai, India",10000+ employees,2004,Company - Public,Farm Support Services,Agriculture & Forestry,₹100 to ₹500 billion (INR),-1
Data Scientist,-1,"• Good Knowledge on the automotive Communication protocols like CAN, Flex ray
• Sound knowledge on the Driver assistance systems (feature functions like lane departure prevention, collision avoidance etc.)
• Practical knowledge of automotive sensors like Camera, RADAR etc.
• Testing, Debugging and validation of application software as per the Requirement (in DOORS)

Additional skills: (Optional)
• Overview on Ethernet communication protocol
• Hands on with visualization tools for sensors
• Good Overview on analyzing time series data, (ASC, MAT, DAT file),
• Good knowledge on latest trends like LIDARs and multi-mode RADARs.
• Knowledge on Atlasian tools like Confluence, JIRA etc.

• Good Knowledge on the automotive Communication protocols like CAN, Flex ray
• Sound knowledge on the Driver assistance systems (feature functions like lane departure prevention, collision avoidance etc.)
• Practical knowledge of automotive sensors like Camera, RADAR etc.
• Testing, Debugging and validation of application software as per the Requirement (in DOORS)

Additional skills: (Optional)
• Overview on Ethernet communication protocol
• Hands on with visualization tools for sensors
• Good Overview on analyzing time series data, (ASC, MAT, DAT file),
• Good knowledge on latest trends like LIDARs and multi-mode RADARs.
• Knowledge on Atlasian tools like Confluence, JIRA etc.",3.4,"Mercedes-Benz Research and Development India Private Limited
3.4",Bengaluru,"Chakan, India",1001 to 5000 employees,1996,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Volkswagen, Tata Motors"
Assistant Manager - Data Scientist,-1,"With a startup spirit and 90,000 curious and courageous minds, we have the expertise to go deep with the world’s biggest brands—and we have fun doing it. Now, we’re calling all you rule-breakers and risk-takers who see the world differently, and are bold enough to reinvent it. Come, transform with us.
Are you the one we are looking for?
We are inviting applications for the role of AM, Data scientist
Role involves to think strategically about data as a core enterprise asset and assist in all phases of the advanced analytic development process
Support advanced analytical and data mining efforts which could include but not limited to clustering, segmentation, logistic and multivariate regression, decision/CART trees, neural networks, time-series analysis, sentiment analysis, topic modeling, random forests, and Bayesian analysis
Responsibilities
The scope of work includes Forecast, Prediction Models, Outlier Reporting, Payment Integrity violation identification, Adhoc analysis
Implementation of Supervised and Unsupervised model development techniques
Work with Data engineers to supervise and help institutionalize models and dashboards for Analytics team of leading Healthcare client
Develops ML models using identified features and packages
Responsible for maintenance and performance monitoring of the production environment for the Advanced Analytics team
Lead the design of complex and large-scale datasets to be used for statistical modeling and data mining.
Slice and dice through the database and come up with actionable analytical insights
Facility with one or more quantitative data analysis languages such as R, SciPy, NumPy, SQL, Python, SAS, SPSS
Experience with relational database management systems (Oracle, Teradata, SQL Server, DB2..)
Works with key stakeholders to generate and test hypotheses
Experience with contemporary big data technologies (Hadoop, HIVE, PIG, MapReduce)
Facility with one or more data analytical methods such as regression, decision trees, experimental designs, support vector machines, machine learning and text mining
Proficiency with Microsoft Office Suite
Work in a dynamic and fast-paced environment without compromising the quality
Conduct explanatory data analysis and prepare data sources to be analyzed.
Excellent domain knowledge on US Healthcare is must
Qualifications we seek in you
Minimum qualifications
Bachelors or Master’s degree with specialization in statistics, applied mathematics, economics, finance, computer science or Information systems/science; Preference given to candidates with demonstrated academic achievement in core subjects and proficiency in quantitative subject matter (Advanced Statistics coursework, Predictive Modeling projects). Familiarity with PBM or Healthcare industry.
Relevant Healthcare domain experience
Preferred qualifications
Solid communication skills with exposure to direct client communication is preferred

Genpact is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. Genpact is committed to creating a dynamic work environment that values diversity and inclusion, respect and integrity, customer focus, and innovation. For more information, visit www.genpact.com. Follow us on Twitter, Facebook, LinkedIn, and YouTube.",3.6,"Genpact
3.6",Gurgaon,"New York, NY",10000+ employees,1997,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"Accenture, IBM, Capgemini"
Data Scientist,-1,"Capable in creating analytics pipelines to pre process, visualize and create machine learning models using at least two of R/SAS/Python
Should have at least working knowledge of SQL and RDBMS
Should have worked on/lead projects using statistical analysis/regression/clustering/other supervised and non-supervised learning algorithms using R/SAS/Python - should have sound basics in Statistics and Machine learning.
Should have experience in working with clients in gathering the requirements and handling client queries
Should have a knack for Problem Solving using technology
Should be capable of working under tight deadlines independently",4.2,"Data Semantics
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,2012,Company - Private,IT Services,Information Technology,₹100 to ₹500 billion (INR),-1
Data Scientist,-1,"Responsibilities
Â· Selecting features, building and optimizing classifiers using machine learning techniques
Â· Data mining using state-of-the-art methods
Â· Extending companyâ€™s data with third party sources of information when needed
Â· Enhancing data collection procedures to include information that is relevant for building analytic systems
Â· Processing, cleansing, and verifying the integrity of data used for analysis
Â· Doing ad-hoc analysis and presenting results in a clear manner
Â· Creating automated anomaly detection systems and constant tracking of its performance

Â· Closely working with Maritime AnalystsÂ
Skills and Qualifications
Â· Excellent understanding of algorithms, SVM, Decision Forests, etc.
Â· Good scripting and programming skills in Python, Tableau and MS Excel
Â· Proficiency in SQL
Â· Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Â· Good communication skills
00-3.00 Years
Masters in Arts (M.A), Bachelor of Commerce (B.Com), Master in Computer Application (M.C.A), Bachelor of Science (B.Sc), Post Graduate Programme in Management for Executives (PGPX), Masters in Technology (M.Tech/M.E/M.Sc), Master OF Business Administration (M.B.A), Bachelor Of Technology (B.Tech/B.E), PGDM, Master of Commerce (M.Com)",-1,Wade Maritime Consultants Private Limited,Chandigarh,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"1. Design, develop, test, deploy, maintain & document innovative solutions for challenging problems with robust, scalable, reusable, efficient, production-quality software
2. To identify, propose and build infrastructure, large-scale data pipelines, data storage strategy, common libraries and useful tools needed to manipulate data so as to create inputs for deep learning algorithms
3.Perform statistical analysis and fine-tuning using test results
4.Train and retrain systems when necessary
5.Extend existing ML/DL libraries and frameworks
6.Understanding of data structures, data modeling, and software architecture
7.Deep knowledge of maths, probability, statistics, and algorithms
8.Ability to write robust code in Python, Java, and R
9.Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
10. Keep abreast of developments in the field
11.An intense sense of ownership, initiative-taking, and a can-do attitude
12.Great attention to detail and a data-driven approach to problem-solving

1.00-5.00 Years",3.4,"Verzeo Edutech Private Limited
3.4",Bengaluru,"Brooklyn, NY",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Position: Data Scientist (Intern)
Status: Open
AGNIK is hiring a Data Science Intern with some background in the following areas and strong motivation. Candidates must have:
1) Familiarity with Machine Learning, Data Mining, Statistics, and Signal Processing
2) Some Experience in Programming in C++/Java/Distributed Programming
3) Pursuing a Degree in Electrical Engineering, Math, Physics, Statistics

Positions do not require US citizenship but the candidates should be authorized to work in the United States. If you are interested, please send resume to jobs@agnik.com with ""Application for Data Science Intern"" in the Subject line.",4.8,"Agnik
4.8",India,"Columbia, MD",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,₹10 to ₹50 million (INR),-1
Data Scientist,-1,"Overview


Elevate is recruiting a Data Scientist to play an integral role in providing service offerings to our esteemed Fortune 500 existing and prospective customers. As a Data Scientist, you will model complex datasets, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques in the legal industry.

Responsibilities & Qualifications


You Might be the Right Person if….
You enjoy working in a fast-paced, entrepreneurial environment
Strong knowledge in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval
Four years of professional experience working as a Data Scientist
Experience with command-line scripting, data structures and algorithms and ability to work in a Linux environment, processing large amounts of data in a cloud environment
Specifically, you will….
Build NLP solutions & products for client
Develop & design Chatbot ,design web services, testing and maintenance of the delivered solutions
Delivery of solutions aligned with project team expectations, on time, within budget, and with anticipated business value
Design and develop plug and play solutions and data integrations across multiple channels
Develop & design prototypes in the space of text , voice & image analytics
Work on proposals & rfp
Mentor & guide junior team members
Analyze and model structured/unstructured data using advanced statistical methods and implement algorithms and software needed to perform analyses
Skills for Success
Strong background in Natural Language Processing
Must have in depth knowledge of NLP Concepts- WordNet, POS Tagging, Lemmatization NP Chunking, Syntactic and Dependency Parsing, Reference Resolution, Clustering, Categorization, Topic Analysis, Summarization, NER
Strong theoretical & practical knowledge of Machine Learning Algorithms
Must have experience in developing chat bots using open source and cloud based api’s
Strong knowledge of Deep learning models like LSTM, CNN, and RNN etc.
Experience in developing models on cloud platform
Experience in developing machine learning models on platforms like tensor flow, keras, pytorch etc
Background and knowledge on Redis and Elasticsearch
Expertise in python programming
Experience with Linux OS, Docker, Kubernetes
Extremely deft at problem solving and algorithm development skills for high level business problems
Understanding of new & emerging technologies/tools related to search, data mining, information storage and retrieval, and product design/development
Strong experience in translating business requirements into prototype design
Good communication & client handling skills
Good to have experience in Image & Voice analytics
Good understanding of the SDLC and Agile Methodologies
Good to have understanding of UI development
Experience
Four years of professional experience working as a Data Scientist
Qualifications
UG: B.Tech/B.E. - Any Specialization
PG:M.Tech CS, MCA - Computers, MS/M.Sc(Science)
Company Information


Elevate is the law company. We provide consulting, technology and services to law departments and law firms. The company’s legal, business and technology professionals extend and enable the resources and capabilities of customers worldwide. Elevate’s achievements and distinctions include:
Winner of The American Lawyer Industry Awards Best Alternative Legal Service Provider of the Year 2019
Winner of British Legal Awards Alternative Service Provider of the Year 2019
Winner of IACCM Innovation and Excellence Awards 2019 - Outstanding Service Provider (Americas and Global)
Ranked as a top Global Services Provider by Chambers & Partners five years in a row.
Learn more at https://elevateservices.com,

https://www.sumatigroup.com/

See more jobs at https://elevateservices.eightfold.ai/careers

Follow us on social media

https://www.linkedin.com/company/elevate-services

https://twitter.com/ElevateServices",3.5,"Elevate Services
3.5",Chandigarh,"Los Angeles, CA",1001 to 5000 employees,2011,Company - Private,Legal,Accounting & Legal,₹5 to ₹10 billion (INR),-1
Data Scientist,-1,"Data Scientist

About the job

We are looking for a data scientist to help us discover the information hidden in vast amounts of data and help us make smarter decisions to deliver even better products. Your primary focus is to apply data mining techniques, doing statistical analysis, and building high-quality prediction systems integrated with our products.
Responsibilities
Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques, and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Requirements
5-7 years of experience manipulating data sets and building statistical models, has a Masters or Ph.D. in Statistics, Mathematics, Computer Science or another quantitative field
Strong problem-solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SLQ) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, and more) and their real-world advantages/drawbacks.
Understanding of advanced statistical methods and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
Familiar with the following software/tools:
Coding knowledge and experience with several languages: C, C++, Java,JavaScript, and more.
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, and more.
Experience querying databases and using statistical computer languages: R, Python, SLQ, and more.
Experience using web services: Redshift, S3, Spark, DigitalOcean, and more.
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, and more.
Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, and more.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, and more.
Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, and more.
Job Type: Full time
Job Location: Technopark, Trivandrum",4.5,"NetObjex
4.5",Thiruvananthapuram,"Irvine, CA",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Science Expert,-1,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc. upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning

Role and Responsibilities

upGrad is looking for people passionate about Data Science & Machine Learning and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow. The job will include the following responsibilities:
Delivering online & offline live sessions and providing guidance to students.
Preparing content for live sessions and aligning it with the recorded modules.
Plan and execute student competency assessment and engagement.
Be the interface between faculty (both academic and industry leaders) and student, to make the student’s online learning experience more engaging.
Vetting and onboarding external/freelance subject matter experts.
What we are looking for

Graduates/Post Graduates with:
Work Experience/Training experience of 2 to 5 years in Data science & machine learning roles.
Machine Learning Concepts - SVM, Recommendation systems, Random Forests, Logistic Regression, Bagging and Boosting, Linear and Nonlinear models, Bayesian theory, etc
NLP, NN and Computer Vision.
Advanced skills in SQL/MySQL.
Advanced programming skills using Python
Experience in the development of ML models at scale and knowledge of its application across sectors.
Smart, curious people who enjoy learning and upskilling in the latest fields of technology.
Ability to quickly learn various concepts, techniques & tools.",3.3,"upGrad Education Private Limited
3.3",Mumbai,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
Data Scientist,-1,"RESPONSIBILITIES
To analyse data and support the development of technology tools relevant for the development sector. Work on creating data insights on developmental and public policy issues with a focus on providing knowledge support to policy makers and informing public discourse.
Support in providing data analytics for all data and technology related projects esp. Jaano India.
Use multivariate statistical analysis to analyse data and produce detailed project reports. Ensure data integrity and consistency across relevant data systems. Making recommendations for solving some of these real world problems.
Collecting, cleaning and maintaining data from Open Government Datasets. Data from all major government schemes and departments must be maintained in a structured data warehouse and updated regularly.
Analysis of cleaned data to identify patterns, correlations and infer meaningful conclusions. Thereafter, presenting them in a visually lucid manner to various stakeholders and policymakers through Swaniti’s Jigyasa portal.
Creating data packages for standardized and customized research output for use of Members of Parliament, Members of Legislative Assembly and Civil Servants.
Conceptualize and create standalone data visualizations and info-graphics on development and governance issues for dissemination to media outlets and general public
Analyzing and interpreting primary level data for Swaniti’s micro planning projects to identify key patterns for national and state level policy making.
If needed provide inputs for knowledge consultations and/or the Jigyasa platform.
QUALIFICATIONS
Graduate degree in any field with courses in Statistics, Econometrics or any data-related subjects. Those with advanced degrees will be given preference.
At least 2 years of active work experience in the public or private sector with a role dealing directly with data cleaning, analysis and visualizations.
SKILLS

Required

The Data Scientist will be expected to have a demonstrated record of being a ‘problem solver’ with ability to analyse big data, and commitment to working on policy and developmental challenges in India.
Familiarity with handling database systems like MySQL and Hive.
Proficiency in Python and Java. Familiarity with packages/libraries used for data manipulation and plotting (eg – numpy, panda, scikit-learn)
Understanding of statistical concepts involving descriptive and inferential stats, hypothesis testing, confidence intervals and sampling, clustering and classification.
Knowledge of common machine learning algorithms, from dimensionality reduction to supervised and unsupervised techniques.
Excellent working knowledge of MS Excel
Strong leadership skills, excellent people and team skills and a constant willingness to learn.

Recommended

Proficiency in R, Python, SAS, SPSS and/or STATA.
Familiarity with MongoDB, Hadoop, Spark.
Understanding of linear algebra concepts such as matrix manipulations, Eigen values and vectors and multivariable calculus.
Knowledge regarding government policies, schemes and their implementation.
Ability to write complex Macros in Excel.",3.9,"Ank Aha
3.9",New Delhi,"New Delhi, India",1 to 50 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Position: Data Scientist

About us: WebMD Health Corp., an Internet Brands Company, is the leading provider of health information services, serving patients, physicians, health care professionals, employers, and health plans through our public and private online portals, mobile platforms, and health-focused publications. The WebMD Health Network includes WebMD Health, Medscape, Jobson Healthcare Information, prIME Oncology, MediQuality, Frontline, QxMD, Vitals Consumer Services, MedicineNet, eMedicineHealth, RxList, OnHealth, Medscape Education, and other owned WebMD sites. WebMD®, Medscape®, CME Circle®, Medpulse®, eMedicine®, MedicineNet®, theheart.org®, and RxList® are among the trademarks of WebMD Health Corp. or its subsidiaries.

Aptus Health is a wholly-owned subsidiary of WebMD. As the analytics arm of Aptus Health, we help our clients and our products realize their potential. Helping understand customer behaviour and traits is at the core of what we do. A team of 8 members, we are analogous to a start-up centre with hands-on responsibility for every member.

Role & Responsibilities:


The selected candidate will work on the following:
• Work with real-world case studies in Data Science and a chance to implement various modeling techniques
• Get real-life experience of working with big data in the digital marketing sphere.
• Opportunity to independently execute and lead analytical projects and assignments
• Help solve some challenging Healthcare related digital marketing problems globally. Transform business question into data requirements; collect and merge the data; analyse the data, link it to the business reality and present the results
• Develop predictive models and machine learning algorithms to study the change in physician prescribing behaviour as well as WebMD integrated campaign response behaviour. Build analysis to understand user engagement and behaviours across various WebMD products.
• Build expertise in data preparation, data visualisations and transformations through SAS, R, Tableau and other analytical tools.

Technical Skills needed:
• Experience with data manipulation in SQL environment is a must. Knowledge of Snowflake data warehousing is good to have

• Experience with statistical and data manipulation tools such as SAS or R is a must • Need very good expertise in using Microsoft Excel, and Microsoft PowerPoint. Excellent presentation skills required

• Experience developing statistical models like hypothesis testing, regression models, classifications models, forecasting etc is a must

• Algorithm designing and implementation skills in R or Python is required

Requirements:
• B.Tech/B.E. / MSc Statistics from premier institutes with minimum 80% marks in 10th and 12th grade
• 1.5-2.5 years of relevant work experience in Analytics field",3.4,"Aptus Health
3.4",Mumbai,"Reading, MA",201 to 500 employees,2008,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Scientist,-1,"PipeCandy is a 'one of its kind', 'data science' driven market intelligence platform that tracks the global eCommerce landscape. Our insights are used by well known global brands and startups. We are venture funded by India, the US, and Singapore based investors.

About the Role:
We are building a complex data product that aims to revolutionize industry intelligence by applying sophisticated machine learning & AI algorithms on millions of data points.
We are looking for a Data Scientist to ensure that the quality of this product always stays top-notch and world-class. If you love working with data, have an eye for detail and a strong adherence to quality then we’d love to hear from you.

This is a senior position where the analyst will work under the general direction of the Chief Data Scientist and senior staff in the Data Management team. The primary responsibility is to treat data as an asset and become the expert source for data standards and policy-related questions.

Key Responsibilities:
Manage the creation, deployment, and maturity of data governance processes and technology including master data, metadata, and data quality initiatives
Identify opportunities to ensure transparent, high-quality data across sources and platforms
Review, clean and add business records and formatting rules to every taxonomy/hierarchy in the product database in support of long-term data governance.
Develop processes and tools for data cleansing, de-duplicating, and other data preparation, standardization, and transformation
Collaborate with various teams to standardize data and ensure adherence to data ingestion and governance standards
Conduct root cause analysis and proposed improvement solutions
Leverage subject matter expertise to ensure data products are understood by the business users
This position requires a proficient level of experienced analytical and programming capabilities, defining requirements, developing and/or maintaining computer applications/systems, and ability to meet business needs within deadlines.

Here’s what we’re looking for in you:
Works to develop analytical/ data mining/ machine learning models using Python, R and other tools
Gather, evaluate and document requirements, ability to build an algorithm (statistical/ data mining/ machine learning) based on requirements and specifications provided
Works with data and is able conceptualize and improvise analytical solutions to problems
Ability to deploy analytical algorithms within a larger business application
Ability to visualize data and results of data analysis & analytical models
Create model documentation as per client/ regulatory standards

Qualifications & Competencies Required:
1+ years of total relevant experience
Degree in a quantitative field (Math, Statistics, Economics, Physics, and/ or Engineering, MBA)

Desired:
Ability to work with business and technology teams to build and deploy an analytical solution as per needs
Ability to multi-task, solve problems and think strategically
Strong communication and collaboration skills

Skills Required:
Experience with statistical analysis using R and Python. Experience with Spark and ML as plus
Good experience in data discovery, exploration and algorithm development
Experience with working on large data sets and developing scalable algorithms
Hands-on experience of machine learning and data mining algorithms such as decision trees, classifiers, text mining/ NLP, clustering, and regression
Exp in SAS, SPSS, or scripting languages such as Java a plus
Knowledge of Hadoop and other distributed computing platforms
Broad knowledge of data mining, NLP algorithms, machine learning algorithms and other techniques technologies
Strong analytical and problem solving skills
Excellent presentation and communication skills

Perks:
Flat organization structure with an opportunity to work very closely with the founders
Access to learning, training sessions outside of your immediate line of work
Access to group kindle account with latest titles
Stocked pantry, of course",4.6,"PipeCandy
4.6",Chennai,"Walnut, CA",1 to 50 employees,2016,Company - Private,Internet,Information Technology,₹100 to ₹500 million (INR),-1
Data Scientist,-1,"Sentieo is powering the future of financial and corporate research in a $30B market. Our vision is to create a world where competitive organizations have the insights they need to win. Built by former hedge fund analysts, we empower competitive investors and corporations to rapidly discover insights so they can make smarter investments and execute winning strategies. Supporting a global customer base of over 900 clients, we are excited to propel Sentieo into the next phase of our company’s global growth - from advanced, unprecedented product development to accelerated team scaling and expansion. Join our team as we reimagine the future of fintech.

We are looking for a Senior Data Scientist to mine our vast database of 30 Million+ financial documents in order to develop tools that make our users better investors. You will be joining a small(but growing team) where you will have a major voice in deciding which projects to undertake. We'relooking for individuals who are excited about the opportunity to build data science tools that can give investors an edge. NLP + Investing/Quant experience is a major plus.


What you'll do:
-Selecting and engineering features to build and based on mining of our large text and
financials database.
-Prototyping/Testing algorithms to help inform us what to build.
-Training and tuning a variety of machine learning models.
-Data mining using NLP & state-of-the-art methods.
-Enhancing data collection procedures to include information that is relevant for building analytic systems.


What you'll bring:
-Knowledge and hands-on working experience with ML techniques and tools.
-Strong understanding of basic statistics concepts including population, confidence intervals,correlation, significance,probability,distributions, hypothesis testing, etc.
-Strong grounded concepts and application knowledge of ML techniques including
linear/logistic regression,decision trees,classification,clustering,ensembles,text mining to build models.
-Hands-on experience with Python and familiarity with machine learning frameworks.
-Comfortable with data visualization tools like pandas,seaborn and matplotlib.
-Ability to work independently and collaboratively within a team.
Life at Sentieo:
-Join a fun & tight-knit team that values transparency and is serious about building and maintaining a great culture.
-Comprehensive health benefits.
-Flexible vacation & sick policy.
-Daily Breakfast and unlimited snack food.
-Fun team outings (offsites, happy hours, etc.).

EEO

Our company values diversity and believes diverse teams make innovation possible. We work on complex, difficult problems with no linear or clear solutions. We believe that a diverse team can bring different perspectives and approaches, and whose experiences reflect the full set of clients we seek to serve. As such, Sentieo is committed to a diverse representation among our employees.",4.3,"Sentieo
4.3",New Delhi,"San Francisco, CA",51 to 200 employees,2016,Company - Private,Financial Analytics & Research,Finance,₹500 million to ₹1 billion (INR),"Bloomberg L.P., FactSet, S&P Global Market Intelligence"
Data Scientist,-1,"For Data Scientist Developer role:
1.Strong programming skill in C++, Object orientated programming and File based Design.
2.Hands-on experience of video Surveillance domain and algorithms evaluation / Testing [AI/ML/Deep learning domain]
3.Familiar with the Linux platform based development
4.Python/Go programming expertise â€“ highly preferred
5.Familiarity with Kaffe, tensor flow is very useful for C++ with python candidates

For QA / Automation Testing role:
1.Strong knowledge in Test Requirement analysis and Design, reviewing software requirements and preparing test scenarios and executing tests on software usability [AI/ML/Deep learning domain].
2.Good Knowledge in Automation using Python, JS Scripting.
3.Hands-on experience of video Surveillance domain and algorithms Testing/evaluation using different automation tools and standard compliance check.
4.Preparing reports on all aspects related to the software testing carried out and reporting to the design team.
5.API testing experience, testing of deep learning machine learning systems is very useful for testers.

4.00-9.00 Years",3.6,"Wipro Limited
3.6",Bengaluru,"Bengaluru, India",10000+ employees,1945,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Cognizant Technology Solutions, Tata Consultancy Services, Accenture"
Data Scientist,-1,"Analytics

Data Scientist

Pune, Maharashtra, India
APPLY

Job title

Data Scientist
Department

Analytics
Report To

NA
Work Location

Pune

It’s Time For A Change…

Your Future Evolves Here

Evolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Our pursuit of this mission is the driving force that brings us to work each day. We believe in embracing new ideas, challenging ourselves and failing forward. We respect and celebrate individual talents and team wins. We have fun while working hard and Evolenteers often make a difference in everything from scrubs to jeans.

Are we growing? Absolutelyabout 40% in year-over-year revenue growth in 2018. Are we recognized? Definitely. We have been named one of “Becker’s 150 Great Places to Work in Healthcare” in 2016, 2017, 2018 and 2019, and One of the “50 Great Places to Work” in 2017 by Washingtonian. If you’re looking for a place where your work can be personally and professionally rewarding, don’t just join a company with a mission. Join a mission with a company behind it.

Who You’ll Be Working With:

You’ll join a team of data scientists, analysts, and software engineers working to push the boundaries of data science in health care. We like to experiment, iterate, and innovate with technology, from developing new algorithms specific to health care’s challenges, to bringing the latest machine learning practices and applications developed in other industries into the health care world. We know that algorithms are only valuable when powered by the right data, so we focus on fully understanding the problems we need to solve, and truly understanding the data behind them before launching into solutions – ensuring that the solutions we do land on are impactful and powerful.

What You’ll Be Doing:
Research, conceptualize, and implement analytical approaches and predictive modeling to evaluate scenarios, predict utilization and clinical outcomes, and recommend actions to impact results.
Manage and execute on the entire model development process, including scope definition, hypothesis formation, data cleaning and preparation, feature selection, model implementation, validation and iteration, using multiple data sources.
Provide guidance on necessary data and software infrastructure capabilities to deliver a scalable solution across partners and support the implementation of the team’s algorithms and models into Evolent’s product offerings.
Contribute to the development and publication of white papers showcasing Evolent’s leadership in healthcare data science.
Collaborate with stakeholders from clinical, operations, and product teams to identify advanced analytics opportunities to add value to Evolent’s solution offerings.
Leverage clinical and administrative data to support other business needs related to clinical program improvement, networks optimization, and other strategic initiatives.
The Experience You’ll Need (Required):
Master’s Degree with a quantitative focus (e.g. data science program, software engineering, statistics, mathematics, computer science, health services research).
3-6 years of professional experience in an analytical field related to health service analytics, predictive modeling in health care, or other health care-related experience.
Strong technical abilities with advanced data and analytics tools and programming languages, including Python or R, and at least one database language such as SQL or Mongodb.
Foundational understanding of core concepts in applying machine learning algorithms: data cleaning, feature selection, and parameter tuning.
Strong communication skills, including both communicating with other stakeholders to fully evaluate project requirements and context, as well as communicating project results, findings, and applicability.
Ability to work independently with little technical guidance day-to-day, in a fast-paced environment.
Finishing Touches (Preferred):
Experience in SAS, SAS/CONNECT, and disparate programming language integration techniques
Proficiency in most areas of mathematical analysis methods, statistical analyses, predictive modeling, and/or machine learning (such as neural networks, random forests, gradient boosting, etc), and in-depth specialization in some areas.
Working knowledge of analyzing administrative medical claims, pharmacy claims, and/or EMR data and clinical data.
Proficiency with git or other version-control software, especially in collaboration with others.
Proficiency working at the command line / shell.
Experience in reporting and visualization tools such as R’sggplot, Python’s bokeh, Tableau, MSTR, or geo-mapping tools.
Experience building and/or using APIs.
Work Environment: The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. This position primarily works in a climate controlled based setting.The noise level and the work environment are moderately quiet. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines

Physical demand: Include the physical demands of the job, including bending, sitting, lifting and driving. For example, while performing the duties of this job, the employee is regularly required to talk or hear. The employee frequently is required to stand; walk; use hands to finger, handle or feel; and reach with hands and arms.

Why Join Evolent?Evolent Health developed an integrated value-based care platform for payers and providers. The company created an internal recognition program that encourages departments to acknowledge outstanding achievement as well as focusing on philanthropic values. The company spent four weeks in 2018 giving back to more than 60 local charities and engaged 3,700-plus employees to participate. Evolent provides healthy snacks and drinks in most of its offices as well as an in-office gym at its headquarters and workstations that include treadmill desks. In 2016, the company launched its diversity and inclusion committee that promotes unconscious bias training and established several business resource groups. In 2017, Washingtonian Magazine named Evolent among the 50 Great Places to Work.

APPLY",2.9,"Evolent Health
2.9",Pune,"Arlington, VA",1001 to 5000 employees,2011,Company - Public,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),-1
Data Scientist,-1,"Location: Chennai, Mumbai, Bengaluru - India
1+ years of Analytics experience
Understand business requirements and technical requirements
Can handle data extraction, preparation and transformation
Create and implement data models
write to careers@ganitinc.com",3.0,"Ganit
3.0",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Technical Skills:
A Ph.D., (or master’s degree plus at least 8 years’ relevant experience), in Computer Science, Statistics, Linguistics, Mathematics, Economics, Physics, or a related scientific discipline.
5+ years of experience working with large datasets for drawing business insights.
Research experience and coursework in Machine Learning
Experience with statistical software (e.g. MLlib, R, pandas) and database languages (e.g., SQL)
Fluency in Scala/Python programming.
Experience identifying business problems and selecting/finding the most appropriate data sets and statistical models to formulate solutions.
Experience with large data sets.
Strong understanding of statistics and modeling techniques.
Desire to work in a highly collaborative environment.
Experience with Natural Language Processing, Information Retrieval, or Recommender Systems.
Experience with distributed computing, such as Hadoop, Spark, or related technologies would also be an added advantage.
Experience with mathematical optimization, control theory, time-series analysis would also be an added advantage.

Additional Skills:
A strong work ethic and the ability to manage yourself and your time
Outstanding teamwork skills
Excellent written and verbal communication skills as well as active listening skills
Demonstrated analytical abilities
Experience managing and/or mentoring junior developers
Experience with Agile/SCRUM development methodologie",4.8,"Firminiq
4.8",Chandigarh,"Buffalo Grove, IL",51 to 200 employees,2018,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Data Scientist,-1,"Data Scientist ( > 4 years experience ) :
Should be highly skilled in using deep learning algorithms and have expertise on tweaking them for Dunzo specific problem statement
Should be able to program in python. Should be highly skilled in this.
Should have experience in formulating problem statement and decide what data can help in solving the problem.
Should have overall idea on how to put machine learning models into production. Although there is no need to work on this directly, it is important to guide data engineering and backend team for getting desired results
Should be able to communicate with business and other stakeholders for understanding problems for producing possible solutions. Should give demos for proof of concepts(poc)
Should be interested in learning about advancements in deep learning field and going through research papers and latest updates of the field.
Should have skills in using pandas,numpy, scipy, sklearn, spacy, nltk, keras/pytorch/tensorflow and familiar in using gpu machines for training purpose
Should have an attitude of owning the problem and generating industry standard solutions and ultimately reach to state of the art solutions to the problems.
It will be really great if presenting at tech conferences is one of the interests. Also, we encourage you to write on tech blog. This part is optional",3.3,"Dunzo
3.3",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Description :
We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products like: automate scoring using machine learning techniques, build recommendation Engines/systems, optimize and extend the features used by our existing classifier, etc

Responsibilities:
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company's data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Develop hypotheses and test carefully by experience; develop and improve predictive modeling algorithms; understand and work around possible limitations in models.
Analyze large datasets to produce statistical models and prediction tools.
Visualize, interpret, report, and communicate data findings creatively in various formats to various stakeholders.
Conduct critical data analysis and prepare data sources to be analyzed.
Discover patterns, find meaning and produce actionable intelligence. Work both autonomously and collaboratively when necessary in a fast-paced, competitive, multidisciplinary environment.

Desired Skills and Qualifications:
Excellent understanding of machine learning techniques and algorithms
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig etc
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Data-oriented personality
Proficient at translating unstructured business problems into an abstract mathematical framework.
BE/BTech/MCA/MTech/MSc in Computer Science
Some development experience in at least one scripting language (Julia, Python, R...).
Ability to initiate and drive projects to completion with minimal guidance.
The ability to communicate the results of analyzes in a clear and efficient manner.
Highly collaborative and curious.
Experience with any big data framework would be a plus.
2-7 years experience

Important:
Should be able to appear for personal interview in our office at Navi Mumbai. Do not apply if you can not appear for personal interview. No telephone round will be conducted.
00-7.00 Years",4.4,"Allerin Tech Private Limited
4.4",Mumbai,"Mumbai, India",51 to 200 employees,2006,Company - Private,Computer Hardware & Software,Information Technology,₹100 to ₹500 million (INR),-1
Data Scientist,-1,"Experience : 2+ years

What will you do:
Should have working knowledge of relational Database designs (SQL Server, MySQL, Oracle).
Should have knowledge of Queue management systems (Redis, MSMQ, RabitMQ etc).
Should have knowledge of SQL query, Stored Procedures, Functions.
Should have knowledge of No SQL will be an added advantage.
Shall analyze, define and document system requirements for data, workflow, logical processes, interfaces with other systems, auditing, reporting requirements and production configuration.
Shall write and maintain functional and technical specifications.
Shall create scripts and packages for data integration, data maintenance or bug fixes.
Shall analyze code for problem resolution and performance optimizations.
Shall write SQL statement for ad-hoc report generation.

What we can offer
Are a young organization and the workplace is an extension of our families back home
Mondays and Fridays have the same effect on us
Value positive vibes, honesty, sense of judgment, empathy and self-motivation
Believe in experimentation and don't think of new things as daunting enough to take up at any point in time
Are looking for driven and focused individuals
Will be more than happy to hear from you
We want to hear from you
Why don't go ahead and send us a video clip of yourself, giving us a creative brief of who you really are.Once you're done with that, jobs@bookmyshow.com :).",4.2,"Bigtree Entertainment Pvt.Ltd.
4.2",Mumbai,"Mumbai, India",201 to 500 employees,-1,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1
Data Scientist,-1,"Primary role

Staying abreast with the latest techniques and algorithms used in data analytics and overseeing their adoption by delivery teams. Leading in house efforts in researching newer and novel analytics methodologies. Expected to be actively involved in all stages of solution delivery to the client.

Secondary role

Mentoring junior staff.

Basic skills

An expert in any two or more of the following; Machine learning, Operations research, Agent based modeling, game theory, statistics or similar methodologies.

A strong experience with at least one of the following; R, Matlab, SAS, SPSS or similar packages.

A basic knowledge of one of the following; Python, C/C++, Java.

Preferred skills

Experience with analyzing actual business data.

Domain knowledge of industry verticals (such as healthcare, telecom etc.)

Education

PhD or MS (with peer reviewed publications) in a quantitative field, such as Physics, Machine Learning, Artificial Intelligence, Statistics, Mathematics, Engineering, etc.

If interested, kindly send your cv on hr@gaugeanalytics.com",3.1,"Gauge Data Solutions
3.1",Noida,"Noida, India",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Data Scientist (NLP),-1,"Job Description:
1. 5+ years of Hands-on Python/R/JAVA programming skills
2. Hands-on working experience in deep NLP Learning algorithms experiences in unstructured text data analysis across industries. The added advantage would be experienced with Stanford Parser and document analysis.
3. Experience in platform development, distributed computing
4. Competence with Agile Development approach
5. Exposure in working with Linux computing environment is plus
6. Deep understanding in information retrieval, computational linguistics
7. Engineering ability to build robustly scalable pipelines

Job Responsibilities:
1. Build product capabilities to analyze documents and data on a large scale.
2. Ability to deliver :
a. Next-generation analytics platform deployed on private and/or public cloud
b. Front-end web applications and back-end services that integrate with other products.
c. High-performance processing with robust analytic data pipeline
3. Research and evaluate different approaches to NLP problems
4. Ability to work in a multi-disciplinary team with a strong product focus
5. Automate and streamline existing processes, procedures, and toolsets whenever needed

Note: Minimum 3 years of work experience with NLP is mandatory.",4.0,"Visible Alpha
4.0",Mumbai,"New York, NY",501 to 1000 employees,2011,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,"Morgan Stanley, UBS, Credit Suisse"
Data Scientist,-1,"Description
BizViz provides a 360 degree view of a business's data, serving any vertical and meeting the demanding needs of all business executives. With a 50+ strong team building the BizViz platform over several years, it is targeted at creating technological solutions that will give our customers the edge they need to succeed.

We strongly believe that our success lies in the success of our customers. We aim to build applications the way they envisioned, keeping each business' unique ideas and requirements in mind. We offer businesses a better alternative to using standard cookie-cutter ERP templates.

Job Summary
Design and execute statistical analysis, modeling, and simulation efforts for clients that lead to actionable decisions affecting operations. Analyze data sets to summarize, identify trends, predict future states, and characterize uncertainty. Author complex written products documenting study results. Apply analytical approaches using statistical programming languages, including Python, SAS, and R. Work closely with teammates from non-mathematical disciplines to ensure that operational strategies are considered in the context of applying statistical theory. Use statistical theory on modeling, simulation, and data analysis to deliver measurable improvements to organizational policies and programs.

Responsibilities
Engage in data mining, algorithm development, statistical analysis, regression, and machine-learning initiatives
As part of ongoing work and interaction with the broader team, identify new opportunities to use modeling and advanced analytics to drive business value
High Proficiency in SQL
Expertise in applied statistics.
Able to translate business objectives into actionable analyses.
Able to communicate findings clearly to both technical and non-technical audiences
Expertise in at least one statistical software package such as SAS or Python and R
Experience with machine learning algorithms and predictive analytics
Natural curiosity to enjoy diving deep into the material to find answers to yet unknown questions.
Demonstrated ability to perform comfortably in a fast-paced work environment
Education, Experience, Skills and Abilities Required for Consideration as a Candidate:
PhD or MSC in a quantitative discipline: Statistics, Applied Mathematics, Operations Research, etc.
3+ years of experience in using statistical and data mining techniques to solve real business problems

Minimum of 3 years of experience in any one of the following:
Machine Learning
Data Mining
Predictive analysis
R & Python or SAS.
Passion for problem-solving, developing creative solutions, and continuous learning.
Experience in at least one of the following domain - Retail, Healthcare & Education.
Location
Bangalore & Hyderabad.",3.0,"BDB
3.0",Bengaluru,"London, United Kingdom",51 to 200 employees,1993,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Description
What will a 'Data Scientist - Data Analytics' do?
Providing a full range of Data and Analytic services(ML, Data Mining, EDA, Feature Engineering, Statistical modeling for Predictive and Prescriptive enterprise analytics) to clients across multiple sectors.
Applicants will be expected to work with a diverse set of data sources, such as time series data, spatial, graph data, semi-structured and unstructured data, and build statistical/machine-learning models in support of on-demand, real-time analytic services.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation and many other business outcomes.
Develop company A / B testing framework and test model quality.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Work with partners in Data Engineering, Product, Programmatic and business teams, to operationalize integration of analytic models into the production environment(s).
Stay current on relevant academic and industry developments to identify best-in-class algorithms, techniques, libraries, etc.

What we are looking for?

Business-minded data scientist with a demonstrated ability to deliver valuable insights via data analytics and advanced data-driven methods.
Developed intricate algorithms based on deep-dive statistical analysis and predictive data modeling.
Experience using statistical computer languages like R, SAS, Python etc.. to manipulate data and draw insights from large data sets.
Analyze and process complex data sets using advanced querying, visualization andanalytics tools.
Passion for solving unstructured and non-standard mathematical and behavioral problems
End-to-end experience with data, including querying, aggregation, analysis, and visualization.
Experience implementing Machine Learning and Deep Learning Algorithms, Data-Driven Personalization.
Excellent communication and presentation skills, being able to explain complex problems and the solutions applied.
Demonstrating data analysis and visualization with one or more leading COTS analytic and presentation solutions including Tableau, Power BI, Qlik view or Qlik Sense, and MS Excel and other MS Office suite applications.
Experience in an Agile environment (SAFe) and work within the Atlassian suite (Jira, Bitbucket, Confluence) and AWS or other computing environments.
Tools: R, Python, Spark, PySpark, Scala, Tensorflow, Keras, Big Data, AWS",4.0,"MTW LABS
4.0",Hyderabad,"Hyderabad, India",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientists,-1,"CAREERS

Data Scientists

Bengaluru, India
JOB DESCRIPTION

As a Data Scientist with Tredence, you will play a key role in translating data into insights for our clients. You will design, develop and implement processes and framework that will help our clients make sense of the data they generate, and consume the insights to make informed decisions.
THE IDEAL CANDIDATE WILL

Have the ability to handle structured /unstructured data and have prior experience in loading, validating and cleaning various types of data.
Have very good understanding of data structures and algorithms.
Have excellent coding skills in one or more of the following languages: Python, Java, C++ or R
Have thorough understanding of one or more of the following: Machine Learning algorithms, Natural Language Processing techniques, and Information Retrieval techniques
Have the ability to apply these algorithms in a professional setting.
Be accountable for measuring and optimizing the quality of algorithms.
Have good background in Math and Statistics.
Have ability to identify opportunities where data science techniques can be applied to solve business problems.
Take ownership of the end to end system from Problem statement to Solution Delivery
Preferred Skills
Experience working with Hadoop/AzureML/Hive/H2O would be an added advantage.
Experience with deep learning techniques like Theano, Torch and TensorFlow is preferred.
ELIGIBILITY CRITERIA

BE/B. Tech/MS degree in Computer Science or related quantitative field with 2-8 years or relevant experience in a team building world class applications in the areas of Predictive Analytics and Data Science.
Send your CV to careers@tredence.com",3.5,"Tredence
3.5",Bengaluru,"San Jose, CA",501 to 1000 employees,2013,Company - Private,Consulting,Business Services,₹1 to ₹5 billion (INR),-1
Data Scientist III,-1,"Description
Amazon.com strives to be Earth's most customer-centric company where people can find and discover anything they want to buy online. We hire the world's brightest minds, offering them a fast paced, technologically sophisticated and friendly work environment.

We need an expert in econometric and statistical tools to extract insights at scale by building models with our world class data systems, designing advanced new experimental methods, and investigating complex behavioral patterns.

Team Introduction
Amazon Search creates powerful, customer-focused product search solutions and technologies. Whenever a customer visits an Amazon site worldwide and types in a query or browses through product categories, our systems go to work. Our Search Engine team designs, builds, and delivers high performance, fault-tolerant, scalable distributed search engine used by millions of Amazon customers every day.

We are looking for a highly motivated Data Scientist who can help ensure our experience on Amazon Search is creating long-term value for our customers. This person will be responsible for architecting insights and systems to anticipate which features will improve customers search experience. This person will also be responsible for designing experiments and devising frameworks that measure the short-term and long-term impact of our product initiatives. Finally, this person would also derive insights using our existing data and experiments to inform new innovation and direction for Search Technologies and internal partner teams.

The ideal candidate will be an expert in the areas of data science, machine learning and statistics, having hands-on experience with multiple improvement initiatives as well as balancing technical and business judgment to make the right decisions about technology, models and methodologies. You will leverage data, experimental design, and analytics to help define new ways to evaluate, visualize and predict to understand outcome and decisions on how to improve customer engagement across customer lifecycle segments. The candidate needs experience with data science / business intelligence, analytics, and reporting systems while striving for simplicity, and demonstrating significant creativity and high judgment backed by statistical proof.

The ideal candidate should have deep expertise in the design, creation, management, and business use of large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and use appropriate statistical and econometric techniques to derive insights and recommendations to leadership. You should excel at bringing large datasets together to answer business questions and drive change.

Responsibilities Scientists at Amazon are expected to develop new techniques to process large data sets, address quantitative problems, and contribute to design of automated systems around the company. Major responsibilities include:
Measure / Quantify / Expand
· Design, size, and analyze field experiments at scale.
· Apply econometric or statistical knowledge to improve Amazon Search (using machine learning techniques is a plus)
· Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance.
· Analyze historical data to identify trends and support decision making.
Explore / Enlighten
· Formalize assumptions about how Amazon Search is expected to work.
· Given anomalies, whether anecdotal or identified automatically, deep dive to explain why they happen, and identify fixes.
Decide / Recommend
· Build decision-making models and propose solution for the business problem you defined
· Implement models based on findings in production back end systems
· Analyze A/B tests and recommend ways to making them faster and more robust
· Conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication.
· Utilize code (python or another object oriented language) for data analyzing and modeling algorithm

Basic Qualifications

· Bachelors or Masters degree in a quantitative field such as Statistics, Applied Mathematics, Physics, Engineering, Computer Science, or Economics
· 4+ years' of experience with data querying languages (e.g. SQL), scripting languages (e.g. Python, R), or statistical/mathematical software (e.g. R, SAS, Matlab, etc.)
· 2+ years of relevant working experience in an analytical role involving data extraction, analysis, and communication
· A natural curiosity and desire to learn
· Experience articulating business questions and using quantitative techniques to arrive at a solution using available data
· Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to research scientists, engineering teams, and business audiences

Preferred Qualifications

· Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment
· Experience with data visualization and presentation, turning complex analysis into insight
· Experience collaborating with software development teams, data scientists, business intelligence or other technical roles
· Masters or PhD in applied quantitative field
· Strong background in statistics methodology, applications to business problems, and/or big data.
· Ability to work in a fast-paced business environment.
· Experience processing, filtering, and presenting large quantities (Millions to Billions of rows) of data
· Experience designing experiments, and ability to infer causal relationships",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
DATA SCIENTIST,-1,"DATA SCIENTIST (Analytics & Technology)

Experience : 7+ yrs.

Location : Gurgaon & Bangalore

Qualification :Masters (preferred) or Bachelors Honors in Statistics, Economics, Computer Science, Engineering, Mathematics preferred

Technical expertise: Provide expertise in Statistics, Mathematical modeling and simulation, Numerical Analysis and Differential Equation.
Curiosity: a desire to go beneath the stated client needs and discover and distill a problem down into a very clear set of hypotheses that can be tested.
Problem solver: Ability to work with adhoc/ unstructured data and arrive at a potential business proposition and hence, be able to define and design customized business solution.
Storytelling: the ability to use data to tell a business-outcome impacting story and to be able to communicate it effectively.
Cleverness: the ability to look at a problem in different, creative ways.
Experienced in mathematical modeling and programming, statistical analysis, forecasting/predictive modeling, simulations, optimization, visualizations, machine learning, data mining, etc.
Proficiency in one or more statistical programming language, like R, SAS, WEKA or Python, and a database querying language like SQL.
Demonstrated ability of thought leadership and to work with ambiguous problem definitions, recognize dependencies and deliver impactful solutions through logical problem solving and technical ideations.
Ability to learn new analytical methods, technologies and apply in practical business problems.
Strong communication and interpersonal skills: Ability to communicate clearly and confidently with clients/stakeholders. Ability to tell a clear, concise, actionable story with data. Ability to work with multiple teams with different backgrounds.
Attitude to work in a fast paced and continuously changing environment.
Understanding of Big Data Technologies like Map Reduce and Hadoop.
Proficiency with any general purpose programming language Java/Python/C/C++.",2.7,"Melstar Information Technologies Limited
2.7",Bengaluru,"Mumbai, India",201 to 500 employees,-1,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),-1
Senior Data Scientist,-1,"Who we are:

automotiveMastermind (aM) provides U.S. automotive dealers with behavior prediction analytics software and marketing solutions to improve the efficiency of the vehicle sales process. The companys cloud-based technology helps dealers more precisely predict automobile-buying behavior and automates the creation of microtargeted customer communications, leading to increased sales and customer retention. aM was acquired by IHS Markit in 2017.

IHS Markit serves more than 50,000 key customers in more than 140 countries, including 80 percent of the Fortune Global 500. They help decision makers apply higher-level thinking to daily tasks and strategic issues across a host of industries and disciplines including energy, finance, automotive, engineering, technology, maritime and trade, aerospace and defense, chemical, and economics and country risk.

What you will do:
Work closely with product owners, designers, data engineers, marketing teams and others across the company to solve challenging business problems with technical expertise, curiosity and creativity
Establish necessary business and domain knowledge to correctly interpret data and results
Weave together disparate data sets and extract actionable insights to guide decisions and improve business outcomes
Bring analytical rigor and statistical methods to the challenges of measuring data quality, product performance, anticipating and interpreting the behavior of end-users
Communicate data-driven insights and recommendations to non-technical stakeholders
Own and lead projects, design and implement experiments, write production-quality code
Automate workflows and apply scientific methods to solve business and engineering problems
Who you are:
You enjoy learning new techniques and sharing your knowledge with others
You are able to work independently but have great collaboration skills
You possess a Master of Science or PhD in a quantitative discipline (e.g., statistics, operations research, computer science, mathematics, physics, electrical engineering, industrial engineering)
You claim 5+ years of related work experience in data analysis and machine learning (such as logistic regression, random forest, gradient boosting, clustering) on large datasets
You are able to demonstrate experience with the following:
Designing and implementing machine learning pipelines in production environments
Designing and implementing production-quality processes
Python and/or R, SQL, and Apache Airflow
Presenting results, insights and recommendations to executives and non-technical audiences
Other desirable experience:
Developed and implemented experimentation pipeline
Developed and implemented recommendation engine in production
Worked with micro-service architecture
Expected Hours of Work:
This is a full-time position. Generally, work is performed Monday through Friday, though holidays and weekends may be required.

We believe in equal employment opportunities:
The company provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, the company complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. The company expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of the companys employees to perform their job duties may result in disciplinary actions up to and including discharge.

-----------------------------------------------
IHS Markit is committed to providing equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by the laws and regulations in any of our locations.

We are proud to provide reasonable accommodations to applicants with disabilities. If you are interested in applying for employment with IHS Markit and need special assistance or an accommodation to use our website or to apply for a position, please contact or call +1 212 849 0399. Determination on requests for reasonable accommodation are considered on a case-by-case basis. This contact information (email and phone) is intended for application assistance and accommodation requests only. We are unable to accept resumes or provide information about application status through the phone number or email address above. Resumes are only accepted through the online application process, and only qualified candidates will receive consideration and follow-up.

IHS Markit maintains a substance-free workplace; employees may be asked to submit to a drug test (where permitted by law). In addition, as a federal contractor in the United States, the company participates in the E-Verify Program to confirm eligibility to work.

For information please click on the following links:

IHS Markit Business Code of Conduct
Right to Work
EEO is the Law
EEO is the Law Supplement
Pay Transparency Statement

-----------------------------------------------

Current Colleagues

If you are currently employed by IHS Markit, please apply internally via the Workday internal careers site.",3.6,"IHS Markit
3.6",Gurgaon,"London, United Kingdom",10000+ employees,2016,Company - Public,Consulting,Business Services,₹100 to ₹500 billion (INR),"Thomson Reuters, International Data Group"
Machine Learning Engineer - Engineering Function (Bengaluru / Remote),-1,"Following a year of rapid growth in our open-source ML projects and winning top tier customers across sectors to support strategic AI platform initiatives, Seldon expanding to find our first technical hire in Bengaluru, India!

We're looking for our first technical base on the ground to help solidify our India operation from day zero. Seldon is looking for a Machine Learning Engineer to join our Solutions Team.

About Seldon
Seldon is a London based scale-up that builds open source and enterprise machine learning frameworks that power massive scale deployments of production AI systems. Our open source frameworks benefits from over 200,000 installations, and power our enterprise product Seldon Deploy, which is currently being used by some of the leading global organisations across industries such as automotive, pharma, finance, etc.

About the role
Your role at Seldon will primarily involve:
Supporting production systems at scale based on our open source and enterprise machine learning products in Kubernetes
Triaging production client deployments to ensure success for large scale production machine learning systems in critical environments
Submit bugs and patches to our open source and enterprise products to resolve issues
Contributing to our open source projects to extend their functionality
Architecting solutions for critical industry machine learning systems
Identifying & documenting best practices for ML Engineering
Optimising the performance of machine learning systems
Designing and delivering high impact solutions with top tier organisations
Contributing to global open source projects and technology conferences
Growing within a scaling startup crafting a role of your own
Required skills:
A degree or higher level academic background in a scientific or engineering subject.
Strong computer science foundations.
Strong System architecture knowledge/experience.
Familiarity with linux based development.
Experience architecting/applying technology to solve real world challenges.
Experience delivering production-level client-facing projects.

Nice-to-have skills:
Experience with Kubernetes and the ecosystem of Cloud Native tools.
Experience using machine learning tools in production.

Benefits:
Share options to align you with the long-term success of the company.
Exciting phase of fast-paced start-up challenges with an ambitious team and unlimited potential for professional growth.
Access to discounted lunches, gyms, shopping and cinema tickets.
Healthcare benefits.
Flexible work-from-home policy.

About our tech stack
Some of our high profile technical projects:
We are core authors and maintainers of Seldon Core, the most popular Open Source model serving solution in the Cloud Native (Kubernetes) ecosystem
We built and maintain the black box model explainability tool Alibi
We are co-founders of the KFServing project, and collaborate with Microsoft, Google, IBM, etc on extending the project
We are core contributors of the Kubeflow project and meet on several workstreams with Google, Microsoft, RedHat, etc on a weekly basis
We are part of the SIG-MLOps Kubernetes open source working group, where we contribute through examples and prototypes around ML serving
We run the largest Tensorflow meetup in London
And much more

Some of the technologies we use in our day-to-day:
Go is our primary language for all-things backend infrastructure including our Kubernetes Operator, and our new GoLang Microservice Orchestrator)
Python is our primary language for machine learning, and powers our most popular Seldon Core Microservices wrapper, as well as our Explainability Toolbox Alibi
We leverage the Elastic Stack to provide full data provenance on inputs and outputs for thousands of models in production clusters
Metrics from our models collected using Prometheus, with custom Grafana integrations for visualisation and monitoring
Our primary service mesh backend leverages the Envoy Proxy, fully integrated with Istio, but also with an option for Ambassador
We leverage gRPC protobufs to standardise our schemas and reach unprecedented processing speeds through complex inference graphs
We use React.js for our all our enterprise user products and interfaces
Kubernetes and Docker to schedule and run our services (Oliver,our Head of Engineering, gave a great talk at KubeCon on how we use these technologies)
AWS for most of our infrastructure
React for internal web dashboards
We also have two physical datacenter sites with actual cables to connect to various third parties

Logistics
Our interview process is normally a phone interview, a coding task, and 2-3 hours of onsite interviews. We promise not to ask you any brain teasers or trick questions. We might design a system together on a whiteboard, the same way we often work together, but we won’t make you write code on one. Our recruitment process has an average length of 3 weeks.",5.0,"Seldon
5.0",Bagalur,"Shoreditch, United Kingdom",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Location: Guntur or Mumbai.
Salary Rs. 60,000 to Rs 1,00,000 per month.
As a Data Scientist you will work with huge datasets, troubleshooting challenging issues with machine learning, programming and analytical techniques.

Requirements:
Strong C/C++ or Java skillsExperience building and deploying real world machine learning applications in a production environment
Previous experience of large datasets
Excellent mathematical skills
Degree educated in Computer Science or related subject

Desirable: MSc Maths, Deep Learning, HPC/GPU experience in the context of machine learning, KDB, Python, Unix, Machine Learning Frameworks
Visualization Tools: SAS VA, TABLEAU, SAP FIORI

Send your resume with cover letter to hr@coveventure.com",-1,Cove Venture,Guntur,"Scottsdale, AZ",51 to 200 employees,-1,Company - Private,Real Estate,Real Estate,₹100 to ₹500 million (INR),-1
Data Scientist,-1,"We are looking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance.
Requirements
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc (depending on specific project requirements). Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills (if you expect that the person in this role will integrate the solution within the base application, list any programming languages and core frameworks currently being used)
Data-oriented personality",-1,Hookfish,Mumbai,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Implement and support data discovery and predictive analytics models by analyzing business data.

Qualifications:
3+ years of experience with R
3+ years of experience with mahout or machine learning algorithms
1+ years of experience with deep learning libraries like TensorFlow or equivalent
Working experience with java or python
Database experience with MySQL or NoSQL database solutions
Ability to design the models to work on small to very large data sets
If interested, please send the latest CV to data@scalein.com or contact using our contact page.",-1,ScaleIn,Bengaluru,"San Jose, CA",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Experience

1 to 4 years.

Roles and Responsibilities
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Qualifications
Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
Technologies and tools needed
R, Python, SQL.",-1,CogniSure,Bengaluru,"Warrenville, IL",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Python Machine Learning & Data Science Fresher Intern,-1,"Job Summary
Developing a project on Python , Machine Learning, Data Science
Key Skills
C,C++, Python , Machine Learning, Data Science
Job Types: Full-time, Internship, Fresher
Education:
Bachelor's (Preferred)
Selection rounds:
Technical Interview
Industry:
Software Development
Work Remotely:
Temporarily due to COVID-19",5.0,"Softtronix IT Solution
5.0",Nagpur,"Nagpur, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Full Time
Gurgaon
Posted on June 3, 2020

Website
Redian Software Redian Software

Redian Software

Qualification: BS/MS/MCA, BCA in Computer Science or equivalent Experience: 3+ Years

Key Responsibilities:
Dive into the data and identify patterns
Development of end-to-end models and policy for our existing products
Development of Fraud models and fraud rule engine
Collaborate with various stakeholders (e.g. tech, product) to understand and design best solutions which can be implemented
Work on cutting-edge techniques e.g. machine learning and deep learning models
Skills Required:
Strong Mathematics Basics
Proficiency in Python, Matlab, C++ or any other AI language of choice
Demonstrated expertise in solving Data Science problems from first principles
Familiarity with relational and NoSQL databases
Experience with Unix/Linux
Good Problem solving & Analytical Skills

To apply for this job email your details to hr@rediansoftware.com.",3.9,"Cubic Web Solutions
3.9",Gurgaon,"Noida, India",1 to 50 employees,2011,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Science Engineer,-1,"Overview:
Will be responsible for promoting data science topics through the local entities; helping entities in integrating data science in their organisation; industrialize data science projects focusing on production, maintenance, monitoring, availability, performance; and manage an innovative set of data science tools (Smart Data Studio), used by data scientists across the group.

Key responsibilities:
Follow and manage the engineering aspects of industrialised Data Science projects: platforms, production constraints, connections, factory compatibility
Advise and support Smart Data Studio users
Help users regarding level 2 and level 3 issues
Help users regarding industrialized data science good practices
Contribute to documentation creation and update (wikis, tutorials, …)
Contribute to tools upgrade
Support Data Science tools development and benchmarking
Help product owner and developers to define functionalities, and prioritise the Smart Data Studio roadmap
Contribute to data science tools benchmarking and evaluation
Contribute to data science tools enhancements and new functionalities

Key skills:
Must have knowledge of machine learning (scikit-learn, MLLib, vowpal wabbit), coding (Python, Scala, R), spark (Python and/or Scala), GNU/Linux, Hadoop (administration and/or development with PIG, HIVE)
Added advantage: Knowledge of H2O, Dato, Data Science challenges track record, Git, Jenkins
Passion for learning new tools, languages and frameworks
Ability to be creative and innovation-minded
Fast adaptation to changing requirements
To work with minimal direct guidance, self-motivated and proactive
Practical, hands on approach to get results
Willing and capacity to teach and transfer knowledge to the team
English - Fluent in speaking and writing
Ability to work in a multi-cultural environment
Strong oral and written communication skills
3-5 years of relevant experience
Experienced in working in an international environment and open to overseas travel",3.3,"AXA Business Services
3.3",Bengaluru,"Bengaluru, India",1001 to 5000 employees,1999,Company - Private,Insurance Operators,Insurance,Unknown / Non-Applicable,-1
Data Scientist,-1,"The Data Scientist & Data Warehouse Expert will work on a team of highly motivated data analysts and data scientists responsible for the development, deployment and support of state-of-the-art statistical and predictive models to support a variety of business needs. The Data Scientist & Data Warehouse Expert will have experience in Oracle Business Intelligence Enterprise Edition and will lead initiatives to develop and rollout OBIEE to the ACI organization to deliver a robust set of reporting, ad-hoc queries and analysis, OLAP and dashboard functionality with rich end-user experience that includes visualization, collaborations, analysis, decision making data, alerts and more. The Data Scientist & Data Warehouse Expert is will obtain an understanding of the business domain and relevant metrics (data and what it means) in order to support our business needs. This position requires communication with stakeholders and senior leadership, issue resolution, reporting, analysis and recommendations to forecast and make business decisions. This position will work closely with Operations Leadership to communicate impacts and report on necessary issues or recommendations where there is impact to our business stakeholders.

A day in the life of this position is extremely diverse and can span across a wide variety of functions, from very simple to highly complex. Analysts are expected to manage their daily workload and have a high degree of autonomy. They are expected to respond to incoming work as well as proactively capture opportunities for improvement. Analysts will navigate multiple levels of management within and outside of the Technology Organization.
Bachelor’s Degree in Computer Science, Business Analytics, Mathematics or related field and/or equivalent experience
Strong quantitative/analytical background, 5 years of data analysis experience and data tools including Oracle Business Intelligence Enterprise Edition (OBIEE), SQL, Server Reporting Service, Excel or IBM Cognos
Experience with relational and hierarchical data base structures is preferred.
Background and experience in predictive analytics, trending, and forecasting in Payments Processing industry.
Statistical process control, analysis of variance, predictive modeling, operational research and blending business background context with statistical information experience strongly preferred.
Strategic and creative thinker with an ability to apply advanced analytics approaches to help support and grow business objectives and priorities.
Knowledge of process improvement methodologies and software development methodologies.",3.4,"ACI Worldwide
3.4",Bengaluru,"Naples, FL",1001 to 5000 employees,1975,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),-1
Senior Data Scientist,-1,"Senior Data Scientist
The Group: Morningstar’s Research group provides independent analysis on individual securities, funds, markets, and portfolios. The Research group also provides data on hundreds of thousands of investment offerings, including stocks, mutual funds, and similar vehicles, along with real-time global market data on millions of equities, indexes, futures, options, commodities, and precious metals, in addition to foreign exchange and Treasury markets. Morningstar is one of the largest independent sources of fund, equity, and credit data and research in the world, and our advocacy for investors’ interests is the foundation of our company.

The Role: As a Senior Data Scientist, you will be a leading expert and primary contributor in the implementation of Artificial Intelligence (AI) within Data Collections software applications, API’s and other data products. This role requires significant interaction with both upstream and downstream stakeholders across Technology, Data, Products, Sales/Service, and Research.

The Senior Data Scientist will transition approved Data Collections AI products from a prototype phase to a fully-fledged, scalable, and consumer service. Often, these services must be integrated into Morningstar’s platform of financial products, so that our clients can use these software tools in the investment decision-making process.

We are looking for an individual who possesses strong technical development skills, an ability to distill analyst requirements into the technical specifications for robust code, and a passion for investment research.

This position reports to the Senior Tech Manager of the Data Collection technology team.

Responsibilities:
• Design & develop enterprise solutions to be flexible, scalable & extensible.
• Improve complex data flow, data structures and db design to move to next platform.
• Be a Role Model to the team to collaborate on good object-oriented designs & domain modeling. Enforce good agile practices like test driven development, Continuous Integration.
• Build solutions that incorporate numerical techniques such as linear algebra, machine leaning, statistics, and optimization.
• Hands-on development will be an integral part of the responsibilities.
• Develop areas of continuous and automated deployment.
• Introduce and follow good development practices, innovative frameworks and technology solutions that help business move faster.
• Follow best practices like estimation, planning, reporting and improvement brought to processes in every day work.

Requirements:
• Minimum of 5 years of experience in software engineering
• An advanced degree in engineering, computer science, statistics or related field

• Expertise with either Python or Java is essential, while experience with both is desirable; other programming language skills are highly desirable. Experience with Python packages like pandas, scikit-learn, TensorFlow, numpy, NLTK is a plus.
• Basic knowledge of statistical/ML/AI algorithms
• Experience with DevOps tools (e.g. Splunk, Git, uDeploy, Jenkins, Control-M) is desirable
• Experience with Agile software engineering practices
• Experience with back-end XML, relational, and file-based databases (e.g. SQL, Postgres, Redshift, Netezza, HDFS)
• Experience developing and deploying solutions using services in the Amazon AWS ecosystem (Lambda, EC2, RDS, EMR)
• Experience with the Hadoop stack (MapReduce, Pig, Hive, Nifi, Spark) is desirable
• Experience with at least one statistical modeling language (e.g. R, MATLAB, Python)

Intermediate knowledge of statistical methods is desirable
• Familiarity with common data cleaning and munging techniques
• Familiarity with automation tools such as Puppet or Chef is a plus.
• Familiarity with data visualization is a plus (e.g. Tableau, Shiny, d3)
• Familiarity with statistical software, linear algebra, optimization, and information visualization is a plus.
• Familiarity with mutual fund, fixed income, and equity data is a plus
• Fluent in both oral and written English.

Morningstar is an equal opportunity employer.

I10_MstarIndiaPvtLtd Morningstar India Private Ltd. (Delhi) Legal Entity",4.1,"Morningstar
4.1",Mumbai,"Chicago, IL",5001 to 10000 employees,1984,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),"Thomson Reuters, FactSet, Bloomberg L.P."
Data Scientist,-1,"We are looking for a Data Scientist with experience of 3-6 years that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in building data science solutions using machine learning algorithms, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities:
Identifying the key problem in the system and proposing a solution
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Identify third party data that can be used to enhance the information gained
Processing, cleansing, and verifying the integrity of data used for analysis
Building unsupervised and supervised learning algorithms on existing data such that systems should be proactive in nature

Skills and Qualifications
3-6 years of experience with post graduate/Phd degree in mathematics, statistics, IT or Computer science from IIT/IIIT/NIT/recognized universities
Excellent understanding of machine learning techniques and algorithms, such as Random Forest, Regression, XG Boost, k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Python, Octave, Java. Excellence in at least one of these is a must.
Great communication skills
Proficiency in SQL is must.
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase will be good to have.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Data-oriented personality
To apply on this job, email your resume at alka.dhingra@magicbricks.com",3.8,"Magicbricks
3.8",Bengaluru,"Noida, India",1001 to 5000 employees,2006,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Looking for:
Strong background in Machine Learning and Statistics.
Fluency in Python and R programming language.
Good understanding of Relational & Non- Relational database and SQL.
Familiar with Tensor Flow, OpenCV and Tesseract OCR.
1-3 years of relevant experience.
Good communication skills.
Portfolio/Demoable project from previous experience.

Responsbilities:
Work on projects related to healthcare.
Build models and analyze medical data collected from healthcare devices and apps.
Build models and tools for analyzing pills and different medicine images.
Expose this data to mobile and web apps to build feature set.

Job Perks:",4.6,"Cumulations Technologies
4.6",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Locations: Bangalore, Data Science & Analytics, Mountain View, New Jersey, New York

Alphonso is a TV data company and the market leader in providing brands and agencies with verified TV audiences across all screens. Alphonso’s TV data platform processes billions of data points every day about TV content and ad viewership, in the US and internationally.

Our best-in-class automated content recognition (ACR) uses advanced fingerprinting technology to identify ads and programming on TV in real time. With the industry’s largest TV data footprint, we map ad exposure data from tens of millions of households to a broad range of third-party data sets such as demographic data, location data, transaction data, web visit data and more, all in a privacy-safe fashion, to help brands understand consumer behavior across the digital and offline realms.

We are looking for data scientists / ML engineers who go above and beyond textbook solutions; critical thinkers who apply their expertise to solve unique problems and draw deep insights from this vast pool of data. You will have the opportunity to drive impact across the board, including making strategic decisions about our products and infrastructure.

Responsibilities:
Develop scalable data models, machine learning algorithms to facilitate data-driven decision making
Take advantage of massive amounts of structured data to understand end user behavior and help our advertising customers get better bang for the buck
Design and evaluate experiments
Use AI/deep learning techniques in conjunction with our ACR technology to extract deep insights
Be a thought leader and go-to expert on everything data

Requirements:
MS/PhD in Computer Science, Statistics, Engineering, or another relevant quantitative field
Experience with machine learning algorithms and/or statistical modeling
Proficiency in Python/R/Scala or other programming languages
Familiarity with Big data technologies like Hadoop, Map/Reduce, Spark, Hive etc. is a plus",4.1,"Alphonso
4.1",Bengaluru,"Mountain View, CA",51 to 200 employees,2012,Company - Private,TV Broadcasting & Cable Networks,Media,Unknown / Non-Applicable,-1
Architect I - Data Science,-1,"Job Title
Architect I - Data Science
Job Description


Key areas of responsibilities
Work with service innovation leaders and R&D leaders to identify opportunities for leveraging system log data to drive serviceability solutions
Designs the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.
Mentors the team and reviews the content created by them
Mine and analyze data from system log central database to drive system diagnostics efficiency
Develop custom data models and algorithms to apply to data sets
Define strategy to develop predictive modelling to increase and optimize system diagnostics experiences
Contribute the technical road mapping for the team
Coordinate with different functional teams to implement models, processes, monitoring of data accuracy & outcomes
We are looking for Our ideal candidate is a driven professional who has a strong background in the following:
Overall 9+ yrs exp with minimum 6+ years of experience in delivering meaningful results through data analytics
Excellent written and verbal communication skills for coordinating across teams
Sufficient business acumen to understand business objectives & dynamics
Deep understanding and minimum 4+ years of hands on experience in developing models using Artificial Intelligence, Machine Learning and Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)
Developed & Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.
Strong hold of concepts in Statistics and expertise in Machin Logs Processing, text mining and text analytics.
Strong programming skills in R and Python
Nice to have
Working knowledge with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data.
Knowledge on Data Integration/Ingestion/Processing/Analytics/Reporting & BI based Visualization.
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Data Scientist,-1,"Why You’ll Love Quark Software:

At Quark, we’re on a mission to transform how our customers create, manage, publish and deliver content. No matter the channel or format — web, tablet, mobile, print – with 35 years of success and unparalleled technology, our employees are making this vision reality. As a result, leaders in industries such as finance, manufacturing, energy, and government can reduce costs, save time, improve consistency and make their content brilliant.

Our customers and employees are the heartbeat of everything we do. Employee development and training is part of our DNA so you can look forward to growth and a defined career path. We’re committed to the health and happiness of our employees and offer a comprehensive and generous benefit package that is effective on your first day of employment.

What You’ll Do:

We are looking for a Data Scientist who will support our product, sales, leadership and marketing teams with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.

Responsibilities:
Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
What we’re looking:

Qualifications & Experience:
Strong problem-solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
We’re looking for someone with 5-7 years of experience manipulating data sets and building statistical models.
He has a bachelors or Master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the following software/tools:
Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc.
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Experience querying databases and using statistical computer languages: R, Python, SLQ, etc.
Experience using web services: Redshift, S3, Spark, Digital Ocean, etc.
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Core metrics, AdWords, Crimson Hexagon, Facebook Insights, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.
Company Profile:

Quark’s mission is to transform the way our customers create and communicate their business-critical content. No matter the channel or format — web, tablet, mobile, print – with 35 years of success and unparalleled technology, leaders in industries such as finance, manufacturing, energy, and government are transforming their content experiences, saving time and improve consistency to make their content brilliant.

Quark is proud to be an equal opportunity workplace and is an affirmative action employer. Quark offers a creative and informal culture with all the exciting challenges and rewards of working for a dynamic, international company. We pride ourselves on our high performing teams, visionary leadership, continuous learning and collaborative environment where everyone is measured on and shares in success. We’re committed to the health and happiness of our employees and offer a comprehensive and generous benefit package that is effective on your first day of employment.",-1,Quark,SAS Nagar,"Jesi, Italy",Unknown,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Family Descriptor
Level Descriptor
Data Scientist is responsible for analyzing data and developing forward-looking business solutions for TCL’s SCM function. He / She would need to evaluate and find areas of improvement in SCM’s way of working basis data. He / She is responsible for bringing scientific rigor and statistical methods to the challenges of strategic procurement.

He / She would be responsible for working closely with internal stakeholders such as Sourcing, Operations, and Logistics teams to produce innovative and actionable quantitative models and analyses to achieve the goals of cost leadership and business velocity. He / She would be required to have a customer-centric approach when helping TCL attain its business goals while building long-term capabilities. He / She would need to have a thorough understanding of how SCM functions interact with each other, with Product / Engineering teams and with external stakeholders such as vendors to create actionable solutions.

He / She would need to drive effective written, verbal, and visual presentation to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation. He / She would need to be a self-starter, quick learner, and be able to work independently. He / She would need to demonstrate attention to detail and resourcefulness. This is a pivotal role that embraces and promotes a change mindset and driving a change to move away from traditional reporting.
Purpose - Broad objective of the role
Operating Network - Key External
Data Scientist is responsible for analyzing data and developing forward-looking business solutions for TCL’s SCM function. He / She would need to evaluate and find areas of improvement in SCM’s way of working basis data. He / She is responsible for bringing scientific rigor and statistical methods to the challenges of strategic procurement.

He / She would be responsible for working closely with internal stakeholders such as Sourcing, Operations, and Logistics teams to produce innovative and actionable quantitative models and analyses to achieve the goals of cost leadership and business velocity. He / She would be required to have a customer-centric approach when helping TCL attain its business goals while building long-term capabilities. He / She would need to have a thorough understanding of how SCM functions interact with each other, with Product / Engineering teams and with external stakeholders such as vendors to create actionable solutions.

He / She would need to drive effective written, verbal, and visual presentation to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation. He / She would need to be a self-starter, quick learner, and be able to work independently. He / She would need to demonstrate attention to detail and resourcefulness. This is a pivotal role that embraces and promotes a change mindset and driving a change to move away from traditional reporting.
Operating Network - Key Internal
Size and Scope of Role - Financial
Size and Scope of Role - No. of direct reports
Size and Scope of Role - Total team size
Size and Scope of Role - Other size parameters
Minimum qualification & experience
Bachelor’s Degree in quantitative disciplines (e.g., Engineering, Statistics, Computer Science)
3 - 5 years of work experience in vendor data analysis related field in procurement department / supply chain managment
Experience in articulating and translating business questions and using statistical techniques to arrive at an answer using available data
Strong understanding of fundamentals of finance and accounting such as debit/credit and opex/capex expenses etc.,
Demonstrated skills in selecting the right statistical tools given a data analysis problem
Ability to visualize models and results to provide data-driven insights (PowerBI experience is preferred)
Demonstrated resourcefulness, self-direction, attention to detail, meticulous
Change management and automation experience is mush
Ability to handle larget data sets and drive insights to support informed management decisions
Preferred
Master's degree in Engineering, Statistics, Mathematics, Economics or an Applied Science or equivalent practical experience
Experience with statistical software (e.g., R, Python, MATLAB, pandas) and database languages (e.g., SQL)
Experience in delivering bespoke analytics to stakeholders
Experience in using and/or deploying digital analytics and measurement solutions
Other knowledge/skills
Key Responsibilities
Data Management &Analysis:

Work effectively with large, complex datasets to derive actionable insights
Conduct analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations
Solve difficult, non-routine analysis problems, applying advanced analytical methods as needed
Leverage data to identify potential supply chain risks

Innovative Solution&Group:

Leverage data analytics and visualization tools to propose innovative solutions for growth, aligned with overall TCL objectives and KPIs
Translate data and model results into tactical and strategic insights that are clear, complete, accurate, relevant, understandable, and applicable to decision-making and needs of varying stakeholders

Stakeholder Management:

Interact cross-functionally, making business recommendations (e.g., cost-benefit, forecasting) with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information
Make presentations to internal stakeholders to integrate recommendations into business processes
Lead and/or participate in cross-functional team projects
Technical Competencies
Knowledge / Skills
Communication Skills

Job Segment:
Database, Scientific, Engineer, Computer Science, Supply, Technology, Engineering, Operations",3.8,"Tata Communications
3.8",Mumbai,"Mumbai, India",5001 to 10000 employees,-1,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,₹500+ billion (INR),-1
Senior Data Scientist,-1,"Date: Jun 30, 2020

Ericsson is one of the leading providers of Information and Communication Technology (ICT) to service providers. We enable the full value of connectivity by creating game-changing technology and services that are easy to use, adopt, and scale, making our customers successful in a fully connected world. Headquartered in Stockholm, Sweden, Ericsson is proud of its global presence across 100+ countries and market areas. With a strong focus on innovation, we possess 49 thousand registered patents and a global strength of over 95 thousand competent professionals. We also take pride in supporting networks that cater to a capacity of 40 percent of the world’s mobile traffic, thereby connecting more than 2.5 billion subscribers and counting. We are a world leader in the rapidly changing environment of communications technology – by providing hardware, software, and services to enable the full value of connectivity.

Senior Data Scientist – Product Development (Global AI Accelerator India)

Job Description

Ericsson Overview:

Ericsson is world’s leading provider of communications technology and services. Our offerings include services, consulting, software and infrastructure within Information and Communications Technology.

Using innovation to empower people, business and society, Ericsson is working towards the Networked Society: a world connected in real time that will open up opportunities to create freedom, transform society and drive solutions to some of our planet’s greatest challenges.

We are truly a global company, operating across borders in over 180 countries, offering a diverse, performance-driven culture and an innovative and engaging environment. As an Ericsson employee, you will have freedom to think big and the support to turn ideas into achievements. Continuous learning and growth opportunities allow you to acquire the knowledge and skills necessary to progress and reach your career goals. We invite you to join our team.

Exciting Opportunity:

It will be practically impossible for human brains to understand how to run and optimize next generation of wireless networks, i.e., 5G network with distributed edge compute, that will drive economic and social transformation for all aspects of society. Machine Learning (ML) and other Artificial Intelligence (AI) technologies will be vital for us to handle this opportunity. We are setting up a Global AI Accelerator (GAIA) in the US, Sweden and India, with 300 experts, to fast-track our strategy execution.

Machine Intelligence, the combination of Machine Learning and other Artificial Intelligence technologies is what Ericsson uses to drive thought leadership to automate and transform Ericsson offerings and operations. MI is also a key competence for to enable new and emerging business. This includes development of models, frameworks and infrastructure where we in our advancements push the technology frontiers. We engage in both academic and industry collaborations and drive the digitalization of Ericsson and the Industry by developing state of the art solutions that simplify and automate processes in our products and services and build new value through data insights.

Ericsson is now looking for Senior Data Scientists to significantly expand its global team for AI acceleration for our group in Chennai.

Do you have in depth understanding of Machine Learning and AI technologies?

Do you want to apply and extend those skills to solve real complex problems with high societal impact; going beyond ML/AI for consumption and advertising?

Then, you do want to join Ericsson’s global team of Engineers/Scientists pushing the technology frontiers to automate, simplify and add new value through large and complex data.

Role Summary:

As a Senior Data Scientist, you shall build and deploy AI models into production with focus on scaling, monitoring and performance. You shall build effective AI models using stacking/ensemble techniques; and provide prediction explainability and prescriptive capability in ML models. You shall work with business stakeholders to define and formulate the right business problem.

Your knowledge and experience in Data Science methodologies will be applied to solve challenging real-world problems as part of a highly dynamic and global team. You will work in a highly collaborative environment where you communicate and plan tasks and ideas. You will be working on high impact initiatives with other DS in Machine Intelligence to drive growth and economic profitability for Ericsson and its customers by accelerating current Ericsson offerings. Your contribution will also help to create new offerings in the areas of MI driven 4G and 5G network, distributed cloud, IoT and other emerging businesses.

Key Responsibilities:
Lead multiple AI/ML projects for a certain product/business
Manage communication, planning, collaboration and feedback loops with business stakeholders.
Work with huge datasets including petabytes of 4G/5G-networks, IoT and exogenous data
Identify the model monitoring strategy in prod and retraining plan.
Define data sourcing, access and pipeline design. Identify and plan for sourcing external data.
Model the business problem statement into AI/ML problem.
Define the Data sourcing strategy and works with stakeholders to procure data. Contribute to IP creation for Ericsson in AI/ML
Define/Design data storage and retrieval strategies from various kind of data sources such as NOSQL Databases. Design data pipelines and flow strategies.
Design APIs for AI/ML models with focus on business, modularity and versioning; and build standard/canonical data models by combining multiple data sources.
Lead functional and technical analysis within Ericsson businesses and for strategic customers to understand MI-driven business needs and opportunities
Contribute to rapid and iterative development of validated minimum viable solutions addressing these needs. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical models, deep learning, reinforcement learning and other machine learning systems
Lead studies and creative usage of new and/or existing data sources. Work with Data Architects to leverage existing data models and build new ones as needed.
Collaborate with product development teams and partners in Ericsson Businesses to industrialize machine learning models and solutions as part of Ericsson offerings including providing source code, workflows and documents
Work with new technologies and be the ambassador for them in MI Communities within Ericsson, nurturing the communities and mentoring junior data scientists.
Provide MI Competence build-up in Ericsson Businesses and Customer Serving Units
Develop new and apply/extend existing, concepts, methodologies, techniques for cross functional initiatives
Engage with external ecosystem (academia, technology leaders, open source etc.) to develop the skills and technology portfolio for MI’s needs
Present and be prominent in MI related forums and conferences, e.g., publishing patents, presenting papers, organizing sessions etc.
Key Qualifications:
Bachelors/Masters/Ph.D. in Computer Science, Data Science, Artificial Intelligence, Machine Learning, Electrical Engineering or related disciplines from any of the reputed institutes. First Class, preferably with Distinction.
Applied experience: 8+ years of ML and/or AI production level experience; and an overall industry experience of about 15+ years.
Proven skills of implementing a variety of Machine Learning techniques
Strong Programming skills (R/Python) with proficiency in at least one
Strong grounding in mathematics, probability, statistics needed for data analysis and experiments
Proven ability of leading AI/ML projects end-to-end with complete ownership
Proven skills in building AI/ML based solutions using a variety of frameworks such as Python, R, H2O, Keras, TensorFlow, Spark ML etc.
Experience in implementing new algorithms and methodologies from leading open source initiatives and research papers
Extensive experience in model development and life-cycle-management in one or more industry/application domain
Experience in building models using semi-structured and unstructured data
Hands-on experience in designing and building AI models using Deep Neural Networks for applicable scenarios
Experience in using ensembles and stacking techniques to solve complex ML problems
Able to build and deploy AI models into production with focus on scaling, monitoring and performance
Knowledge of building explainable models (XAI) and prescriptive analytics
Experience with working in Big Data technologies such as Hadoop, Cassandra etc.
Able to Define/Design data storage and retrieval strategies from various kind of data sources such as NOSQL DBs
Knowledge of designing data pipelines and flow strategies
Familiarity with data pipelining frameworks such as Air Flow, AWS Sagemaker, etc. would be a plus
Able to design APIs for AI/ML models with focus on business, modularity and versioning
Experience in writing and presenting white papers, journal articles and technical blogs on the results
Soft Skills:
Good communication skills in written and spoken English
Great Team worker and collaborator
Creativity and ability to formulate problems and solve them independently
Self-driven and ability to work through abstraction
Ability to build and nurture internal and external communities
Additional Requirements:
Certifying MI MOOCS, a plus
Applications/Domain-knowledge in Telecommunication and/or IoT, a plus.
Experience with data visualization and dashboard creation is a plus
Knowledge of Cognitive models is a plus
Ability to work independently with high energy, enthusiasm and persistence
Experience in partnering and collaborative co-creation, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence

What’s in it for you?

With over 90,000 employees across 180+ countries, we have a culture that respects and supports your ambitions, in alignment with our values of Respect, Professionalism and Perseverance. Ericsson is extremely focused on learning and development, supports mobility and flexible working hours. We are also committed to diversity and inclusion and to be a responsible and relevant driver of positive change. We also offer some awesome benefits, amazing career development and training programs to provide an empowered career in a connected world.

Next Steps:

What happens next once you apply? Read about the next steps here

For your prep and reference, here is our overall Brand video and some insights about our innovations in 5G

……………………………………………………………………………………………………………………………………

Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development. Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information

Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development. Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information.
—",3.9,"Ericsson-Worldwide
3.9",Chennai,"Stockholm, Sweden",10000+ employees,1876,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Huawei Technologies, IBM, Cisco Systems"
Data Scientist,-1,"AppZen delivers the world’s leading AI platform for modern finance teams. Starting with business spend, we automate manual process, uncover problems, and optimize decision making for enterprises around the globe, including one-fourth of the Fortune 500. Our platform combines patented deep learning, computer vision, and semantic analysis with intelligence from thousands of online data sources to understand financial transactions in business context and make decisions before those transactions happen. AppZen is a must have for CFOs and their teams to reduce spend, achieve compliance, and streamline process.

We’ve taken off this year! Since we released our platform in 2016, over 1,800 enterprises have standardized on AppZen, including three of the top ten banks, four of the top ten media companies, three of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and five of the top ten software providers. We were a Gartner Cool Vendor last year, have been recognized as one of the fastest-growing technology companies in the market, and we just announced $50 million in Series C funding.

We are looking for a Data Scientist to come and work on our growing AI stack. You will be working with a team of highly skilled and motivated data scientists and machine learning engineers. If you are excited about natural language understanding and machine translation, AppZen is the right place for you to apply and grow your skills.

Must-Have:
Solid understanding of machine learning fundamentals, and familiar with standard algorithms and techniques.
Ability to analyze a wide variety of data: structured and unstructured, observational and experimental, to drive system designs and product implementations.
Expert knowledge of a statistical computing language such as Python or R Knowledge of probability and statistics, including experimental design, predictive modeling, optimization, and causal inference Experience in design and deployment of real-world, large-scale, user-facing systems.
Ensure data quality throughout all stages of acquisition and processing, including such areas as data sourcing/collection, ground truth generation, normalization, transformation, cross-lingual alignment/mapping, etc.
Manage your own process: identify and execute on high impact projects, triage external requests, and make sure you bring projects to conclusion in time for the results to be useful.
Excellent written and verbal technical communication skills; communicate proposals and results in a clear manner backed by data and coupled with actionable conclusions to drive business decisions.
M.Sc. or M.E. or M.Tech in Computer Science, Engineering, Statistics, or other relevant technical fieldMust have 4-6 years of industry experience.
Able to work onsite in Pune, IN
You are a team player
Come as you are, we do not discriminate! We celebrate, support, and thrive upon our diverse customer and employee base.",3.8,"AppZen
3.8",Pune,"San Jose, CA",201 to 500 employees,2012,Company - Private,Financial Transaction Processing,Finance,₹500 million to ₹1 billion (INR),-1
Data Scientist,-1,"We are looking for a Data Scientist who will support our IoT products, sales and marketing teams with insights gained from analyzing data.
The ideal candidate will be adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to build products for mobile apps. They must be comfortable working with a wide range of functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with a team to improve product outcomes.
Responsibilities
Collaborate with cross-functional teams including but not limited to Engineering, Products, Operations, Sales, Marketing, etc. to breakdown complex problems and recommend data science products.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use machine learning and analytical techniques to create scalable solutions for problems.
Contribute to the development/ deployment of machine learning algorithms.
Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes
What do we need?
Degree (B.Tech, MS, PhD or equivalent) in Computer Science, Mathematics, Operational Research, Statistics or Natural Sciences
1-7 years of work experience in data science and statistical modeling
Strong problem solving skills with an emphasis on product development.
Experience working with and creating data architectures.
A very clear understanding of probability and statistics, analytical approach to problem solving, and capability to think critically on a diverse array of problems
Supervised Machine Learning Algorithms: Predictive Analytics, Logistic Regression, Bayesian Approach, Decision Trees, Support Vector Machines. Neural Networks etc.
Understanding of advanced algorithms (i.e. Deep Learning, Probabilistic Graph Models) will be good to have
Familiarity with statistical methods such as hypothesis testing, forecasting, time series analysis, etc - gained through work experience or graduate level education
Expertise in following languages: Python, Java, C++, R, SQL etc.
Experience with relational databases NoSQL databases such as MongoDB, Elastic Search, Redis or any graph database
Skilled at data visualization and presentation
Most importantly, an inquisitive mind, an ability for self-learning and abstraction along with a risk appetite for experimentation and failure",3.0,"ZunRoof Tech
3.0",Gurgaon,"Gurgaon, India",51 to 200 employees,2016,Company - Private,Consumer Electronics & Appliance Shops,Retail,Unknown / Non-Applicable,-1
Data Scientist,-1,"Zauba Technologies is a startup based in Bangalore. Zauba's services are used by leading companies in India. Zauba is powered by a young and passionate team. We are looking for individuals who would like to be a part of our founding team.

As a Data Scientist and as a part of founding team, you will be expected to design and develop applications related to information retrieval, artificial intelligence, natural language processing and predictive modelling. Your rewards will be directly proportional to the value you generate.

Design and development of robust, scalable and highly efficient data engineering solutions for structured and unstructured data
Design and develop out-of-the-box solutions to solve complex data problems
Develop statistical models for various use cases
Develop processes for text mining and extraction of information from unstructured data
Design and implement data models that scale across the enterprise
Take ownership of existing data workflows and processes
Enhance scalability, performance, and stability of existing infrastructure
Work closely with other team members to integrate your innovations and algorithms into our production systems

Essentials
Java / R / Python - Intermediate to advanced level`
Regex - Advanced
SQL - Advanced
Apache Weka / Mahout or other similar tools - Intermediate to advanced level
Experience in Search Algorithms, Semantic Analysis, with good knowledge of Machine learning/Distributed System/Data Mining/NLP/Artificial Intelligence
Linux - Intermediate

Good to have
Hadoop/Spark
R
MongoDB

Must have qualities
Skills to learn new skills quickly
Desire to create disruptive products and services
Passion; not just to work in startups but to take them to next level
Above average programming aptitude
Be passionate about producing high quality engineering deliverables
Be productive working independently or collaboratively
Have an eye for building efficient processes
Be self motivated
Proactively take ownership

Interested?

Send your resume to hr@zaubacorp.com",3.8,"Zauba Corp
3.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
Data Scientist,-1,"Work with clients to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases, live feeds, third pary sources etc to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Primary Skills: 1. Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
We’re looking for someone with experience in manipulating data sets and building statistical models, and is familiar with the following software/tools:
a. Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
b. Experience querying databases and using statistical computer languages: R, Python, SLQ, etc.
c. Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.
d. Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
e. Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
f. Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
g. Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.

Secondary Skills: a. Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc.
b. Experience in multiple industry verticals will be an added advantage.

Soft Skills: a. Must be good at Client interaction skills.
b. Excellent oral and written communication skills.

Educational Background: Must have Master’s or PHD in Statistics, Mathema
Experience Range: 8 Years - 10 Years
Number of Positions: 2
Timeline: Immediate
Location: Bangalore, India
Travel Needs: Occasional Travel to Client Locations.",-1,Germane Analytics Pvt Ltd,Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Description:
Interact with customers to understand business objectives and create analytical strategies to help achieve them
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner.
Communicate results and educate others through reports and presentations.
Skills Required
Expertise in Data Mining, Data wrangling, and data munging using one or more of the most
commonly used data science tools: R, Python, SAS, SPSS, Weka
Experience in end-to-end data science and engineering activities
Must be hands-on and must have worked on implementing machine learning and data mining algorithms
Additional Skills (optional) Scala, Spark, H2O,Mahout, Hive
Job Type: Full-time

Salary: ₹500,000.00 - ₹800,000.00 per year

Experience:
work: 5 years (Preferred)
total work: 2 years (Preferred)
Education:
Bachelor's (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,root2ai,Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"Job Description:
Interact with customers to understand business objectives and create analytical strategies to help achieve them
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner.
Communicate results and educate others through reports and presentations.
Skills Required
Expertise in Data Mining, Data wrangling, and data munging using one or more of the most
commonly used data science tools: R, Python, SAS, SPSS, Weka
Experience in end-to-end data science and engineering activities
Must be hands-on and must have worked on implementing machine learning and data mining algorithms
Additional Skills (optional) Scala, Spark, H2O,Mahout, Hive
Job Type: Full-time

Salary: ₹500,000.00 - ₹800,000.00 per year

Experience:
work: 5 years (Preferred)
total work: 2 years (Preferred)
Education:
Bachelor's (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,root2ai,Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Data scientist,-1,"The ideal candidate will be responsible to develop, sustain and enhance our digital software and solutions.

Duties & Responsibilities

What you'll do:
Design,implement and improve new and existing algorithms for 2D & 3D image processing.
Implement and execute deep learning based trainings and evaluate the result.
Performing code reviews and providing suggestions for fixes and improvements.
Keep ownership of technical designs, source code, and component test execution to demonstrate alignment to the functional specifications.
The Individual

What you'll definitely need:
Must possess at least a Bachelor’s or Master’s degree in Computer Engineering/Science or equivalent.
Must have 3+ years of practical Experience with Python and Deep Learning.
Expert Knowledge in Linux, and Python and C++

Proven practical experience specifically with

Image Processing
and Deep Learning / CNNs
preferably also with 3D data
Good knowledge of Software architecture.

To find out more about life at Smiths Detection check out our LinkedIn page https://www.linkedin.com/company/smiths-detection/life/c58d0d07-ffe6-4a79-aa69-062062454d6d/and follow our story.

Join us for a great career and competitive compensation & benefits whilst keeping the world a safer place.

Diversity & Inclusion

We believe that different perspectives and backgrounds are what make a company flourish. All qualified applicants will receive equal consideration for employment regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, economic status, disability, age, or any other legally protected characteristics. We are proud to be an inclusive company with values grounded in equality and ethics, where we celebrate, support, and embrace diversity.",3.5,"Smiths Detection
3.5",Bengaluru,"HEMEL HEMPSTEAD, United Kingdom",1001 to 5000 employees,1985,Company - Private,Electrical & Electronic Manufacturing,Manufacturing,₹50 to ₹100 billion (INR),Rapiscan Systems
Data Scientist,-1,"Experience : NA
Qualification : Bachelors in Computer Science.
Functional Area : IT Software (Banking)
Employment Type : Full time
Location : Bangalore
Job Description

We are looking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Applications include Fraud Analytics, Automated credit scoring using Machine Learning Techniques, Recommendation system for credit products.

Responsibilities

Selecting features, building and optimizing classifiers using machine learning techniques.
Data mining using state-of-the-art methods.
Extending company’s data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis.
Doing ad-hoc analysis and presenting results in a clear manner.
Creating automated anomaly detection systems and constant tracking of its performance.
Designing algorithms to solve specific issues faced by the financial sector.
Skills and Qualifications

Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. Excellence in at least one of these is highly desirable.
Great communication skills.
Experience with data visualisation tools, such as Microsoft SSRS.
Proficiency in using query languages such as SQL.
Experience with NoSQL databases, such as MongoDB, Cassandra.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills .
Data-oriented personality.
Bachelors in Computer Science with relevant experience is preferred.

Email : hr@processwaresystems.com

Phone No : 080-26572188, 26579635",3.5,"Processware Systems
3.5",Bengaluru,"BENGALURU, India",51 to 200 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Logistics done differently.

At XPO Logistics, we’re constantly looking for ways to improve, enhance and adapt in an ever-changing marketplace. The selected candidate will possess a combination of data science skills including data wrangling, advanced programming and statistical analysis (machine learning and data mining). Further, this individual will be able to take complex data, analyze it, draw meaningful conclusions and communicate findings in a manner that can be easily understood by a wide variety of audiences

What you’ll do on a typical day:
Strong understanding of Warehouse concepts, Labor planning, Demand forecasting and Industrial Engineering
Demonstrated ability to provide guidance and development to a group of analyst and engineers
Strong analytical skills with the ability to collect, organize, analyze and disseminate information with attention to detail and accuracy
Demonstrated experience with database design, data models and integration/extraction technologies and techniques
Experience with visualization tools (Power BI, Tableau, and Oracle’s Business Intelligence preferred)
Expertise in programming for data wrangling and statistics (R, Python)
Strong knowledge of statistics and experience using statistical modeling (logistic regression, SVMs, etc.) to solve business specific problems
Experience with text analytics (e.g. semantic analysis) is a plus
It’d be great if you also have: Primary Skills (Must Have):
Programming: Python, R, CPLEX, SQL, VBA
Visualization: Power BI, Tableau, Oracles Business
Statistical modeling techniques: Linear/logistic regression (including advanced predictor selection techniques), classification (decision trees, random forests), Support Vector Machines (SVMs), neural networks, etc.
Algorithm Development: Machine learning, Deep learning, and advanced Algorithmic solution development
Be part of something big.
XPO is a leading provider of cutting-edge supply chain solutions to the most successful companies in the world. We help our customers manage their goods most efficiently using our technology and services. Our greatest strength is our global team – energetic, innovative people of all experience levels and talents who make XPO a great place to work.

The above statements are intended to describe the general nature and level of work being performed by people assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills required of personnel so classified. All employees may be required to perform duties outside of their normal responsibilities from time to time, as needed.",3.7,"XPO Logistics
3.7",Mumbai,"Greenwich, CT",10000+ employees,2011,Company - Public,Transportation Management,Transportation & Logistics,₹500+ billion (INR),"DHL Supply Chain, UPS, FedEx"
Customer Analytics-Data Scientist,-1,"Job Description

What we are looking for

Must-Have:

1.

Overall 8-14 years of working experience with
preferably 5 years in single domain at senior levels.

2.

Domain Expertise:
The candidate should have a good hold on one or more domains as listed:
Communication & Media, Retail, CPG, BFSI, Utilities, Automobiles

3.

Ability to
perform statistical modelling (predictive, regression, hypotheses testing,
multivariate analysis, Time Series, Cluster, forecasting, ARIMA) using R/
Python.

Good to Have:

Knowledge of Spark, Yarn, other big data technologies

Responsibilities:

1.
As a Data Scientists you must be able to translate Business Problem to a
Statistical Problem and Statistical solutions to a viable Business solution.

2. Ability to manipulate unstructured
data to form insights about the business.

Minimum Qualification:

15 years of full-time education;

Minimum percentile of 50% in 10th, 12th, UG & PG (if applicable)

Job Function

TECHNOLOGY

Role

Scientist

Job Id

159069

Desired Skills

Machine Learning | Python | Statistics

Desired Candidate Profile

Qualifications :
BACHELOR OF ENGINEERING",3.8,"Tata Consultancy Services
3.8",Bengaluru,"Mumbai, India",10000+ employees,1968,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Accenture, IBM, Infosys"
Data Scientist,-1,"We are building our team to offer business and operations analytics solutions to our international and

domestic clients, and are looking for a Data Scientist with comprehensive knowledge of existing and next

gen analytics tools and technology platforms. Passionate, self-starter and innovative our Data Scientist will

bring expert skills and meaningful experience to fore, focusing primarily on Healthcare, Pharmaceuticals,

Banking, Financial Services & Insurance industry verticals.

Responsible for leading client engagements and People, our Data Scientist will be a problem solver, who

relishes the journey of crafting intelligent client solutions – live to find patterns and insights within structured

and unstructured data. Industrious, analytical and result-oriented, our Data Scientist will be a thinker with

natural desire to go beneath the surface of a problem; understand how the products are developed; and

have statistical, mathematical, predictive modelling as well as business strategy skills to build the algorithms

necessary to ask the right questions and find the right answers – You propose analytics strategies and

solutions that challenge and expand the thinking of everyone around you. With hands-on knowledge of

the business, products, technology, regulatory environment, operations our Data Scientist will continuously

seek fresh challenges to engineer solutions that make valuable client business impacts.

A seasoned professional our Data Scientist will operate in collaboration with cross-industry, cross-function,

experts and be a leading example of the Profisor People Culture, independently managing client

engagements, multiple projects and project teams.

Careers

Responsibilities:
Results-based quality delivery of data analytics solutions and services

Manage multiple client projects, problem statements, and multiple project teams

Organize and manage quality review of data analytics operations delivery

Design & develop client solutions and collaboratively respond to client RFP’s & RFI’s

Lead thought leadership articles – point of views – and business development initiatives

Manage client relationships, client experience and client feedback to resolve engagement issues

Co-develop Profisor People and People career models

Manage team performance reviews, expansion and progression planning and People reporting

Lead analytics capability development, learning and training

Counsel, develop People, and manage talent identification and hiring

Minimum Knowledge, Skills & Abilities Required:
8+ years of experience designing and devising data analytics capabilities and solutions for

Healthcare, Pharmaceuticals, BFSI and or Cross-industry clients

Comprehensive knowledge of Natural Language Processing, Machine Learning, Conceptual Modelling,

Statistical Analysis, Predictive Modelling & Hypothesis Testing

Solution-oriented thinker, capable of managing business and technology challenges

Data driven and highly analytical with working knowledge of compliance and ethical standards and

evolving global regulatory environment

Excellent communication (both written and vocal), problem solving and presentation skills

Good human relations and interpersonal skills to collaborate and manage People with diverse

backgrounds

Additional Knowledge, Skills & Abilities:
Data munging, visualization and communication knowledge

Hands-on knowledge of Lean and Agile delivery techniques

Demonstrated ability to maintain strict confidentiality of internal and external customer information

Desirable Knowledge, Skills & Abilities:
Ph.D. or Master’s degree in operations research, applied statistics, mathematics, data mining, machine

learning, physics or a related quantitative discipline

Management experience in Big Data or Data Analytics practice setup",4.5,"Profisor Services
4.5",Gurgaon,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Miles is looking to expand its data science and data engineering team in INDIA!

Here's a quick checklist:
You live in India
Want to work for a fast-growing Silicon Valley Startup
You are passionate about solving challenging problems
You are looking to put your stamp on the product

What you'll need:

Education
Master's/PhD (preferred) or Bachelor's (required) in CS/ML/AI or relevant computational/engineering discipline

Machine Learning/Data Science:
Solid theoretical understanding of ML fundamentals: linear algebra, probability, statistics (as relevant to ML), optimization
Knowledge of different ML techniques and when/how to use them: classification, regression, clustering, outlier detection, dimensionality reduction, etc.
Comfortable manipulating and analyzing complex, high-volume, high-dimensionality data from varying, heterogeneous sources
Experience with messy real-world data -- handling missing/incomplete/inaccurate data
Proficient in the Python ML ecosystem: NumPy, Pandas, SciPy, Scikit-Learn
Strong understanding of relational databases like PostgreSQL is a plus

Programming experience:
At least 2+ years of experience writing production-quality Python code
Version control: Git, GitHub/Bitbucket
Experience delivering large-scale deployable projects

Great to have
We deal with large volumes of geospatial data, so experience working with geospatial data at scale is a big plus
Knowledge of Python (Shapely, GeoPandas, Fiona, CartoPy, etc) and/or database (PostGIS) geometry/geospatial tools
Domain experience in building models for location-based services, transportation, scheduling, vehicle routing",1.8,"Miles
1.8",Bengaluru,"Redwood City, CA",1 to 50 employees,2016,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Location
Powai, Mumbai
Experience
5+ years
Education
BE/B.Tech
Type
Regular/Full time
Roles and Responsibilities

Identify valuable data sources and automate collection processes
Undertake reprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams

Desired skills and experience

Deep experience in machine learning
Excellent skills in Python
Exposure to advanced deep learning techniques such as LSTM, CNN, Dense neural networks as well as neural networks design and implementation through tools like tensorflow/keras/pytorch/deep AI or equivalent
Experience of working in multiple text mining / NLP solution
Should have experience of deploying and putting into production ML based solution
Should have at-least 1 end-to-end ML project experience
Must possess experience in Python
Experience: 5+ years",3.6,"NSEIT
3.6",Maharashtra,"Mumbai, India",1001 to 5000 employees,1999,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Title:
Senior Data Scientist and Machine Learning Engineer

Location:
India, Bangalore
Role Overview:


McAfee is looking for an experienced data scientist to work on our next-gen threat assessment platform. You will work with experienced developers, security researchers and data scientists to understand and implement solutions to the problems found in todays fast-changing security landscape. You will also work with development teams in Oregon, UK and India as they maintain and extend our existing classification systems.



Company Overview


From device to cloud, McAfee provides market-leading cybersecurity solutions for both business and consumers. We help businesses orchestrate cyber environments that are truly integrated, where protection, detection, and correction of security threats happen simultaneously. For consumers, McAfee secures your devices against viruses, malware, and other threats, both at home and away. We want to continue to shape the future of cybersecurity by working together to build best in class products and solutions.

About the role:
You will collect and analyse data to spot trends and help us face the challenges of an evolving security landscape.
Design, debug and test complex software in the field of data science.
Manipulate large volumes of data, create new solutions for data collection, usage and malware classification. Work with team members (developers and malware researchers) to develop and review designs and requirements to analyse data and build ML models.
Knowledge of security practises, procedures and capabilities to perform non-repetitive, work. You will report to the Engineering Manager.
About You:
You have the following required skills:
Display understanding of and ability to use programming languages: C++, Python, C#, and SQL. Have a knowledge of security research (malware analysis tools, filetypes), statistics, programming, data mining, machine learning, algorithms and advanced mathematics.
Have ability to think and research creatively. Createstories told by the data and presents them to other scientists.
5+ years experience working in security research, data mining or natural language processing. Use predictive modelling, statistics, Machine Learning, Data Mining, and other data analysis techniques to collect and explore insights from structure and unstructured data .
Develop software, algorithms and applications to apply mathematics to data, perform large-scale experimentation and build data-driven apps to translate data, solve a variety of business problems and ensure strategy. Assist business with casual inferences & observations with finding patterns , relationships in data.
Have understanding of internal business segment (partners).
Typically requires expertise in relational database structures, research methods, machine learning, Cloud-based technologies, Big Data technologies (i.e. Hadoop , HBase, Lucene/Solr), analytics packages (i.e. R, Mahout, Matlab, Octave, Weka), scripting languages (i.e. Python, Perl), programing languages (i.e. Java, C/C++, SQL).
Typically have advanced degree in Computer Science, Mathematics, Machine Learning, Operation Research, and Statistics or equivalent expertise.
Company Benefits and Perks:


We work hard to embrace diversity and inclusion and encourage everyone at McAfee to bring their authentic selves to work every day. We offer a variety of social programs, flexible work hours and family-friendly benefits to all of our employees.
Pension and Retirement Plans
Medical, Dental and Vision Coverage
Paid Time Off
Paid Parental Leave
Support for Community Involvement
We're serious about our commitment to diversity which is why McAfee prohibits discrimination based on race, color, religion, gender, national origin, age, disability, veteran status, marital status, pregnancy, gender expression or identity, sexual orientation or any other legally protected status.

Job Type:


Experienced Hire

Primary Location:
India, Bangalore

Additional Locations:",3.6,"NSEIT
3.6",Maharashtra,"Santa Clara, CA",5001 to 10000 employees,1987,Company - Private,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Palo Alto Networks, NortonLifeLock, CrowdStrike"
Data Scientist,-1,"The Opportunity

This mid-level Data scientist role provides an opportunity to be a part of the Near’s Data Science team. You’ll join a team of experts in application of data science models for a location intelligence platform. They carry out R&D, prototyping, development and deployment of best-in-class AdTech and MarTech data science solutions. The role requires to partner with key decision makers in business, product and engineering teams within the company. You will design, develop and craft narratives that help us understand the user base and pitch the product to our clients.

You will be part of one of the fastest growing Enterprise SaaS companies, where you are given the freedom to experiment and innovate new winning ways – a great opportunity for people who can work independently and are self-driven.

Tasks include
Developing core data science models and capabilities that power the Near Location Intelligence Platform and associated products.
Applying various data science methods such as time series, causal inference, experiments, machine learning, modeling, and forecasting to understand the most important aspects of our product, users, and business.
Use advanced data analytics including processing structured (payments, telecom, page clicks etc) and unstructured data in multiple formats (text, audio, video) spanning multiple domains including user profile data, geo-spatial data, network data and retail data.
Research and create intellectual property for the company that will benefit Near and its partners.
Use nonparametric and probabilistic models to generate insights keeping in mind the bias- variance trade-off.
Work closely with the Engineering team to operationalize and deploy the models.
Partner with technology and the business team to build a superior data quality pipeline that will feed the models.
Understand and prioritize the data science work based on cost effectiveness and leverage time management skills.
Attend conferences and organize workshops/meet-ups to be in touch with the data science community.
Skills and Requirements
You should hold a degree in M.Tech/MS/PhD in quantitative field (e.g. Computer Science, Econometrics, STEM fields) a plus.
Overall 3-6 years of experience with at least 3 years of working experience in any data driven company/platform, developing data science models and quantitative models.
Must have thorough mathematical knowledge of correlation/causation, decision trees, classification and regression models, recommenders, probability and stochastic processes, distributions, priors and posteriors.
Understand the model lifecycle of cleansing/standardizing raw data, feature creation/selection.
Write complex transformation logic to generate independent and dependent variables, model selection, tuning, A/B testing and generating production ready code.
Knowledge of Numerical optimization, Linear/Non-linear/Integer programming, Statistics, Combinatorial optimization is a plus.
Familiarity with R, Apache Spark (Java, Scala, Python), PrestoDB, AWS Cloud, PyMC3/theano/tensorflow and other scientific python/R modules is a plus.
Need to be comfortable writing code for model building and bootstrap, test and own models through their lifecycle including devops and deploying into cloud.
Candidate is expected to have exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Must have completed academic projects in data science experimenting with raw data and generating insights, publications are a plus.",4.0,"Near
4.0",Bengaluru,"San Francisco, CA",1 to 50 employees,-1,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Back-end Python Engineer who will write, test, and refactor Python code for our data analysis components.

You will also design databases and other storage systems that interact with the code in a way that is resilient and fast;
You will collaborate with the Operations and Development teams to tackle the high scalability challenges that come with rapid growth and participate in code review and scrum meetings.

Requirements

Expertise in Python
Familiar in Git and Linux
Work in an Agile Environment
Experience in Python Django, Celery, REST Frameworks
Must be able to work in an often chaotic rapidly growing startup environment and present their ideas openly to others.",5.0,"Turbolab Technologies
5.0",Kochi,"Kochi, India",51 to 200 employees,2014,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Scientist / Senior Data Scientist,-1,"Position Summary

NextNav is launching a groundbreaking location service for smartphones, IOT, and other devices – an ability to determine floor level altitude service across the country – a capability that does not exist at scale anywhere today! No longer constrained by legacy “flat earth” technologies, applications and users will be able to determine floor-level altitude, which is essential for navigation, user context and relevancy and many other applications that are used indoors.

This position will consist of building tools to aid with alerting of our system, developing real-time metrics of our end-to-end network performance, and calibration quality at all levels. The position will also develop models to aid in our end-to-end system, including calibration and forecasting, as well as applying machine learning and deep learning algorithms.

Responsibilities

·Develop algorithms to further improve the accuracy of NextNav's Z-axis solution.

·Efficiently clean, prune, fix, prepare, process and analyze network and field data.

·Create and develop machine learning algorithms to help aid in positioning and calibration of devices and network.

·Develop strong domain expertise with atmospheric science.

·Interpret data and guide company to maximal benefit.

Desired Skills& Experience

Required:

·Bachelor's degree with 5 years’ experience, orMaster's/PhDin engineering disciplines such as mechanical engineering, electrical engineering, or sciences such as mathematics, statistics, computer science, physics, or another closely related field, with research emphasis on data modelling and analysis.

·Solid foundation in statistics and data processing, including data reduction, regression, automation and visualization.

·Strong scientific coding skills, including proficiency in one or more of the following: Python, R, MatLab, SQL, etc. Expertise with object-oriented languages such as Java or C++ a bonus.

·Familiarity with machine learning and deep learning framework applied to real world problems.

·Ability to work independently and collaboratively across multiple departments, including hardware and software.

·Strong written and oral communication skills, with the ability to communicate clearly and effectively across teams.

Preferred:

·Experience in performing analysis of large data sets by exploiting parallel computing infrastructure.
5 years’ experience with machine learning and deep learning framework, including scikit-learn, Tensor Flow, or PyTorch.
·Experience in providing data support for internal and external engagements for trials and demos.

·Demonstrated experience as a problem solver and a data analyst of a variety of gridded and point weather data.

·Experience with driving projects across all stages, including ideation, testing, and marketing.

·Track record of source code contribution to open source projects.",3.7,"NextNav
3.7",Bengaluru,"Sunnyvale, CA",51 to 200 employees,2007,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1
DATA SCIENTIST,-1,"Employment: Full time.

Role: Data Scientist

Job Summary

We are looking for experienced data scientists with strong advanced analysis and machine learning model development experience. Data scientists will be working with a team of technical experts on the development of a scalable, real-time, big data analytics solutions with data visualizations leveraging the latest technologies. The ideal candidate will have a proven track record of solving large, complex big data challenges and developing machine learning models to address emerging cybersecurity requirements. Responsibilities will include the analysis of the data to uncover useful and valuable information and finally supporting the engineering team to build the results into the end product. You will be working with an experienced team of data scientists and technical experts, and be part of the Security, Risk, and Governance (SR&G) solutions Centers of Excellence (COE). This position is responsible for the design, architecture, development, and implementation of emerging Security and Operations use cases, and partner with R&D engineers to productize the same to support go-to-market initiatives.

Responsibilities and Duties
Collaborate with a multi-disciplinary team of engineers and analysts on a wide range of cybersecurity problems.
Bring analytical rigour and statistical methods to the challenges of measuring quality, improving security products, and understanding the behaviour of end-users, computer systems, and network devices.
Build innovative predictive analytics and data science solutions for a myriad of cybersecurity problems.
Multi-task and work independently
‘Think like an adversary’
Identify and articulate risks and remediation in a relevant and approachable manner with both technical and non-technical audiences.
Identifies data sources, collects, transforms and prepares large amounts of data for analysis. May also develop tools to help the data collection process as needed.
Uses appropriate methods, tools, and algorithms to analyze the data and create an implementation plan from the business problem.
Validates the results of the data analysis to avoid errors.
Interprets results and identifies value form the analysis to help solve the business problems. Works with the business or customer and provides guidance on risks and limitations.
Monitors and continuously improves the data sources, usability and data
mining results.

Required Experience, Skills and Qualifications Education and Experience
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field
3-5 years of working experience in machine learning and data science projects;
2-3 years of experience in working with large scale production data sets
Good understanding of the foundations of machine learning methods
Exceptional coding skills in SQL, and Python or R
Excellent communication skills
Knowledge and Skills

Basic Qualification:
Experience with deep learning methods, models and frameworks
Familiarity with multiple programming and scripting languages (such as Java, Javascript, C/C++, Perl, etc.)
Familiarity with data visualization tools
Experience with passive and active measurement techniques
Experience with applying statistical modelling, machine learning and data mining algorithms to business problems.
A profound understanding of big data systems
Must have:
Background in statistics
Linux System knowledge as user and administrator
Experience with Vertica or other column store databases is a plus
Experience in cybersecurity, network data
Knowledge of networking concepts and devices (Firewalls, Routers, Switches,
and Load Balancers)
Knowledge of network and web related protocols (such as TCP/IP, UDP, IPSEC,
HTTP, HTTPS, DNS, SSH, routing protocols)",-1,Inference Labs,Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Requirements
Should have good knowledge of statistics and machine learning techniques
Should able able to soft through data and extract the underlying patterns and insights which could be applied to solve the problem or add value
Should have good problem solving skills
Should have working knowledge or experience with tools such as R, Matlab etc
Should be able to convert high level goals into set of use cases or KPIs to be added to the solution to solve customer problem
Should be able to prepare datasets, tune params, select set of attributes etc to ensure the model trained solves the problem in efficient manner

Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques.
Data mining using state-of-the-art methods.
Extending company’s data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis.
Doing ad-hoc analysis and presenting results in a clear manner.
Creating automated anomaly detection systems and constant tracking of its performance

Skills and Qualifications
Excellent understanding of machine learning techniques and algorithms, such as Classification, regression, RF, CRF, SVM, Clustering, CNN, Neural network etc...
Experience with common data science toolkits, such as R, Matlab, Python related etc.
Experience with data visualisation tools, such as D3.js, GGplot, etc. to present the observation or solution in simple and consummabale manner on dashboard
Proficiency in using query languages such as R, SQL etc. Experience in Python is plus
Experience with various sdks like mitie, dib, stanford NLP, etc are preferred
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Understand the high level problem and provide set of solutions to solve it using machine learning or otherwise
We’re looking for someone with 5-8 years of experience manipulating data sets and building statistical models, has a Master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field",3.7,"IQLECT
3.7",Bengaluru,"Bengaluru, India",1 to 50 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Description :
3+ years of experience as a Data Scientist in delivering building complex ML models and delivering key business insights and metrics for financial or product organizations
One or more analytic software tools or languages (e.g., R, Python, Hadoop)
Experience in applied analytics, descriptive statistics, and predictive analytics on industrial datasets
Demonstrated in modeling techniques, Predictive modeling, Supervised learning, Unsupervised learning, Machine Learning, Statistical Modeling
Experienced in working with large data sets, with big data processing tools like MapReduce, Spark, Hive, etc.
Experience with cloud service providers like AWS, GCP, Azure.
Understanding of how to apply predictive and machine learning techniques like logistic regression, random forest, GBM, Neural Nets, SVM etc is required
Additional Responsibilities
Work with business teams to understand the analytical products/platform being used, asks and identify opportunities to re-design using scalable open-source big data technologies
Work with large datasets to investigate key business trends, behaviours, and metrics
Develop, build and train machine learning models using a wide range of machine learning tools
Key Job Attributes :


Data Science
Data Scientist
Machine learning
Python
Hadoop

Educational Qualifications :


B.E/B.Tech

Key Skills :


Machine learning
Statistical modelling
Python
Predictive modeling
Mapreduce
Big data

Contact Details :


Email Id : anbu@handigital.com",3.6,"Han Digital Solution
3.6",Bengaluru,"Bengaluru, India",51 to 200 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Scientist,-1,"Exp: 3 - 8 years

CTC: 12 - 42 LPA

Preferred: Talents from eComms/Product/BFS

Responsibilities
• Work with a team of high-performing data science professionals, and cross-functional teams to identify business opportunities, optimize product performance or go to market strategy.
• Build data expertise, act like an owner for the company and manage complex data systems for a product or a group of products.
• Performing all of the necessary data transformations to serve products that empower data-driven decision making.
• Establishing efficient design and programming patterns for engineers as well as for non-technical partners.
• Designing, integrating and documenting technical components for data flows or applications that perform analysis at a massive scale.
• Ensuring best practices and standards in our data ecosystem are shared across teams.
• Understand the analytical objectives to make logical recommendations and drive informed actions.
• Engage with internal platform teams to prototype and validate tools developed in-house to derive insight from very large datasets or automate complex algorithms.
• Initiate and drive projects to completion with minimal guidance.
• Contribute to engineering innovations that fuel LinkedIn’s vision and mission.

Basic Qualifications
• Bachelor or higher degree in a quantitative discipline: statistics, operations research, computer science, informatics, engineering, applied mathematics, economics, etc.
• 3+ years relevant industry or relevant academia experience working with large amounts of data
• Experience with SQL/Relational databases
• Experience with manipulating massive-scale structured and unstructured data.
• Experience with distributed data systems such as Hadoop and related technologies (Spark, Presto, Pig, Hive, etc.).
• Background in at least one programming languages (e.g., R, Python, Java, Scala, PHP, JavaScript)
• Experience with data modelling, ETL (Extraction, Transformation & Load) concepts, and patterns for efficient data governance.
• Understanding of technical and functional designs for relational and MPP Databases, Reporting and Data Mining systems.
• Experience working with databases that power APIs for front-end applications.
• Knowledge of Unix and Unix-like systems, git and review board.

Preferred Qualifications
• Masters or Ph.D. degree in a quantitative discipline: statistics, operations research, computer science, informatics, engineering, applied mathematics, economics, etc.
• Bachelors with 10+ years or Masters with 6+ years or Ph.D. with 4+ years of industry experience
• Experience in developing data pipelines using Spark and Hive.
• Experience with either data workflows/modeling, front-end engineering, or back-end engineering.
• Strong communication skills, with the ability to synthesize, simplify and explain complex problems to different audiences.
• Experience in either the front-end or back-end development of data-powered applications.
• Experience working in the product, sales, or marketing analytics domains.
• Experience in data visualization and dashboard design including tools such as Tableau, R visualization packages, D3, and other Javascript libraries, etc.",-1,Staffio HR,Bengaluru,"Bengaluru, India",1 to 50 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Scientist,-1,"Ahmedabad
Be a part of the movement to revolutionize the in-store customer experience through the loyalty program and the other features we have to offer.We believe in creating memories that will last forever. We want to help businesses develop personal connections with their customers and provide the customers with experiences that they will cherish forever and will keep them coming back.
We’re scrappy, hard-working perfectionists looking for people who can add immediate value to our team. As a member of the founding team of # Loyalty, you will have the opportunity to work across different business verticals in an extremely faced paced environment. You'll play a key role in product development, strategy and other business decision.

Job Description
Machine Learning & Artificial Intelligence are embedded deeply into our products evolution. We are looking for talented individuals to help us build these tools and embed them into our product offering. The exposure and impact on the product will be massive! And select individuals would be offered a full-time or part-time position post the internship, depending on the performance during the same.

What we're looking for:
Experience working with Python and libraries like NumPy, SciPy, Pandas, Scikit-learn, Tensorflow etc.
Experience working with large data-sets (provide links to your work on Github/Kaggle)
Solve complex performance problems and architectural challenges
Passionate about Machine Learning and AI
Strong knowledge of PHP web frameworks {{such as Laravel, CI,}}
Worked on real world recommender / ranking systems
Prior experience working at a startup environment would be great
Other Skills
Python, Machine Learning, Numpy/Scipy/Pandas/Scikit-learn
Should be able to handle a team technically.
Experience
PHP: 1+ years (Preferred)

Contact Us to Apply : (+91) 851 187 8094 info@r3coder.com",-1,Staffio HR,Bengaluru,"Ahmedabad, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Role: Data Scientist
Company: PayU Payments Pvt Ltd
Location: Gurgaon/Bengaluru

About Company:
PayU, the fintech-arm of Naspers, is a leading financial services provider in global growth markets. We use our expertise and heritage in cross border and local payments to extend the services we offer to merchants and consumers. Our local operations span 18 growth markets across Asia, Central and Eastern Europe, Latin America, the Middle East and Africa. PayU India forays into two business verticals - payment offerings under PayU Payments Services Ltd. and alternate lending under PayU Finance. Headquartered in Sohna Road, Gurgaon, the company has a presence in Mumbai, Pune and Bangalore and has a total strength of 600+ employees. Mr. Anirban Mukherjee is the CEO for PayU India working with the global CEO Laurent Le Moal.
Under the aegis of PayU Payments Services Ltd., PayU provides payment gateway solutions to online businesses through its cutting-edge and award-winning technology. In India, PayU covers nearly 60% of the airline business and 90% of the entire e-commerce business and processes over INR 95,000 crores worth of digital payments annually. The company offers more than 70 local payment methods and serves more than 350,000 merchants including leading ecommerce businesses in India. The company also empowers SMBs, enabling them to accept mobile and online payments with minimum development effort. PayU India has processed more than 1 Billion transactions, the date for which is being used for offering Credit services.
With credit being the key business priority, PayU has also developed LazyPay, an alternate lending platform to offer credit solutions such as Small Ticket Credit (Buy Now, Pay Later), App based personal loans and Point of Sale Credit (Merchant EMI). Since its launch in 2017, LazyPay has gained significant traction and has disbursed 20mn+ loans to a customer base of a million user.
This role is with the Global analytics function for Credit and Payments, with specific focus on improving our credit offerings in India, Colombia and Poland.

What you will be doing:
As a part of the Global Credit Risk and Data Analytics team, this person will be responsible for carrying out analytical initiatives which will be as follows: -
Dive into the data and identify patterns
Development of end-to-end Credit models and credit policy for our existing credit products
Leverage alternate data to develop best-in-class underwriting models
Working on Big Data to develop risk analytical solutions
Development of Fraud models and fraud rule engine
Collaborate with various stakeholders (e.g. tech, product) to understand and design best solutions which can be implemented
Working on cutting-edge techniques e.g. machine learning and deep learning models
Example of projects done in past:
Lazypay Credit Risk model using CatBoost modelling technique ; end-to-end pipeline for feature engineering and model deployment in production using Python
Fraud model development, deployment and rules for EMEA region
Basic Requirements:
1-3 years of work experience as a Data scientist (in Credit domain)
2016 or 2017 batch from a premium college (e.g B.Tech. from IITs, NITs, Economics from DSE/ISI etc)
Strong problem solving and understand and execute complex analysis
Experience in at least one of the languages - R/Python/SAS and SQL
Experience in in Credit industry (Fintech/bank)
Familiarity with the best practices of Data Science
Add-on Skills :
Experience in working with big data
Solid coding practices
Passion for building new tools/algorithms
Experience in developing Machine Learning models
Behavioural Skills:
Team Player
Perseverance
Knowledge sharing skills
Energetic & Positive attitude
Go getter instinct
So what do we offer?
Opportunity to work on exceptional projects using cutting edge technology in big data environment
A Competitive salary, including benefits
Modern offices with individual working spaces
Awesome teams that love finding ways of making things better, faster, stronger
Interesting growth prospects",3.5,"PayU Payments Pvt Ltd
3.5",Bengaluru,"Hoofddorp, Netherlands",1001 to 5000 employees,-1,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
SCON - Data Scientist - Science of Winning - Pursuit,-1,"SCAM ALERT: Caution against fraudulent job offers!
More Info

×

SCAM ALERT
Caution against fraudulent job offers!

We have been informed of instances where jobseekers are led to believe of fictitious job opportunities with Deloitte India (“Deloitte”). In one or more such cases, false promises of actual or potential selection, or initiation or completion of the recruitment formalities appear to have been or are being made. Some jobseekers appear to have been asked to pay money to specified bank accounts of individuals or entities as a condition of their selection for a ‘job’ with Deloitte. These individuals or entities are in no way connected with Deloitte and do not represent or otherwise act on behalf of Deloitte.

We would like to clarify that:
At Deloitte, ethics and integrity are fundamental and not negotiable.
We are against corruption and neither offer bribes nor accept them, nor induce or permit any other party to make or receive bribes on our behalf.
We have not authorised any party or person to collect any money from jobseekers in any form whatsoever for promises of getting jobs in Deloitte.
We consider candidates only on merit and that we provide an equal opportunity to eligible applicants.
No one other than an authorised official of Deloitte is permitted to confirm any job offer from Deloitte.
Anyone who at any time has made or makes any payment to any party against promises of job or selection for a job with Deloitte or any matter related to this (including those for ‘registration’, ‘verification’ or ‘security deposit’) or otherwise engages with any such person who has made or makes fraudulent promises or offers, does so (or has done so) entirely at their own risk. Deloitte takes no responsibility or liability for any such unauthorised or fraudulent actions or engagements.
We encourage jobseekers to exercise caution. If you have queries about the veracity of a job offer you have received which relates to Deloitte or would like to report a fraud with regard to job offers with Deloitte, please send an email to inhiringalert@deloitte.com

“Deloitte” is
the brand under which tens of thousands of dedicated professionals in
independent firms throughout the world collaborate to provide audit,
consulting, financial advisory, risk management, tax, and related services to
select clients. These firms are members of Deloitte Touche Tohmatsu Limited, a
UK private company limited by guarantee (“DTTL”). Each DTTL member firm
provides services in particular geographic areas and is subject to the laws and
professional regulations of the particular country or countries in which it
operates.

Deloitte in U.S and U.S
India

In the US,
Deloitte LLP and Deloitte USA LLP are member firms of DTTL. The subsidiaries of
Deloitte LLP provide industry-leading audit, consulting, tax, and advisory services
to many of the world’s most admired brands, including 80 percent of the Fortune
500 and more than 6,000 private and middle market companies.

Background

The U.S. India Consulting Sales &
Pursuit Excellence (S&PE) is an extension of the U.S. Consulting S&PE
team which is dedicated to the success of the firm’s sales efforts as they are
defined by Deloitte Consulting leadership.
The team supports sales success by driving continuous improvement in
sales effectiveness.

The Science of Winning program uses data
science, neuroscience, and consumer behavior research techniques to identify
why Deloitte Consulting wins and loses opportunities, then designs and
implements solutions to increase the likelihood of winning. Solutions range
from highly manual presentations in PowerPoint to automated algorithms that
provide information in Salesforce environments.

The Science of Winning team works in a
fast-paced pursuit environment, supporting all types of professionals in the
sales process: writers, designers, senior sales partners, consultants, and
analysts. Concise, actionable, insightful information provided in a timely
manner is the cornerstone of the Science of Winning program, which has been in
existence since 2017.

S&PE
is looking for employees In US India, interested in supporting Deloitte
Consulting’s Sales strategy. This position will be based in Hyderabad.

Function

Deloitte
Consulting India Private Ltd.

Service Line

US
S&PE

Job level

Sr
Consultant

Professional qualification

Bachelor’s or Master’s degree with quantitative and analytical background
preferred. MBA Finance or related field.

Work experience

5
Plus. 4 years in related field

Key job
responsibilities include but are not limited to…

The Science of Winning Senior
Data Scientist will work closely with the Science of Winning India Lead to
deliver innovative and transformative data science solutions. The Senior Data
Scientist will be consistently challenged—leveraging both existing strengths
and developing new skills. Soutions will range from natural language processing
to video analysis to audio analysis to more straightforward regression
modeling.

The Senior Data
Scientist will be responsible for understanding the business requirements and
making sure the technical environment and solution fulfill those business
requirements in the most efficient way. In order to do this, he/she will work
with fellow Science of Winning Data Scientists, designers, IT professionals,
software developers, and his/her own network. Due to the nature of the sales
process, work take place in a constantly evolving environment, so agility and
flexibility will be critical.

Specific

responsibilities include:
·
Develop
a deep understanding of the Consulting sales process

·
Interrogate
the data stored in the MS Azure data science lab and other secure locations

·
Collect
and document business requirements

·
Develop
industry-leading designs

·
Develop
the solution—either programming directly, or serving as an advisor to more
junior programmers

·
Test
the solution

·
Coordinate
industrialization of the solution so that it can be used throughout Deloitte
Consulting US

·
Participate
in a network of data scientists across Deloitte departments to ensure a culture
of inclusivity and innovation

·
Commit
to continuous improvement and learning—both personally and in support of team
members

·
Provide
honest and open transparency into work successes and challenges

Key competencies

·
Strong
verbal and written English communication skills

·
Deep
curiosity about the Consulting sales process

·
Proactive,
self-motivated and demonstrated ability to work independently with minimal
guidance

·
Strong
interpersonal skills

·
Knowledge
of current data science techniques and passion for staying current

·
Familiarity
with MS Azure and Data Bricks

·
Data
munging skills using R and Python

·
Strong
data science skills

o
Deep
insights into statistical modeling and simulation tools like R and Python

o
Good
understanding and implementation of graph analytics and graph algorithms

o
Experience
with Big Data execution using Spark

·
Strong
Natural Language Processing skills

o
Know
semantic technologies (RDF,OWL) and natural language processing, Text Mining,
search algorithm development and development in Java/J2EE/Scala

o
Experience
with text mining using GATE or UIMA

o
Experience
with Open source NLP libraries e.g. Corenlp, Opennlp, mallet, etc

o
Good
Knowledge of indices such as Apache Solr, Lucien and Elastic Search will be
plus

·
Strong
knowledge of statistics

·
Experience
with video and audio classification and analysis

·
Commitment
to learning and designing the best solutions in the world

Career Development

This position needs long term
commitments. Options to grow will be provided as the Science of Winning team
expands.

Disclaimer: Please note that this Job Description is subject to
change based on the business/project requirements and at the discretion of
management.

\\“Deloitte\\” is the brand under which tens of thousands of dedicated professionals in independent firms throughout the world collaborate to provide audit, consulting, financial advisory, risk management and tax services to selected clients. These firms are members of Deloitte Touche Tohmatsu Limited DTTL, a UK private company limited by guarantee. Each member firm provides services in a particular geographic area and is subject to the laws and professional regulations of the particular country or countries in which it operates. DTTL does not itself provide services to clients. DTTL and each DTTL member firm are separate and distinct legal entities, which cannot obligate each other. DTTL and each DTTL member firm are liable only for their own acts or omissions and not those of each other. Each DTTL member firm is structured differently in accordance with national laws, regulations, customary practice, and other factors, and may secure the provision of professional services in its territory through subsidiaries, affiliates and/or other entities. In the United States, Deloitte LLP is the member firm of DTTL. Like DTTL, Deloitte LLP does not provide services to clients. Instead, services are primarily provided by the subsidiaries of Deloitte LLP, including: Deloitte & Touche LLPDeloitte Consulting LLPDeloitte Financial Advisory Services LLPDeloitte Tax LLP

Requisition code: E20HCSCONRS-SOW",3.9,"Deloitte
3.9",Hyderabad,"New York, NY",10000+ employees,1850,Company - Private,Accounting,Accounting & Legal,₹500+ billion (INR),"Amazon, PwC, McKinsey & Company"
Data Scientist,-1,"Miles is looking to expand its data science and data engineering team in INDIA!

Here's a quick checklist:
You live in India
Want to work for a fast-growing Silicon Valley Startup
You are passionate about solving challenging problems
You are looking to put your stamp on the product
What you'll need:
Education
Master's/PhD (preferred) or Bachelor's (required) in CS/ML/AI or relevant computational/engineering discipline

Machine Learning/Data Science:
Solid theoretical understanding of ML fundamentals: linear algebra, probability, statistics (as relevant to ML), optimization
Knowledge of different ML techniques and when/how to use them: classification, regression, clustering, outlier detection, dimensionality reduction, etc.
Comfortable manipulating and analyzing complex, high-volume, high-dimensionality data from varying, heterogeneous sources
Experience with messy real-world data - handling missing/incomplete/inaccurate data
Proficient in the Python ML ecosystem: NumPy, Pandas, SciPy, Scikit-Learn
Strong understanding of relational databases like PostgreSQL is a plus

Programming experience:
At least 2+ years of experience writing production-quality Python code
Version control: Git, GitHub/Bitbucket
Experience delivering large-scale deployable projects

Great to have
We deal with large volumes of geospatial data, so experience working with geospatial data at scale is a big plus
Knowledge of Python (Shapely, GeoPandas, Fiona, CartoPy, etc) and/or database (PostGIS) geometry/geospatial tools
Domain experience in building models for location-based services, transportation, scheduling, vehicle routing",3.9,"Miles
3.9",Bengaluru,"Bergen, Norway",51 to 200 employees,2005,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Min. Exp: 3 years
Ahmedabad, India
Job Role
Skills Required
Personality
Job Role
Develop and refine algorithms for machine learning from large datasets.
Write offline as well as efficient runtime programs for meaning extraction and real-time response systems.
Develop and improve Ad-Targeting based on various criteria like demographics, location, user-interests and many more.
Design and develop techniques for handling real-time budget and campaign updates.
Be open to learning new technologies.
Collaborate with team members in building products.
Skills Required
MS/PhD in Computer Science or other highly quantitative field.
Minimum 8 - 10 yrs of hands on experience in different machine-learning techniques.
Strong expertise in Big-data processing.
(Combination of the technologies you should be familiar with Kafka, Storm, Logstash, ElasticSearch, Hadoop, Spark)
Strong coding skills in at-least one object-oriented programming language (e.g. Java, Python).
Strong problem solving and analytical ability.
Prior 4+ year experience in advertising technology is preferred.
Personality
You want to work in a small, agile team.
You mentor other developers when needed.
You work hard and don’t need much oversight.
You like variety in your projects.
You want to be proud of what you do at your job.
Interested applicants should send their resume and cover letter at career@iqm.com",-1,iqm.com,Ahmedabad,"New York, NY",1 to 50 employees,2014,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Description :
Required competencies:
Phd/MTech/MS or equivalent degree in Computer Science or Mathematics or Statistics
Relevant industry or research experience
Strong knowledge of data mining, machine learning techniques and statistics
Experience with analysis on large scale datasets
Strong problem solving, programming skills and computer science fundamentals
Preferred Skills:
Knowledge of Hadoop and other distributed computing platforms
Experience with tools like Weka, R and other machine learning packages
Location : Bangalore",-1,WeRecruit Talent,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"Job Description :
Required competencies:
Phd/MTech/MS or equivalent degree in Computer Science or Mathematics or Statistics
Relevant industry or research experience
Strong knowledge of data mining, machine learning techniques and statistics
Experience with analysis on large scale datasets
Strong problem solving, programming skills and computer science fundamentals
Preferred Skills:
Knowledge of Hadoop and other distributed computing platforms
Experience with tools like Weka, R and other machine learning packages
Location : Bangalore",-1,WeRecruit Talent,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"Experience required: 2-4 years

We are looking for a passionate Data Scientist to turn data into meaningful information that can help our clients make data informed decisions

Typical responsibilities include end to end execution of advanced data science projects primarily involving applying data mining techniques, doing statistical analysis, and building high quality prediction systems. Youll have access to large B2B and B2C data sets on a robust analytic platform. Customer and account data is enriched with demographics and firmographics, transactional purchase history, Web behavior and cross-channel marketing campaign history. Tools and analytic environment include SAS, Tableau, R/Python and well-managed MPP RDBMS, Hadoop & Hive.

Loyalytics is a startup and our work environment is very conducive to trying and testing out a variety of new things. A high degree of passion, commitment to our customers priorities and willingness to learn new things on the go are some of the qualities that will help individuals succeed at Loyalytics.

Job Description:

· 2-4 years real world experience working as a data scientist

· Hands on experience in statistical modelling software such as R, Python or SAS (optional) along with data visualization tools like Tableau/Power BI

· Good understanding of statistical and predictive modeling concepts.

· Strong expertise in either R or Python

· Excellent analytical thinking, and problem-solving skills.

· Hands on experience in working on data mining and statistical machine learning problems

· In depth understanding of advance ML techniques and algorithms like regression, clustering, decision trees, Neural Networks, Gradient descent, SVM etc

· Experience in project management and handling client communications

· Excellent communication (written/verbal) skills, including logically structuring and delivering presentations.

· Open to learning new methods/techniques in the ever-changing world of analytics. High aptitude to learn quickly, assimilate to new teams and projects, and work well under pressure with appropriate attention to detail.",4.2,"loyalytics consulting
4.2",Bengaluru,"Bengaluru, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Position title
Data Scientist
Description
Excellent understanding of machine learning techniques and algorithms
Proficiency with R/ Octave for modeling, Python & Java for production-ready code.
Experience with common data science toolkits, such as R/ Octave for modeling, Python & Java for production-ready code. Excellence in at least one of these is highly desirable.
Experience with data visualization and extracting insights from them.
Proficiency in using query languages such as SQL, Learning in the area of NLP, predictive models & recommendation engines is a big plus
Crunch a large volume of data, observe trends and build scalable & analytical models.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality
Good knowledge of databases like NoSQL, MongoDB, Postgre, etc.
Perform Exploratory Data Analysis and Statistical Analysis; clearly present the results of an analysis to customers and management.
Experience with AWS, Google Cloud is a plus
Exposure with deep learning algorithms is a big plus
Required Skills
Selecting features, building and optimizing models using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Adopting new research methodologies including deep learning (CNNs LSTMs) on projects
Job Responsibilities
Bachelors/ Masters in Computer Science or Electronics from tier 1 & 2 colleges
Contacts

careers@algoscale.com",3.7,"Algoscale
3.7",Noida,"Noida, India",1 to 50 employees,2014,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"A dynamic professional with 8 years of work experience in ERP.
Extensive experience in implementation, customization and production support of ERP systems.
Excellent in interacting with the users in collecting the requirements and Proficient in customizing the requirements to Functional Specifications.",4.0,"Sulekha
4.0",Chennai,"Chennai, India",1001 to 5000 employees,2004,Company - Private,Internet,Information Technology,₹10 to ₹50 billion (INR),-1
Data Scientist,-1,"Overview:
The team that looks at constantly extracting valuable information for use in strategic decision making, product development, trend analysis, and forecasting. We deal with all kinds of structured/unstructured (image, text, etc) data and build data-driven solutions to solve customer problems. Our continued endeavor is to help users find a suitable match for themselves at the earliest.

Here is what we look for in a Data Scientist :
At Shaadi, we always put our users first. We are looking for A Data Scientist who is continuously adapting to new technologies and excited to work on products that affect millions of people every day.
Be the USER: Start by looking at things from the user’s perspective and don’t stop until you’ve evaluated
how the solution has impacted the user.
Deliver WOW: Never settle for mediocrity. Aspire for new user benchmarks and operational/technical excellence.
Passionately seek unconventional solutions that have the potential of redefining customer expectations.
Embrace & Drive CHANGE: Embrace curiosity. Accept and enthusiastically encourage change while
questioning the status quo and showing initiative. Never let the fear of failing hold you back.

Role :
A Data Scientist is responsible for understanding and deriving insights from the data collected by the company. He would be responsible for maintaining the data and building models from scratch using this data and also tuning and improving existing models as per business requirements.

What you will do in this role
Work with Product to identify opportunities for leveraging data to drive business solutions.
Preprocess large amounts of structured and unstructured data and analyze it to discover trends and patterns
Develop custom data models and algorithms, Use predictive modeling to increase and optimize customer
experiences, revenue generation, user-to-user discovery (matchmaking), weed out fraudster & scammers.
Collaborate with engineering and product teams in deploying the Models.
Develop processes and tools to monitor and analyze model performance and data accuracy.
What you should have
2-3 years of Data Science & Machine Learning experience in consumer internet products and technologies or B2C business.
Graduate/Post Graduate in Statistics, Computer Science or Engineering preferred; other graduate degrees should at least completed a diploma/certification in Data Science.
Machine learning Skills: Expertise in recommender systems, user profiling, natural language processing, image processing and other machine learning and predictive modeling techniques is required
Statistical Skills: Ability to work with large data sets and to interpret them statistically, find patterns (including anomaly detection) is expected.
Programming Skills: Proficiency in R, Python & SQL is required along with hands-on experience of Numpy/Pandas/scikit-learn/Keras/Theano/TensorFlow (or similar) preferred.
Visualization Skills: Ability to work with data warehousing solutions like Redshift, exposure to BI tools such as Looker or Tableau will be useful.
Strong Problem-solving aptitude
Brownie Points
Experience in working with big data platforms such as Hadoop, Spark, Hive, Pig will be useful.
Exposure to BI tools such as Looker or Tableau will be useful.",4.4,"People Interactive Pvt Ltd.
4.4",Mumbai,"Mumbai, India",1001 to 5000 employees,1996,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Sciences Intern,-1,"Description:

Presenting a program that provides women candidates, who've taken a career break, an opportunity to gain relevant work experience while being part of collaborative teams - BounceBack. Are you an analytics oriented woman professional on a career break and looking for an opportunity to re-tool your skill-set in the Data Analytics Space? This 36-week comprehensive and application-intensive Internship program is specially designed for you. At the Data Analytics India team in Target Corp., were solving cutting-edge problems in Retail using a combination of statistical analysis, optimization and behavioural economics. A few problems were trying to solve today are:

How do I predict a noisy outcome like customer buying behavior (or sales)?

What operational signals tell me if a customer is going to churn in 6 months to a year?

What is the financial value of making a customer happy? What exact initiative made a customer happy and by how much?

What will happen to my sales if I reduce the queues in my store by 2 people?

How much additional backroom space do I need, and in which stores, to maintain in-stocks during peak sales season?

How can I improve workload forecast for stores to optimize payroll?

What factors drive unavailability of products in Stores?

Come, join a dynamic, high-performing & Inclusive team that advices business on making critical decisions with the use of Advanced Analytics and Data Science.

You will have:
3 years of relevant work experience (in Consulting/Analytics domain in the past)
2 +years of ongoing break from work
Very strong Math skills and Quantitative Ability
Prior experience working in algorithms and programming (Primary Skillset - SQL, R/SAS/Python)
Excellent interpersonal skills
Ability to work with large-datasets to glean meaningful insights
Keen to develop business acumen
You will get
A medium that facilitates transition back in to professional career, and relevant work experience
Opportunity to strengthen technical skills, ramp up on newer tools and technology
Gain confidence and ramp up on latest technologies
Get mentorship from Target India leaders
A well-designed exposure to business problems and hands-on experience of problem-solving on those for 36 weeks
Opportunity to witness the 2nd largest Big Box retailer in the US in operations
A high pedigree peer and mentor network to collaborate from top Undergrad and Post Grad colleges in India and US
Steep learning curve and access to Industry-leading learning material
An Industry par monthly Stipend with food & day care re-imbursement along with subsidized transport.
Opportunity to convert internship to a full-time role to reignite your career with one of the leading analytics teams industry-wide
Qualifications:",4.1,"Target
4.1",Bengaluru,"Minneapolis, MN",10000+ employees,1962,Company - Public,General Merchandise & Superstores,Retail,₹500+ billion (INR),-1
Data Scientist,-1,"Greetings from Careator Technologies Private Limited., (CTPL).

CAREATOR Technologies is an emerging technology company, based on the strengths of understanding evolution of technologies right from the inception stage, offers a wide spectrum of services that span across both Application Life Cycle Management process of Software Engineering and Resource Management of Projects that deliver complex IT solutions for critical business processes. We @ CAREATOR, closely work with best MNCs (Product Based Companies & Service Based Companies) in India, UK, Australia, Canada & USA. CAREATOR is always been successful in meeting their customer needs and follows best IT practices to retain the right talented professional

We are hiring the following professionals on immediate basis. If you are interested and suitable for this position, please apply immediately.

Experience: 2-5 Years

Job Summary

Design and execute statistical analysis, modelling, and simulation efforts for clients that lead to actionable decisions affecting operations.

Analyse data sets to summarize, identify trends, predict future states, and characterize uncertainty.

Author complex written products documenting study results. Apply analytical approaches using statistical programming languages, including Python, and R.

Work closely with teammates from non-mathematical disciplines to ensure that operational strategies are considered in the context of applying statistical theory.

Use statistical theory on modelling, simulation, and data analysis to deliver measurable improvements to organizational policies and programs.

Responsibilities
Engage in data mining, algorithm development, statistical analysis, regression, and machine-learning initiatives
As part of ongoing work and interaction with the broader team, identify new opportunities to use modelling and advanced analytics to drive business value
High Proficiency in SQL
Expertise in applied statistics.
Able to translate business objectives into actionable analyses.
Able to communicate findings clearly to both technical and non-technical audiences
Expertise in Python for ML model development.
Experience with machine learning & Deep learning algorithms and predictive analytics
Natural curiosity to enjoy diving deep into the material to find answers to yet unknown questions.
Demonstrated ability to perform comfortably in a fast-paced work environment
Education, Skills and Abilities Required for Consideration:
Sound experience in using statistical and data mining techniques to solve real business problems
Having skills on Python for ML model Development
Passion for problem-solving, developing creative solutions, and continuous learning.
1+ years of Experience in Automotive / Mechanical background.
2+ years of ML/ Data science Experience
Good to have: Having worked on connected device. Having Idea on Clustering etc
Preferred : Deep Learning with Pytorch or TensorFLow Location: Bangalore",4.4,"Careator Technologies
4.4",Bengaluru,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Location: Bangalore

Skill Sets:
Strong learning acumen
Team Player
High sense of ownership
Ability to work in a fast-paced and deadline driven environment
Passion for technology
Highly skilled at Data Interpretation
Problem solver
Responsibilities:
Hypothesis testing, insights generation, root cause analysis, factor analysis
Statistical model (predictive & prescriptive) development using various statistical methods
Familiar with Machine learning techniques/algorithms
Test/train the model, Improve Model accuracy, Execute & Monitor model performance, prepare reports based on the results of the analysis
Data Extraction from various platforms such as SQL/Big Data Platform/Google CP, Dataset Preparation (creation of base data, aggregation, transformation), performing EDA
Qualifications:
Experience with data analysis/Modelling
Postgraduate with Engineering Background
Hands on exposure of machine learning concepts and algorithms
Must be fluent with any one of these Python, R or Java
Strong in statistical & machine learning concepts
Knowledge of Python Libraries – Scipy, Numpy, Pandas, IPython, Scikit-learn, Tensor-flow, Keras, Theano etc.
Strong Python skills for data wrangling / analysis / visualization / modeling
Experience with distributed big data processing (PySpark, Jupyter, Linux, AWS)
Deployed at least one industrial project using supervised / unsupervised machine learning",2.5,"Bharat Light & Power
2.5",Bengaluru,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Description

We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques.
Data mining using state-of-the-art methods.
Extending company’s data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis.
Doing ad-hoc analysis and presenting results in a clear manner.
Creating automated anomaly detection systems and constant tracking of its performance.
Required Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Perl, Python, SparkML, Weka, NumPy, MatLab, etc.
Experience with data visualization tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig.
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase.
Experience with Hadoop or similar distributed computing and storage platforms.
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills.
Exceptional analytical abilities,creativity and attention to details.
Good organizational and problem solving skills.
Good team player who is a self-starter and well organized.
Strong oral and written communication skills.
Required Education
Graduate degree in Math, Statistics, Computer Science, or other quantitative discipline.
Please email your resume to careers@gtpltech.com",-1,GridEdge Technologies,Pune,"Rockaway, NJ",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"SkillData Scientist
Experience7-9yrs
Job Location:Bangalore.

Job Description:
3 year of relevant experience
Expertise in machine / deep learning, and used various complex algorithms related to NLP, Recommendation Systems, Scoring, etc.
Good knowledge on different Neural Networks (RNN, CNN), Tensor Flow, NeuMF, Google Cloud API, etc.
00-9.00 Years",3.1,"Indecomm Global Services India Private Limited
3.1",Bengaluru,"Edison, NJ",1001 to 5000 employees,2003,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),-1
Data Scientist,-1,"“Make every logistics journey your best one yet” - Quincus

The Company.

At Quincus, our technology is designed to ease shipping issues—wherever in the world they may be. We commit ourselves in designing the most effective total end to end supply chain solutions through a dedicated technology ecosystem. This offers our users a personalized experience that bypasses traditional and expensive logistics options. By combining advanced technology, data analytics, and hands-on experience, we eliminate traditional and expensive logistics options.

The Opportunity.

As our business continues to grow, we are looking for a Data Scientist to join our team. The incumbent will turn data into understandable information for effective business making decisions. This person is passionate about Machine Learning. numbers and loves the idea of helping to make decisions with the support of data.

Your day to day.

- Partner with Product and Engineering teams to solve problems and identify trends.
- Creating and interpreting dashboards and reports to help leaders make more effective decisions.
- Building key data sets to empower operational and exploratory analysis.
- Experiments against data points and provide previously undiscovered solutions to command data challenges.

Who you are.

- Bachelor’s/Master’s in Computer Science/Engineering/Mathematics. [MCA, B.tech, M.tech]
- Minimum 5 years of experience in the same role.
- Proficient with one or more programming languages (Java, Python, R, etc.)
- Demonstrated experience applying data science methods to real-world data problems
- Ability to integrate multiple data sources and databases into one system.

What’s in it for you.

People: Work with passionate, smart, and entrepreneurial go-getters.
Fun environment: cool office space, stocked pantry, and team bonding.
Compensation: competitive salaries and benefits.



QUINCUS is not obligated to accept candidate profiles from any third parties on behalf of potential candidates for any position (advertised or otherwise) by any means, unless QUINCUS has fully executed a written agreement with such third party and has expressly requested such third party for candidate referrals/introductions. Third parties who provide unsolicited resumes of candidate(s) shall waive and forfeit all rights to claim for any placement fees or referral fees in the event that such candidate is eventually engaged and/or employed by QUINCUS.",4.4,"Quincus
4.4",New Delhi,"Singapore, Singapore",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"We have immediate requirement for Data Scientist
Data Scientist having skills in Python, ML, Statistical modelling,NLP with experience years 5 to 8 years in the respective filed
Interested please share updated CV
00-8.00 Years",3.5,"Quincus
4.4",New Delhi,"Bengaluru, India",201 to 500 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Ready to be a Cooper too? This might just be right up your alley!

We’re here to keep the dream of home ownership alive. Oh, and while we’re at it, we’re determined to change the lending industry itself. It’s simple, but it won’t be easy. And we’ll need a great team behind us. (That’s where you come in.) We want to show the world that transparency, candor and collaboration aren’t just good values. They’re good business. Working here isn’t for people who want to punch a clock. It’s for people who want to punch a hole in the status quo. Come join us. And make a difference instead of just a living.

Role/Responsibilities:
Develop novel solutions to market-driven problems using knowledge of the latest ML techniques, statistical analysis, and practical experience on previous data science projects.
Collaborate with stakeholders, business unit product owners, development teams to understand business needs and technical requirements
Work actively in all aspects of model development, including design, model implementation, validation, calibration, documentation, monitoring, and reporting
Research complex business issues and recommend solutions, including input requirements, other required data sets, modeling approaches, and end products

Required Skills and Experience:
Masters in a quantitative / applied field (Statistics) or PhD preferred
8+ years of experience in data science roles
3+ years in handling teams
Strong statistical foundation with broad knowledge of supervised and unsupervised techniques
Experience with predictive modeling (classification, regression, parameter tuning, optimization criteria, feature selection), preferably with multiple techniques is a requirement.
Experience in model validation techniques, model testing and continuous monitoring of model performance
Strong knowledge of programming and modeling using R and SAS (the candidate would work in Python ecosystem)
Strong SQL skills and experience working with large data sets.
Experience working collaboratively, including building and maintaining relationships with stakeholders/clients.
Experience advising a team on innovative methodologies, data science tools, and environments.
Ability to articulate complex technical concepts/ideas to both technical and non-technical audience.
Experience applying modern machine learning techniques
Very strong in identifying hidden use cases from dataset/ business interactions and come up with new solutions

Nice to Have Skills & Qualities

Flexibility to learn and apply new methodologies
Mortgage Industry experience /knowledge

Mr. Cooper is committed to nurturing a diverse and inclusive environment where every employee is empowered to be their authentic self. We know that a large part of our success as a business is directly tied to our ongoing efforts to attract and retain diverse talent and maintain an inclusive environment where each employee can thrive. Embracing and leveraging diversity through an inclusive work environment fosters new ideas, new insights, and constant innovation. We strive to weave the principles of diversity and inclusion throughout the fabric of how we work, how we interact, and how we engage with our customers and the community.

Job Requisition ID:
011698

Job Category:
Information Technology

Primary Location City:
Chennai

Primary Location Region:
Tamil Nadu

Primary Location Postal Code:
600089

Primary Location Country:
India

Posting Organization:
Xome

Line of Business:
Information Technology

Additional Posting Location(s):
Alternate Requisition:
No",3.0,"Unitforce Technologies Consulting Pvt Ltd
3.5",Bengaluru,"Lewisville, TX",1001 to 5000 employees,2012,Company - Private,Real Estate,Real Estate,Unknown / Non-Applicable,-1
Data Scientist,-1,"• Good Knowledge on the automotive Communication protocols like CAN, Flex ray
• Sound knowledge on the Driver assistance systems (feature functions like lane departure prevention, collision avoidance etc.)
• Practical knowledge of automotive sensors like Camera, RADAR etc.
• Testing, Debugging and validation of application software as per the Requirement (in DOORS)

Additional skills: (Optional)
• Overview on Ethernet communication protocol
• Hands on with visualization tools for sensors
• Good Overview on analyzing time series data, (ASC, MAT, DAT file),
• Good knowledge on latest trends like LIDARs and multi-mode RADARs.
• Knowledge on Atlasian tools like Confluence, JIRA etc.

• Good Knowledge on the automotive Communication protocols like CAN, Flex ray
• Sound knowledge on the Driver assistance systems (feature functions like lane departure prevention, collision avoidance etc.)
• Practical knowledge of automotive sensors like Camera, RADAR etc.
• Testing, Debugging and validation of application software as per the Requirement (in DOORS)

Additional skills: (Optional)
• Overview on Ethernet communication protocol
• Hands on with visualization tools for sensors
• Good Overview on analyzing time series data, (ASC, MAT, DAT file),
• Good knowledge on latest trends like LIDARs and multi-mode RADARs.
• Knowledge on Atlasian tools like Confluence, JIRA etc.",4.2,"Daimler
4.2",Bengaluru,"Stuttgart, Germany",10000+ employees,1886,Company - Public,Transportation Equipment Manufacturing,Manufacturing,₹500+ billion (INR),"Audi, Porsche, BMW"
Data Scientist,-1,"Data Scientist
Experience

– 2 to 4 Years
Education

– B.Sc / M.Sc (Maths / Statistics) B.Tech /B.E. – Computer Science
Job Description:


2 - 4 years of experience in machine learning and data mining
Excellent understanding of different software such as Perl, Python, Hadoop, Java and R programming
Strong technical background and have excellent problem-solving abilities
Good in at least one programming or scripting language
Understanding of databases and ability to write SQL queries
Excellent oral and written communication skills with business acumen
Should be a self-starter with high initiative and enthusiastic to learn and deliver on latest tools and technologies
Experience worked in big data environment is an added advantage",3.1,"Sybrant Technologies
3.1",Chennai,"Chennai, India",1 to 50 employees,2007,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Type: Permanent

Job Location: Kochi/ Trivandrum

Experience : 7 to 10 years

Able to connect to new and relevant data and get to customer insights very quickly.
Research and devise innovative statistical models for data analysis.
Enable smarter business processes and implement analytics for meaningful insights.
Keep current with technical and industry developments

Technical skills:
Proficient with data mining, mathematics, and statistical analysis.
Strong Experience in Cloud (AWS/Azure/Google Cloud)
Expertise in Distributed Data (Hadoop/Spark/Kafka/Hive/Pig etc.)
Knowledge in Legacy Enterprise Tools (Informatica/ Talend/SSIS)
Expertise in Programming Skills (Python/Java/R/Scala etc.)
Experienced in 2 or more packages, implementing across multiple customers (Oracle/Microsoft SQL Server/IBM DB2/ Postgres/ MySQL/ AWS Redshift/ MongoDB/ CouchDB)
Experienced at working with Unstructured data.
Awareness on at least one of the Data Visualization Tools (Microsoft Power BI/ Tableau/ Qlik)

Soft Skills:
Excellent English language communication skills, verbal and written
Ability to build strong working relationships.
Ability to facilitate change management with teams.
Experience in the full project delivery life cycles
Good team player",4.2,"Experion
4.2",Thiruvananthapuram,"Trivandrum, India",201 to 500 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Key Deliverable :

- Build Machine Learning tools to automate processes and reporting

- Enhancing data collection procedures

- Undertake processing, cleansing, and verifying the integrity of data used for analysis

- Automate various reports across Portal

- Apply data mining techniques on various kinds of data and

- Conduct routine predictive analysis

- Perform statistical analysis

- Continuously enhance the user experience and features of reports

- Work closely with Sales & Marketing teams and demonstrate proactiveness at all times

Job Type: Full-time

Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Bachelor's (Required)
Work Remotely:
No",-1,Alif Realty,Noida,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"Roles and responsibilities

Explore large datasets to surface useful trends, signals, and segments. The role drives business and industry solutions focused on Big Data and Advanced Analytics, in diverse domains such as product development, pricing, marketing research, public policy, optimization and risk management. The role uses analytics to provide predictive, prescriptive, and decisive insight:
Translate business objectives into analytic approaches, and identify data sources to support analysis.
Analyze and model structured data using advanced statistical methods
Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns.
Analyze data using SAS, R, Python, Java, open source packages and commercial/enterprise applications.
Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods.
Implement algorithms and software needed to perform analyses
Drive client engagements focused on Big Data and Advanced Business Analytics, in diverse domains such as product development, marketing research, public policy, optimization, and risk management.
Interface with databases (SQL, NO SQL, HDFS) to extract, transform and load data
Communicate results and educate others through reports and presentations.
Essential skills required
Education / professional qualifications

Masters, or PhD in Computer Science, Statistics, Mathematics

Prior Experience:

Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience

Technical skills
Ability to break down complex problems, and develop strategies to solve them
Masters, or PhD in Computer Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research, or related fields, with 5+ years of relevant experience
Strong mathematical background with ability to understand algorithms and methods from a mathematical viewpoint and an intuitive viewpoint.
Expertise in at least one of the following fields: machine learning, data visualization, statistical modeling, data mining, or information retrieval
Develop and apply machine learning, and statistical analysis methods, such as classification, collaborative filtering, association rules, time-series analysis, advanced regression methods and hypothesis testing
Strong data extraction and processing, using NoSQL, MapReduce, Pig, and/or Hive preferred
Experience with command-line scripting, data structures and algorithms
Ability to work in a Linux environment, and process large amounts of data in a cloud environment
Proficiency in analysis (e.g. R, SAS) packages, and programming languages (e.g. Java, Python, Ruby)
Behavioral / team skills
Personal drive and positive work ethic to deliver results within tight deadlines and in demanding situations
Flexibility to adapt to a variety of engagement types, working hours and work environments and locations, strong time management skills
Excellent written and verbal communication skills Team player; self-driven and ability to work independently
Team player; self-driven and ability to work independently",4.2,"Anlage HRO Services
4.2",Bengaluru,"Mumbai, India",201 to 500 employees,1996,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Data Scientist Large Banking MNC 5 - 10 years Bangalore QUALIFICATION Bachelor’s or Masters Technology Degree in Computer science or Equivalent Job Description The senior data scientist will get the opportunity to work in an agile software development enviornment addressing machine learning and optimization analytics problems. The senior data scientist will be part of cross diciplinary data science team working on software development projects, typically involving large, complex data sets. They will work with technical team in development and deployment and application of predictive analytics. Key Skills Required Demonstrated skill of data cleansing, data qualityy assesment.

Use the descriptive statistics, feature extraction and predictive analytics on real datasets. Skills at data visualization and storytelling for an audience of stakeholders. Experience in working with Hadoop and spark will be added advantages.",-1,TALCHEMIST,Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Sr. Applied Scientist,-1,"Sr. Applied Scientist, Retail Systems, Amazon Bangalore


Impact

As a member of Amazon's Global Retail Systems Development team, you'll play a key role in the evolution of our Competitive Monitoring team to solve the world's most complex technical challenges in Natural Language Processing, Optimization, Classification and Prediction.

Innovation

Are you seeking an environment where you can drive innovation? Do you want to apply state-of-the-art computer science and advanced machine learning to solve real world problems of competitive data analysis? Does the challenge of building real time, highly scalable solutions for the most complex online business using innovative technology excite you?

Opportunity

To meet these challenges, the Amazon.com Retail Systems team is looking for passionate, talented and innovative applied scientists for a new team that will be based in Bangalore focused on building and deploying advanced algorithmic systems that help optimize millions of transactions every day. This team will also coordinate with teams in Chennai, India and Seattle, US.
You will be involved in analyzing and modeling terabytes of data to solve real world problems, will own end-to-end business problems/metrics that directly impact the profitability of the company.


Basic Qualifications

· A MS or PhD in Computer Science or Machine learning or Operational research or Statistics or in a highly quantitative field
· 7+ years of hands-on experience in applied Machine Learning and Big data.
· Strong grasp of machine learning, data mining and data analytics techniques
· Strong Problem solving ability
· Comfortable using Java or C++/C.
· Good knowledge of scientific programming in scripting languages like R/Python/Matlab

Preferred Qualifications


· PHD in any of the following disciplines - Computer Science, Machine Learning, Data Mining, Statistics, Operational Research
· Experience with distributed algorithms
· Experience with Hadoop, Hive, Pig, Spark
· Superior verbal and written communication skills, ability to convey rigorous mathematical concepts and considerations to non-experts.",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Scientist,-1,"About Company:
Casepoint provides full eDiscovery capabilities through a powerful, secure, cloud-based platform. We are repeatedly chosen by leading law firms and multinational corporations for their largest matters. On an upward trajectory for almost a decade, Casepoint is looking to expand its team globally. Team cooperation, work hard, play hard attitude, open communication, and kindness mark Casepoints culture.
Job Description
We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products
Key job responsibilities:
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending companys data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Required skills & experience
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, Logistic Regression (LR), Linear Discriminant Analysis (LDA), K-Nearest Neighbors (KNN), Classification and Regression Trees (CART), Gaussian Naive Bayes (NB), Support Vector Machines (SVM).
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. Excellence in at least one of these is highly desirableX
Great communication skills
Experience with data visualization tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality
Compensation & culture:
Excellent culture produces an excellent product. We value our team members, so we provide a nurturing environment of camaraderie. We recognize talent with competitive compensation and career empowerment.
Location: Surat, India",3.5,"Casepoint Pvt. Ltd
3.5",Surat,"Washington, DC",51 to 200 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"We are hiring Data Engineer / Data Scientist with below criteria.

Key Responsibilities

· Coordinate and direct projects through detailed plans and drive integration of business and technical activities

· Advise Champions’ clients on best practices in software development to maximise return on investment in projects

· Direct design and development of software platforms/products/product components using Microsoft .NET technologies

· Provide technical leadership for one or more development teams

· Work in a cross functional role in collaboration with business analytics teams

· Consistent focus on delivery quality and quantifiable process improvement

· Gain strong functional knowledge in the area of business analytics

Desired Profile

· Graduate(BE/B.Tech)/Masters(ME/M.Tech/MS) in Computer Science or equivalent from a premier institute (preferably IIT/NIT) with 6+ years’ experience

· WinForms and web Sourcing (Basic knowledge on data science )

· Experience in working closely with clients in implementation of business requirements

· Data oriented mindset with interest in deriving insights though data analysis

· Excellent knowledge of Microsoft .NET WinForms Applications and ASP MVC 4.0

· Experience on Object Oriented Design and Analysis, application design patterns

· Hands on experience in .Net 3.5/4.0, C# ,VB.Net, ADO.Net, web services, Simple Object Access Protocol (SOAP), XML, Json, XSD, SSLWCF, WF , WPF, LINQ, WEB 2.0, ASP.Net with Ajax, Web Services, XML/XSLT, DHTML, JQuery , ASP.Net MVC, Entity Framework

· Well versed with databases preferably Microsoft SQL server 2012 or higher

· Knowledge of HTML, CSS, JavaScript is a plus

· Experience with Agile methodologies like Scrum and Test Driven Development is a plus

· Strong knowledge of software development best practices

· Experience of developing web apps for various form factor devices is a plus

· Good hands-on experience with Code Repository tools (like SVN), Unit Testing Frame works (/JUnit/TestNG) and Java debugging tools

· Excellent verbal and written communication skills

· NoSQL Cassandra, MongoDB, DynamoDB is a plus

Thanks ,

Poojitha

Job Type: Full-time

Salary: ₹300,000.00 - ₹1,000,000.00 per year

Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Bachelor's (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.0,"champions infometrics pvt ltd
4.0",Bengaluru,"Bangalore, India",1001 to 5000 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"The Clinton Health Access Initiative, Inc. (CHAI) is a global health organization committed to saving lives and reducing the burden of disease in low-and middle-income countries, while strengthening the capabilities of governments and the private sector in those countries to create and sustain high-quality health systems that can succeed without our assistance. For more information, please visit: http://www.clintonhealthaccess.org
CHAI, in partnership with its India affiliate William J Clinton Foundation (WJCF), works in close partnership with and under the guidance of the Ministry of Health and Family Welfare (MoHFW) at the Central and States’ levels on an array of high priority initiatives aimed at improving health outcomes. Currently CHAI/WJCF works across projects to expand access to quality care and treatment for HIV/AIDS, Hepatitis-C, tuberculosis, cancer and immunization.
Background
The world has not experienced a pandemic at the scale or pace of the current COVID-19 pandemic; the virus has ferociously attacked high- and low-income countries alike, but in so doing has exposed inequities in access to quality care within and across countries. Despite a proactive mitigation and stringent suppression strategy, the number of COVID cases in India continues to rise. While the indirect impacts of the COVID-19 on availability and utilization of routine health services cannot yet be known, lessons from previous crises suggest that service disruption and displacement will have grave impact on population health. In order to address these challenges, a robust response based on strengthened health workforce, resilient supply chains and rapid increase in diagnostic capacity is being spearheaded by the Ministry of Health and the Indian Council of Medical Research (ICMR).
Program Overview
WJCF, in partnership with its affiliate CHAI, is supporting the COVID-19 response in the areas of testing policy, strengthened data and delivery systems, and development of guidelines. The programme has been supporting the ICMR in scaling up testing, providing data-driven insights to support supply chain management including forecasting and inventory management, and helping build guidelines and Standard Operating Procedures (SOPs) for downstream distribution of commodities. Separately, the programme also supports selected states on localized strategies for testing scale up and equitable access, stronger engagement with the private sector, improved treatment readiness, robust awareness campaigns and capacity building initiatives, and analytics-based programme management.
Role
We seek a highly motivated individual with demonstrated analytical abilities for the role of Data Scientist based at Delhi. The Data Scientist will analyse programme data and support government stakeholders in scientific research. The Data Scientist will also be responsible for synthesizing data from multiple datasets and creating frameworks for analysing program data which can be used for informing strategic programmatic decisions. The Data Scientist will also be responsible to propose additional research and program management initiatives supported with data / data collection exercises.
A strong profile will include outstanding credentials, analytical ability, and communication skills. The candidate must be self-driven, entrepreneurial, adaptable, and have a high level of comfort with ambiguity. The candidate must be able to function independently and flexibly with a strong commitment to excellence. We place great value on qualities such as resourcefulness, responsibility, tenacity, independence, energy, and work ethic.

Support evaluation of data and data systems for research enhancement and research management; iteratively review data and data acquisition systems along with published and ongoing research on Covid-19 and recommend exploration of additional areas of research.
Product management of a large reporting portal (software engineering experience required); recommend and manage program and governance metrics and additional features/reports and functionalities to inform programmatic decision-making. Coordinate with software development team to enhance/add features and manage change requests.
Proactively develop guidelines and policy for data management, audit mechanisms, best practices and data sharing, including relevant methodology for data sharing (HIEs, PII removed data, REST APIs etc depending on context).Develop and validate multiple hypothesis using relevant statistical tests to answer programmatic questions and test management frameworks distributions and anomalies by performing statistical tests of significance, i.e. Chi Square tests, t-tests, correlation matrices, LDA, ANOVA/MANOVA templates that can be used on multiple datasets with minimum rework.
Coordinate a team of software engineers and assist with UI best practices. Recommend UI development strategies for information sharing on the reporting portal by developing wireframes, functionalities and coordinating development and UAT releases.
Analyse reporting needs and requirements, assesses current reporting in the context of strategic goals and devise plans for delivering the most appropriate reporting solutions to users.
Support capacity building of key government functionaries on relevant competencies for sustained ownership and delivery
Perform other responsibilities as requested by program leadership.

Master's/Bachelor’s degree in engineering and or related fields (Courses with Linear Algebra, Calculus, computer programming) with 5+ years’ work experience
Experience of integrating ML projects into software systems
Proficient in SQL:
Ability to write production grade queries (including nested queries)Understanding of stored procedures, partitioning of tables, AD security, and indexes
Proficient in R/Python:
Familiarity with control structures, loops, OOPS principles
Understanding of notebooks
Familiarity with data structures and algorithms - Intermediate
Understanding of text operations including regular expressions, string processing
Proficient in machine learning techniques
Familiarity with Linear and Logistic Regressions
Basic experience with tree and tree ensemble learning techniques (Bagging and Boosting)
Familiarity with unsupervised learning techniques (knn, Cosine similarity, hierarchical clustering)
Proficient in NLP (Named Entity Extraction, POS Tagging, Cosine Similarity, Sequence Networks such as RNN (Recurrent Neural Networks,) BERT, Word2Vec)
Experience with distributed systems such as Hadoop / Spark (PySpark / SparkR)
Experience in open source BI tools such as Metabase and D3
Entrepreneurial mindset, including ability to work independently, self-motivate, and propose and implement new initiatives
Exceptional communication (written and verbal) skills and stakeholder management capabilities
Ability to think strategically, handle ambiguity, and problem solve in a fast-paced, limited-structure, multicultural environment
Ability to be effective in high-pressure situations, handle multiple tasks simultaneously, and set priorities
Ability to absorb and synthesize a broad range of information, especially clinical, scientific and technical manufacturing information
#jobreference2",3.5,"champions infometrics pvt ltd
4.0",Bengaluru,"Boston, MA",501 to 1000 employees,-1,Non-profit Organisation,Social Services,Non-Profits,Unknown / Non-Applicable,-1
Data Scientist,-1,"Primary Responsibility: The data scientist/analyst will support DSS in the areas of advanced data analytics. The analyst will be required to provide support in client engagement and data analysis, create dashboards, benchmarking.

Need strong power point, excel modelling skills, analytical and quantitative problem-solving skills, work effectively with people at all levels, communicate complex ideas effectively – both verbally and in writing. Willingness to travel extensively. Experience in the areas of Operations Management in industry verticals such as Oil & Gas/ Chemicals/ Utilities/ Mining & Metals would be an added advantage.

Desired Skillsets

4-8 years of professional experience in Data insights generation & storytelling,
Ability to build Visualization layers using Tableau/Power BI to drive the story
Capability to build predictive models using R & Python etc.
Strong presentation skills with Powerpoint and ability to articulate insights very clearly to clients
Good knowledge of scripting and ability to write complicated yet efficient SQL queries and stored procedures
Experience in building data products, Embedded analytics and reporting
Full understanding of the processes of data quality, data cleansing, and data transformation
Experience in leading team of 2-4 people, coach them and drive project outcomes through them
Can handle end to end project by his own and ability to independently manage the clients and expectations
Experience in end-to-end implementation of Business Intelligence (BI) reports & dashboards.
Background in software/web application development with tools such as Javascript, HTML, C# etc. is added advantage
Comfortable in manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources.Ability to research and troubleshoot technical problems.

Other Requirements

Experience in operations risk management consulting space is preferred
Preferably in one of the industries - Oil & Gas/ Chemical & Petrochemicals/Utilities/Mining & Metals
Proven work experience as a data analyst / data scientist
Programming experience in statistical modelling languages such as R, Python is a plus
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information/data with attention to detail and accuracy
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Knowledge and experience with reporting packages and databases
Knowledge of statistics and experience using statistical packages for analyzing large datasets (Excel, DB, Hadoop etc.) is a plus
Adept at queries, report writing, interpreting and presenting findings

MUST be open to travel on client engagements to within and outside India (for short durations)",-1,DSS Sustainable Solutions,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
Connected Car Data Scientist,-1,"Job Description: Data Scientist

Education & Training

• Bachelor’s degree or Masters in Computer Science/Statistics/Mathematics

Experience
• 7 to 9 years of experience in executing data-driven solutions to increase efficiency, accuracy, and utility of internal data processing.
• Experienced at creating data regression models, using predictive data modeling, and analyzing data mining algorithms to deliver insights and implement action-oriented solutions to complex business problems.
• Proficient knowledge in statistics, mathematics and data analysis
• Excellent understanding of business operations and analytics tools for effective analysis of data
• Experience on optimized data collection procedures and generate reports.
• Experience on building predictive models and machine-learning algorithms.
• Experience in designing complex reports such as Drill-down, Drill-through, Cascading, Matrix, cross tab and Map reports using Power BI or Tableau
• Expertise in data storage structures, data mining, and data cleansing
• Systematic problem-solving approach with strong communication skills and a sense of ownership and drive

Skills
• Primary Skills
• Strong hold of concepts in Statistics
• Strong programming skills in R, Python, Java
• Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark.
• Proficient with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data
• Proficient in with SQl Databases like MSSql, Postgres.
• Have a good exposure to Azure Analytics Products like, Data Factory, HD Insights, Azure Data Lake Storage, Data Bricks.
• Experience on different data visualization tools like PowerBI , Tableau.
• Secondary Skills
• Tools - Qliksense , Tableau
• Kusto Query Language
Job Responsibilities

• Supporting the analytics needs of business by analyzing data from multiple sources
• Identify valuable data sources and automate collection processes
• Undertake preprocessing of structured and unstructured data
• Analyze large amounts of information to discover trends and patterns
• Support in collecting, organizing, and interpreting data along with fellow colleagues.
• Build predictive models and machine-learning algorithms
• Use machine learning tools and statistical techniques to produce solutions to problems
• Combine models through ensemble modeling
• Present information using data visualization techniques
• Propose solutions and strategies to business challenges
• Collaborate with engineering and product development teams

Job Responsibilities
Responsible
for installation, maintenance, and providing support for Application
Performance Monitoring and Instrumentation with the primary focus on
AppDynamics and Azure Monitor.
Help
define and implement best practices for Production Application Management
monitoring
Assist
engineers with production Infrastructure Monitoring
Ability
to develop necessary POCs & POVs in sandbox/testing environment
Ability
to support setup and configuration of the APM tool
Assist
in building an APM Centre of Excellence
Operating
system and server architecture knowledge of UNIX/Windows/virtual systems
Assist
development teams with application and server troubleshooting and
diagnostics
Programming
automation (VBA /VB.Net, JAVA or major scripting languages such as Perl
and Python, Unix/Linux shell scripts)",3.4,"Mercedes-Benz Research and Development India Private Limited
3.4",Bengaluru,"Chakan, India",1001 to 5000 employees,1996,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Volkswagen, Tata Motors"
Machine Learning Engineer/Data Scientist,-1,"Job Requisition ID #
20WD40887
Job Title
Machine Learning Engineer/Data Scientist
Job Description

Autodesk is seeking a Machine Learning Engineer/Data Scientist to join our Sales Data Science team. We build innovative data products and machine learning solutions for Autodesk's sales teams. In this critical role, you will work alongside product development, product managers, and data engineers to tackle fundamental data science models in our Asia-Pacific (APAC) sales region.

Data, automation and advanced analytics technologies are drastically transforming our sales team in APAC and this person will be the data scientist in charge of overseeing our data science practice in Singapore, India, China, Korea, Australia, and New Zealand. As the Data Scientist for APAC, your primary responsibility will be to empower our sales teams with machine learning models and data analytics to make them more productive and better equipped to be customer-centric. You will collaborate with our Data Scientists in Barcelona and the US to build major data science products.

The ideal candidate is a strong communicator and has experience as a Data Analyst or Data Engineer who has strong Data Science leanings, and has built out multiple analytic models and machine learning algorithms before.

You will be in charge of establishing and maintaining machine learning deployment pipelines, including their associated life-cycle management systems and practices, in coordination with their architecture peers and communities of practice throughout the company

Your responsibilities will be:
Designing and implementing Machine Learning models and algorithms that enable account selection, customer targeting, and process improvements for the sales teams in APAC.
Develop and maintain model deployment pipelines for many types of machine learning including supervised and unsupervised learning as well as CNNs, RNNs or other deep learning algorithms
Working closely with data scientists, domain experts and sales team, both to understand model performance management requirements and design suitable inferencing instrumentation systems and practices that meet them
Designing and implementing outbound data engineering pipelines that serve curated datasets to business intelligence and reporting
Designing integration solutions including applications as needed to deliver inferencing outcomes or curated data sets for consumption and action
Ensuring your model deployment, outbound data engineering and integration pipelines are architecturally and operationally integrated with inbound ingestion and contextualization pipelines designed by your peer domain architects
Delivering and presenting results to sales leaders regarding their business, forecast, pipeline, and potential customers.
Education & Experience:

- Very strong communicator
Advanced degrees in computer science and data science strongly preferred, though an equivalent level engineering, data science or mathematics degree, a technical undergraduate degree and relevant experience will also be considered
5+ plus years of relevant work experience
3+ years of experience working with data scientists in a data engineering or production machine learning inferencing capacity, working with various types of supervised and unsupervised learning algorithms for classification, recommendation, anomaly detection, clustering and segmentation, as well as CNNs, RNNs or other deep learning algorithms
5+ years of full-stack experience developing large scale distributed systems and multi-tier applications
5+ years of programming proficiency in, at least, one modern JVM language (e.g. Java, Kotlin, Scala) and at least one other high-level programming language such as Python
2+ years of production DevOps experience
3+ years of programming on the Apache Spark platform, leveraging both low level RDD and MLlib APIs and the higher-level APIs (SparkContext, DataFrames, DataSets, GraphFrames, SparkSQL, SparkML).
Demonstrated deep understanding of Spark core architecture including physical plans, DAGs, UDFs, job management and resource management
At least 1 year of implementation experience with Apache Airflow, and a demonstrated expert level understanding of both segmented and unsegmented Directed Acyclic Graphs and their operationalization
Experience working with Neo4J and a demonstrated ability to lead architecture efforts for its implementation
Strong technical collaboration and communication skills
Additional Qualifications:
Passion for sales and customer segmentation
Proficiency with functional programming methods and their appropriate use in distributed systems
Proficiency with AWS foundational compute services, including S3 and EC2, ECS and EKS, IAM and CloudWatch
Proficiency with Sagemaker, Kubernetes, and Docker
Preferred Qualifications
Experience with data science toolkits like: R, Pandas, Jupyter, scikit, TensorFlow, etc.
Experience with Sagemaker and data pipelines in AWS
Familiarity with statistics concepts and analysis, e.g. hypothesis testing, regression, etc.
Experience building dashboards in platform: Power BI, Tableau, Qlik, Looker, etc.
Salesforce experience is a plus

At Autodesk, we're building a diverse workplace and an inclusive culture to give more people the chance to imagine, design, and make a better world. Autodesk is proud to be an equal opportunity employer and considers all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender, gender identity, national origin, disability, veteran status or any other legally protected characteristic. We also consider for employment all qualified applicants regardless of criminal histories, consistent with applicable law.

Are you an existing contractor or consultant with Autodesk? Please search for open jobs and apply internally (not on this external site). If you have any questions or require support, contact Autodesk Careers.",4.0,"Autodesk
4.0",Bengaluru,"San Rafael, CA",5001 to 10000 employees,1982,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),-1
Data Analyst - Associate,-1,"JPMC is looking at expanding our digital capabilities and we are investing in growth opportunities for various businesses. We are looking for commercially minded, customer focused, hands on engineers, who want to be a part of building exciting product offering. A core responsibility is to produce secure, scalable technical solutions to support our market leading products.

Culture is as important to us and we are looking for intellectually curious and honest, passionate, hungry individuals who would like to expand their skills whilst working on a new exciting venture for the firm. This role will be based in Bangalore, India. A JPMorgan Chase & Co.'s global team of technologists and innovators, helps to positively impact the company, as well as our clients and our business partners around the world.

The success of this business relies on the platform that will be built - we will be using a stack that is cloud native relying on cutting edge technology and seek full stack minded engineers.

In this role, the candidate will be responsible for providing analytical SQL support to various functions within the business. Over time, the support will also extend to providing statistical analysis and consequently, this role will suit a candidate looking to extend their analytical capabilities.

Key Responsibilities
Provide analytical support using SQL in order to help Business-LOBs to measure KPIs or perform ad-hoc data exploration
Gain familiarity with a variety of data sources ranging from incoming event-streams to tabular data across various LOBs
Help the LOB stakeholders innovate through data-driven decisioning by querying data and merging information from diverse data sources to create rich datasets that enable better decision-making
Work with other Analytics teams and multi-task on projects to summarize and synthesize data and present recommendations to the businesses in a clear and logical manner
Identify unexplored data opportunities for the business to unlock and maximize the potential of digital data within the organization
Support ongoing technology evaluation process and proof of concept projects
Qualifications
Proven working experience as a data analyst or business data analyst
Knowledge of modern MPP databases and big-data (Hadoop) concepts
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
Experience with relational databases utilizing SQL to pull and summarize large datasets, report creation and ad-hoc analyses
Experience in agile reporting development and ability to interpret unstructured data and draw objective inferences given known limitations of the data
Demonstrated ability to think beyond raw data and to understand the underlying business context and sense business opportunities hidden in data
Strong written and oral communication skills; ability to communicate effectively with all levels of management and partners from a variety of business functions
Self-starter who can provide insights and drive results in a dynamic and fast evolving environment
Ability to define and track project deliveries through to implementation
Proactive/self-starter with the ability to deliver value-added support to business partners in a dependable, timely and accurate manner
Adept at multi-tasking and meeting deadlines in high-pressure environment
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.",3.9,"J.P. Morgan
3.9",Bengaluru,"New York, NY",10000+ employees,1799,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Data Scientist,-1,"Educational qualifications
B Tech/ BE, M.Sc.(Maths) or M Tech/ MS or equivalent in Mechanical/Metallurgical/ Electrical/ Electronics/ Computer Science/Instrumentation/Industrial Engineering/Operations Research or in any other relevant discipline.

Relevant experience (Type/ Nature and years of relevant experience required to execute the role)
Min. 2-4 years of experience

Locations: Jamshedpur / Kalinga nagar / Kolkata/ Mumbai

Experience related to advanced analytics
Machine learning, Deep learning, Fuzzy logic, data visualisation, statistics, Derived data analysis etc.
Programming and process trouble-shooting experience will be preferred.
Exposure to mathematical modelling will be preferred.
Understanding of statistics and statistical modelling will be required.
Good process knowledge related to supply chain, iron and steel manufacturing, marketing or mining/mineral processing is preferable.
Programming skills using a high level language (preferably in .net environment) will be necessary.
Knowledge on data acquisition, analytics, statistics and other mathematical modelling tools will be useful.
Sound concepts on Big data analytics will be helpful.

Technical Competencies
Statistics, Data analytics, Artificial intelligence, programming, system engineering and flow design, Logic building, Scenario analysis.
Coding in R/ Python language is Compulsory.

Behavioral Competencies
Learning inclination, Collaboration, Achievement orientation, change orientation",-1,Imurgence,Jamshedpur,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
AI / ML Data Scientist – Democratize commerce through Technology!,-1,"The focus of our data science team is to work on highly scalable data-driven products that have massive impact on business. If you are passionate about finding patterns in big data and developing prediction models, this is the place for you. We encourage our team to be creative in building products, learning continuously, and solving interesting problems. We foster a culture where we enjoy raising the bar constantly for ourselves and others, and that strongly supports the freedom to explore and innovate.

The role holder will be an expert in his AI/ML domain to support the team in different data science projects. He/she is expected to deliver solid implementation of different AI/ML algorithms to meet production standards.

Key Responsibilities:
Develop robust machine learning models.
Extract huge volumes of data from multiple internal and external sources.
Develop data pipelines and infrastructure to scale and automate the analyses that enable rapid product iteration.
Maintain team’s best research and engineering practice.
Work closely with Data Analysts, Software Engineers, and Product Owners to deliver insights and impactful products for the company.
Devise data mining process and architecture.
Read research papers / article to create the best model / system architecture available.
Explore and examine data from a variety of angles to determine hidden weaknesses, trends, and/or opportunities.
Employ sophisticated analytics programs, machine learning, and statistical methods to prepare data for use in predictive & prescriptive modeling.

Qualifications:
Minimum Master’s degree in data science field, e.g. Math, Physics, and Computer Science.
2+ years of experience in applying analytical modeling to solve business problems.
Strong problem-solving skills with good analytical approach and logical thinking.
Proficiency in at least one programming language, i.e.: Python, Go, C/C++, etc.
Good understanding of different AI/ML models/algorithms.
Familiarity with at least one Deep Learning framework.
NLP, image processing knowledge is a plus.
Good communication skills.
A humble team player.
Experience with Google Cloud Platform is a plus.
If this sounds like the kind of opportunity you’ve been looking for, then we’re going to need your resume of course, but more importantly include a short note giving us a sense of why you think you are absolutely the right person for this job. Write to deepa.m@careerxperts.com to get in touch!

Location: Noida",-1,CareerXperts,India,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist 1,-1,"This team is part of PayPals Risk and Data organization and is responsible is to stay on top of recent business trend and offer insights through analytical support for PayPals global Consumer Credit products. This individuals key performance KPIs will include Loss Performance, Fraud Decline rates, Revenue/Margin enabled, and Customer Experience. The Fraud Analytics team has ownership on portfolio management through by stay on top of recent business trend and offer insights through analytical support for PayPals global Consumer Credit products .

Day to day responsibilities includes
Identifying opportunities and gaps within current portfolio of PayPals Fraud Risk controls, including continuously evolving fraud trends
Based on analysis, formulating a solution to ensure optimal balance between user experience, business enablement, operational expense and loss exposure related to proposed solution
Collaborating with external partners, including external Credit/Banking partners and Data vendors
Closely monitoring performance of existing and new solutions to ensure expectations are met
Required Skills:
Proficiency in SQL and Excel
Proficiency in at least one statistical analysis tool: SAS / R / Python
Strong analytical skills: ability to build quick estimates using back-of-the-envelope analysis, structure (and, if needed, execute) more complex analyses, pull together business cases, navigate multi-dimensional sets of tradeoffs. Above all, the job calls for comfort with data ability to manipulate it, question its validity, interpret it, and develop recommendations based on it
Ability to manage a large, diverse set of to-dos prioritize, stay on top of multiple work streams, monitor progress
Ability to work with leadership & stakeholders to define project scope and direction, driving large pieces of the work independently
Dedicated, proactive, curious and eager to learn new approaches / methodologies a must
Desired Skills:
Bachelors degree in Mathematics, Statistics, Finance, Economics or related quantitative discipline
2+ years of proven credit or fraud risk analytics experience, or equivalent
Must be an intuitive, organized, analytical thinker, with the ability to perform detailed analysis
Strong written, oral, and interpersonal skills a must, including the ability to explain and/or present analysis
Must have good business judgment with demonstrated ability to think creatively and strategically
Aptitude and willingness to roll up the sleeves and get involved in the details",3.7,"PayPal
3.7",Chennai,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Data Scientist-PL-Prime Markets,-1,"Job Description
A.
Analytical Support Provide end to end analytical support for the given business lines with an objective of increasing campaign revenue / marketing efficiencies / customer value.
B.
Model Building Build predictive models / behavioral segments / event triggers for x-sell / activation / retention / attrition control - models to meet minimum performance benchmark To be done for all product / business lines handled by the analyst.
C.
Statistical Analysis & Validation Work with business / campaign stakeholders to understand objective / problem statement, generate hypothesis to solve the objective / problem and run statistical analysis to validate the same D.
Campaign Work jointly with campaigns and business team to identify business problem, discuss analytical approach and explain the solution which has been developed E.
Implementation of Analytical Solutions Work jointly with campaigns and business team to ensure that minimum 60% of analytical solutions developed in the FY are utilized for campaigns / on ground activities.
Seek feedback from campaigns and business which can be plugged back to the analytical solution F.
Performance Monitoring Monthly monitoring of performance of predictive scorecards / solutions and ensuring the performance is as per the internal benchmarks through regular enhancements of the solutions.

Skills
Expertise in SAS, SQL and Python programming
Experience in handling unstructured data / big data technology will be an advantage
Demonstrated ability to pro-actively report and present to Seniors Management
Planning and Organizing Skills
Communication
Knowledge of Competition & Current trends in financial Industry.",3.6,"HDFC Bank
3.6",Mumbai,"Mumbai, India",10000+ employees,1995,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),"State Bank of India, ICICI Bank, Axis Bank"
Advisory-Consulting-Data Analytics-Manager-KOL,-1,"Line of Service

Advisory

Industry/Sector

Not Applicable

Specialism

Managed Services

Management Level

Manager

Job Description & Summary

A career in our Advisory Acceleration Centre is the natural extension of PwC’s leading class global delivery capabilities. We provide premium, cost effective, high quality services that support process quality and delivery capability in support for client engagements.

To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be an authentic and inclusive leader, at all grades/levels and in all lines of service. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.

As a Manager, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:
Pursue opportunities to develop existing and new skills outside of comfort zone.
Act to resolve issues which prevent effective team working, even during times of change and uncertainty.
Coach others and encourage them to take ownership of their development.
Analyse complex ideas or proposals and build a range of meaningful recommendations.
Use multiple sources of information including broader stakeholder views to develop solutions and recommendations.
Address sub-standard work or work that does not meet firm's/client's expectations.
Develop a perspective on key global trends, including globalisation, and how they impact the firm and our clients.
Manage a variety of viewpoints to build consensus and create positive outcomes for all parties.
Focus on building trusted relationships.
Uphold the firm's code of ethics and business conduct.
Education (if blank, degree and/or field of study not specified)

Degrees/Field of Study required:Degrees/Field of Study preferred:

Certifications (if blank, certifications not specified)

Desired Languages (If blank, desired languages not specified)

Travel Requirements

Not Specified

Available for Work Visa Sponsorship?

No

Government Clearance Required?

No

Job Posting End Date

August 3, 2020",3.8,"PwC
3.8",Kolkata,"New York, NY",10000+ employees,1998,Company - Private,Accounting,Accounting & Legal,₹500+ billion (INR),-1
Data Scientist,-1,"We provide Virtual Business Process Services to various types of overseas clients and this position is to be part of the team which provides support to USA client from Mortgage Finance industry. Hence we are looking to hire Data Scientist with experience in analyzing large amounts of data and information. Data Scientist will provide data manipulation, scrubbing and synthesizing of information into easy to read weekly, monthly and quarterly reports.

RESPONSIBILITIES

Work with large data sets and produce real-time and streamlined analysis
Work will include analyzing lender performance, asset type, leverage, etc.
Analyze third party vendor data and helping to apply that data retroactively to back-test default history
Ability to perform data mining
Pro-actively apply data frameworks to better optimize pool performance
Participate in client conversations, phone calls, company presentations, etc.
Develop forms and enhanced data tools to streamline processes and create efficiencies.
Will include data tracking and pipeline management.

QUALIFICATIONS and EXPERIENCE

Strong intellect with solid communication, quantitative, financial and analytical skills
College degree in Finance, Math, Engineering, Computer Science, Statistics, Economics or related field
Strong modeling skills to include Excel VBA and Macros, SQL (Python and Tableau a plus), Access, etc.
3+ Years of experience in similar roles
Excellent written and English verbal communication skills who works well with others in a team environment.
Strong analytical skills and attention to detail
Ability to interpret and error-check work to ensure analysis is logical
Experience with real estate mortgages is a plus
Self-starter and motivated individual with a good attitude
Ability to multi-task while working independently in a fast-pace environment

SKILLS

Advanced MS Excel skills, Excel VBA and Macros and MS PowerPoint skills
Data Science, Data Analytics and Reporting
Working Knowledge in Data Visualization Applications
Creative problem solver, Exceptional interpersonal skills, Impeccable integrity and trustworthiness
Strong Knowledge in using internet and web based applications

QUALITIES

Strong commitment to support overseas client with utmost care.
Good team player with greater level of integrity
Maintains Strict confidentiality of Client’s Data and information
Self-Motivated and Tough task master.
Quick learner and continuous learner of new technologies.

Location: Hi-Tech City, Hyderabad

Timings: USA Shift IST 5-30pm to 2-30am

salary range: As Per Industry Standards

Send Application TO: hr@finacplus.com",4.4,"FinAcPlus
4.4",Hyderabad,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore
Desired Skills and Experience
Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.
Responsibilities
The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.0,"Nanobi Data And Analytics
3.0",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job Title: Data Scientist
Experience: 5 to 10 years

Job Location: Bangalore, Mumbai

Job Description:
5 years of experience including statistics, classical Machine Learning and Deep Learning
Applying CNNs for image segmentation, object detection. Using CNN architectures like v-net, W-Net
Applying RNN/LSTM/GRU for building sequence models
Applying RNN/ LSTM for natural language processing including natural language understanding, intent classification, NER, encoders/decoders for machine translation
Building longitudinal view of customer from Customer Journey data
Experience with ML in IoT use cases like Digital twins
Experience building deep learning models using Keras/ Tensorflow /pyTorch
Application of Auto Encoders, GANs in creating synthetic data and creating latent representations of customer behaviour.

Total Exp:
Relevant Exp Data Scientist
Relevant Exp as Machine Learning
Current CTC
Excepted CTC

Notice Period:
Current Location
Preferred Location
Reason for Job
00-10.00 Years",-1,Ness Technologies India Private Limited,Bengaluru,"Hyderabad, India",1001 to 5000 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Lead Data Scientist,-1,"Data Scientist role @ ThoughtWorks India

Bangalore, India

We are passionate technologists who believe in the power of software and technology as tools for social change. The 1000+ people in ThoughtWorks India are as diverse in personality as we are in our backgrounds, culture, and expertise.

If you're someone who's passionate about technology, by joining ThoughtWorks, you become a part of a community. People join because they get to talk to the people who wrote the books that influenced them, work with tools they wish to use, and collaborate on projects that propel change in the real world.

ThoughtWorks India is looking for talented Data scientists passionate about building large scale Machine Learning Solutions to help manage the ever-growing information needs of our clients.

As a Data Scientist Practitioner, here's what you can do at ThoughtWorks:
Understand business challenges and goals of a client to formulate the approach for data analysis and model creation that will support their business decision making
Create advanced analytics models using statistical and machine learning methods
Work with software developers and solutions designers to deliver analytics-driven solutions
Interact with clients in a variety of domains, who have a spectrum of challenging problems
Represent ThoughtWorks and Data community in various online and offline forums (events, conferences)
Work in a dynamic, collaborative, transparent, non-hierarchical, and ego-free culture where your talent is valued over a role title
Develop your career outside of the confinements of a traditional career path by focusing on what you're passionate about rather than a predetermined one-size-fits-all plan
Here is what you will bring:
PhD/MS/BS or equivalent in Applied mathematics, statistics, physics, computer science or operations research background.
At least 2-3 years commercial experience with PhD or at least 10+ years of experience with BS degree
Depth of knowledge in advanced analytics methods such as parametric, non-parametric and graphical models
Breadth of knowledge across statistical methods and machine learning algorithms
Programming skills in languages like R and Python is a MUST
Familiarity with large scale data processing tools like Hadoop and Spark
Strong algorithmic problem-solving skills
Ability to design effective experiments in business and social environments
Understand how to harvest complex data from a variety of sources
Consultative skills and the ability to communicate complicated technical and analytical information to non technical audiences
Other desirable skills include: relational databases, NoSQL and visualisation techniques, knowledge and experience in any software technologies along with research experience
If you relish the idea of being part of ThoughtWorks' Data Practice that extends beyond the work we do for our customers, you may find ThoughtWorks is the right place for you. If you share our passion for technology and want to help change the world with software, we want to hear from you!

#LI-INDIA

#LI- RP1",4.4,"ThoughtWorks
4.4",Bengaluru,"Chicago, IL",5001 to 10000 employees,1993,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Accenture, Infosys, Boston Consulting Group"
Senior Data Scientist,-1,"We are establishing a world class Data Engineering Team in our Digital Centre in Bangalore to service Global Equipment, one of the fundamental departments in Maersk which is responsible for management of all Containers and associated assets. As part of your role, you will collaborate very closely with our business stakeholders spread across the globe in converting business needs into cutting edge data platform products that will deliver significant bottom line impact. If you have a strong data engineering background, are passionate about quality, speed and impact, and have a service mindset, then read on!

Show More
We offer

Joining Maersk will embark you on a great journey with career development in a global organization. As Senior Data Engineer, you will gain broad business knowledge of the company’s activities globally, as well as take part in the digitalization of the transport and logistics industry.

You will be exposed to a wide and challenging range of business issues through regular engagement with key stakeholders across all management levels within Maersk.

You will work and communicate across geographical and cultural borders that will enable you to build a strong professional network. We believe people thrive when they are in-charge of their career paths and professional growth. We will provide you with opportunities that broaden your knowledge and strengthen your technical and professional foundation.

By choosing Maersk’s Technology vertical, you join not only for the role, but for a career. From here your path may take you towards extended responsibilities within Product Service and Engineering, Technology Delivery or Technology Leadership.

We aim to be a world-class professional Technology organization that delivers business value through turning ideas into prototypes and data products driving automation, standardization and innovation. We believe in empowerment where each of us takes ownership and responsibility for developing and implementing new ways of working.

Show More
Key responsibilities

• Be part of a team of highly skilled data engineers and analysts, responsible for designing and developing cutting edge end to end big data products for our global organization
• Build, develop and maintain data models, data automation products, reporting systems and performance metrics that ensure ongoing realization of business value
• Define and utilize statistical methods to solve domain-specific problems in logistics relevant to the organization
• Work closely with internal customers in researching problems and determine the data required to answer specific questions
• Compare and analyze provided statistical information to identify patterns and relationships that can be developed into new initiatives
• Examine, interpret and report results of products to stakeholders in leadership, technology and other departments
• Design appropriate enhancements and recommend alternative approaches, when necessary to drive delivery of superior products
• Train other members of the team how to properly organize findings and read data collected

Show More
We are looking for

• Master’s degree in mathematics, statistics or related field
• Strong math and analytical skills are essential to complete job requirements successfully
• Technical expertise regarding data models, database design development, data mining and segmentation techniques
• Exposure to coding languages like R, Python, Pyspark and Scala
• Able to compile and organize statistical information retrieved and present findings to management
• Good instincts around data analytics with confidence in decision making and the ability to explain processes or choices as needed

Great to have
• Solid experience in contributing hands-on products built within data technologies, ranging from relational databases to big data solutions (Hadoop or Spark)
• Data engineering and pipeline technology experience - particularly open source and modern frameworks
• Familiarity and experience with Azure services particularly DevOps, Data Factory and Databricks in implementing new applications

Generic Skills

• Fluent and effective communication in both written and oral English
• An excellent team player who can at the same time demonstrate strong autonomy and high motivation to produce individually with a “can do” attitude
• Someone who is open to new ideas, demonstrates steep learning curve and is innovative in approach
• Able to work in remote teams for a large program and distributed organization while showcasing a service mindset
• Willingness and interest to travel when required to be close to our internal customers

Show More",3.9,"Maersk Group
3.9",Bengaluru,"Copenhagen, Denmark",10000+ employees,1928,Subsidiary or Business Segment,Shipping,Transportation & Logistics,₹100 to ₹500 billion (INR),-1
Data Scientist,-1,"When you click 'Apply', you will need to click on 'Create Account'. By creating an account, you will be able to view your applications and their statuses. Your password must contain 8 characters, 1 upper case letter, 1 number and 1 special character. Please make sure your name is formatted correctly and not in all uppercase.
Check It Out!


Ready to be a Cooper too? This might just be right up your alley!

We’re here to keep the dream of home ownership alive. Oh, and while we’re at it, we’re determined to change the lending industry itself. It’s simple, but it won’t be easy. And we’ll need a great team behind us. (That’s where you come in.) We want to show the world that transparency, candor and collaboration aren’t just good values. They’re good business. Working here isn’t for people who want to punch a clock. It’s for people who want to punch a hole in the status quo. Come join us. And make a difference instead of just a living.

Role/Responsibilities:
Develop novel solutions to market-driven problems using knowledge of the latest ML techniques, statistical analysis, and practical experience on previous data science projects.
Collaborate with stakeholders, business unit product owners, development teams to understand business needs and technical requirements
Work actively in all aspects of model development, including design, model implementation, validation, calibration, documentation, monitoring, and reporting
Research complex business issues and recommend solutions, including input requirements, other required data sets, modeling approaches, and end products
Required Skills and Experience:
Masters in a quantitative / applied field (Statistics) or PhD preferred
8+ years of experience in data science roles
3+ years in handling teams
Strong statistical foundation with broad knowledge of supervised and unsupervised techniques
Experience with predictive modeling (classification, regression, parameter tuning, optimization criteria, feature selection), preferably with multiple techniques is a requirement.
Experience in model validation techniques, model testing and continuous monitoring of model performance
Strong knowledge of programming and modeling using R and SAS (the candidate would work in Python ecosystem)
Strong SQL skills and experience working with large data sets.
Experience working collaboratively, including building and maintaining relationships with stakeholders/clients.
Experience advising a team on innovative methodologies, data science tools, and environments.
Ability to articulate complex technical concepts/ideas to both technical and non-technical audience.
Experience applying modern machine learning techniques
Very strong in identifying hidden use cases from dataset/ business interactions and come up with new solutions
Nice to Have Skills & Qualities
Flexibility to learn and apply new methodologies
Mortgage Industry experience /knowledge
Mr. Cooper is committed to nurturing a diverse and inclusive environment where every employee is empowered to be their authentic self. We know that a large part of our success as a business is directly tied to our ongoing efforts to attract and retain diverse talent and maintain an inclusive environment where each employee can thrive. Embracing and leveraging diversity through an inclusive work environment fosters new ideas, new insights, and constant innovation. We strive to weave the principles of diversity and inclusion throughout the fabric of how we work, how we interact, and how we engage with our customers and the community.

Job Requisition ID:

011698

Job Category:

Information Technology

Primary Location City:

Chennai

Primary Location Region:

Tamil Nadu

Primary Location Postal Code:

600089

Primary Location Country:

India

Posting Organization:

Xome

Line of Business:

Information Technology

Additional Posting Location(s):

Alternate Requisition:

No",3.3,"Mr. Cooper
3.3",Chennai,"Dallas, TX",5001 to 10000 employees,1994,Company - Public,Lending,Finance,₹500+ billion (INR),-1
Data Scientist,-1,"Description

Key Responsibilities: Team leads for small or module leads for large teams. Responsible for delivery of assigned module/ components /phases of a project.Responsible for people Management, including goal setting and providing performance feedback.Responsible for Status reporting .Responsible for Knowledge transfer and arriving at SLAs for steady state.Technical problem solving skills. Job Requirement and Skills Has a good practical understanding of technology and its application. Good grasp of technology and tools used for development. Good design skills and architectural skills in the technical area.Fair amount of domain expertise gained through working on the application or certification programs (if working in a vertical).Good understanding of the sphere of activities in a horizontal domain. Anticipates and resolves potential problems , handles escalations. Supervisory Level: Works under general supervision with few direct instructions. Carries out routine and semi-routine tasks. Provides input to project-related decisions.People Interactions Within own team or department at operational level.Contact with user/customer at peer / first /middle management level. Qualifications

About ECS

ECS is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., ECS is ranked 205 on the Fortune 500 and is consistently listed among the most admired companies in the world.",3.0,"ECS
3.0",Chennai,"Jersey City, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Science Engineer,-1,"Data Science Engineer

With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.

Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What you need to make real what matters

Responsible for the development and delivery of parts of a product, in accordance to the customers’ requirements and organizational quality norms. Activities to be performed include:

• Requirement analysis and design of software solutions based on requirements and architectural /design guidelines.

• Improving user experience, scalability and performance.

• Implementation of features and/or bug-fixing and delivering solutions in accordance with coding guidelines and on-time with high quality.

• Ensuring integration and submission of solution into software configuration management system, within committed delivery timelines.

• Performing regular technical coordination / review with stake holders and ensuring timely reporting and escalations if any.

• Supporting Project Manager for planning, ensuring risk identification and initiating steps towards risk mitigation.

• Identification and implementation of unit and integration tests to ensure solution addresses customer requirements, and quality, security requirements of product are met.

• Good at communicating within the team as well as with all the stake holders

• Strong customer focus and good learner.

• Highly proactive and team player

What do I need to qualify for this job?

• 4-6 years’ work experience in Software Engineering especially in professional software product development.

• Proven skills in R and Python is a must

• Involved in Probabilistic Data analysis of any domain specific data.

• Strong knowledge in frameworks like shiny, Dplyr, Ggplot2, Esquisse etc.

• Strong knowledge in frameworks like NumPy, SciPy, Pandas etc.

• Expertise in programming and usage of any unit testing framework.

• Expertise in integration testing and continuous integration.

• Knowledge of Software Engineering processes. Experience with Agile/Lean practices is preferred

• Knowledge of design patterns

• Knowledge of source code management tools like git

• Knowledge for JIRA and Confluence will be a plus

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: ADVANTA

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.0,"Siemens Healthineers
4.0",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Data Scientist,-1,"Experience : 2+ years

What will you do:
Should have working knowledge of relational Database designs (SQL Server, MySQL, Oracle).
Should have knowledge of Queue management systems (Redis, MSMQ, RabitMQ etc).
Should have knowledge of SQL query, Stored Procedures, Functions.
Should have knowledge of No SQL will be an added advantage.
Shall analyze, define and document system requirements for data, workflow, logical processes, interfaces with other systems, auditing, reporting requirements and production configuration.
Shall write and maintain functional and technical specifications.
Shall create scripts and packages for data integration, data maintenance or bug fixes.
Shall analyze code for problem resolution and performance optimizations.
Shall write SQL statement for ad-hoc report generation.

What we can offer

Are a young organization and the workplace is an extension of our families back home
Mondays and Fridays have the same effect on us
Value positive vibes, honesty, sense of judgment, empathy and self-motivation
Believe in experimentation and don't think of new things as daunting enough to take up at any point in time
Are looking for driven and focused individuals
Will be more than happy to hear from you

We want to hear from you
Why don't go ahead and send us a video clip of yourself, giving us a creative brief of who you really are.Once you're done with that, [email protected] :).",-1,big tree,Mumbai,"Großostheim, Germany",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"Looking for Women in Data Science

GSN Games is looking for a Senior Data Scientist to join our team in Bangalore!
About The Analytics & Data Science Team:
Our incredibly talented team provides the data, analytics, and algorithms necessary to make GSN Games a fun and rich experience for players.
What You’ll Do
The GSN Data Science team delivers machine-learning based tools, products and insights that help to move the needle in the business of our games. You will lead a team of Data Scientists and collaborate with other members of the Data Engineering and Data Analytics teams to conceptualise, develop and roll-out ML-based products and features to help games grow and make our games more fun. This is an exceptional opportunity to apply Data Science, Software Engineering, and organizational skills to drive actionable insights across a portfolio of games.
You will:
● Collaborate with other data scientists and data analysts to build, tune, and optimize machine learning models to optimize all aspects of the business.
● Partner with studios to solve business-critical questions. Sometimes these questions are brought to us, and sometimes we bring these questions to the game teams.
● Proactively explore the data to find new insights and opportunities for growth and optimization.
● Help develop best practices with data and analytic techniques across the game studios.
● Keep up with industry trends and developments, and make sure our technologies are cutting edge.
About You
● 3 to 5 years experience working as a data scientist developing Machine Learning based products.
● Strong background in probability, statistics, and machine learning.
● Fluent in Python
● Strong software engineering skills, including distributed systems, data pipelines, machine learning production systems, and scaling solutions.
● Working knowledge of AWS and/or GCP.
● Strong hands-on experience with SQL.
● Experience with A/B testing and other forms of causal inference, and good skills in data visualization.
● Excellent communication skills.
● BS in a quantitative field such as math, physics, economics, or computer science (MS preferred)
● Bonus points for experience in games.",3.8,"GSN Games
3.8",Bengaluru,"Boston, MA",201 to 500 employees,1999,Company - Private,Video Games,Media,Unknown / Non-Applicable,-1
Data Engineer (APAC),-1,"MongoDB is the leading modern, general purpose database platform, designed to unleash the power of software and data for developers and the applications they build. Developers around the world are using MongoDB to build software to create new businesses, modernize existing businesses, and transform the lives of millions of people around the world.

Headquartered in New York, with offices across North America, Europe, and Asia-Pacific, MongoDB has more than 17,000 customers, which include some of the largest and most sophisticated businesses in nearly every vertical industry, in over 100 countries.

MongoDB is growing rapidly and seeking a Data Engineer to be a key contributor to the overall internal data platform at MongoDB. You will build data driven solutions to help drive MongoDB's growth as a product and as a company. You will take on complex data-related problems using very diverse data sets.

Our ideal candidate has experience with
Several programming languages (Python, Scala, Java, etc.)
Data processing frameworks like Spark
Streaming data processing frameworks like Kafka, KSQ, and Spark Streaming
A diverse set of databases like MongoDB, Cassandra, Redshift, Postgres, etc.
Different storage format like Parquet, Avro, Arrow, and JSON
AWS services such as EMR, Lambda, S3, Athena, Glue, IAM, RDS, etc.
Orchestration tools such as Airflow, Luiji, Azkaban, Cask, etc.
Git and Github
CI/CD Pipelines
You might be an especially great fit if you
Enjoy wrangling huge amounts of data and exploring new data sets
Value code simplicity and performance
Obsess over data: everything needs to be accounted for and be thoroughly tested
Plan effective data storage, security, sharing and publishing within an organization
Constantly thinking of ways to squeeze better performance out of data pipelines
Nice to haves
You are deeply familiar with Spark and/or Hive
You have expert experience with Airflow
You understand the differences between different storage formats like Parquet, Avro, Arrow, and JSON
You understand the tradeoffs between different schema designs like normalization vs. denormalization
In addition to data pipelines, you're also quite good with Kubernetes, Drone, and Terraform
You've built an end-to-end production-grade data solution that runs on AWS
You have experience building machine learning pipelines using tools likeSparkML, Tensorflow, Scikit-Learn, etc.
Responsibilities

As a Data Engineer, you will:
Build large-scale batch and real-time data pipelines with data processing frameworks like Spark on AWS
Help drive best practices in continuous integration and delivery
Help drive optimization, testing, and tooling to improve data quality
Collaborate with other software engineers, machine learning experts, and stakeholders, taking learning and leadership opportunities that will arise every single day
Do you know, Why MongoDB is a fantastic place to work and build your career?
Disrupting a $64 Billion market
Top NoSQL database in the world
Largest Ecosystem and the fastest growing database in the world
Close to 17,000 customers in over 100 countries and over 90+ million downloads
>120% net ARR expansion rate over each of the last twenty quarters
Sequoia Capital and a number of other Top VC firms have invested in MongoDB. Sequoia Capital calls us out as one of their flagship portfolios; Sequoia has also invested in Apple, Google, Youtube, and WhatsApp
9-figure revenue company, with very high double-digit growth rates
Be a part of the company that's reinventing the database, focused on innovation and speed
Enjoy a fun, inspiring culture that is engineering focused
Work with talented people around the globe
Learn, contribute, and make an impact on the product and community.


Life at MongoDB

Our India office culture
180+ people, with teams in Sales, Engineering, HR, Finance, IT & Marketing
Regular group outings and opportunities to get to know your colleagues
Employee affinity groups


Our Benefits
Competitive salary and equity
Comprehensive Health cover, dental cover, travel insurance & Life Insurance.
Free lunch twice per week and a fully stocked kitchen with healthy and sweet treats.
Macbooks are company standard
26 weeks Maternity & 20 Paternity leave to spend time with new arrivals.",4.5,"MongoDB
4.5",Gurgaon,"New York, NY",1001 to 5000 employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Science,-1,Data Science,3.3,"Sage IT India
3.3",Bengaluru,"Frisco, TX",501 to 1000 employees,2003,Company - Private,IT Services,Information Technology,₹100 to ₹500 billion (INR),-1
Associate Data Scientist - MFG,-1,"Noodle's Data Scientists build advanced AI models that change the way our clients do business by empowering them to make better decisions. Our solutions impact small and large businesses ranging from media, to retail companies, to airlines, to e-commerce, financial services, to government agencies. Members of our Data Science team are passionate about problem solving with applied data science and work with clients to explore, specify, and communicate high-value, AI- based solutions. We geek out about AI technology.

As a Data Scientist at Noodle.ai, you will collaborate with the Noodle Client Service team, Data Engineers, SW Engineers, UX Designers, and industry-specific experts from our client companies to build a deep understanding of our clients' business context and then develop, test, and deploy advanced AI models. As we grow, you will also develop reusable IP to help us move faster, dive deeper, and work more efficiently by generalizing the models, methodologies, and supporting infrastructure that you build. As one of the early hires to join the Noodle.ai team, you will have a significant impact on the future of Enterprise Artificial Intelligence.

Qualifications:

Must haves
1+ years of experience in applied artificial intelligence technologies including machine learning, predictive data analytics, and/or data science
BE/B.Tech or Advanced degree in a relevant field (Computer Science, Operations Research, Statistics, Mathematics, Electrical Engineering, or other Computational Science)
Proficient in python
Experience with spark
Knowledge of data science/machine learning concepts
Demonstrated ability to iteratively conceptualize, design and build data-driven analytical models
Strong capabilities in modern analytics languages/tools
Collaborative, open, and respectful working style
Passion for learning and a desire to grow – Noodlers are life-long learners!
Nice to haves
Experience applying advanced AI techniques (g., machine learning, predictive analytics. optimization, semantic analysis, time-series analysis, advanced visualization) to real-world problems
Experience with R
Experience manipulating and preparing large, heterogeneous data sets (""Big Data"") to support advanced analytics
Demonstrated energy and passion that extends beyond your field of study – Are you a computer scientist who writes poetry? A mathematician who loves psychology? An engineer passionate about public policy? We want to build something with
Experience with (and excitement for) interdisciplinary collaboration",4.5,"Noodle.ai
4.5",Bengaluru,"San Francisco, CA",201 to 500 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1
Data Scientist,-1,"Role: Data Scientist
Location: Bhubaneswar

Key Responsibilities:
Apply Data Mining/ Data Analysis methods using a variety of data tools, building and implementing models using algorithms and creating / running simulations to drive optimization and improvement across business functions.
Assess accuracy of new data sources and data gathering techniques.
Perform Exploratory Data Analysis, detailed analysis of business problems and technical environments in designing the solution.
Apply Supervised, Unsupervised and Reinforcement Learning Algorithms.
Apply advanced Machine Learning Algorithms and Statistics: Regression, Simulation, Scenario Analysis, Time Series Modelling, Classification (Logistic Regression, Decision Trees, SVM, KNN, Naive Bayes, Clustering, K-Means, Apriopri), Ensemble Models (Random Forest, Boosting, Bagging and Neural Networks).
Lead and manage Proof of Concepts and demonstrate the outcomes quickly.
Document use cases, solutions and recommendations.
Work analytically in a problem-solving environment.
Work in a fast-paced agile development environment.
Coordinate with different functional teams to implement models and monitor outcomes.
Work with stakeholders throughout the organization to identify opportunities for leveraging organisation data and apply Predictive Modelling techniques to gain insights across business functions – Operations, Products, Sales, Marketing, HR and Finance teams.
Help program and project managers in the design, planning and governance of implementing Data Science solutions.

Experience and Skills:
2+ years of professional working experience in Analytics.
Experience in Retail, Financial Services and Manufacturing.
Experience using statistical packages of R, Python and Spark ML to work with data and draw insights from large data sets.
Experience with distributed data/ computing tools: Hadoop, Hive, Spark, Python.
Experience with SQL.
Experience visualizing/ presenting data for stakeholders using matplotlib, ggplot or Excel or Tableau.
Excellent written and verbal communication skills for coordinating across teams.

Education qualification:
Bachelors/ Masters in a Quantitative Discipline (Statistics, Econometrics, Mathematics, Engineering and Science)
Reach us on careers@eta-iota.com.",-1,ETAIOTA Systems,Bhubaneswar,-1,-1,-1,-1,-1,-1,-1,-1
MASTER DATA SCIENTIST,-1,"The Data Scientist will be part of the Core Data Scientist Team. This team identifies and develops advanced analytics statistical model, machine learning methods and solutions for our clients to improve various business outcomes.

The objective of the team is to:
Successfully develop, conceptualize and test various statistical models.Integrate the outcomes as real time analytics to create value for clients in areas and through means not immediately apparent to clients.

Job location:
Bangalore. Candidate should be flexible to travel & open for onsite positions within India & outside India for short-durations of 4 to 6 months.

Industry Focus:
Manufacturing, Financial Services, Investment Banking

Experience:
4 to 7 years of research experience in Statistical and Machine Learning Models. PhD freshers can also apply (Thesis submitted).

Qualifications:
Masters in a quantitative discipline such as Mathematics, Statistics & Machine Learning
Hands-on experience in running various methods in Supervised & Unsupervised ML like Regression, Classification, Clustering Random forest, k-NN, k-means, boosted trees, SVM, Neural Network, dimension reduction, model optimization, text mining, statistical modeling, data mining, exploratory data analysis, hypothesis testing & descriptive statistics.
Compelling communication and influencing skills. Should be able to communicate results and key findings to the stakeholders in a clear, concise and business friendly manner.
Ability to think creatively in solving problems real time.
Experience in diagnosis and prognosis of machines for early detection of signs of failure using ML techniques, using sensor data to analyze trend & patterns for industrial problems will be an added advantage.",-1,Inference Labs,Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Applied Scientist,-1,"Excited by Big Data, Machine Learning and Predictive Software? Interested in creating new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?
At Amazon, we are developing state-of-the-art large-scale Machine Learning Services and Applications on the Cloud involving Terabytes of data. We work on applying predictive technology to a wide spectrum of problems in areas such as Amazon Retail, Seller Services, Customer Service, Alexa, Chatbots and so on. We are looking for talented and experienced Machine Learning Scientists (Masters/Ph.D. in a related area preferred) who can apply innovative Machine Learning techniques to real-world e-Commerce problems. You will get to work in a team dedicated to advancing Machine Learning technology at Amazon and converting it to business-impacting solutions.
Major responsibilities
- Use machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
- Analyze and extract relevant information from large amounts of Amazons historical business data to help automate and optimize key processes
- Design, develop and evaluate highly innovative models for predictive learning
- Establish scalable, efficient, automated processes for large scale data analyses model development, model validation and model implementation
- Research and implement novel machine learning and statistical approaches




Basic Qualifications

- A PhD in Computer Science, Machine Learning, Operational research, Statistics or in a highly quantitative field
- Experience in predictive modelling and analysis, predictive software development
- Strong problem-solving ability
- Good skills with Java/Scala or C++, Perl/Python (or similar scripting language)
- Experience in using R, Matlab, or any other statistical software
- Strong communication and data presentation skills



Preferred Qualifications

- Experience handling gigabyte and terabyte size datasets
- Experience working with distributed systems and grid computing
- Knowledge of the latest and state of the art ML technology
- Publications or presentation in recognized Machine Learning and Data Mining journals/conferences",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
R&D Software Engineer (Data Science),-1,"Job Code : DQ319-01
Posted on : September 1, 2019
Job Location : Bangalore
Industry : Healthcare/Lifesciences
Discipline : Product Development

Description:
We are looking for a talented software engineer who can join our R&D team and work on problems of diverse complexity and scope within the Healthcare and Life Sciences industries.

Responsibilities:
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.

Requirements:
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field.
1-3 years of experience
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like Tensorflow or PyTorch) and libraries (like scikit-learn)

To apply for the above position, please send your word resumes to careers@vitrana.com by specifying the Job Code.",4.9,"Vitrana
4.9",Bengaluru,"Cranbury, NJ",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Sciences - Associate,-1,"Job Description – Associate - Data Science

We, at TheMathCompany, enable data analytics transformations for Fortune 500 organizations across the world. We enable our clients to build core capabilities that set them on a path to achieve analytics self-sufficiency.
Over the last three years, we have been consistently doubling in size year-on-year with 300 (and counting…) Data Scientists & Engineers, Consultants, and Visualization experts
TheMathCompany has won multiple awards recognizing us as a global Data and Analytics firm – We ranked #23 in the Deloitte Technology Fast 500™ Asia Pacific 2019 and #2 in Deloitte Technology Fast 50™ India 2019.
35+ Fortune 500 Companies, from almost 10 different industries and countries, trust us to power their analytical transformation.
WHAT’S IN IT FOR YOU:
An exciting opportunity to be a part of the growth journey of one of the fastest-growing AI & ML firms – scope for experimentation, the big & small victories, the learnings and everything in between
Our in-house learning and development cell - Co.ach, run by world-class data analytics experts, enables our folks to stay up to date with the latest trends and technologies
At TheMathCompany, we insist on a culture that provides us all with enough flexibility to accommodate our personal lives without compromising on the dream of building a great company
We are changing the way companies go about executing enterprise-wide data engineering and data science initiatives, and we’d love to have you grow with us on this journey
ROLE DESCRIPTION

As an Associate, you will be responsible for a wide range of opportunities to ensure you have a steep learning curve. Along with solving complicated business problems for organizations using data science techniques, you will be the face of MathCo. in client engagements. You will also have multiple opportunities to build, design & execute initiatives (ranging from contributing to the hiring & training programs to developing learning packages utilizing hot Analytics industry trends) that help us in our growth trajectory

The responsibilities are detailed as below:
Liaising with clients/stakeholders to understand the business problem
Define, breakdown and solve the business problems across domains while leveraging conventional & new age data sources, and a wide array of techniques
Accountable for the delivery of end to end analytical solutions
Depending on the engagement, lead a team of Analysts/Associates to enable consumption of the analytical solution
Contributing to the learning programs through sessions, content creations, etc. based on the nature of the engagements
REQUIRED QUALIFICATIONS

We are looking for individuals who are curious, excited about learning and navigating through the uncertainties and complexities that are associated with a growing company. Some qualifications that we think would help you thrive in this role are:
Strong application knowledge on tools (R/SAS/Python/SPSS etc.) and techniques (Regression, Machine Learning, Classification, Time series, etc.)
Experience of working on analytics projects and initiatives, preferably around 2-5 years
Strong analytical/problem-solving skills/mindset
Bachelor/Master of Engineering, BSc/MSc Honours, Ph.D. or equivalent
PREFERRED QUALIFICATIONS
Experience or certifications with visualization tools (Tableau/Qlik/PowerBI etc)
Understanding of software development methodologies (Agile essential), values, and procedures
Well versed with big data handling using Hadoop, etc.
Strong cultural fit
Ability to work without guidance
Focused on continuous learning and improvement
Ownership to drive results and strive for excellence
Takes initiatives to foster company growth
Develops and Engages the team
Supports diversity and understand different perspectives
Communicates effectively
High Emotional Quotient
TheMathCompany would provide you with an ecosystem to learn and grow in your professional journey, offering guidance to help you be successful. We are also a fun bunch and will help you in making this memorable.

Do you believe you have what it takes to build TheMathCompany and analytics capabilities for Fortune 500 organizations?

Have some questions or suggestions? Unclear about certain opportunities? Feel free to reach out to us anytime for a friendly chat:

Website: http://themathcompany.com/

e-mail: careers@themathcompany.com

About US | LinkedIn | Culture",3.6,"TheMathCompany
3.6",Bengaluru,"Bengaluru, India",201 to 500 employees,2016,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Developer - Data Science,-1,"Data Science (Data Engineer)
Python, PySpark, SparkSQL
Feature Engineering and Data Modeling
Data Visualization Tools: PowerBI, Tableau, etc.
SQL: PL/SQL and T-SQL

Build your career with us.
It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this changesupporting our clients digital journeys and offering our professionals exciting career opportunities.

At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create.

Be part of building one of the largest independent technology and business services firms in the world.

Learn more about CGI at www.cgi.com.

No unsolicited agency referrals please.

CGI is an equal opportunity employer.

Your future duties and responsibilities

Required qualifications to be successful in this role",3.5,"CGI
3.5",Hyderabad,"Montreal, Canada",10000+ employees,1976,Company - Public,Consulting,Business Services,₹500+ billion (INR),"IBM, Accenture, Booz Allen Hamilton"
Data Scientist,-1,"Experienced professional or an active researcher in one or multiple of the following areas: OCR-ICR technologies, Artificial Intelligence, Semantic Technologies, Natural Language Processing, Image Mining, Pattern Recognition on Digital Media ,and Information Retrieval (handling data types, ranging from traditional structured data, semi-structured data such as logs; text, social networks, audio, images, and video)
Experience in Neural network, Deep learning (Feed forward, Recursive, Recurrent LSTM, Auto encoder, CNN), Transfer
Minimum 4-8 years of
Full Stack developer using Tensor flow, Theano, Caffe
Familiarity with details of implementing algorithms on multi-core CPUs, clusters (MPI), GPUs
Strong knowledge in Capability to develop production ready solution using Python.
Worked as a Data Scientist in the product development project
Experience in distributed frameworks (e.g. Graph Lab, Spark, Hadoop)
Experience in Mongo DB, Index server, Graph DB, MQ.",2.9,"Innominds Software
2.9",Hyderabad,"San Jose, CA",501 to 1000 employees,2003,Company - Private,Computer Hardware & Software,Information Technology,₹1 to ₹5 billion (INR),"GlobalLogic, Persistent Systems (India), Mobica"
DATA SCIENTIST,-1,"The required skills are :


Post graduate degree in Statistics, Math or any other with strong analytical background .
Must have exposure to Big Data analytics..
Need Strong mathematical background (calculus, linearalgebra, probability and statistics).
Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning) is a plus.
Must be a quick learner and capable to solve complex problems in multiple domains.
Skill Set : Language - C#,C++, Python or R, Scripting - Java script

Position Type : Permanent

Qualification : Any postgraduate degree with analytics

Experience : 0 - 4 Yrs

Salary Package :Best in Industry
Job Location : Calicut, Kerala, India

Recruitment Process : Technical Interview & HR interview",4.0,"Tech27 Systems
4.0",Kozhikode,"Aberdeen, United Kingdom",51 to 200 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Scientist/Senior Data Scientist - Deep Learning,-1,"Danaher Corporation

Danaher is a global science and technology innovator with more than 59,000 associates committed to helping our customers solve complex challenges and improve quality of life around the world. Our world class brands have unparalleled leadership positions in some of the most demanding and attractive industries and our technologies address a broad range of societal needs:
Protecting the global water supply and ensuring environmental stewardship
Protecting the world's food supply and verifying pharmaceutical dosages and authenticity
Leading scientific research and advancing patient health with the highest diagnostic confidence
Improving dental outcomes and promoting access to comfortable patient care around the world
Danaher generates over $20 billion USD of annual revenue from business segments: Life Sciences, Diagnostics, Water Quality, and Product Identification.

For additional company details, see www.danaher.com.

Danaher Digital

Danaher Digital is our digital innovation and acceleration center where were bringing together the leading strategic product and business leaders, technologists and data scientists for the common purpose of accelerating development and commercialization of disruptive and transformative digital solutions into the marketplace.

We accelerate Danahers digital innovation journey by partnering with Danaher operating companies (OPCOs) to monetize and commercialize the potential of emerging digital trends.

Located in Silicon Valley, the heart of global innovation, Danaher Digital is ideally situated to capitalize on the digital mega trends transforming our world, including IoT, Data, AI, cloud, mobile, Augmented Reality (AR), Blockchain and other Digital frontiers.

Position Description


This position reports to Director of Data & Analytics and is responsible for leading the vision, design and development of scalable Machine Learning (ML) solutions for Danahers IoT and Analytics (ML) initiatives. You will work with other Data Scientists, Software engineers and business groups and lead the development of innovative ML models for Danahers big data from health sciences, medical diagnostics, industrial and other markets. You will use your Agile experience to work collaboratively with other Product Managers/Owners in geographically distributed teams.

Responsibilities
Understand business challenges and propose new modeling and algorithmic solutions that leverages the latest in statistical and machine learning techniques.
Study new data sources and find insights/correlation to investigate how data can be used to solve new business challenges. Create prototypes with data sets and provide guidance on leveraging and combining new data sources for new business insights.
Apply statistical analysis and modeling techniques on small and large datasets to solve specific business problems in diverse industrial domains.
Provide strategic leadership in selection of platform, tools, techniques and processes in the practice of Data Science discipline.
Work collaboratively with other Product Owners/Product Managers from other business units and/or customers to translate business requirements in to technical requirements that can be answered with statistical and machine learning techniques. Guide and work with engineers and domain owners to produce the required data if not available.
Provide mentorship to other Data Scientists in the team.
Own and drive contemporary best practices in applying and deploying data science at scale.
Requirements
Advanced degree (Ph.D. preferred) in Engineering, Science, Mathematics, or related
Expert knowledge of statistical programming languages such as R, Python, and SQL.
Expert knowledge of probability, statistics and machine learning theory including experience in: Deep Learning, Clustering, Decision Trees, Logistic Regression, Dimensionality Reduction, and Random Forests for prediction and recommendations.
Must have delivered data science components as part of a commercial solution at scale.
Readiness to work with engineering teams to develop a prototypes of software products leveraging exploratory data analytics.
Desirable: Consultative experience providing technology and solution consultation to customers/clients.
Expert knowledge of data visualization, using tools such as Tableau or PowerBI.
Experience working with the cloud computing, including AWS and/or Azure
Experience working with distributed data storage and computing, including Hadoop, Spark, Cassandra, and so forth
Experience working with traditional databases, such as MS SQL, Teradata, MySQL, and Postgres.
Expert knowledge of Experimental Design and Statistical Decision Theory
Agile mindset to jump in to a diverse set of projects.
Ability to summarize results from analysis to a diverse set of audiences with varying background and technical skills.
Willingness to travel up to 25% required.
Experience


Required:
7+ years working with business stakeholders as a trusted adviser in Data Science and Monetization
7+ years communicating effectively with project and business stakeholders about Data Science and data science projects
5+ years building production-ready image or video analysis models using Deep Learning techniques such as CNN and RNN.
3+ years leveraging tools such as TensorFlow or Theano.
5+ years providing mentorship, education, and thought leadership to organizational stakeholders regarding best practices in data science
5+ years translating business requirements into data science problem statements and execution tasks
5+ years leading the organization towards adoption of a data-driven culture
3+ years mentoring and supporting junior team members
Desired:
7+ years building operations analytics models, including demand forecasting, inventory optimization in manufacturing or related industries.
7+ years building IoT analytics models, including failure diagnosis and failure prediction
7+ years executing customer advanced analytics, including marketing mix analysis, segmentation, retention modeling, targeted marketing, basket analysis, next product recommendation, and so forth.
5+ years executing data science in the fields of life sciences, medical diagnosis, biostatistics, and so forth.
Danaher Corporation and all Danaher Companies are equal opportunity employers that evaluate qualified applicants without regard to race, color, national origin, religion, sex, age, marital status, disability, veteran status, sexual orientation, gender identity, or other characteristics protected by law. The EEO is the Law poster is available here.",-1,Danaher Digital,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist / Sr. Data Scientist,-1,"Did you know: Piramal Glass is a trailblazer in the use of digital technology in glassmaking and has recently been recognised as India 100 Best Companies to work for by #GreatPlaceToWork.

Click below to read more about our digital accomplishments:
https://www.piramalglass.com/digital/

https://news.microsoft.com/en-in/features/piramal-glass-real-time-manufacturing-insights-azure-iot/

https://www.expresscomputer.in/news/piramal-glass-implements-indias-first-iot-implementation-in-the-glass-manufacturing-industry/33693/

Purpose of the Job

As a Data Scientist you will work in collaboration with our business and engineering people, on creating value from data. Often the work requires solving complex problems by turning vast amounts of data into business insights through advanced analytics, modeling and machine learning. You have a strong foundation in analytics, mathematical modeling, computer science, and math - coupled with a strong business sense. You proactively fetch information from various sources and analyze it for better understanding about how the business performs. Furthermore, you model and build AI tools that automate certain processes within the company. The solutions produced will be implemented to impact business results.

The Data Scientist believes in a non-hierarchical culture of collaboration, transparency, safety, and trust. Working with a focus on value creation, growth and serving customers with full ownership and accountability. Delivering exceptional customer and business results

Responsibilities

Develop an understanding of business obstacles, create solutions based on advanced analytics and draw implications for model development
Combine, explore and draw insights from data. Often large and complex data assets from different parts of the business.
Design and build explorative, predictive- or prescriptive models, utilizing optimization, simulation and machine learning techniques
Prototype and pilot new solutions and be a part of the aim of ‘productifying’ those valuable solutions that can have impact at a global scale
Guides and coaches other chapter colleagues to help solve data/technical problems at an operational level, and in methodologies to help improve development processes
Identifies and interprets trends and patterns in complex data sets to enable the business to take data-driven decisions

Qualifications

Industry

Any (prefer – Manufacturing, Logistics); willingness to learn manufacturing systems (OT systems and data stores)

Work experience

~2+ years of industry exposure in Data Science and Analytics projects, preferably in Manufacturing / Supply chain management

Skills and competencies required

Extract and present valuable information from data
Understand business requirements and generate insights
Build mathematical models, validate and work with them
Explain complex topics tailored to the audience
Validate and follow up on results
Work with large and complex data sets
Establish priorities with clear goals and responsibilities to achieve a high level of performance.
Work in an agile and iterative manner on solving problems
Evaluate different options proactively and ability to solve problems in an innovative way. Develop new solutions or combine existing methods to create new approaches
Good understanding of Digital & analytics
Strong communication skills, orally and in writing

Education
Bachelors or masters in Computer Science or Engineering / Mechanical Engineering / Chemical Engineering / Process Engineering

Functional knowledge required
Microsoft Azure
Analytics and statistics
Mathematical modeling
Python
Spark
SQL
Machine Learning
Deep learning
Optimization
Notebooks

Primary Location: India-Gujarat-Vadodara
Work Locations: Baroda Piramal Glass India, 3rd Floor,The Baroda Central Co-Operative Bank, Station Road,Sayajigunj Vadodara 390005
Job: Digital
Organization: Piramal Glass Limited
Day Job
Job Posting: 08-Jul-2020, 5:39:01 AM",3.5,"Piramal Glass Limited
3.5",Vadodara,"Mumbai, India",1001 to 5000 employees,-1,Contract,Advertising & Marketing,Business Services,₹500+ billion (INR),-1
Data Scientists,-1,"Our Data Scientists are quantitative analysts who can extract meaningful insights from customer data, and leverage predictive models to optimize business performance. They support Risk management, Marketing, Capital Markets, Operations and Finance teams. This is a strategic role that sits at the heart of value creation by turning data into a long term competitive advantage.

As a Senior Data Scientist you will...

Drive the evolution of best in class Channel Analytics by:
Working with Tech & Data teams to define requirements and review solution builds
Applying insights from customer response data to build response and targeting models
Building Attribution Models and optimising offline and online Marketing Mix to drive growth
Developing and applying real time links between spend across channels and response patterns
Working with Tech and Operational teams to ensure identified wins are delivered
Managing and mentoring direct and indirect reports to deliver significant increases in productivity
Deliver cutting edge models using the latest techniques and upskill the team: Use advanced statistical analysis to design testing and predictive models whilst creating and improving on best practices to be used across the Funding Circle analytics community
Drive thought leadership across the business: Recommend optimal business strategies based on historical performance, predictive analytics and scenario analysis
Build global frameworks that are scalable across markets and help to drive business outcomes & portfolio performance
Work closely with partner teams across business and risk to ensure analytical outputs meet stakeholder expectations
Communicate effectively analytical outcomes to wide variety of internal and external constituents including senior stakeholders Up to 20% travel
Demonstrable strong Machine learning/AI experience along with proficiency in analytical tools like R and Python, Excel VBA, Tableau, SQL
Demonstrates strong knowledge of data architecture, modelling techniques, consumer behaviour patterns and the key drivers of marketing or credit performance optimization
Has exceptional analytical skills with an advanced degree in a quantitative field like mathematics, physics, computer science, statistics, economics, econometrics etc
Have strong experience in a channel or product analytics role in a major digital or financial services organization with demonstrated track record of data science delivery in channel analytics, marketing analytics and/or risk analytics
Possesses strong interpersonal skills and the ability to communicate effectively to technical and non-technical audiences
Identifies with our mission, “to build a better financial world”
What You Need for this Position

You should have knowledge of:
Python
Excel VBA
Tableau
SQL
Risk management
Marketing
Capital Markets
Operations
Finance teams.
Aditional
No. of Positions
Education level
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
Data Scientist Machine Learning and Predictive Sciences,-1,"Description


Overall Purpose
Experienced data scientist position that uses highly advanced skills in the use of predictive sciences for voice virtual assistant and risk management - predictive modeling, statistical methods, multivariate analysis, decision trees, clustering/segmentation analysis, time series analysis, survival analysis, forecasting, association rules, data mining, test and control experimentation (design of experiments/DOE), sampling, trend analysis, visualization techniques, and other statistical or data analysis techniques to analyze large data files from both internal and external sources to explain or predict behavior and or solve a variety of business problems. Will perform networking and research of business unit functions and underlying processes, identify corporate data sources and uses for data, and translate results into meaningful financial impacts and operational recommendations. Implementation of statistical methods and interactive tools for analysis of clients business challenges.

Key Roles and Responsibilities

• Participate in client engagements in enhancing current statistical models and develop new models for business needs or design of experiments for test/control analysis and business process trials.
• Consult with cross-functional teams on matters relating to statistics, knowledge discover, data modeling, and analytics.
• Own predictive models/ML and DOE/A-B testing areas of voice virtual assistant customer interactions and negotiations
• Develop business context for environment and ML uses/applications and deep knowledge of data inputs, outputs, and statistical testing/modeling
• Write/Run data extraction algorithms to acquire data from primary or secondary data sources and ability to describe/direct data requests for representative data necessary for analyses
• Develop statistical tests and predictive solutions to make business recommendations for decisioning
• Train/develop models, run evaluation experiments, and perform statistical analysis of results and refine models
• Develop understanding of data framework and how it relates to business use, specific process time points, and make recommendations for any new data needs. Coordinate with data engineers to ensure data is representative of analysis solutions.
• Use of data analytics and other strategies that optimize statistical efficiency and quality
• Interpret data, analyze results using statistical techniques and provide ongoing reports
• Identify, analyze, and interpret trends or patterns in complex data sets
• Filter and clean data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
• Work with management to prioritize business and information needs
• Perform Ad Hoc Data Analysis and reporting for model performance
• Locate and define new process improvement opportunities for testing and predictive modeling
• Partner with systems team to design, plan, execute, monitor, and evaluate DOE/A-B test experiments
• Responsible for regular reports/analyses while the trials are in progress, as well as analyze the results from the completed trial
• Responsible for developing presentation (i.e. PowerPoint-PPT) to share end-end storyboard for analytical initiative, including appropriate visualization
• Use of NLP statistical techniques to transform natural language data into useful features via identification of patterns with voice to text data, to feed classification algorithms, select appropriate annotated datasets for Supervised Learning methods, and use effective text representations to transform natural language into useful features which can be used as attributes/predictors for other negotiation modeling components, decisioning, and in other processes.

Qualifications


Required Skills

• Overall minimum experience of 9 years and above. Typically requires a Masters or foreign equivalent degree in Statistics, Data Science or Industrial Engineering.
• Minimum Relevant Experience of 3 years and above using ML (machine learning), statistical predictive modeling, multivariate/regression, clustering, time series/survival analysis, DOE(design of experiments), sampling, statistical analysis/testing, text mining/NLP, and visualization techniques; client engagements to solve business challenges and develop processes using data from various inputs and developing statistical solutions for business needs
• Minimum Relevant Experience of 3 years and above utilizing analysis tools such as Base SAS, SAS/Macros, SAS/STAT, SAS Enterprise Miner, SAS Viya, R, Python and familiarity with SQL and data management/cleaning techniques to ensure data is representative of statistical analysis, predictive model, or analysis solution.
• Experience in client engagements, interpreting clients business challenges, and recommendations for statistical analysis solutions (i.e. analytical consulting and solution design)
• Strong understanding of internal business segment or stakeholders and strong presentation skills including visualizations and storyboard of analysis results via PowerPoint.
• Strong financial acumen and analysis experience to determine business impacts for application of statistical solution
• Experience in presentation design, development, delivery, and communication skills to present analytical results and recommendations for action-oriented data driven decisions and associated operational and financial impacts.",3.4,"AT&T
3.4",Bengaluru,"Dallas, TX",10000+ employees,1983,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Verizon, T-Mobile, Sprint"
Data Scientist: Advanced Analytics,-1,"Introduction
Quantum computers are incredibly powerful machines that take a new approach to processing information. Built on the principles of quantum mechanics, they exploit complex and fascinating laws of nature that are always there, but usually remain hidden from view. By harnessing such natural behavior, quantum computers can run new types of algorithms to process information more holistically. They may one day lead to revolutionary breakthroughs in materials and drug discovery, the optimization of complex manmade systems, and artificial intelligence. We expect them to open doors that we once thought would remain locked indefinitely.

IBM Services is looking for a Quantum Data Scientist who will interface with research and algorithm experts to implement quantum approaches, which includes data pre-/post-processing, running numerics and visualizing data. Working with quantum industry experts, you will be a key member of a multi-discipline squad focused on building quantum capabilities and researching quantum application development for clients within Communication sector industries including specific focus on telecommunications.

Your Role and Responsibilities

Work with IBM Q Start team on active exploratory research engagements to prepare for future use case commercialization within specific industry
Interact with client data science teams to define promising areas for quantum
Implement quantum approaches, which includes data pre-/post-processing, running numerics and visualizing data
Collaborate with industry and solutioning experts to design and shape experiments to demonstrate quantum-enabled advantage
Contribute best practices related to information architecture, including collection, integration, organization, analysis and visualization of data for quantum-enabled impact
Support practice development initiatives focused on building employee knowledge and skills in specific areas of expertise through coaching and development of training course material

Required Technical and Professional Expertise

PhD/Masters in STEM-related fields with knowledge in quantum computing.
2+ years of data engineering and data science experience
1+ year of consulting experience within specific industries
Familiarity with classical approaches to machine learning and linear algebra, including Support Vector Machine (SVM) for linear categorization and Singular Value Decomposition (SVD) to reduce dimensionality of data
Familiar with Qiskit software, including Qiskit Aqua for domain applications and Qiskit Terra for quantum circuit design and optimization
Excellent ideation, facilitation and communications skills
Detail-oriented team player with strong interpersonal skills and ability to take a leadership role when necessary
Willingness to travel globally up to 40% once we return to a travel-safe environment.
English: Fluent

Preferred Technical and Professional Expertise

2+ years of experience in at least one of the industries, with knowledge of industry trends, R&D areas, and computationally intensive processes (e.g. optimization)
Familiarity with Qiskit

About Business Unit
IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter business by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM
What matters to you when you’re looking for your next career challenge?

Maybe you want to get involved in work that really changes the world. What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Machine Learning Engineer - Customer Engagement,-1,"Because you belong at Twilio.

The Who, What, Why and Where

Twilio seeks a Machine Learning Engineer to be a key leader in defining a new product offering at Twilio in the customer engagement space. The person in this role will be critical in shaping Twilio's data and intelligence strategy, which will empower our customers to create highly personalized communications and experiences for their contacts. Come be part of a team that's building a set of ML-driven APIs that deliver intelligent audience and personalization recommendations.

Who?

You have:
Personal traits: Curious, humble, team player
Professionally: Passionate, customer-obsessed, gets things done, highly collaborative, excellent communicator, and very comfortable with rapid change and uncertainty
You have hands on experience developing, deploying and monitoring a large scale machine learning model in production
Ph.D. or MS in Computer Science, Statistics, or related field
4+ years of applied ML experience in statistical and mathematical modeling such as supervised and unsupervised machine learning, deep learning, and/or reinforcement learning
You are familiar with concepts related to testing and maintaining models in production such as A/B testing, retraining, monitoring model performance
You've explored modern data storage, messaging, and processing tools (Kafka, Spark, Hadoop, Cassandra, etc.) and demonstrated experience designing and coding in big-data components such as DynamoDB or similar
You have a deep understanding of frameworks like - PyTorch, TensorFlow, or Keras, why and how these frameworks do what they do
Proficiency in Python is preferred. We will also consider strong quantitative candidates with a background in other programming languages
Experience working in an agile team environment
Big plus: Experience in AWS cloud computing
What?

You live the Twilio Magic values:
EMPOWER OTHERS: Be part of a small, high-impact and multi-talented engineering team. Show strong engagement in the team setting
WEAR THE CUSTOMER'S SHOES: Passion for and demonstrated track record of executing product opportunities deeply grounded in customer needs
DRAW THE OWL: Self-starter who can see the big picture and prioritize work to make the largest impact
BE BOLD: Help us take one of the world's most extensive communication data sets and transform it into leading-edge AI applications and products that solve meaningful customer problems
BE INCLUSIVE: Collaborating and brainstorming product ideas with product managers, data scientists and engineers
DON'T SETTLE: Experienced working at a massive scale with distributed, scalable systems, including making tradeoffs for consistency/availability
NO SHENANIGANS: Experience successfully applying machine learning to real-world problems
Why?

Today, Twilio powers the delivery of billions of the world's communications. Increasingly, we're hearing from our B2C customers that they're struggling to harness the massive amounts of valuable data they generate, much of which stems from the communications we help them send. We seek to uncover how Twilio can help customers utilize their valuable data to create unique, individualized experiences that their competitors can't replicate. We want to help them become more proactive (outcome-driven) than reactive (event-driven) in their customer engagements. We are a new initiative and team at Twilio that will function much like an internal start-up. If you want to shape the future of B2C Customer Engagement and Twilio, this project is for you!

Twilio is a company that is empowering the world's developers with modern communication in order to build better applications. Twilio is truly unique; we are a company committed to your growth, your learning, your development, and your entire employee experience. We only win when our employees succeed and we're dedicated to helping you develop your strengths. We have a cultural foundation built on diversity, inclusion, and innovation and we want you and your ideas to thrive at Twilio.

Where?

This position will be located in our office in Bangalore, India. You will enjoy our office perks: catered meals, snacks, game room, ergonomic desks, massages, Wednesday dinners, bi-weekly All Hands, and more. What you will also get to experience is a company that believes in small teams for maximum impact; seeks well-rounded talent to ensure a full perspective on our customers' experience, understands that this is a marathon, not a sprint; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves.

About us:

Millions of developers around the world have used Twilio to unlock the magic of communications to improve any human experience. Twilio has democratized communications channels like voice, text, chat, video and email by virtualizing the world's communications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world's most demanding applications. By making communications a part of every software developer's toolkit, Twilio is enabling innovators across every industry — from emerging leaders to the world's largest organizations — to reinvent how companies engage with their customers.",4.0,"Twilio
4.0",Bengaluru,"San Francisco, CA",1001 to 5000 employees,2008,Company - Public,Internet,Information Technology,₹100 to ₹500 billion (INR),-1
Data Scientist,-1,"Roles and Requirements ·

passion of teaching and motivating students.

Excellent communication skills

· Approachable and vibrant personality.

· Has knowledge about Training - Soft Skill & Technical Skills

· Able to conduct the assessment within the batch

· Should conduct Training on JAVA, Python and Tableau

· Conduct online and classroom training sessions by providing practical knowledge, cases studies and assignments

· Good analytical skill and capable to handle team management.

· Monitor student progress and make recommendations to the reporting manager if any interventions are needed to bridge the gap * Managing the data science team, planning projects and building analytics models. You should have a strong problem-solving ability and a knack for statistical analysis. If you’re able to align our data products with our business goals, we’d like to meet you. * Your ultimate goal will be to help improve our products and business decisions by making the most out of our data. You should know enough about the product to dive in when needed, but not shrink from the responsibility of leading the team to achieve their objectives. * Proven experience implementing and deploying advanced AI solutions using Python at scale. * Apply machine learning algorithms, statistical data analysis, text clustering, summarization, extracting insights from multiple data points. * Excellent understanding of Analytics concepts and methodologies including machine learning (unsupervised and supervised). * Hand on in handling large amounts of structured and unstructured data. * The measure, interpret and derive learning from results of the analysis that will lead to improvements in document processing. Technical Skills: * Python, NLP, NLG, NLU, Machine Learning, Deep Learning * Word Embeddings, Sentence Embedding, Document Embedding * CNN, RNN (LSTM & GRU) and Transformers * Pretrained Embeddings (word2vec/GloVe/BERT/Elmo/GPT2/XLNet/RoBERTa/XLM) * Unsupervised, Semi-Supervised & Supervised Deep Learning * Graph Neural Networks * GPU Computing * Good knowledge of statistics/bayesian stats/probability/Linear Algebra/Vector Calculus * Frameworks: Keras/Tensorflow/PyTorch * Model Deployment and Interpretability * Reinforcement Learning * Optimization techniques and Game Theory

Job Types: Full-time, Part-time, Contract

Experience:
work: 2 years (Preferred)
total work: 2 years (Preferred)
Education:
Master's (Preferred)
Work Remotely:
Temporarily due to COVID-19",-1,Digitalparadize,New Delhi,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist 2,-1,"PayPal’s Next-Generation Platforms Consumer Risk team is responsible for assessing and managing buyer-side financial risk exposures for this $8 billion portfolio (including identity theft, stolen financials, account takeover, and credit risk), as well as developing and implementing the policies, treatments, and experiences related to the management of these exposures. The team is also responsible for partnering with the corresponding Business Units to align with and influence their strategic priorities, educate business partners about Risk management principles, and collaboratively optimize the Risk treatments and experiences for these unique products and partners.

Each Decision Scientist on this team has full ownership of a portfolio of merchants and is responsible for end-to-end management of loss and decline rates. Day-to-day duties include data analysis, monitoring and forecasting, creating the logic for and implementing risk rules and strategies, providing requirements to data scientists and technology teams on attribute, model and platform requirements, and communicating with global stakeholders to ensure we deliver the best possible customer experience while meeting loss rate targets.

Scope of Responsibility:
Works independently and proficiently. Accountable for own results. Reviews are mainly for consultation and sharing ideas
Works on multiple assignments simultaneously and in all areas of a standard project in the area of responsibility
Focuses primarily on how to achieve overall analytic objectives of a project with speed and quality.
Suggests ideas for operational plans and objectives
Clear subject matter expert within group / geography
Works independently and proficiently on multiple assignments simultaneously with speed and quality
Mentor junior decision/data scientists.

Job Requirements:
Strong analytical skills - ability to build quick estimates using back-of-the-envelope analysis, structure (and, if needed, execute) more complex analyses, pull together business cases and forecasts to navigate through multi-dimensional sets of tradeoffs.
Enthusiasm for data-driven problem solving within a fast-paced environment is a must. In addition, experience with Microsoft Excel or statistical software, working knowledge of SQL or other relational database languages, and hands-on experience in data analysis involving large data sets are strongly desired Work experience at the management consulting firms is a plus.
Polished communication and influence skills – risk decision scientists need to collaborate cross-functionally with product managers, data scientists, business owners, and customers to learn from subject-matter experts, present findings in a clear and concise manner, and reach alignment on how to execute risk strategies. Demonstrated ability to influence groups and effectively resolve conflicts is required.
An innate intellectual curiosity, and a willingness to build awareness of current payments industry and risk management best practices. PayPal is constantly innovating by introducing new products and entering new markets, so successful risk analysts on this team must quickly get up speed on new content areas. You will be expected to become an expert in your specific domain.
“Can-do” attitude, team player, energetic personality, ability to work well under pressure in a fast-paced and constantly changing environment to meet deadlines. The successful risk analyst is a self-starter who has the resilience to learn from their mistakes and reach their true potential.
Identify typical problems and issues during normal course of work and take proactive actions to solve them with minimum guidance. Recommends changes to policies and establishes procedures that affect immediate organization(s).
Exercises discretion in resolving a variety of issues in imaginative as well as practical ways.
Impact of decision has moderate to large reach
Offers insight for and contributes to improving existing technology, tools, processes, and business solutions. Adds value to brainstorming sessions

BS/BA degree with 8+ years of related professional experience or master’s degree with 6+ years of related experience or Doctorate with 4+ years of related experience.

Job_Description_Summary: We are looking for Lead Decision Scientist with experience of Managing large portfolios to develop PayPal’s Risk strategy within the Next-Generation Platforms & Strategic Partners portfolio. This portfolio is comprised of PayPal’s newest leading-edge payments solutions, as well as customized experiences developed for the company’s highest-priority strategic partnerships. Lead Decision Scientist will be the end to end owner of the Tokenization portfolio and is responsible for end-to-end management of loss and decline rates. Day-to-day duties include data analysis, monitoring and forecasting, creating the logic for and implementing risk rules and strategies, providing requirements to data scientists and technology teams on attribute, model and platform requirements, and communicating with global stakeholders to ensure we deliver the best possible customer experience while meeting loss rate targets. If you’re interested in working with PayPal’s most interesting payments experiences then this is the right team for to join!

Who we are: Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 286 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.

We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities.",3.7,"PayPal
3.7",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Data Scientist III,-1,"Job Title:
Data Scientist III

Job Description

We are seeking an experienced, motivated, creative Python Developer/Data Scientist to join our Cognitive/AI Automation development team to build AI solutions using Python and related AI Technologies across our 450+ market-leading customer base. This role requires a high degree of independent execution, ownership and responsibility for customer success. The Data Scientist is expected to be highly resourceful at swiftly executing development tasks with high quality coding standards. This is a varied role which offers exposure to a wide range of technologies. A commitment to collaborative problem solving, sophisticated design, and delivering quality product(s) is essential.

TECHNICAL SKILLS & KEY RESPONSIBILITIES

In depth knowledge of Python 3.6 and 2.7.
Strong knowledge of Django/Flask Framework and REST API Creation.
Handling of data objects in JSON, XMLCommon open source libraries in Python
Experience in advanced statistical techniques, multivariate regression, classification problems, predictive analytic/, text analytics, NLP and large data.
Multi-lingual text analytics and NLP development and deployment.
Knowledge of Machine Learning, AI, BOT, Chatbots
Familiarity in integrating from external rest APIs and web services
Strong knowledge of UI development with database handling in Python.
Develops clear definitions for data elements. Develops worked examples to promote understanding of data changes. Promotes consistent data naming standards (such as table columns, class attributes, etc.) across the enterprise. Captures metadata for data elements.
Prior Experience in using Machine Learning/Computer Vision is highly preferred
Should have experience on storing and Deploying Repository Objects, Retrieving Objects from the Repository, Deploying the Stream etc.
Experience with scripting languages like including Shell.
Good understanding of Object Oriented Design methodology
Knowledge of SQL (SQL PL, T-SQL or PL/SQL/ Hadoop would be an asset).
Understanding of SDLC.

DESIRED SKILLS

Design and implement large sized high-performance and scalable solutions.
Designing applications for cloud deployment.
Understand trends in technology and be able leverage them in technical solutions.
Must be able to design and implement frameworks for technical solutions.

PREFERRED SKILLS

Must have good written and verbal communication skills. Must be able to effectively communicate all aspects of a project solution with managers, client and project team.
Strong interpersonal and leadership abilities which can execute effective negotiation and team management skill.
Be able to think creatively.

#WAH

Location:
IND Gurgaon - Bld 6 Ground & First Floor

Language Requirements:
Time Type:
Full time",3.9,"Concentrix
3.9",New Delhi,"Fremont, CA",10000+ employees,2004,Subsidiary or Business Segment,Staffing & Outsourcing,Business Services,₹100 to ₹500 billion (INR),-1
Data Scientist Intern,-1,"Internship Cohort Team Size : 3

Apply Via Naukiri Posting

https://www.naukri.com/job-listings-Data-Scientist-Intern-zBliss-Technologies-Pvt-Ltd-Bengaluru-Bangalore-Chennai-0-to-1-years-110520000083

Apply only if you can work full time at least for Five Months

and

Only if you can demonstrate the Skills listed below through Previous projects, College Projects, or self-learning exercises reflected in your resume

Skills:
Python
Thorough understanding of Pandas, Tensorflow 2, Keras and other related modules
Experience in managing datasets with millions of rows and multiple features
Strong understanding and subject expertise in Artificial Neural Network (ANN) and Recurrent Neural Network (RNN)
RNN and ANN Modeling using TensorFlow 2 and Keras
Diligence and accuracy in coding and data analysis
Conscientiousness, and Professional approach towards team work, project management, coding, and product development
Education: Students pursuing Data Science related graduate, post graduate, Doctoral, and integrated courses.

Internship Duration: The internship will be for six to nine months. We cannot accommodate internship period less than three months

Internship Project: Development and implementation of AI algorithms in Healthcare. You will be guided and coached extensively. You will need to perform and contribute positively to the project on a daily basis

This is a full time PAID Internship for six to nine months.

Location: Chennai, or Work From Home because of the COVID19 Lockdown

Application Process:
Apply through this web page.

After reviewing your resume we will send you a pre-interview Programming Assessment Exercise to test your skills in Python, Data Management and Machine Learning. You will have to complete this exercise within five days of receipt of the Exercise and send the completed Exercise back to us.

We will review your submission and if we consider your skills to match our expectations, we will do a phone interview and if possible an in-person interview. Upon successful completion of the interview process you will be given an internship offer.

Job Features
Job Category Data Scientist Intern",-1,zBliss Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"Scienaptic is the world's leading AI powered Credit Underwriting platform company. Designed by seasoned Chief Risk Officers, its platform is creating industry leading business impact in terms of lifts such as higher approvals (15-40%) and lower credit losses (10-25%) with all the regulatory explainability. Last year alone, we have helped financial institutions evaluate 45 Million consumers and offer credit to over 15 Million. Scienaptic’s clients include Fortune 100 banks, community banks and Fintechs.

The Data Scientist role will enable you to be at the forefront of latest cutting-edge technology and create a significant and visible business impact for Scienaptic. You will be working with some of the best-in-class Coders, AI/ML Scientist and Business Analytics Consultants in an environment which will encourage you to contribute widely to functional and technological aspects without worrying about conventional job silos.

Role Responsibilities -
Design, build, test and deploy ML models at scale
Experience with modern machine learning techniques including Ensemble Methods,
Recommender Systems, NLP and Deep learning
Experience in handling recommender system algorithms like Non-personalized recommenders, Content based recommenders, Collaborative filtering etc.
Write production ready code and deploy real time ML models ; expose ML outputs through APIs
Analyse website and apps effectiveness and recommend changes to content, navigation and design
Hypothesis Testing and Design of experiments to analyse and monitor results
Experience in building digital enquiry generation models, product recommendations on website, marketing response models, social media analytics.
Engineer features to improve decision algorithms
Partner with data/ML engineers and vendor partners for input data pipes development and ML models automation

Skills and Experience
ML algorithms – Supervised / Unsupervised Learning, Clustering, Time Series Forecasting, recommender systems, Deep learning
Languages and packages - Python, Spark, PySpark, SparkML, MLlib, Tensorflow, NLP Packages like NLTK
Knowledge in cloud platform – Microsoft Azure ADF, Azure kafka, Azure Databricks, Databricks MLflow
Experience building scalable / highly available distribute systems in production

Experience
3-5 years of hands-on experience in Data Science with exposure to online recommender systems, NLP, traditional ML
Work experience with Digital-native companies, Travel aggregator website, application companies OR
e-commerce companies.

Send your CVs to febina@scienaptic.com",3.7,"Scienaptic Systems
3.7",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Job ID: JDS01

As a Data Scientist, you will work to resolve ambiguity with data, play a crucial role in the iteration and optimization solutions, and support data-driven decision-making across the organization.

ROLE RESPONSIBILITIES
Tasked with solving a real-life business problem that requires a processing/analyzing large amounts of data and handling a variety of data sources.
Take ownership of successful completion for the end to end life cycle and implementation.
Proactively investigate, report, and where possible, address data quality issues.
S
Can envision & implement the optimal analytics technique/approach required for the problem.
Ability to work and execute projects on both structured and unstructured data in a big data environment.
Ability to work across geographies and interact with global stakeholders.
Ability to coordinate and work within multiple business units from a project management perspective.
Prior experience working in Agile methodologies/JIRA would be a plus.
MINIMUM REQUIREMENTS
BS/BE in Computer Sciences, Math, Statistics, or related field. Masters preferred.
An expert in at least one of the machine learning frameworks - Keras, Tensorflow, PyTorch, etc, as well as programming, visualization, and statistical tools such as R, JMP, SAS, Tableau, Python, Perl, Java/C++
Minimum of 4+ years of experience in data, advanced analytics, data science, and business intelligence.
Proficient in SQL and experience with efficient processing of large data sets. Ability to write sophisticated and optimized queries against large databases.
Proficient in Python ML libraries, Hadoop/Redshift/BigQuery.
Experience in the Ad-Tech industry is a must.
OTHER INFORMATION

Join a fun and lively young Startup based in Dubai Silicon Oasis (while operating from Noida, India). Boost your experience and learn about the different types on Online AdTech environments and models. Show your skills and potentially become a pillar of our fast-growing team.Jubna offers an Attractive compensation, Health Insurance, Travel Allowance.
Some travel to Dubai, UAE is required (10%)",-1,Jubna,Noida,"Dubai, United Arab Emirates",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Applied Scientist - Intern,-1,"Excited by Big Data, Machine Learning and Predictive Software? Interested in creating new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?

At Amazon Bangalore, we are developing state-of-the-art large-scale Machine Learning Services and Applications on the Cloud involving Terabytes of data. We work on applying predictive technology to a wide spectrum of problems in areas such as Amazon Retail, Seller Services, Customer Service, Alexa, Chatbots and so on. We are looking for talented and experienced Machine Learning Scientists (Ph.D. in a related area preferred) who can apply innovative Machine Learning techniques to real-world e-Commerce problems. You will get to work in a team dedicated to advancing Machine Learning technology at Amazon and converting it to business-impacting solutions.

Major responsibilities
· Use machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
· Analyze and extract relevant information from large amounts of Amazons historical business data to help automate and optimize key processes
· Design, develop and evaluate highly innovative models for predictive learning
· Establish scalable, efficient, automated processes for large scale data analyses model development, model validation and model implementation
· Research and implement novel machine learning and statistical approaches

Basic Qualifications

Basic Qualifications
· A Masters and/or PhD in CS, Machine Learning, Operational research, Statistics or in a highly quantitative field.
· Experience in predictive modelling and analysis, predictive software development.
· Strong problem-solving ability
· Good skills with Java/Scala or C++, Perl/Python (or similar scripting language)
· Experience in using R, Matlab, or any other statistical software
· Strong communication and data presentation skills

Preferred Qualifications

Preferred Qualifications
· Experience handling gigabyte and terabyte size datasets
· Experience working with distributed systems and grid computing
· Knowledge of the latest and state of the art ML technology.
· Publications or presentation in recognized Machine Learning and Data Mining journals/conferences",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Scientist,-1,"5+ years of experience in software development of large-scale data infrastructure and distributed systems
5+ years of experience in data extraction, transformation, statistical analysis and data modeling
5+ years of experience developing enterprise software using Java or Python
3+ years of experience in applying Data Mining and Machine Learning techniques to solve business problems
3+ years of experience using major RDBMS, Hadoop, Spark, Elasticsearch, or similar technologies
3+ years of experience with statistical modeling tools such as R, SAS, SciKit-learn, or TensorFlow
Bachelor’s degree in Computer Science, Computer Engineering, Machine Learning, or related field or equivalent experience.
Amazon strives to be Earth's most customer-centric company where people can find and discover anything they want to buy online. We hire the world's brightest minds, offering them a fast paced, technologically sophisticated, and friendly work environment.

The FinAuto Data Engineering and Analytics team, part of Finance Automation Org focuses on the application of machine learning methods designed to enable Amazon to increase free cash flow by optimizing spend, expense, payroll defects. All of this work is performed in close coordination with senior business leaders. These are exciting fast-paced businesses in which we get to work on extremely interesting analytical problems, in an environment where you get to learn from other data engineers and apply econometric, statistics, and machine learning at massive scale.
As a member of the FinAuto Data Engineering and Analytics team, you will partner closely with a team of stake holders, payment teams, data engineers and software engineers.

In this role you will:
Work with data engineers to design and implement machine learning applications and solutions.
Implement and maintain a high-volume, highly available, hybrid (SQL + No SQL) data processing solutions that consists of structured and semi-structured data.
Design and implement a very large distributed data warehousing and reporting solution and integrate it with business intelligence tools
Master’s degree in Computer Science, Computer Engineering, Machine Learning, or related field; PhD a plus
Deep expertise in Statistics, Machine Learning or related disciplines
Advanced knowledge in performance, scalability, numerical accuracy, enterprise system architecture, best practices.
Experience building solutions using AWS big data and machine learning services
Ability to communicate complex technical concepts and solutions to all levels of the organization",-1,Amazon Dev Center India - Hyd,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"Responsibilities:
Undertake preprocessing of structured and unstructured data.
Build data products to extract valuable business insights
Build models to address business problems.
Propose solutions and strategies to business challenges.
Presenting information using data visualization techniques.

Requirements:
MSc / PhD in Computer Science, Statistics, Engineering or related field
Experience in probability, statistics, and statistical modeling or machine learning
Fluency in at least one scripting language
Excellent analytical and problem-solving skills
Excellent communication skills and business acumen
Good command in written and spoken English",-1,RedLotus,Mumbai,"Kowloon City, Hong Kong",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Consultant - Data Science,-1,"Antuit.ai is the leader in AI-powered SaaS solutions for Demand Forecasting & Planning, Merchandising and Pricing. We have the industry’s first solution portfolio – powered by Artificial Intelligence and Machine Learning – that can help you digitally transform your Forecasting, Assortment, Pricing, and Personalization solutions. World-class retailers and consumer goods manufacturers leverage antuit.ai solutions, at scale, to drive outsized business results globally with higher sales, margin and sell-through.

Antuit.ai’s executives, comprised of industry leaders from McKinsey, Accenture, IBM, and SAS, and our team of Ph.Ds., data scientists, technologists, and domain experts, are passionate about delivering real value to our clients. Antuit.ai is funded by Goldman Sachs and Zodius Capital.

The Role:
Antuit.ai offers AI products that help CPG and retail companies to plan and operate their business better. The data scientist will play a critical role in ensuring the products are configured to provide the best solution to the users.

Responsibilities:
A key member of the Forecasting and Supply Chain team, this person will facilitate product solutioning and enhance user experience with analytical insights and addressing the problem statements encountered by users. Specific tasks include:
Understand the client’s business including nuances of the products, sales channels, business cycles and levers like promotions, advertising etc.
Ensure completeness, accuracy and quality of data received
Identify anomalies in the business using the data and work with the client to resolve the anomalies
Configure the AI product model to generate the necessary model outputs
Evaluate the accuracy of the model outputs and analyze the output to identify issues in the model
Create and present reports showing model performance, and have an engaging conversation with business stakeholders
Analyze and resolve any ongoing issues with model performance
Qualifications and Skills:
4+ years of experience working with retail or CPG clients
Good understanding of CPG or retail supply chain process. Understanding of Retail/CPG data model is a plus.
4+ years of hands on experience in python and SQL to do exploratory analysis and identify anomalies
Good understanding of regression and/or time series models
Expertise in evaluating model output and identifying model improvement opportunities.
Excellent problem-solving skills
Natural ability to think analytically
The ability to plan work and meet deadlines
Accuracy and attention to detail
Flawless oral and written communication skills
Massive appetite to learn and curiosity to understand the business problem and solutions
Good team player with humility and patience to work with high caliber talent
Information Security Responsibilities
Understand and adhere to Information Security policies, guidelines and procedure, practice them for protection of organizational data and Information System.
Take part in Information Security training and act accordingly while handling information.
Report all suspected security and policy breach to Infosec team or appropriate authority (CISO).
EEOC
Antuit is an at-will, equal opportunity employer. We consider applicants for all positions without regard to race, color, religion, national origin or ancestry, gender identity, sex, age (40+), marital status, disability, veteran status, or any other legally protected status under local, state, or federal law.

To apply, please send your resume or CV to careers@antuit.com",4.0,"Antuit
4.0",Bengaluru,"Chicago, IL",201 to 500 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist,-1,"Profile Requirements
Analyze and dig out carefully vetted, actionable insights from (mostly! pre-cleaned) data.
Turn insights into precise changes in the system; applying a toolset including calculus, statistical modeling, advanced algorithms, and machine learning to create measurable dollar impact.
Scale and generalize forecasting models and optimization algorithms to handle requirements from new markets and clients.
Travel and engage clients directly to translate their business needs into implementable science.
Fundamental math and designing robust algorithms from scratch excites you (as opposed to just running boost.fit).
You care deeply about true measurable value, not just methods; and you are willing to go the many extra miles to create it.
You are hands-on, like to get in there yourself; and can take a vague problem all the way through to designing, implementing, and proving the solution.
You pay attention to writing clean, minimal code; bugs really bother you.
You are pragmatic and have an eye for detail.
Solid understanding of machine learning fundamentals, probability, and algorithms.
At least 1-year of experience coding in R/Python .
1 – 3 years of experience in building analytical models; familiarity with common machine learning techniques.
Experience in C a big plus.
Experience in statistical inference and causal experimentation design a big plus.
Knowledge of data visualization tools like Tableau/Power Bi etc will be an added advantage
Pay Scale : 4.8 Lac – 13.0 Lac
Positions : 3",-1,SearchUrCollege,Noida,"Noida, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist - Advanced Analytics,-1,"Position Title
Data Scientist - Advanced Analytics

28-Jul-2020

Job ID
297623BR

Job Description
70 tactical buyers are supporting both commercial and NTO towers out of Prague NGSC, covering region Europe, Switzerland, Middle East and North America.

To establish and maintain effective measures to monitor and ensure that the global process is fully and consistently implemented across the regions and within the countries. Lead operations and continuous improvement reviews to define and implement actions and projects to continuously enhance the process effectiveness and efficiency.
Your responsibilities include, but are not limited to:
•Manage the creation, deployment and on -going maintenance of metrics and benchmark to monitor the performance of the global process and its enabling system(s).
•Responsible for the management of the end-to-end procurement process by enabling globally defined solutions and driving the local adoption in order to achieve Sourcing excellence.
•Support the process super user community, ensuring regular engagement, training (including process & tool demo) and collection of feedback.
•Provide guidance and support to the regions and countries and identify areas requiring process and systems reviews.
•Coordinate and support process reviews in the regions and countries and provide direction to develop and implement action plans to address identified gaps. -Support the execution of the region or countries performance improvement plans.
•Champion specific projects and change management activities to fully establish and continuously improve the process.
•Facilitate the discussion with key stakeholders, within procurement and with other functions, to identify opportunities and to drive full process adoption.

https://www.youtube-nocookie.com/embed/Mo1vwtVPVA0

Minimum requirements
•M.S/Ph.d in Computer Science, Robotics, Mathematics, Statistics, Operations Research, Cognitive Sciences, Psychology, Engineering, Finance, Economics, Medicine, Technology, Management Science, Quantitative Methods and other related disciplines
•6 -10 years of overall experience with demonstrated track record in data science solutioning
•Programming environments: java/python/Hive/Hadoop/HBase/C++/CSharp/Unix/Map Reduce/Perl/ Matlab/Xml
•Advanced in-depth specialization in mathematical analysis methods, machine learning, Experience in statistical learning: Supervised and Unsupervised Learning, Classification, Regression, Clustering, Neural Networks, Ensemble Modelling (random forest, boosted tree, etc.), Multivariate Statistics, Non-parametric Methods, Reliability Models, Markov Models, Stochastic models, Bayesian Models is required for this role
•Proven track record in delivering analytics solutions using Time Series Forecasting, Keras, Tensorflow, CNN, GAN, and RNN techniques
•Experience working with big data - identifying trends, patterns, and outliers in large volumes of data
•Comfortable in using Python or R to build automated dashboards using, D3.js, Plotly, Dash, Flask, Django, R-Shiny, etc.
•Excellent problem-solving skills, critical thinking and conceptual thinking abilities

Why consider Novartis?
799 million. That’s how many lives our products touched in 2019. And while we’re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people’s lives?

We believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you’re given opportunities to explore the power of digital and data. Where you’re empowered to risk failure by taking smart risks, and where you’re surrounded by people who share your determination to tackle the world’s toughest medical challenges.

Imagine what you could do at Novartis!

Commitment to Diversity & Inclusion:
Novartis embraces diversity, equal opportunity and inclusion. We are committed to building diverse teams, representative of the patients and communities we serve, and we strive to create an inclusive workplace that cultivates bold innovation through collaboration, and empowers our people to unleash their full potential.

Join our Novartis Network: If this role is not suitable to your experience or career goals but you wish to stay connected to learn more about Novartis and our career opportunities, join the Novartis Network here: https://talentnetwork.novartis.com/network

Job Type
Full Time

Country
India

Work Location
Hyderabad, AP

Functional Area
Procurement

Division
NBS

Business Unit
PROCUREMENT NBS

Employment Type
Regular

Company/Legal Entity
Nov Hltcr Shared Services Ind

Shift Work
No",3.9,"Novartis
3.9",Hyderabad,"Basel, Switzerland",10000+ employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
Data Scientist Bangalore,-1,"Data Scientist

Exp: 3+ Years

We are hiring for the role of Data Scientist for a Sweden based company for their offices in Bangalore.
Bachelor in Engineering, Data Science, Maths, Stats or Computer Science
2+ years of related work experience in Data science field
Fluency in SQL for data access, manipulation, and validation
Proficiency in either R, Python or SAS for data analysis
Passion for data visualization and information design
Capable of clearly communicating complex analyses to a non-technical audience, including extensive experience presenting to leadership groups
Ability to initiate, refine, and complete projects with minimal guidance
Mail your resume to team@equinoxes.in",-1,Equinox e Services,Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Machine Learning Engineer (Data Science Engineer),-1,"We are looking for Machine Learning Engineers/ Data Scientists to join our talented software team in building high performing, low latency, enterprise grade and cloud-based product suite. You will play a key role in building our innovative product pipeline. Using your deep understanding of modern web architectures and Cloud platforms, programming expertise and operational experience, you will help building successful SaaS products at Pype.

Please join our ML team and work together in breaking barriers and bringing AI to the construction software industry. Applicants should have a strong computer science background with good analytical, problem solving skills apart from good foundations in Machine learning with bent towards NLP/Image Understanding. Working proficiency with Python is mandatory. Knowledge of distributed systems like Hadoop/Spark is a plus.

Roles & Responsibilities

Formulate, code and evaluate machine learning models required for the product/application
Production deployment with required optimization, vectorization and system integration
Verification/validation and continuous integration of advanced variations
Identify/adopt feedback loops to maintain high fidelity data governance across the product portfolios

Qualifications:
Bachelor’s/Master’s degree in Computer Science or equivalent area from reputed institutes
Around 2-6 years of experience in applied or theoretical Machine learning roles in the industry or research institutes
Good grasp of Linear Algebra, Probability and Statistics
Working knowledge and inclination towards Statistical pattern recognition, Machine learning, Neural Nets, Image Processing
Experience with Python/Scikit-Learn/TensorFlow/OpenCV
Ability to work with a team in an Agile environment
To apply send your resume to hr-india@pype.io",3.9,"Pype
3.9",Bengaluru,"Herndon, VA",1 to 50 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Tech Lead - Data Scientist (NLP),-1,"AI team at Ultria is working on state of the art Natural Language Processing technologies including document structure detection, domain specific neural embeddings, deep neural network architectures for extraction and classification tasks etc. We are looking for a passionate data scientist to develop new statistical models for delivering high-quality NLP products.

RESPONSIBILITIES:
Identify new opportunities to apply Machine Learning to different parts of the product
Develop advanced algorithms to solve problems of high dimensionality in a computationally efficient and statistically effective manner
Have responsibility for the creation and development of our Text Analytics strategy and software
Take end to end ownership of Machine Learning products
Partner with other teams such as Data, Design and Product to collaborate on projects across the company
Work with the engineering management team to develop new initiatives and improve existing processes across the entire engineering team
Implement small and large scale projects in Advanced Analytics to help derive business insights for measurable success
Evaluate emerging datasets and technologies that may contribute to our products
Requirements
3 -7 years of strong Python development experience
3+ years of experience in Machine Learning/Deep Learning, specifically in NLP and text analytics domain including:
Extracting, cleaning and embedding text data
Text classification
Entity extraction/NER
Text summarization
Similarity and sentiment analysis
Topic modelling
Research experience in machine learning or natural language processing
Experience in deploying ML projects in production environment
Strong statistical analysis skills and demonstrated experience in deriving insights from unstructured data
Ability to run experiments scientifically and analyze results
Good understanding of ML tools/libraries like: Tensorflow, Keras, Pandas, Spacy, Pytorch, NLTK, SkLearn etc
Knowledge of big data technologies like Hadoop, Hive, Scala or Spark is preferred
Strong collaborative mindset
Excellent critical thinking and problem solving skills
Benefits

About Ultria

Ultria offers end-to-end, SaaS-deployed, Contract Lifecycle Management solution for the Enterprise—Ultria CLM. It is a market-proven solution with a legacy of successful deployments over more than seven years. With a workflow based authoring and approval tool, and a comprehensive repository of contracts and clauses, Ultria CLM helps companies across the spectrum derive greater value from their contracts. By connecting with eSignature and CRM solutions, Ultria CLM seamlessly streamlines the quote to contract conversion process. Its post-signoff contract management capabilities empower the enterprise to extract the maximum value out of contracts, mitigate risks, and ensure regulatory compliance.

Our Products are built around an intuitive user experience, leveraging a comprehensive knowledge base, robust Artificial Intelligence technology, encapsulates industry's best-of-breed processes and methodologies.

Several of Fortune 500 companies have chosen Ultria solutions for the following reasons:
In-depth industry and domain expertise with a robust implementation methodology
Ability to ensure semantic and structural data integrity and quality
End-to-end solution for Data Governance renowned by leading market Analysts
To know more, you can visit our website: www.ultria.com",4.1,"Ultria
4.1",Bengaluru,"Princeton, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Perform data-mining, modeling and hypothesis generation in support of high-level business goals.
Stay current with emerging tools and techniques in machine learning, statistical modeling & analytics.
Strong aptitudes for business, technology, mathematics & statistics.
Need strong oral & written communication skills to present data as a concise story for diverse audiences.
Develop customized algorithms to solve analytical problems with incomplete data sets.

Skills Needed:
R/Python Programming

SQL

Statistical Modeling

Machine Learning Techniques

Knowledge on Software Development is an added advantage",2.2,"BrandIdea Consultancy P Ltd
2.2",Chennai,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist,-1,"Experience
– 2 to 4 Years
Education
– B.Sc / M.Sc (Maths / Statistics) B.Tech /B.E. – Computer Science

Job Description:
2 - 4 years of experience in machine learning and data mining
Excellent understanding of different software such as Perl, Python, Hadoop, Java and R programming
Strong technical background and have excellent problem-solving abilities
Good in at least one programming or scripting language
Understanding of databases and ability to write SQL queries
Excellent oral and written communication skills with business acumen
Should be a self-starter with high initiative and enthusiastic to learn and deliver on latest tools and technologies
Experience worked in big data environment is an added advantage",-1,Sybrant Data,Chennai,-1,-1,-1,-1,-1,-1,-1,-1
Sr Data Scientist,-1,"Responsibilities :

A Sr Data Scientist contributes to Blue Yonder's current and upcoming solution and services offering through the improvement, research, design, and development of innovative algorithms and models based on machine learning, operation research, and other techniques.

Skills Required:
Good understanding of basics of Statistics, Probability, Linear Algebra and Calculus
Should be able to explain all ML/DS projects mentioned in resume
Good in qualitative and result interpretation
Good understanding of business problem
Profound understanding of basic DS and ML skills like outlier handling, data imputation, bias, variance, cross validation etc.
Good understanding of basic ML algorithm, like linear regression, logistic regression, random forest etc.
Take Ownership of on boarding new customers and continuously improve our existing.
Experience in building machine learning models or optimization software to solve business problems.
Ability to communicate results clearly to both colleagues and less technically versed audiences.
Knowledge of multivariate preferably in the Python Data ecosystem.
Good either at Python or R from DS perspective
Understand and uses pandas, numpy, scikit-learn and other scientific libraries
effectively and efficiently.
Understand basic data structure of python, write pythonic code
Good understanding on using packages like data. table, ggplot, dplyr etc.
Good understanding of matrix algebra and memory management.
Supply Chain Nation

Our Values

If you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success – and the success of our customers. Does your heart beat like ours? Find out here: Core Values

Check out Blue Yonder's blog - Supply Chain Nation - the platform for supply chain trends and innovations.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.",4.3,"Blue Yonder
4.3",Bengaluru,"Scottsdale, AZ",5001 to 10000 employees,1985,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 billion (INR),"SAP, Oracle, Manhattan Associates"
DATA SCIENTIST,-1,"Data Scientist
About Happiest Minds
Technologies

Happiest
Minds, the Mindful IT Company, applies agile methodologies to
enable digital transformation for
enterprises and technology providers by delivering seamless customer
experience, business efficiency and actionable insights. We leverage a
spectrum of disruptive technologies such as: Big Data Analytics, AI & Cognitive Computing, Internet of Things,
Cloud, Security, SDN-NFV, RPA, Blockchain, etc.
Positioned as Born Digital . Born Agile, our capabilities spans across
product engineering, digital business solutions, infrastructure management
and security services. We deliver these services across industry sectors such
as retail, consumer packaged goods, edutech, e-commerce, banking, insurance,
hi-tech, engineering R&D, manufacturing, automotive and
travel/transportation/hospitality.

Headquartered in Bangalore, India; Happiest Minds has
operations in USA, UK, The Netherlands, Australia and Middle East.

Skills

Required Skills: Data
Science, Machine Learning, Deep Learning, Python

Desired Skills:

Roles and responsibilities

·
Experience
in Data Modelling, R, Python, SQL, Data Science, Machine Learning, Deep
Learning, Statistics

·
Have
ability to solve Business problems using Data

·
Should
possess extensive knowledge of and experience in applying data mining and
machine learning techniques on large amount of datasets

·
High level
of proficiency in statistical tools like R, Python

·
Candidate
will be expected to communicate analytical results in a way that is
meaningful for business stakeholders and provides actionable insights.

·
Have the
ability to discover new opportunities where advanced analytical techniques
can be leveraged for solving business problems

Good to Have

·
Expertise
in programming languages like Java/C/C++/Python

·
Experience
with relational databases and SQL is good to have

·
Relevant
experience in Big Data platforms like Hadoop eco-system

·
Come up
with innovative algorithms and solutions

Staffing Type: Permanent",4.1,"Happiest Minds Technologies
4.1",Bengaluru,"Bengaluru, India",1001 to 5000 employees,2011,Company - Public,IT Services,Information Technology,₹5 to ₹10 billion (INR),-1
Data Scientist,-1,"3- 6 Years – Hyderabad, Gurgaon
Job Description

Big Data Eco System like Hadoop and Spark and Scala ML

Machine learning models. Predictive Analytics .

Exp Range: 3 Years to 6 Years

Salary: Open

Industry: IT-Software / Software Services

Functional Area: Analytics & Business Intelligence

Role Category: Analytics & BI

Role: Data Analyst

Keyskills:
Hadoop, Spark, SCALA, BigData, Machine Learning, Predictive Analytics.",-1,AGUILASS,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
GIS Developers- Machine learning (Data Scientist),-1,"B.SC/M.SC/M.Tech computer Science or IT or similar degree
The candidate should be responsible for satellite image processing using deep learning/machine learning algorithm and computer vision

Feature extraction

Development of customized algorithm for image processing and process automation

Development of web based algorithm for image processing

B.SC/M.SC/M.Tech computer Science or IT or similar degree

Working experience with python and associated libraries in Deep Learning/ Machine Learning Framework. The candidate should have experience in image processing and large volume data handling

Algorithm Development, Image Processing, API, web development, data analytics

Tensorflow, Keras, Pytorch, AutoEncoder, GDAL. Applied Mathematics, Advance Statistics",3.4,"Infinium Solutionz
3.4",Ahmedabad,"Ahmedabad, India",201 to 500 employees,2008,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),-1
Senior Data Scientist,-1,"As a Data Scientist at Noodle.ai, you will collaborate with our Enterprise Services team,Software Engineers, Designers, and industry-specific experts from our customers. You willvbuild a deep understanding of the business problems our customers are tackling and then develop, test, and deploy advanced machine learning algorithms. As we grow, you will also develop reusable IP to help us move faster, dive deeper, and work more efficiently by generalizing the algorithms, methodologies, and supporting infrastructure that you build. As one of the early hires to join the Noodle.ai team, you will have a significant impact on the future of Enterprise Artificial Intelligence.

Job responsibilities:
Implement a breadth of different modeling approaches/ techniques in machine learning
Manipulate and prepare large, heterogeneous data sets to support advanced analytics
Iteratively conceptualize, design and build data-driven analytical models
Develop processes and tools to monitor and analyze model performance and data accuracy
Translate deep mathematical concepts and practices into language that non-experts can understand and build upon. And conversely, translate business needs and user needs into language and concepts that other data scientists can understand and work with.
Productionalizing machine learning code and interfacing with industry standardmsoftware systems
Understand and manipulate unstructured data from different platforms.
Demonstrate proficiency at real-world modeling problems/DS problems - getting to a result that demonstrably generate business value

Qualifications:Required:
Graduate degree in a relevant field (Computer Science, Operations Research, Statistics, Applied Math...) or Bachelors degree and 2-4 years applying advanced AI techniques to real-world problems

Good to have:
4+years of experience applying advanced AI techniques to real-world problems
Experience tackling data science problems characterized as high-dimension, low sample size (i.e., lots of potentially predictive features and highly diverse but low quality or highly sparse data.)
Knowledge & understanding of a functional area of focus (i.e. Experience applying advanced analytics to supply chain optimization, demand forecasting, and/or revenue management)
Knowledge & understanding of an industry area of focus (i.e. retail, manufacturing,CPG, etc...)

Skills and Competencies:
Experience with common analysis tools (SQL, R, and Python).
Demonstrable familiarity with code and programming concepts.
Knowledge of Spark and/or Hadoop
Knowledge of machine learning areas and techniques - Supervised machine learning,Unsupervised machine learning, Time series, Natural language processing, Outlier detection, Computer vision, Recommendation engines, Survival analysis,
Reinforcement learning, and Adversarial learning
Knowledge of data visualization tools - ggplot, d3.js and Matplottlib, and Tableau
Strong problem solving skills with an emphasis on product development
Focus on delivering value and building lasting relationships through collaboration in an open and respectful working style
Passion for learning and a desire to grow",4.5,"Noodle.ai
4.5",Bengaluru,"San Francisco, CA",201 to 500 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1
Data Scientist,-1,"Data Scientist

31st January 2020

By Nalini Hire

In

/

vPhrase Analytics Solutions Pvt. Ltd.

Published

15th July 2020

Location

Pune, India

Category

Engineering

Job Type

Full-time

Description

Role Overview

As a data scientist at vPhrase you would be responsible for developing, testing and maintaining our NLG engine as well as the analytical engine of our product Phrazor. These models would power analytical and decision modules of our product’s AI engine. The candidate is also expected to lead our independent applied research team.

Requirements
Masters/Bachelors in Statistics, Computer Science, Economics or a related field with at least 5 years of experience.
Proficiency making ML models work at scale in production environments. With comfort working with tools to manage large datasets.
Deep understanding of machine learning models, data analytics tools and deep learning frameworks.
Background in Natural Language Processing (NLP) and text analytics is preferred.
Ability to handle large and complex structured as-well-as unstructured datasets.
Ability to perform independent research across various domains of analytics.
Proficiency working with scripting languages like Python/R and Query languages SQL.
Experience working with B2B SaaS products in preferred.
Key Responsibility
Improving analytical engine, our domain agnostic decision models as well mining algorithms.
Working closely with our product teams to power intelligence in our product.
Designing own experiments and developing new methodologies for analysis as per business goals.
Comfortable with finding possible problems, exploring different approaches and arriving at solutions that enhance our analytical modules.
Building data models and maintaining them in testing as well as production environments.
Impact

We are transforming the way people interpret data with our proprietary AI powered NLG(Natural Language Technology) engine that analyses, reasons and writes like a human being. We have filed several patents in this field and are leaders across the globe with only NLG product company in India.

Major BFSI, Health, Media organisations across the globe use our product Phrazor everyday to churn out millions of AI powered stories in real-time.

Benefits

Being part of a startup that’s turning out to be a game-changer, you will be blessed with:
A young and energetic workplace where new ideas are always welcome. The crazier, the better.
Freedom to try new things; failure is not censured.
Casual dress code
5 day work week. Yes, Sat-Sun off
No over-time, proper work-life balance
Take-it-when-you-need-it vacation
Above all, we as a team devote one day every month to volunteer for social causes close to our hearts.

Apply

Apply

Your name *

Your e-mail address *

Your phone number *

Total Work Experience *

Current CTC *
(In Rs.)

Expected CTC *
(In Rs.)

Notice Period *
(In months)

Linkedin Profile Link *

Relocation *
Confirm that you are willing to relocate to the job location

Covering Letter *

Your CV *
Drop files here

browse files ...

Captcha

Captcha *


Related

Customer Success Executive

Content Writer",4.2,"vPhrase
4.2",Pune,"Mumbai, India",1 to 50 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"Senior Data Scientist
If you are visionary and a statistical mastermind and are keen to make a difference in a unique way, then we are looking for you….

We are looking for highly passionate and enthusiastic players for solving problems in medical data analysis using a combination of image processing, machine learning, and deep learning.

As a Senior Computer Scientist at SigTuple you will have the onus of creating and leveraging the state-of-the-art algorithms in machine learning, image processing and AI which will impact billions of people across the world by creating healthcare solutions that are accurate and affordable. You will collaborate with our current team of super awesome geeks in cracking super complex problems in a simple way by creating experiments, algorithms and prototypes that not only yield high-accuracy but are also designed and engineered to scale. We believe in innovation – needless to say that you will be part of creating intellectual properties like patents and contributing to the research communities by publishing papers – it is something that we value the most.

What we are looking for:
Hands on experience along with a strong understanding of foundational algorithms in either machine learning, computer vision or deep learning. Prior experience of applying these techniques on images and videos would be good-to-have.
Hands on experience in building and implementing advanced statistical analysis and machine learning and data mining algorithms.
Programming experience in C, C++, Python
What should you have:
3 – 5 years of relevant experience in solving problems using machine learning or computer vision
Bachelor degree or Master degree or PhD in computer science or related fields.
Be an innovative and creative thinker, somebody who is not afraid to try something new and inspire others to do so.
Thrive in a fast-paced and fun environment.
Work with a bunch of data scientist geeks and disruptors striving for a big cause.",2.6,"SigTuple
2.6",Bengaluru,"Bengaluru, India",51 to 200 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"We are looking for an expert in machine learning to help us extract value from our data. You will lead all the processes from data collection, cleaning, and preprocessing, to training models and deploying them to production. The ideal candidate will be passionate about artificial intelligence and stay up-to-date with the latest developments in the field, and know how to program in C++ (we rarely use Python).

Requirements
B.Tech./ B.E / MCA degree in Computer Science, Engineering or a related stream.
3+ years of machine learning experience.
Proficiency with a deep learning framework such as TensorFlow or TensorRT.
Expertise in visualizing and manipulating big datasets.
Proficiency with Linux, C++, OpenCL, OpenMP and OpenCV (we have no use of Python in deployments).
Ability to determine hardware requirements to run an ML model with the required latency.
Extremely good understanding of embeddings, and how to play with them.
Extremely good understanding of CNN, LSTM, GANs, Attention Models, Advanced Loss Functions, Hyper-convergence and batch processing.
What we Expect from you?
Analyzing the ML algorithms that could be used to solve a given problem and ranking them by their success probability.
Exploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world.
Verifying data quality, and/or ensuring it via data cleaning.
Supervising the data acquisition process if more data is needed.
Defining validation strategies.
Defining the preprocessing or feature engineering to be done on a given dataset.
Defining data augmentation pipelines.
Training models with hyper-convergence strategies and tuning their hyperparameters.
Analyzing the errors of the model and designing strategies to overcome them.
Deploying models to production in C++.
Understanding business objectives and developing models that help to achieve them, along with metrics to track their progress.",4.1,"Inkers
4.1",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Artificial Intelligence / Machine Learning Engineer,-1,"Hewlett Packard Enterprise is an industry leading Technology Company that enables customers to go further, faster. With the industrys most comprehensive portfolio, spanning the cloud to the data center to workplace applications, our technology and services help customers around the world make IT more efficient, more productive and more secure.

Learning does not only happen through training. Relationships are among the most powerful ways for people to learn and grow, and this is part of our HPE culture. In addition to working alongside talented colleagues, you will have many opportunities to learn through coaching and stretch assignment opportunities. Youll be guided by feedback and support to accelerate your learning and maximize your knowledge. We also have a reverse mentoring program which allows us to share our knowledge and strengths across our multi-generation workforce.

HPE Pointnext is the innovative IT services organizationpart of Hewlett Packard Enterprisebuilt to make Hybrid IT simple and power the Intelligent Edge. As an agile technology partner, we help our customers modernize their legacy infrastructure with the flexibility of the cloud, and maximize the value of their connected devices. We make their mission our mission: To drive rapid transformation across an enterprise on a customers terms.

Description:
Has business experience and customer - facing skills that enables them to drive an engagement and interact at the CxO / VP level, as well as a technical background that enables them to easily interact with IT professionals, software developers and architects
Adept at thinking strategically and analytically about business, product, and technical challenges, with the ability to build and convey compelling value propositions, and work across multiple functional teams to build consensus
A keen sense of ownership, drive, and scrappiness is a must
You must enjoy communicating with customers of all shapes and s. You will have a passion for helping customers, from hot start - ups to established enterprises in India
A broad and strong leader part builder, part operator and part general manager who can prioritize well, communicate clearly and compellingly and who understands how to drive a high level of focus.
Responsibilities
Define and target market segments in India, identify key entities within those segments, and identify key industry partners including ISVs and system integrators
Set a strategic business development plans for the AI business and for target markets in India. Execute the strategic business development plans while working closely with internal stakeholders including account, marketing, & partner teams, solution architects, professional services and support teams, legal and contract teams, and the service teams.
Thought leadership develop compelling audience - specific messages and tools (product videos, customer success stories, demos, whitepapers, presentations, how to guides etc.) and evangelize cloud services and technologies through forums, whitepapers, reference architectures and public speaking events such as Cloud Summit and User - Group events.
Education and Experience Required:
Typically 4 - 8 years of experience.
Bachelor's or Master's degree in Computer Science, Information Systems, or equivalent.
Knowledge of the AI & ML technology
Landscape with an ability to understand and articulate the business and technical frameworks, architectures and solutions
Identify specific prospects/partners to approach while communicating the specific value proposition for their business and use case
Some relevant technical knowledge is helpful in areas such as: database systems, core distributed computing concepts, fundamentals of cloud computing and virtualization, storage systems, etc.
Strong understanding and experience in the field of AI and related technologies
Strong analytical skills, and demonstrated ability to turn detailed data analysis into useful strategic insight in order to drive customer adoption and make appropriate recommendations to the business
Strong experience using cloud computing and related emerging technology
Hewlett Packard Enterprise Values:

Partner. Innovate. Act.

We live by three core values that drive our business.

Simplified, we are good partners, great innovators and we make things happen.

Extensive social benefits, flexible working hours, a competitive salary and shared values, make Hewlett Packard Enterprise one of the world´s most attractive employers. At HPE our goal is to provide equal opportunities, work-life balance, and constantly evolving career opportunities.

If you are looking for challenges in a pleasant and international work environment, then we definitely want to hear from you. Apply now below, or directly via our Careers Portal at www.hpe.com/careers
You can also find us on:
https://www.facebook.com/HPECareers
https://twitter.com/HPE_Careers

1063801",4.1,"Hewlett Packard Enterprise
4.1",Bengaluru,"Palo Alto, CA",10000+ employees,2015,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Oracle, Accenture"
Senior Data Scientist,-1,"Site Name: India - Karnataka - Bangalore
Posted Date: Jun 11 2020

GSK is one of the worlds foremost pharmaceutical and healthcare companies and we are proud to be leading a healthcare revolution.

By disrupting our approaches to R&D and commercial business processes, D&A is allowing us to integrate, simplify and unlock all our data to drive innovation, decision making and enable our transformation in servicing our patients, healthcare professionals and consumers.

YOU would be responsible for the following:

As a GSK Global Commercial Data Scientist, you will lead and collaborate with others in GSK in discovery, development, scaling code based statically modeling, machine learning or artificial intelligence capabilities to be leveraged by global business units and local markets. The primary focus of your efforts will be on streamline strategic decision information, uncover new opportunities and automate the commercial execution ensure last mile value.

This role will provide YOU the opportunity to lead key activities to progress YOUR career, these responsibilities include some of the following
Partner with leaders from across the business to translate the company's business objectives, market opportunities & portfolio of offerings into a formal, cohesive global commercial strategy
Apply a broad array of analytics skills including machine learning, statistics, text-mining/NLP, and modeling to extract insights from structured and unstructured data sources and complementary real-world & digital information streams to business challenges
Developing and evolving core commercial models used across all analytics packages. Examples of the models will be: Multi-Channel Analytics, Patient Pathways, Omni-Channel Segmentation, Territory Design, Customer Targeting, Attribution Modeling, & Predictive Commercial Mix
Design data test and learn experiments to drive personalized solutions across the customer journeys addressing key customer needs as well as enabling personalized experiences across each touch points through connective analytics
Collaborate across business to prototype, launch and Iterate analytics capabilities that quickly scale globally
Lead the development and implementation measurement planning aligning to strategy
Lead the collaborate with local and global teams to ensure data driven decisions are embedded into business process.
Automate analytics models and simplify information management
Consult with markets, regions, and leadership on defining the business questions to apply to be answered with analytic and then pulled through for measured value.
We are looking for professionals with these skills to achieve our goals. If YOU have these skills, we would like to speak to you.
Bachelors degree
Hands on experience using Apache Spark, Python, R, SQL and Data Visualization tools
Experience or understanding of end to end software tool/solution development and life cycle management
If you have the following characteristics, it would be a plus:
Masters degree
Ability to simplify the complex with a product development mindset
Formalizing problems
Story telling
Intellectual Curiosity
Applied digital marketing, sales, or customer analytics
Knowledge of the data landscape in healthcare (EHR, claims data, real world data, HEOR data)
Experience in healthcare, pharmaceutical, or consulting
Self-starter who is comfortable working independently and focused on delivering value quickly
Why GSK?


Our values and expectations are at the heart of everything we do and form an important part of our culture. These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance and trust, the successful candidate will demonstrate the following capabilities.

GSKIndia_DA

*LI-GSK

Our goal is to be one of the worlds most innovative, best performing and trusted healthcare companies. We believe that we all bring something unique to GSK and when we combine our knowledge, experiences and styles together, the impact is incredible. Come join our adventure at GSK where you will be inspired to do your best work for our patients and consumers. A place where you can be you, feel good and keep growing.

Important notice to Employment businesses/ Agencies

GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.

It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.

GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKilne (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.

If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in gsk.com, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine.",3.9,"GSK
3.9",Bengaluru,"Brentford, United Kingdom",10000+ employees,1830,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Pfizer, AstraZeneca, Merck"
Senior Data Scientist / Algorithms Specialist,-1,"Job Description:
Should possess strong design and architecture skills.
Deliver solutions for Fortune 100 customers using an Agile Development model
Understanding and working to come up with solutions to problems, design and architect, Building and collaborating with business and technical teams to deliver software.
Positions : 10

Skillset:
At least 4+ years of solid experience in the software industry
Experience working in / Understanding of Big data a technologies – worked in Hadoop, MapR and Map/Reduce, Pig, Hive
Played pivotal roles as an engineer and architect across domains
Understanding of Big data a technologies – Hadoop, MapR and Map/Reduce, Pig, Hive
NoSQL solutions like Hbase, Cassandra, MongoDB, CouchDB, and be comfortable with commercial solutions too
Expertise in SQL databases (e.g. MySQL or Oracle), Analytics platforms (e.g. Pentaho, BO or similar) and OLAP technologies
Solid technology stack in J2EE and .Net (desirable but not essential)
Be very comfortable with Agile methodologies in order to be able to arrive at difficult engineering decisions quickly.
Good to have experience with MPP databases like Netezza, ETL tools like Informatica, and BI tools like SAS etc.
Good to have knowledge of web Analytics and exposure working with data sources clickstream data etc.
Proven ability to lead a team of engineers

Other Skillset:
Passion for technology and willingness to learn is required
Have ability to work in a fast paced and dynamic work environment and be able to produce efficient and robust solution
High energy, confidence, and agility to drive a team.
A creative thinker who can bring in new ideas and innovations to the company.
Job Type: Full-time

Required experience:
Hadoop, MapR : 2 years

Required education:
Bachelor’s",4.3,"AmyLogic
4.3",Bengaluru,"Jaipur, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"Graduate in the analytical fields with strong academic credentials
Excellent written and verbal communication skills
Should have worked on excel and advance excel, MS Office
Please send your CV to:careers@q-dat.com",5.0,"Q-Dat IT Solutions
5.0",Bengaluru,"RajajiNagar, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist / Data Analyst,-1,"This position will be responsible for Finance Analytics product offerings thereby generate Business Performance Improvement opportunities for the Stake Holders. Our Client is looking for an experienced Senior Data Scientist to join our talented engineering team. As our data guru, you’ll be responsible for analyzing the large data set and making recommendations that will impact major business decisions. They are looking for a proven technical leader that can excel in a fun, fast-moving startup environment and help them elevate their customer experience.

Job Responsibilities

Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of sales projections, processes, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modelling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Develop algorithms and predictive models, create prototype systems and visualizations
Implement and keep models in optimal production state
Strong data & visual presentation skills and ability to explain insights using tools like tableau, D3 charts or other tools.
Experience working with big data tools such as MapReduce, Pig, Spark and NoSQL data will be an add-on
Must have end-end hands-on experience in delivering & implementing data analytics models in production. Must have skills, such as Synthesizing data, defining the problem, feature engineering, building the model, deploying the same in production.
Ability to work closely with others to execute projects rapidly in a multi-disciplinary environment
Demonstrated data science experience in the Sales & Marketing domain with at least 3 to 4 projects delivered end-to-end, Ability to collaborate business and data science.
Strong project management skills, a passion to drive task based processes to successful completion – organized, strong communicator, high-energy and takes initiative
Consultative and collaboration skills; able to influence complex stakeholder communities
Education : Bachelor’s degree in computer science, statistics, engineering and relevant fields,

Experience : with 6+ years of hands-on experience in the following:

Statistical analysis tools such as R, Python, SAS, etc.
Machine learning techniques for classification, regression, clustering, decision trees, text analytics, deep learning & time-series data etc.
Scripting languages such as Python, Perl, Ruby, etc.

Strong communicator written and oral; able to work effectively with remote, global project teams

What You Need for this Position

You should have knowledge of:
Data Science
Data Analyst
SQL
R
Python
SAS
Python
Perl
Ruby
MapReduce
Pig
Spark and NoSQL
Aditional
No. of Positions
3
Education level
Bachelor’s Degree in Computer Science
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
Data Scientist / Data Analyst,-1,"Amazon's Marketplace Trust team works to ensure that buyers, brands and sellers can trust Amazon while transacting on our marketplace. We are looking for a hands-on, detail oriented and highly motivated data analyst to help create data backed insights.The candidate should be comfortable interfacing with technology systems and be able to analyze data and gather actionable conclusions. Operating in a rapidly changing environment will require the candidate to be adept at dealing with ambiguous, new and challenging situations.
Role and Responsibilities:
· Enable effective decision making by retrieving and aggregating data from multiple sources and compiling it into a digestible and actionable format Put on your business thinking cap to drive insights and action we can take to improve the business
· Measure the metrics of our business and propose/implement projects to improve these metrics.
· Ensure KPIs are published and reviewed on a daily, weekly, monthly basis and perform analysis on any behaviours / processes that could impact on data integrity.








Basic Qualifications



· Bachelor's degree in Computer Science, Engineering, Operations Research, Math, or related discipline.
· Strong SQL Knowledge and Hands-on experience.
· Minimum 2+ years of experience as an Analyst role preferred. Highly proficient in Microsoft Office and Windows based applications. Demonstrated Analytical ability, results-oriented environment with external customer interaction.
· Excellent written and verbal communication and presentation skills and the ability to express thoughts logically and succinctly.
· Entrepreneurial drive and demonstrated ability to achieve stretch goals in an innovative and fast-paced environment.



Preferred Qualifications


· Experience with E-Commerce, Retail and Business Analytics would be an advantage.
· Proficiency with visualisation tools like Tableau
· Understanding of data warehousing, data modeling concept and building new DW tables
· Advanced SQL skills, fluent in R and/or Python, advanced Microsoft Office skills, particularly Excel and analytical platforms",4.3,"Bloom Consulting Services
4.8",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Sceintists,-1,"One of the reasons for ABB’s success is our rigorous and forward-thinking Finance function. With more than 3,600 people in over 100 countries, the integrated Finance organization delivers the insights we need to make successful, long-term business decisions. You as Data Scientist will be part of global advanced analytics team and will be responsible for providing data insights and analytics to the business.
This role is based in Bangalore and reporting into Delivery Manager - Analytics. Your responsibilitiesYour backgroundMore about usBring your very own sense of pride and purpose as you help us drive forward the Fourth Industrial Revolution – creating a sustainable future for our planet, and your career. Join ABB and harness the power of our diverse global network, as you collaborate with and learn from our world-class teams. Above all, challenge yourself every day. Let’s write the future, together.
Important, please include in your CV the following passage:
“I hereby agree for my personal data, included in my job application, to be processed in line with the needs of recruitment,
in accordance with the Law on Personal Data Protection of 29th August 1997 (Law Gazette from 2002, No.101, heading
926, as amended).”",3.9,"ABB
3.9",Bengaluru,"Zurich, Switzerland",10000+ employees,1891,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),"GE, Siemens, Schneider Electric"
Data Analyst,-1,"Unacademy is India’s largest, online learning platform. It allows educators to create courses on various subjects. Our vision is to get the best minds of the country to share knowledge in an easily comprehensible form. You can find out more about our journey in this YourStory article.

Headquartered in Bengaluru, the platform brings expert educators together with millions of students in need of quality education. With a growing network of 10,000 registered educators and 3 million learners, Unacademy is changing the way India learns. The company has raised Series D funding from prominent investors such as Sequoia India, SAIF Partners, Nexus Venture Partners and Blume Ventures.

Roles and Responsibilities:
●Interpret data, analyze results using statistical techniques and provide ongoing reports

●Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.

●Acquire data from primary or secondary data sources and maintain databases/data systems.

●Identify, analyze, and interpret trends or patterns in complex data sets.

●Filter and “clean” data.

●Work with management to prioritize business and information needs.

●Locate and define new process improvement opportunities.


Eligibility:
Any Graduate / Post Graduate with 1 to 5 years of relevant experience.
Preferrably worked in Data reporting, Data Insights, Data Analysis role for minimum of 1 year.",4.2,"ABB
3.9",Bengaluru,"Bengaluru, India",51 to 200 employees,2015,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Lead Data Scientist,-1,"Experience Required: 8+ year experience in Software development, having BE/BTech degree.
Deep understanding of statistics and ML algorithms work internally with proficiency in at least 2 supervised and unsupervised algorithms in each bucket.
Supervised algorithms : Regression [linear/polynomial], Decision Tree, Random Forest or classification [Logistic Regression, Naïve Bayes, SVM etc]
- Model design and implementation : Experience in deriving feature sets, model training and testing

- Preferred tools and programming languages: TensorFlow/Keras, Python

- Exposure to Deep Learning and NLP is an added advantage.",3.7,"PayPal
3.7",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
"Data Engineer, Enterprise Data",-1,"Position Overview

The Data Engineer is an emerging role in Ralph Lauren’s Analytics team, and will play a pivotal role in operationalizing the most critical data and analytics initiatives for Ralph Lauren’s digital business initiatives.

Purpose & Scope

Based in Bengaluru, India this Data Engineer will work with the Global Analytics team to build, maintain, and optimize data pipelines for key data and analytics consumers including business and data analysts and data scientists covering our digital and physical channels and value chain. Data engineers also need to guarantee compliance with data governance and data security requirements while creating, improving and operationalizing these integrated and reusable data pipelines. This would enable faster data access, integrated data reuse and vastly improved time-to-solution for Ralph Lauren’s data and analytics initiatives. The data engineer will be measured on their ability to integrate analytics and (or) data science results with Ralph Lauren’s business processes.

This role will require both creative and collaborative working with IT and the wider business. It will involve evangelizing effective data management practices and promoting better understanding of data and analytics. The data engineer will also be tasked with working with key business stakeholders, IT experts and subject-matter experts to plan and deliver optimal enterprise data assets.

Essential Duties & Responsibilities

Build data pipelines: The primary responsibility of data engineers is to architect, build, and maintain data pipelines that will provision high quality data ready for analysis. This includes ingestion, exploration, modeling, and curation of high value data.

Drive Automation through effective metadata management: The data engineer will be responsible for using innovative and modern tools, techniques and architectures to partially or completely automate the most-common, repeatable and tedious data preparation and integration tasks in order to minimize manual and error-prone processes and improve productivity.

Learning and using modern data preparation, integration and AI-enabled metadata management tools and techniques.
Tracking data consumption patterns.
Performing intelligent sampling and caching.
Monitoring schema changes.
Recommending — or sometimes even automating — existing and future integration flows.

Educate and train: The data engineer should be curious and knowledgeable about new data initiatives and how to address them. This includes applying their data and/or domain understanding in addressing new data requirements. They will also be responsible for proposing appropriate (and innovative) data ingestion, preparation, integration and operationalization techniques in optimally addressing these data requirements. The data engineer will be required to train counterparts such as data scientists, data analysts, LOB users or any data consumers in these data pipelining and preparation techniques, which make it easier for them to integrate and consume the data they need for their own use cases.

Participate in ensuring compliance and governance during data use: It will be the responsibility of the data engineer to ensure that the data users and consumers use the data provisioned to them responsibly through data governance and compliance initiatives. Data engineers should work with data governance teams (and information stewards within these teams) and participate in vetting and promoting content created in the business and by data scientists to the curated data catalog for governed reuse.

Become a data and analytics evangelist: The data engineer will be considered a blend of data and analytics “evangelist,” “data guru” and “fixer.” This role will promote the available data and analytics capabilities and expertise to business unit leaders and educate them in leveraging these capabilities in achieving their business goals.

Experience, Skills & Knowledge

Education and Experience

A bachelor's or master's degree in computer science, statistics, applied mathematics, data management, information systems, information science or a related quantitative field is required.
The ideal candidate will have a combination of IT skills, data governance skills, analytics skills and Retail industry knowledge with a technical or computer science degree.
At least 4 years or more of work experience in data management disciplines including data integration, modeling, optimization and data quality, and/or other areas directly relevant to data engineering responsibilities and tasks.
At least 2 years of experience working in cross-functional teams and collaborating with business stakeholders in Retail in support of a departmental and/or multi-departmental data management and analytics initiative.
Deep Retail Industry knowledge or previous experience working in the business would be a plus.

Technical Knowledge/Skills

Strong experience with advanced analytics tools for Object-oriented/object function scripting using languages such as R, Python, Scala, or similar.
Strong ability to design, build and manage data pipelines in PySpark and related technologies for data structures encompassing data transformation, data models, schemas, metadata and workload management. The ability to work with both IT and business in integrating analytics and data science output into business processes and workflows.
Strong experience with popular database programming in relational and nonrelational environments including on AWS Redshift, AWS Aurora, SQL Server and similar platforms.
Experience in working with large, heterogeneous datasets in building and optimizing data pipelines, pipeline architectures and integrated datasets using traditional data integration technologies. These should include ETL/ELT, data replication/CDC, message-oriented data movement and upcoming data ingestion and integration technologies such as stream data integration and data virtualization.
Strong experience in working with and optimizing existing ETL processes and data integration and data preparation flows and helping to move them in production.
Experience in working with both open-source and commercial message queuing technologies such as Kafka, Amazon Simple queuing Service, stream data integration technologies such as Apache Nifi, Apache Kafka Streams, Amazon Kinesis and stream analytics technologies such as Apache Kafka KSQL.
Basic experience working with popular data discovery, analytics and BI software tools like MicroStrategy, Tableau, Qlik, PowerBI and others for semantic-layer-based data discovery.
Basic understanding of popular open-source and commercial data science platforms such as Python, R, KNIME, Alteryx, others is a strong plus but not required/compulsory.
Basic experience in working with data governance, data quality, and data security teams and specifically and privacy and security officers in moving data pipelines into production with appropriate data quality, governance and security standards and certification.
Demonstrated ability to work across multiple deployment environments including cloud, on-premises and hybrid, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service and others.
Experienced in agile methodologies and capable of applying DevOps and increasingly DataOps principles to data pipelines to improve the communication, integration, reuse and automation of data flows between data managers and consumers across an organization

Interpersonal Skills and Characteristics

Strong experience supporting and working with cross-functional teams in a dynamic business environment.
Required to be highly creative and collaborative. An ideal candidate would be expected to collaborate with both the business and IT teams to define the business problem, refine the requirements, and design and develop data deliverables accordingly. The successful candidate will also be required to have regular discussions with data consumers on optimally refining the data pipelines developed in nonproduction environments and deploying them in production.
Required to have the accessibility and ability to interface with, and gain the respect of, stakeholders at all levels and roles within the company.
Is a confident, energetic self-starter, with strong interpersonal skills.
Has good judgment, a sense of urgency and has demonstrated commitment to high standards of ethics, regulatory compliance, customer service and business integrity.

#LI-AD1

Data Engineer, Enterprise Data",3.6,"Ralph Lauren
3.6",Bengaluru,"New York, NY",10000+ employees,1967,Company - Public,Other Retail Shops,Retail,₹500+ billion (INR),-1
Machine Learning and Data Scientist,-1,"Worked on End to End Data Mining/Machine Learning Project Life Cycle
Experience on statistical / machine learning model development and implementation
Programming efficiency in Python / R.
Participate in data architecture and engineering decision-making to support analyticsUnderstanding machine learning algorithms
Development and implementation of datasets and database with machine learning tools for real time business problems
Understanding big data system architecture elements, tools and frameworks - like Hadoop, HDFS, hive, impala, Hbase, etc

Key Responsibilities:
Guide the client on technology evaluation, design data architectures, application architectures and techniques.
Support in business development activities like opportunity identification, client proposals, identifying new business opportunities, etc.
Assist in response to RFPs, RFIs, scoping, technical architecture, delivery mechanisms, approach notes, etc
Lead team in delivering machine learning solutions to client
Responsible for delivering client engagements and POCs, requirement gathering, solution design and development involving multiple work streams, machine learning solutions.

Exp: 3 to 8 yrs

Location: Bangalore/Mumbai/Hyderabad/Chennai/Pune/NCR",4.1,"Camsdata
4.1",Mumbai,"Bengaluru, India",51 to 200 employees,2017,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),eTeam
Connected Car Data Scientist,-1,"Job Description: Data Scientist

Education & Training

• Bachelor’s degree or Masters in Computer Science/Statistics/Mathematics

Experience
• 7 to 9 years of experience in executing data-driven solutions to increase efficiency, accuracy, and utility of internal data processing.
• Experienced at creating data regression models, using predictive data modeling, and analyzing data mining algorithms to deliver insights and implement action-oriented solutions to complex business problems.
• Proficient knowledge in statistics, mathematics and data analysis
• Excellent understanding of business operations and analytics tools for effective analysis of data
• Experience on optimized data collection procedures and generate reports.
• Experience on building predictive models and machine-learning algorithms.
• Experience in designing complex reports such as Drill-down, Drill-through, Cascading, Matrix, cross tab and Map reports using Power BI or Tableau
• Expertise in data storage structures, data mining, and data cleansing
• Systematic problem-solving approach with strong communication skills and a sense of ownership and drive

Skills
• Primary Skills
• Strong hold of concepts in Statistics
• Strong programming skills in R, Python, Java
• Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark.
• Proficient with NoSQL databases like MongoDB, PostgreSQL and Cassandra running huge volumes of data
• Proficient in with SQl Databases like MSSql, Postgres.
• Have a good exposure to Azure Analytics Products like, Data Factory, HD Insights, Azure Data Lake Storage, Data Bricks.
• Experience on different data visualization tools like PowerBI , Tableau.
• Secondary Skills
• Tools - Qliksense , Tableau
• Kusto Query Language
Job Responsibilities

• Supporting the analytics needs of business by analyzing data from multiple sources
• Identify valuable data sources and automate collection processes
• Undertake preprocessing of structured and unstructured data
• Analyze large amounts of information to discover trends and patterns
• Support in collecting, organizing, and interpreting data along with fellow colleagues.
• Build predictive models and machine-learning algorithms
• Use machine learning tools and statistical techniques to produce solutions to problems
• Combine models through ensemble modeling
• Present information using data visualization techniques
• Propose solutions and strategies to business challenges
• Collaborate with engineering and product development teams

Job Responsibilities
Responsible
for installation, maintenance, and providing support for Application
Performance Monitoring and Instrumentation with the primary focus on
AppDynamics and Azure Monitor.
Help
define and implement best practices for Production Application Management
monitoring
Assist
engineers with production Infrastructure Monitoring
Ability
to develop necessary POCs & POVs in sandbox/testing environment
Ability
to support setup and configuration of the APM tool
Assist
in building an APM Centre of Excellence
Operating
system and server architecture knowledge of UNIX/Windows/virtual systems
Assist
development teams with application and server troubleshooting and
diagnostics
Programming
automation (VBA /VB.Net, JAVA or major scripting languages such as Perl
and Python, Unix/Linux shell scripts)",4.2,"Daimler
4.2",Bengaluru,"Stuttgart, Germany",10000+ employees,1886,Company - Public,Transportation Equipment Manufacturing,Manufacturing,₹500+ billion (INR),"Audi, Porsche, BMW"
Senior Data Scientist,-1,"We are building a world-class language-related product that has the potential to positively transform lives worldwide. We have a passionate team of data scientists, coders, and linguists who have been working on it. We are looking for a Senior Data Scientist who will lead the team from the technology standpoint. You will identify and implement the best data-driven methodologies considering the product requirements and guide the team in delivering meaningful results. As a Senior Data Scientist, you will serve as the technology leader driving the vision of the product.

Work location: Mumbai

If this opportunity sounds exciting, APPLY NOW!!",2.9,"Daimler
4.2",Bengaluru,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Data Scientist / Sr. Data Scientist,-1,"Purpose of the Job

As a Data Scientist you will work in collaboration with our business and engineering people, on creating value from data. Often the work requires solving complex problems by turning vast amounts of data into business insights through advanced analytics, modeling and machine learning. You have a strong foundation in analytics, mathematical modeling, computer science, and math - coupled with a strong business sense. You proactively fetch information from various sources and analyze it for better understanding about how the business performs. Furthermore, you model and build AI tools that automate certain processes within the company. The solutions produced will be implemented to impact business results.

The Data Scientist believes in a non-hierarchical culture of collaboration, transparency, safety, and trust. Working with a focus on value creation, growth and serving customers with full ownership and accountability. Delivering exceptional customer and business results

Responsibilities
Develop an understanding of business obstacles, create solutions based on advanced analytics and draw implications for model development
Combine, explore and draw insights from data. Often large and complex data assets from different parts of the business.
Design and build explorative, predictive- or prescriptive models, utilizing optimization, simulation and machine learning techniques
Prototype and pilot new solutions and be a part of the aim of 'productifying' those valuable solutions that can have impact at a global scale
Guides and coaches other chapter colleagues to help solve data/technical problems at an operational level, and in methodologies to help improve development processes
Identifies and interprets trends and patterns in complex data sets to enable the business to take data-driven decisions
Industry

Any (prefer - Manufacturing, Logistics); willingness to learn manufacturing systems (OT systems and data stores)

Work experience

~2+ years of industry exposure in Data Science and Analytics projects, preferably in Manufacturing / Supply chain management

Skills and competencies required
Extract and present valuable information from data
Understand business requirements and generate insights
Build mathematical models, validate and work with them
Explain complex topics tailored to the audience
Validate and follow up on results
Work with large and complex data sets
Establish priorities with clear goals and responsibilities to achieve a high level of performance.
Work in an agile and iterative manner on solving problems
Evaluate different options proactively and ability to solve problems in an innovative way. Develop new solutions or combine existing methods to create new approaches
Good understanding of Digital & analytics
Strong communication skills, orally and in writing
Education
Bachelors or masters in Computer Science or Engineering / Mechanical Engineering / Chemical Engineering / Process Engineering
Functional knowledge required
Microsoft Azure
Analytics and statistics
Mathematical modeling
Python
Spark
SQL
Machine Learning
Deep learning
Optimization
Notebooks",3.4,"Piramal Enterprises Ltd
3.4",Vadodara,"Mumbai, India",1001 to 5000 employees,-1,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"Bengaluru

Qualification:
Any graduation

Experience:
2 – 4 years

Roles and Responsibilities:
Development of Machine Learning based application modules for integration in our xcPEP platform

Skills required-:
Data Acquisition and Validation
Experience in Text Analytics, developing different Statistical Machine Learning, Data mining solutions to various business problems and generating data visualizations using Python.
Experience in image processing and Optical Character Recognition
Working knowledge of PostgreSQL and mySQL
Linear Regression, Logistic Regression, Decision Trees, Random Forest, K-Means Clustering
Please write to us at careers@advancedstructures.in with (Machine Learning Engineer) in the subject line. Advanced Structures India Private Limited is an Equal Opportunity Employer",3.6,"Advanced Structures India Pvt Ltd
3.6",Bengaluru,"Bengaluru, India",51 to 200 employees,2014,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Data Scientist/Data Analyst,-1,"JOB SUMMARY:
TRIARQ Health is a Physician Practice Services company that partners with doctors to run modern patient-centered practices so they can be rewarded for delivering high-value care.

TRIARQ’s Physician-led partnerships simplify practices’ transition to value-based care by combining our proprietary, cloud-based practice, care management platform and patient engagement services to help doctors focus on better outcomes.

LOCATIONS:
India: TRIARQ Health 5th floor, Rushiraj Tower, Jehan Circle, Gangapur Road Nashik -422013
US: TRIARQ Health, 1050 Wilshire Drive, Suite 300, Troy, Michigan 48084

REQUIREMENT:

We are looking for Data Scientist/Data Analyst that will help us to discover the Insights in vast amounts of data and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, performing statistical analysis, and building high quality prediction systems integrated with our products.

Experience: 1+ year

RESPONSIBILITIES:
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Enhancing data collection procedures to include information that is relevant for building analytics systems
Processing, cleansing, data wrangling and verifying the integrity of data used for analysis
Build a robust Data Platform Understanding the various Data sources
SKILLS AND QUALIFICATIONS:
Basic understanding of machine learning techniques and algorithms, such as Linear Regression, Classification, SVM, Decision Forests, etc.
Experience with common data science toolkits like NumPy, Pandas, Sklearn, Matplotlib,Seaborn
Google Cloud Platform knowledge is added advantage
Write a Python program to maintain the raw file archival in the GCS bucket.
Creating the API s to connect Source Applications with GCP.
End to End Integration Data ingestion into Google Cloud Platform. Experience with data visualization tools, such as D3.js, GGplot, Plotly etc.
Proficiency in Database such as BigQuery,SQL, Postgres
Good in applied statistics skills, such as distributions, statistical testing, regression, classification etc.
Good scripting and programming skills Python, Angular JS, HTML
Data-oriented personality
Data science certification should add an advantage
BENEFITS:

TRIARQ Health is the people’s first company work within a great company culture.
Individuals can develop from technical to communication to leadership. Proactively build your career - with help from your manager, set the path you would like to take - and then do it!

Gain incredible experience working with numerous technologies.

Interested candidates can call at Mob Number: 9420869028.

Website: www.TRIARQhealth.com

Job Types: Full-time, Contract

Experience:
total work: 1 year (Required)
Education:
Bachelor's (Required)
Work Remotely:
Temporarily due to COVID-19",4.6,"TRIARQ Health
4.6",Nashik,"Troy, MI",51 to 200 employees,2005,Company - Private,Healthcare Services & Hospitals,Healthcare,₹500 million to ₹1 billion (INR),-1
"Data Scientist, NLP",-1,"About Fractal :

Fractal is one of the most prominent players in the Artificial Intelligence space. Fractal's mission is to power every human decision in the enterprise and uses the power of AI to help the world's most admired Fortune 500 companies. Fractal's products include Qure.ai to assist radiologists make better diagnostic decisions, Cuddle.ai to assists CEOs and senior executives make better tactical and strategic decisions, Theremin.ai to improve investment decisions and Eugenie.ai to find anomalies in high velocity data. Fractal has consistently been rated as India's best companies to work for, by The Great Place to Work® Institute. Fractal has been featured as a leader in the Customer Analytics Service Providers Wave 2019 by Forrester Research, and recognized as an ""Honorable Vendor"" in 2019 magic quadrant for data & analytics by Gartner

Role Brief:

As a NLP Data Scientist in the Consumer analytics team, you will be building solutions that require analyzing and transforming natural language data into useful features using NLP techniques. To succeed in this role, you should possess outstanding skills in statistical analysis, machine learning methods and text representation techniques.

Responsibilities:
Build Solutions that identify intent and other features from user comments, chat transcript and other unstructured text data.
Design NLP applications
Identify appropriate annotated datasets for Supervised Learning methods
Use effective text representations to transform natural language into useful features
Find and implement the right algorithms and tools for NLP tasks
Train the developed model and run evaluation experiments
Perform statistical analysis of results and refine models
Basic logical pseudo code writing
You will need to have:
Experience of design, building and deployment of ML/NLP Solutions
Proficient in Python
Experience in NLP tools like Gensim, spacy, Stanford NLP
Hands on with Deep learning frameworks like Keras, Pytorch, Tensorflow
Experience automating data within Tableau/Qlik/ggplot/Shiny to tell a story through interactive visualizations",-1,Fractal.ai,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist,-1,"Must be able to handle periods of high stress.
 Strong analytical and problem solving skills.
 Excellent interpersonal and communication skills to effectively handle any business need.
 Knowledgeable in software development processes & lifecycle management.
 Demonstrated experience in effectively presenting technical information to non-technical audience
 5-10 years of experience in applying concepts in Data Science, Machine Learning, Algorithm development, Advanced Computing or Statistical Modeling to solve real-world problems

Work on complex, cross-functional analytical and research-oriented projects using advanced computational, machine learning and deep learning algorithms
 Work on a particular Data set or a Problem Statement
 Use relevant knowledge of machine learning and statistics to help build scalable Machine learning models and Processing Pipelines.
 Practical experience in at least one of the following programming languages: R or Python. Strong modelling skills and ability to build practical models using advanced algorithms such as Random Forests, SVM, Neural Networks. Familiarity with algorithms in recommendation systems, chatbots or structuring NLP centric processing pipeline as well as Computer Vison. Knowledge of big data frame-works such as Hadoop/Spark is a bonus. Familiar with implementing organizational processes using tools like Asana/Git/Docs/Slack/etc.

Job Types: Full-time, Volunteer

Experience:
total work: 7 years (Preferred)
Education:
Bachelor's (Preferred)",-1,Boston Ivy Healthcare Solutions Pvt Ltd (Medikabazaar),Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Lead Data Scientist,-1,"We are looking for a Lead Data Scientist who will support our product teams with insights gained from analyzing company data. The ideal candidate has background in a quantitative or technical field, is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of a product.

Responsibilities:
Designing and deploying deep learning algorithms and predictive models
Develop custom data models and algorithms to apply to data sets
Assess the effectiveness and accuracy of new data sources and data gathering techniques
Develop processes and tools to monitor and analyze model performance and data accuracy
Collaborate with data and subject matter experts throughout the organization to identify opportunities for leveraging data to drive business solutions
Qualifications:
7+ year of experience with BS or MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Specialization in machine learning preferred
Experience of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Experience of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Applied experience with Deep Learning algorithms such as Convolutional Neural Networks, Recurrent Neural Networks and LSTM etc.
Familiarity with Deep Learning frameworks such as TensorFlow and PyTorch, and strong experience in at least one of those
Experience with data cleansing, data quality assessment, and using analytics for data assessment
Excellent programming skills in languages such as Python and R. Experience with Java and Scala is a plus.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Flink, Spark, Cassandra, etc.
Experience visualizing/presenting data for stakeholders using: Periscope, D3, ggplot, etc.
Ability to drive a project and work both independently and in a team",2.9,"Qualys
2.9",Pune,"Foster City, CA",501 to 1000 employees,1999,Company - Public,Computer Hardware & Software,Information Technology,₹10 to ₹50 billion (INR),"NortonLifeLock, McAfee, Verisign"
Data Analyst,-1,"Punchh creates the consistent, modern experiences consumers expect by bringing the power of identity resolution into physical retail. Punchh is the leader in delivering one-to-one customer engagement and loyalty beyond mobile devices for a consistent brand experience through every channel. The Punchh Loyalty and Engagement Platform, powered through artificial intelligence, guides consumers through their lifecycle from first-time customer to superfan, building meaningful relationships and dramatically increasing lifetime customer value. Nearly 200 global enterprise brands rely on Punchh to grow revenue by building customer relationships. The company is based in Silicon Valley, California with a second US office in Austin, TX and global offices across Canada, India, the United Kingdom, and Singapore.

Punchh, Jaipur is looking out for a Data Analyst, who will take ownership of data analytics activities and work closely with end users (both internal and external clients) to translate requirements into data-driven applications and data visualization solutions (e.g. reporting and dashboards)

Total and Relevant Experience Required: 2+ years

Job Location: Jaipur

Key Responsibilities:
Participate in client calls with senior executives who are based in different geography and hence different time zone to understand business needs and define reporting solutions
Work with the CS managers to develop an insightful analytics report for our clients. Make actionable business recommendations. Define performance measurement / KPI / recurring reports.
Be One of the key owners of the quarterly business review process that highlight the relevant business opportunities.
Be a key liaison between the data and CS teams to:
Address and resolve data requests.
Ensure high quality of our data warehouse.
Represent the company's expertise in advanced analytics in a variety of media outlets such as client interactions, conferences, blogs, and interviews.
Skillset Required
Relevant experience in analytics
Advanced degree in Data technology, business, economics, statistics or other related fields, with a strong interest in marketing technology.
Expertise in creating analytics dashboards using such as Tableau (preferably), Power BI, etc from various data sources.
Strong knowledge of and experience with databases (SQL, Redshift, Snowflake, etc.)
Self-starter, with a keen interest in technology and highly motivated towards success
Must be proactive and be prepared to address meeting in different time zones.
Good to have skillset: R, Python, Tableau Server, Big Data Tools like Databricks, Spark",4.2,"Punchh
4.2",Jaipur,"San Mateo, CA",201 to 500 employees,2010,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹5 to ₹10 billion (INR),-1
Data Analyst,-1,"The healthcare landscape is rapidly changing, and we are looking for a person that wants to help lead that change. We are looking for a person that wants to work in a fast-paced environment where the collective team emphasis is to generate market driven solutions that work. The Data Analyst II position helps provide detail analytics for specific ASG healthcare solutions. You will be working with Medicare, Medicaid, and Commercial data as well as a variety of other reference data sources. This position requires that you are a data guru– you will have an uncanny ability to tie disparate data sources together. Because of the tightness of our team, you will be a subject matter expert on our data, processes, and business methodologies. You will be responsible for data acquisition, critical analytics, project design and analysis, code development and testing of ad hoc or standard reports to support effective and rapid decision making. You will also ensure that consistent documentation is developed and actively maintained throughout all phases of work.
Principal Responsibilities and Essential Duties:
· Assist with the development and deployment of predictive and/or machine learning modeling processes

· Design innovative analytic methods that improve the accuracy or efficiency of our analytic and reporting processes

· Identify opportunities in the development of new capabilities that increase the value added to our clients

· Meet with users to gather requirements for project definition. Analyze existing procedures to identify system/process changes needed to meet such requirements

· Assist in testing of deliverables to ensure that requirements are accurately met

· Be responsible for the design, analysis, development and testing of ad hoc or standard analytics/reports to support effective and rapid decision making

· Assist in determining and monitoring of quality measures for reporting and analytics processes

· Ensure that consistent documentation is developed and actively maintained throughout all phases of work including but not limited to: Process overviews, Reporting Inventory, Business Requirements, Technical Requirements, Report Workbooks, and Release Checklists.

· Completes all responsibilities as outlined on annual Performance Plan.
Completes all special projects and other duties as assigned.
Must be able to perform duties with or without reasonable accommodation.

Requirements:
· Minimum of 5-8 years of experience analyzing and manipulating Healthcare data, including general knowledge of medical procedures, health conditions and provider practices

· Experience with open source analytic software a significant plus

· Ability to work in a SAS, SQL, R or other understood analytic environment

· Experience with data mining tools

· Thorough knowledge of Medicare Risk Model and CMS guidelines

· Data manipulation skills using database and spreadsheet applications

· Working knowledge of database applications, including extraction and querying skills. Proficient using SQL to extract data, SAS experience, a plus

· Experience analyzing raw data, with ability to think logically and process sequentially with a high level of detailed accuracy

· Problem solver, resourceful, quick learner

· Strong written and verbal communication skills and discipline to multitask and prioritize projects to meet scheduled deadlines

· Professionally interact with a diverse group of stakeholders including executives, managers, clients and subject matter experts

· Master’s degree in an Allied Health, Analytics/Informatics, Computer Science, Programming or equivalent work experience",3.7,"Cotiviti
3.7",Hyderabad,"Atlanta, GA",1001 to 5000 employees,1979,Company - Private,IT Services,Information Technology,₹50 to ₹100 billion (INR),-1
Data Sciences Intern V,-1,"Description:

Presenting a program that provides women candidates, who've taken a career break, an opportunity to gain relevant work experience while being part of collaborative teams - BounceBack. Are you an analytics oriented woman professional on a career break and looking for an opportunity to re-tool your skill-set in the Data Analytics Space? This 36-week comprehensive and application-intensive Internship program is specially designed for you. At the Data Analytics India team in Target Corp., were solving cutting-edge problems in Retail using a combination of statistical analysis, optimization and behavioural economics. A few problems were trying to solve today are:

How do I predict a noisy outcome like customer buying behavior (or sales)?

What operational signals tell me if a customer is going to churn in 6 months to a year?

What is the financial value of making a customer happy? What exact initiative made a customer happy and by how much?

What will happen to my sales if I reduce the queues in my store by 2 people?

How much additional backroom space do I need, and in which stores, to maintain in-stocks during peak sales season?

How can I improve workload forecast for stores to optimize payroll?

What factors drive unavailability of products in Stores?

Come, join a dynamic, high-performing & Inclusive team that advices business on making critical decisions with the use of Advanced Analytics and Data Science.

You will have:
3 years of relevant work experience (in Consulting/Analytics domain in the past)
2 +years of ongoing break from work
Very strong Math skills and Quantitative Ability
Prior experience working in algorithms and programming (Primary Skillset - SQL, R/SAS/Python)
Excellent interpersonal skills
Ability to work with large-datasets to glean meaningful insights
Keen to develop business acumen
You will get
A medium that facilitates transition back in to professional career, and relevant work experience
Opportunity to strengthen technical skills, ramp up on newer tools and technology
Gain confidence and ramp up on latest technologies
Get mentorship from Target India leaders
A well-designed exposure to business problems and hands-on experience of problem-solving on those for 36 weeks
Opportunity to witness the 2nd largest Big Box retailer in the US in operations
A high pedigree peer and mentor network to collaborate from top Undergrad and Post Grad colleges in India and US
Steep learning curve and access to Industry-leading learning material
An Industry par monthly Stipend with food & day care re-imbursement along with subsidized transport.
Opportunity to convert internship to a full-time role to reignite your career with one of the leading analytics teams industry-wide
Qualifications:",4.1,"Target
4.1",Bengaluru,"Minneapolis, MN",10000+ employees,1962,Company - Public,General Merchandise & Superstores,Retail,₹500+ billion (INR),-1
Sales and Marketing Analytics- Data Scientist,-1,"Job Description

We are looking for professionals with good logical and analytical skills.

As a Data scientist, you must have ability to translate business problem to a statistical problem and statistical solution to business solutions.

What we are looking for:

Must have:

• Min 8 years of hands-on experience in building predictive and optimization models within analytics area.

• Experience on analytical business consulting and Business development skills

• experience in solving business problems by choosing right set of statistical methods and steps to be followed and able to explain to client with convincing answers

• Knowledge of various machine learning techniques

• the ability to provide consultancy beyond what the ask is

• the ability to create visually appealing Presentations that convey solution in an effective manner

• Ability to handle clients while working on projects

• Strong Statistics,Mathematics and Quantitative skills.

• BFSI experience will be a definite plus.

• Broad Knoweldge on Hadoop implementation

• Architecture view for building cloud compatible solutions and with familiarity with AWS,Azure and GCP platforms.

Good to Have:

Responsibilties:

1. Ability to independently work with client

2. Work on offering components and present solution to multiple stakeholders.

3. Supporting New Offering development and related research activities

4. Help in creating internal assessts for company

5. Willing to travel based on requirement of location of the project

6. Support solutions to be provided for RFP and RFI

Minimum Qualification:

1. 15 years of minimum education;

2. Minimum percentile of 50% in 10th, 12th, UG & PG (if applicable)

Job Function

TECHNOLOGY

Role

Database Administrator

Job Id

159208

Desired Skills

AWS | Business Analysis | Machine Learning | Data architect

Desired Candidate Profile

Qualifications :
BACHELOR OF TECHNOLOGY",3.8,"Tata Consultancy Services
3.8",Mumbai,"Mumbai, India",10000+ employees,1968,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Accenture, IBM, Infosys"
Principal Data Scientist,-1,"We're looking for a
Principal Data Scientist ( Bangalore, India)
Be a senior member of the Big-Data Machine-Learning Data Science team, and contribute to the R&D. The work centers around machine learning algorithms and data analysis techniques -- especially natural language processing and deep learning.

In this role you will...
Working very closely and collaboratively with team-members in the big-data Machine-Learning Platform team.
Work on NLP through deep learning techniques towards building next-gen products on employee workforce predictive insights.
Perform preliminary data analysis to discover hidden correlations and come up with prototype models.
Work with the team for the development of at-scale efficient machine-learning-models to be able to handle large volumes of data that will be integrated with the MLP.
Active participation in the technical discussions.
You’ve got what it takes if you have...
We are looking for a candidate with a strong background in Natural Language Processing techniques and Deep-Learning using PyTorch. In particular, the candidate should have work experience with:

PyTorch and its ecosystem of libraries.
Word and document embeddings.
Transformers and Attention.
RNN, LSTM.
A background in BERT and its variants.
transfer-learning practices.
·nltk.
genism
Besides this, the candidate must possess a mature understanding of, and hands-on experience in, the broad field of machine-learning and statistical methods. Must be conversant with:
scikit-learn
pandas
·numpy
plotting using matplotlib, seaborn, etc.
Experience with any of the following is considered a plus:

-Tensorflow
-Big-data and PySpark
-Beautiful Soup or Scrapy
-NetworkX
-R libraries
-Test-driven development
-Data-pipelines
-Taking models to production
-Java programming
-GCP
Our Culture:
Our mission is to empower people, businesses and communities. A culture created less by what we do and more by who we are. When people are asked to describe the team, the answer is always the same: smart, cool, dependable, and visionary. We are not a typical tech company (paid sabbaticals, generous stock units, education reimbursement, and 100% paid employee health coverage), because, well, our employees aren't your typical techies... We're always on the lookout for new, curious and capable people who can help us achieve our goal. So if you want to work for a friendly, global and innovative company, we'd love to meet you!
What We Do:
Cornerstone OnDemand (NASDAQ: CSOD) was founded with a passion for empowering people through learning and a conviction that people should be your organization’s greatest competitive advantage. Cornerstone is a global human capital management (HCM) leader with a core belief that companies thrive when they help their employees to realize their potential. Putting this belief into practice, Cornerstone offers solutions to help companies strategically manage and continuously develop their talent throughout the entire employee lifecycle.
Cornerstone’s HCM platform is successfully used by more than 75 million people in 180+ countries and in 40+ languages.
Check us out on Linkedin, The Muse, Glassdoor, and Facebook!
Cornerstone takes special care to ensure the security and privacy of the data of its users.",3.9,"Cornerstone OnDemand
3.9",Bengaluru,"Santa Monica, CA",1001 to 5000 employees,1999,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹50 to ₹100 billion (INR),"SAP, Oracle, Workday"
Data Analyst,-1,"Hewlett Packard Enterprise is an industry leading Technology Company that enables customers to go further, faster. With the industrys most comprehensive portfolio, spanning the cloud to the data center to workplace applications, our technology and services help customers around the world make IT more efficient, more productive and more secure.

Customer Solution Centers are made up of teams that provide remote (offsite) service; customer access, pre-sales, post-sales, and service delivery. Technical teams focus is to solve various business systems and applications problems for customers, onsite engineering personnel and Authorized Service Providers on standard, specialized or complex systems.

Job brief

We are looking for a passionate certified Data Analyst. The successful candidate will turn data into information, information into insight and insight into business decisions.

Data Analyst Job Duties

Data analyst responsibilities include conducting full lifecycle analysis to include requirements, activities and design. Data analysts will develop analysis and reporting capabilities. They will also monitor performance and quality control plans to identify improvements.

Responsibilities
Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and clean data by reviewing computer reports, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities
Requirements
Proven working experience as a Data Analyst or Business Data Analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (PostgreSQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS, Kibana etc)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
Minimum Education : B.Tech./ BE in Computer Science, Information Management, MCA

Minimum Year of Experience as Data Analyst : 5 Yrs.

Hewlett Packard Enterprise Values:

Partner. Innovate. Act.

We live by three core values that drive our business.

Simplified, we are good partners, great innovators and we make things happen.

Extensive social benefits, flexible working hours, a competitive salary and shared values, make Hewlett Packard Enterprise one of the world´s most attractive employers. At HPE our goal is to provide equal opportunities, work-life balance, and constantly evolving career opportunities.

If you are looking for challenges in a pleasant and international work environment, then we definitely want to hear from you. Apply now below, or directly via our Careers Portal at www.hpe.com/careers

You can also find us on:
https://www.facebook.com/HPECareers
https://twitter.com/HPE_Careers

1065301",4.1,"Hewlett Packard Enterprise
4.1",Gurgaon,"Palo Alto, CA",10000+ employees,2015,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Oracle, Accenture"
Machine Learning Engineer,-1,"Job Locations :
Bangalore, Kochi

Must have

3 - 10 years’ experience developing software for Computer Vision, Machine/Deep learning
Hands on with C, C++, Python, Linux, C#
Hands on with OpenCV, TensorFlow, Caffe, CUDA, OpenCL, OpenGL
Hands-on experience with internals of networks (CNN, RNN, LSTM, SSD etc). Customization of NN and improving performance
Experience with GPU/DSP/ISP/SoC architecture and system software.
Hands-on experience with one or more leading embedded SoC platforms (Nvidia, Qualcomm, NXP, Movidius, etc.)
Good analytical and problem-solving skills
Knowledge of computer architecture
Can build prototypes leading to production worthy solutions
Contribution in research communities, publishing papers or participation in Github projects related to machine learning would be a distinct advantage.

Education

Electronics/Electrical/Computer Science Graduate/Post Graduate/PhD",4.2,"Ignitarium Technology Solutions
4.2",Bengaluru,"Bengaluru, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Science Engineer,-1,"Roles and Responsibilities:
Extracting and transforming data from systems like Hadoop and SQL, using tools such as Pig, Scalding, Hive, Presto
Exploring and visualizing data to drive insights
Applying machine learning techniques for a variety of modeling and relevance problems involving users, their relationships, their Tweets and their interests.
Designing and implementing metrics that help teams focus on what to optimize for
Transforming complicated problems into simpler, tractable ones
Requirements:
Experience with one or more object oriented languages like Scala, Java
Experience with scripting languages like Python or Ruby etc.
Experience with statistical programming environments like R or Matlab
Experience with algorithms like pattern matching (fuzzy matching algorithm), pattern generation, distance matching algorithms
Experience with large datasets and Map Reduce architectures like Hadoop and open source data mining and machine learning projects
What You Need for this Position

You should have knowledge of:
Hadoop
SQL
Pig
Scalding
Hive
Presto
Python
Ruby
Scala
Java
Aditional
No. of Positions
Education level
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
Data Science,-1,"Selecting features, building and optimizing classifiers using machine learning techniques.
Data mining using state-of-the-art methods.
Extending company's data with third party sources of information when needed.
Enhancing data collection procedures to include information that is relevant for building analytic systems.
Processing, cleansing, and verifying the integrity of data used for analysis.
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Creating Heat Maps, should be able to develop custom codes over Google Maps API
Deduce a unique and more efficient TRP (Television Rating Point) system and similar rating system for other advertising
mediums like Radio and Print

Location: India (Bengaluru)",3.6,"ADmyBRAND
3.6",Bengaluru,"Bengaluru, India",1 to 50 employees,2016,Company - Private,Publishing,Media,₹500 million to ₹1 billion (INR),-1
Data Engineer,-1,"Do you love problem solving? Do you enjoy learning new ideas and apply them to problems? Are you looking for real world engineering challenges? Do you dream about elegant high quality solutions?
Want to be a part of an amazing team that delivers first class analytical solutions to our business world-wide?

AWS is seeking a highly motivated and passionate Data Engineer who is responsible for developing, maintaining, and supporting the Data Warehouse / Data Mart environment for AWS Procurement and Supply Chain.

The successful candidate will be passionate about Data Warehousing Architecture, developing reliable, efficient, and maintainable ETL solutions, obsessed with providing our users with robust information solutions, and will possess an excellent understanding of the tools and support needed by the organization in order to develop these solutions productively.

In this job, you will:
· Build and improve Data Warehouse / Data Mart solution by translating business requirements into robust, scalable, and supportable solutions that work well within the overall system architecture.
· Design and Develop Dimensional Data Models to support Data Warehouse Architecture
· Extract and combine data from various heterogeneous data sources; develop new datasets.
· Perform detailed source-system analysis, source-to-target data analysis, and transformation analysis
· Design and build data mappings from multiple source systems to data warehouse, maintaining source data integrity
· Participate in the full development cycle for ETL: design, implementation, validation, documentation, and maintenance
· Validate and test ETL build mappings to meet requirements
· Evolve the Data Warehouse environment within the organization, including better information delivery mechanisms and methodologies
· Work to develop the best technical design and approach for new solution development

Basic Qualifications

· Bachelor or graduate degree in computer science (or related field)
· 7+ years experience in a Data Warehouse environment.
· 5+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets; Expert level skills in Advanced SQL.
· Strong understanding of ETL concepts and experience building them with large-scale, complex datasets.
· Dimensional Modeling experience.
· Experience with scripting for automation.
· Excellent verbal & written communication, and documentation skills.

Preferred Qualifications

· Experience in cluster based or column based databases
· Experience with AWS Redshift
· Experience with AWS Hammerstone",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
"Senior Data Scientist, Machine Learning",-1,"About Fractal

Fractal is one of the most prominent players in the Artificial Intelligence space. Fractal's mission is to power every human decision in the enterprise and uses the power of AI to help the world's most admired Fortune 500 companies. Fractal's products include Qure.ai to assist radiologists make better diagnostic decisions, Cuddle.ai to assists CEOs and senior executives make better tactical and strategic decisions, Theremin.ai to improve investment decisions and Eugenie.ai to find anomalies in high velocity data. Fractal has consistently been rated as India's best companies to work for, by The Great Place to Work® Institute. Fractal has been featured as a leader in the Customer Analytics Service Providers Wave 2019 by Forrester Research, and recognized as an ""Honorable Vendor"" in 2019 magic quadrant for data & analytics by Gartner

Role Brief

As a Senior data scientist you will primarily develop machine learning solutions that will predict a customer's needs/intentions in real-time at the moment of interaction, in batch prior to the event, or in batch after the event for analytical labeling/categorization. The outputs of these models will then be used to determine the optimal engagement and experience to provide to the customer.

You will partner with functional and channel stakeholders, work with domain experts, design and execute experiments on the data to achieve predefined outcomes.

In addition to model development, you may, independently or within a team, need to build solutions to support the overall project, including label generation, data schemas, ad hoc analytics, output structure/packaging, or end-to-end prototype demos. You will be responsible for presenting your own work to team members, peers, and leadership, and will build any visualizations or presentations necessary for those communications.

The Person : Qualification & Experience
Knowledge of predictive/prescriptive analytics including Machine Learning algorithms (Supervised and Unsupervised) and deep learning algorithms, Artificial Neural Networks (CUDA, Keras, Tensorflow) or Combinatorics (Mixed Integer Programming).
Experience leading the end-to-end design, development, and deployment of predictive modeling solutions.
Advanced SQL skills with Teradata, SQL Server, Hive and Spark experience.
Experience with Natural Language Processing (NLTK) and text analytics for information extraction, parsing and topic modeling.
Six or more years of relevant work experience
Ability to plan work and meet deadlines
Experience with using big data to develop models.
Experience with Spark.
Experience presenting to and influencing functional leaders and stakeholders.
Deep expertise in applying machine learning to solve a class of AI problems such as NLU/NLP, Reinforcement Learning, Voice Biometrics, Text Mining, and Intelligent Process Automation.",-1,Fractal.ai,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
"Senior Data Scientist, Machine Learning",-1,"About Fractal

Fractal is one of the most prominent players in the Artificial Intelligence space. Fractal's mission is to power every human decision in the enterprise and uses the power of AI to help the world's most admired Fortune 500 companies. Fractal's products include Qure.ai to assist radiologists make better diagnostic decisions, Cuddle.ai to assists CEOs and senior executives make better tactical and strategic decisions, Theremin.ai to improve investment decisions and Eugenie.ai to find anomalies in high velocity data. Fractal has consistently been rated as India's best companies to work for, by The Great Place to Work® Institute. Fractal has been featured as a leader in the Customer Analytics Service Providers Wave 2019 by Forrester Research, and recognized as an ""Honorable Vendor"" in 2019 magic quadrant for data & analytics by Gartner

Role Brief

As a Senior data scientist you will primarily develop machine learning solutions that will predict a customer's needs/intentions in real-time at the moment of interaction, in batch prior to the event, or in batch after the event for analytical labeling/categorization. The outputs of these models will then be used to determine the optimal engagement and experience to provide to the customer.

You will partner with functional and channel stakeholders, work with domain experts, design and execute experiments on the data to achieve predefined outcomes.

In addition to model development, you may, independently or within a team, need to build solutions to support the overall project, including label generation, data schemas, ad hoc analytics, output structure/packaging, or end-to-end prototype demos. You will be responsible for presenting your own work to team members, peers, and leadership, and will build any visualizations or presentations necessary for those communications.

The Person : Qualification & Experience
Knowledge of predictive/prescriptive analytics including Machine Learning algorithms (Supervised and Unsupervised) and deep learning algorithms, Artificial Neural Networks (CUDA, Keras, Tensorflow) or Combinatorics (Mixed Integer Programming).
Experience leading the end-to-end design, development, and deployment of predictive modeling solutions.
Advanced SQL skills with Teradata, SQL Server, Hive and Spark experience.
Experience with Natural Language Processing (NLTK) and text analytics for information extraction, parsing and topic modeling.
Six or more years of relevant work experience
Ability to plan work and meet deadlines
Experience with using big data to develop models.
Experience with Spark.
Experience presenting to and influencing functional leaders and stakeholders.
Deep expertise in applying machine learning to solve a class of AI problems such as NLU/NLP, Reinforcement Learning, Voice Biometrics, Text Mining, and Intelligent Process Automation.",-1,Fractal.ai,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Science,-1,"Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com

Role :Digital Data Engineering Practitioner
Role Description :Develop analytics based solutions that produce quantitative and qualitative business insights. Work with partners as necessary to integrate systems and data quickly and effectively, regardless of technical challenges or business environments.
Must Have Skills :Data Science
Good To Have Skills :Python Scripting,R Programming,Spark Programming
Job Requirements : Role: Data Scientist
Must Have:
1 Exp in Data science frameworks Jupyter notebook, AWS Sagemaker etc
2 Exp querying databases and using statistical computer languages: R, Python, SLQ, etc
3 Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis,
4 Exp with distributed data/computing tools: Map/Reduce, Flume, Drill, Hadoop, Hive, Spark, Gurobi, MySQL

Good to Have:
1 Coding knowledge and experience with several languages: C, C, Java, JavaScript, NodeJS
2 Experience using cloud services: RDS, Athena, Redshift, Kinesis, S3, AWS glue
3 Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks
4 Exp in visualizing/presenting data for stakeholders using: AWS Quicksight, Tableau, Periscope, Business Objects, D3, ggplot",3.9,"Accenture
3.9",Hyderabad,"Dublin, Ireland",10000+ employees,1989,Company - Public,Consulting,Business Services,₹500+ billion (INR),"Cognizant Technology Solutions, EY, McKinsey & Company"
Lead Software Engineer - Data Scientist,-1,"About Freshworks:-

Freshworks provides innovative customer engagement software for businesses of all sizes, making it easy for teams to acquire, close, and keep their customers for life. Freshworks Software-as-a-Service (SaaS) products provide a 360-degree view of the customer, are ready to go, easy to use, and offer a quick return on investment. Headquartered in San Mateo, USA, Freshworks 2,000+ team members work in offices throughout the world. Freshworks has global offices in India, Singapore, Australia, UK, Netherlands, France, and Germany. The company counts over 220,000 businesses in its customer-for-life community around the world including Honda, Bridgestone, Hugo Boss, University of Pennsylvania, Toshiba, Sling TV, and Cisco.

Freshworks’ suite of products that transform the way world-class organizations collaborate with customers and co-workers include Freshdesk (Omni-channel customer support), Freshservice (IT Service Desk), Freshsales (Intuitive fully-integrated CRM), Freshmarketer (Marketing Automation Suite), Freshteam (HR Management System for growing teams), Freshchat (Modern messaging software) and Freshcaller (Cloud PBX system).

Freshworks has received numerous accolades from analysts and media including making it to Forbes’ Cloud 100 list, Economic Times Startup of the Year, 2019 LinkedIn Top 25 Companies to work for in India and a listing on the Magic Quadrant for CRM Customer Engagement & IT Service Management. While Freshworks has had incredible organic growth over the last few years, the company also has made targeted acquisitions that add critical capabilities to the portfolio including Natural Language Processing, Chatbots, Machine Learning, Social and Messaging Transformation. Freshworks has raised over $250 million in the capital and is funded by Accel, CapitalG, Sequoia Capital and Tiger Global Management. More information is available at www.Freshworks.com.

Overview:

As a Lead Data Scientist at Freshworks, you will help identify the right business problems that will be more effectively solved with Machine Learning techniques. Then you will apply your algorithmic and statistical skills, knowledge of ML techniques, grasp of fundamental math, and familiarity with big data to solve the problem in the simplest possible way. You will also lead and mentor junior Data Scientists and engineers in ML projects.

Responsibilities:
Collaborate with product and business teams to understand all aspects of the problem
Define the right target metrics that best represent the end-user value
Apply knowledge of ML, statistics, and advanced mathematics to conceptualize, experiment and design an intelligent system
Work with engineers to build the system end-to-end including Big Data pipelines and ensure the serving system is scalable and highly performant.
Qualifications:
A Bachelor’s degree or a higher degree in Computer Science, Statistics, Mathematics or a related field.
Strong problem-solving and programming skills with a deep understanding of data structures and algorithms.
Solid understanding of mathematical underpinnings behind Machine Learning algorithms and proficiency in probability, statistics, linear algebra, calculus, and optimization.
Must have 2+ years of experience in ML with a proven record of successful ML projects with strong individual contribution
Experience with NLP, Distributed Systems, large scale computing, Big Data technologies like Hadoop and Spark are plus.
Submit Your Application

You have successfully applied

You have errors in applying

Apply With Resume


First Name


Middle Name

Last Name


Email


Mobile

Phone

Social Network and Web Links

Provide us with links to see some of your work (Git/ Dribble/ Behance/ Pinterest/ Blog/ Medium)

+

Cover Letter

Attach a file",4.4,"Freshworks
4.4",Chennai,"San Mateo, CA",1001 to 5000 employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Salesforce, Zendesk, ServiceNow"
Data Scientist - Machine Learning,-1,"1.

At
least one-year experience in Python

2.

At
least one-year experience in Java

Technical Requirements:

1.

Python
3, Flask, NLTK, OpenCV

2.

AWS
Services such as (Elastic Beanstalk, S3, ec2,

3.

Google
Cloud services as (Google Vision, Firebase)

4.

At
least one-year experience in Java, SQL database (Required)

5.

At
least one-year experience in Python. (Required)

6.

At
least one-year experience in developing backend or microservices. (Required)

7.

Version
Control/Git

8.

Testing/Debugging
(Browser developer tools like inspector and JavaScript console)

9.

Knowledge
of JSON

Roles &
Responsibilities
Perform professional and technical engineering work relative to
microservices related to data extraction from pdf, image processing and
natural language processing in python
Working with other services such as Git, AWS and Google Cloud to
manage and support application infrastructure, development and deployments
Some understanding of basic machine learning algorithms and neural
networks.
Some experience with natural language processing such as named
entity recognition, Part-of-speech tagging, etc.
Some experience using Google Vision API, Auto ML, or similar
services preferred.
Some experience using OpenCV for image processing preferred.
Required understanding of back end/micro services development, json
Able to Monitor, identify production and non-production application
issues and immediately come up with solutions to fix issues.
Responsible for testing software functional, design and quality
requirements for the components, document and Simulate complex customer
issues to find solutions and fixes to issues reported by customer.
Analyze functional requirements and seek clarification for better
understanding the requirement, define timeline estimates based on the
requirements, complexity and in-house capabilities.
Conduct coding as per design; Follow coding standards and best
practices to check code quality; Share developed code supervisor; Rework
on code based on inputs if required.
Conduct feed forward meeting with Manager to seek suggestions to
improve.
Should be an effective communicator, excellent team player, eager
to learn from others and share skills with colleagues.
Should be flexible to learn new programs and script languages.
Should show good levels of enthusiasm and interest in all computer
related things.
Promptly attend scheduled meeting with due deliverables.",-1,Accrualify Inc,Nagpur,"San Mateo, CA",1 to 50 employees,2015,Company - Public,-1,-1,₹50 to ₹100 million (INR),-1
Data Science Engineer - Image Database,-1,"Senior Data Architect

Summary

We are looking for a technical lead who will design, build and maintain the data pipeline for creating training datasets for our AI research engineers. Additionally he or she will be responsible for automating the large dataset creation process. The ideal candidate should have 6-10 years of industrial experience in related field as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence/Data/DW Engineer, Data Scientist etc.) and 1-2 years of experience in leading a team.


Responsibilities
Lead the data pipeline setup, operation and maintenance.
Assemble large, complex data sets that are analysis/training ready for the machine learning engineers/researchers
Design and build scalable and reliable data pipeline that collects, transforms, loads and curates data from internal systems. Ensure high data quality for pipelines you build and make them auditable. Support design and deployment of distributed data store that will be central source of truth across the group.
Develop, customize, configure automation scripts/tools that help engineers to extract and analyze data from our internal data store. Develop reporting and data visualization solutions, as well as looking to build out a dynamic platform
Evaluate new technologies and build prototypes for continuous improvements in data engineering. Creation of new capabilities and modules in our data pipeline. Develop and maintain expertise in advanced and/or emerging data management and analytical information technologies such as data warehouse, data lake and Big Data
Build data connections to company's internal IT systems
Design, implement and continuously optimize the group’s data strategy. Provide thought leadership and lead efforts to design data integration and implement extract, transform and load (ETL) jobs/processes, detailed data warehouse models and data mappings. Provide consultation on best practices and standard practices to internal team members
Perform performance optimization and tuning on new and/or existing data warehouse implementations.
Requirements
5 years of hands on industry experience with a track record of manipulating, processing, and extracting value from large data sets.
Demonstrated ability in building data pipelines, data modeling, ETL development and familiarity with design principles. Experience building data products incrementally, integrating, and managing data sets from multiple sources. Knowledge of data warehouse technologies and relevant data modeling best practices. Experience with a DW technology (Redshift, SQL Server, etc.) and relevant data modeling. Experience processing large amounts of data, in various formats and processing data in batch mode and streaming mode
Excellent SQL skills. Proficiency in a scripting language (Python, Ruby, Perl etc.) and/or a major programming language (C , Java etc.). Knowledge of R is a plus.
Experience with working in Spark/Hadoop and/or other distributed computing frameworks is required
Experience working in a multi-layered distributed architecture is essential. Experience with scalable service architecture and design
Exposure and knowledge of Data Security and Governance. Awareness of best practices to secure data and processes from unauthorized access.
Knowledge and direct experience using business intelligence reporting tools (Tableau, PowerBI etc.) is a plus.
Understanding of data science, machine learning, and AI is a plus.
Strong analytical and problem solving skills (data analysis and requirement documentation)
Excellent project management skills and ability to prioritize issues
Excellent oral and written communication, organizational and client facing skills.
Academic Qualification Profile:


B.E. / B. Tech in Computer Science

Certification or Masters in Big Data Science",4.2,"Daimler
4.2",Bengaluru,"Stuttgart, Germany",10000+ employees,1886,Company - Public,Transportation Equipment Manufacturing,Manufacturing,₹500+ billion (INR),"Audi, Porsche, BMW"
Research Associate/Research Scientist (Downstream Process),-1,"Position: Research Associate/Research Scientist (Downstream Process)

Location: Bangalore, India

Contact: Please email admin@stringbio.com

No of Openings: 1

The candidate will be responsible for design, planning and execution of downstream processes. The employee will also be involved in compilation and interpretation of data from lab scale experiments. He/she will be responsible for inventory management which includes the amount and efficiency of product generation. He/she will be responsible for coordination of activities related to departmental audits, communicating with vendors for technical queries, preparation of BMR, SOP, technical presentations and data compilation. The candidate is someone who is enthusiastic about taking challenges and has an eagerness to learn new techniques.

POSITION RESPONSIBILITIES

Design, plan, test and improve downstream processing for a particular molecule.
Support and manage operations of separation, chromatography, TFF, filtration and drying systems.
Quantify, monitor and establish the yield and efficiency of unit operations
Optimize the process for specific target metrics
Monitor and support end to end execution at lab and pilot scale
Should be conversant with interpretation of analytical and process data and should be conversant with DSP scale-up principles.
Good communication skills.
Be a conscientious laboratory citizen.
Adhere to EH&S standards, and use knowledge of laboratory procedures to advance projects under shifting priorities and timelines.
The position is full-time.

CANDIDATE PROFILE

EDUCATION AND EXPERIENCE

M.Tech in Bio-Chemistry/Bio-Technology, MS/M.Sc(Science) in Biotechnology

>4 years’ work experience in downstream process

Experience in unit operations like separation, filtration, drying, centrifugation etc.

Proficiency with MS Office suite.

PERSONAL QUALITIES

Driven, dedicated team player with attention for detail

Ability to work independently and deliver on project objectives

Capacity to be proactive and take initiatives

Good organizational skills

Effective interpersonal skills

Strong oral and written communication skills

Creative, out of the box thinker with strong analytical and problem-solving capabilities

Ability to adapt to changing drivers.",4.7,"String Bio
4.7",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"Job Description:
Work with business partners and stake holders to understand the business, formulate the problems, come up with the solutions and communicate them back effectively to non-technical audience
Analyze data to identify trends, perform root cause analysis and test hypotheses
Design A/B testing experiment set ups and measure their performance across product platform & marketing
Work with large volumes of data; extract, manipulate & visualize large datasets using standard tools such as SQL, Python, R & Tableau
Lead complex, multifunctional data science projects
Communicate complex concepts and the results of the models and analyses to technical and non-technical audience
Design, develop and implement real-time, highly automated solutions to solve credit business problems and improve existing monitoring capabilitie
Qualification:
Advance degree (MS or PhD) in science or engineering field with 6+ years of relevant experience
Strong problem-solving and communication skills
Ability to deal with large amount of data and fluency with SQL or SQL-like tools
Proven track record of building and implementing automated advanced analytical solutions
Experience in leading cross-functional, highly complex Data Science projects
Data Mining experience in Python, R.
Familiar with various Machine Learning algorithms and Statistical methods
Have a passion for working on big data and professional experience in data mining, statistical analysis, predictive modeling and data manipulation
Financial services or eCommerce experience a big plus",3.7,"PayPal
3.7",Chennai,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Data Science Intern,-1,"ABOUT SHIPSY


Driven by a team of computer scientists and electrical engineers from IIT Delhi and IIT Madras, Shipsy aims to create platforms for data-driven decision making with the vision of bringing visibility and operational efficiency to the Supply Chain industry.
Most of our paying clients are in the Supply Chain industry and we are enabling new business models, swifter operations using algorithms and machine learning. We are processing ~10 million transactions per month through our system.

ROLE

The Data Science Intern will leverage our wealth of data to work on machine learning and statistics projects that improve care. The Data Science Intern will receive hands-on mentoring in Unix, python, data management, machine learning, and statistical analysis. We are looking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high-quality prediction systems integrated with our products.

RESPONSIBILITIES:

Develop machine learning algorithms.
Perform statistical analyses.
Query data sources.
Clean and format data.
Meet with clinical experts and end users.
Perform other duties as required.
Must read, understand, and adhere to all HCA/HealthONE policies and procedures
Practice and adhere to the Code of Conduct and Mission and Value Statement.
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending the company’s data with third-party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing the ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance.
improve and extend the features used by our existing classifier
build system for automated fraud detection


TEAM


Our current team has 50 people from top institutes across the country like IITs, IIITs, NITs with experience in Big Data, Software Architecture, ML, AI, Robotics, Blockchain. Our founding team has CS/Elec folks from IIT Delhi and IIT Madras.


PERKS


- Free breakfast, dinner, and snacks at the office
- Monthly team outings, e.g., laser tag, paintball, football, trampoline etc.
- Quarterly team parties and annual offsite
- Company sponsored enrollment worth 40K annually to online learning resources like Coursera, edX etc.
- International trip vouchers for top performers
- Company sponsored asset purchase worth 50K
- Games in office - Mini golf, pool, foosball
- Regular tech seminars with pizza and beer",4.2,"Shipsy
4.2",Gurgaon,"Gurgaon, India",51 to 200 employees,2015,Company - Private,Internet,Information Technology,₹100 to ₹500 million (INR),-1
Jr. Data scientist,-1,"<
Junior Data Scientist

About the job :
Responsibilities :
Responsibilities include Identify, develop and implement the appropriate statistical
techniques, algorithms and Deep learning / ML Models to create new, scalable solutions that
address business challenges across industry domains.
Define and develop, maintain and evolve data models, tools and capabilities.
Communicate your findings to the appropriate teams through visualisations.
Collaborate and communicate findings to diverse stakeholders.
Provide solutions but not limited to: Object detection/Image recognition, natural language
processing, Sentiment Analysis, Topic Modeling, Concept Extraction, Recommender
Systems, Text Classification, Clustering , Customer Segmentation & Targeting, Propensity
Modeling, Churn Modeling, Lifetime Value Estimation, Forecasting, Modeling Response to
Incentives, Marketing Mix Optimization, Price Optimization.

Qualifications and Experience :
Bachelors Computer Science, Information Systems, Machine Learning, Statistics,
Econometrics, Applied Mathematics, Operations Research or related technical degree with
ability to break complex business problems.
Minimum of 1 to 3 years of experience in a related position, as a data scientist or business
analyst building predictive analytics solutions for various types of business problems.
Knowledge of statistical techniques, machine learning algorithms and deep learning
frameworks like Tensorflow, Theano, Keras, Pytorch.
Minimum 1 years of Programming background and expertise in building models using at
least one of the following languages: Python, R ,Java, C,C++.

To apply for this job please send your resume to connect@blackstraw.ai

Location :
Blackstraw.ai , Chennai, 4th floor, Tower C, Ratha Tek Meadows Rd, Elcot Sez, Sholinganallur, Chennai, Tamil Nadu 600119, India",4.6,"Blackstraw
4.6",Chennai,"Tampa, FL",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
"Senior Data Scientist [ML Model,azure ML Pipeline,python,r ]",-1,"Job Description
You will be aligned with our AI/ML Data Science vertical and help us apply your expertise in building world class solutions, conquering Real World business problems,addressing technical challenges using AI Platforms and technologies.

Must Have Skills

Experience : 8-12 Years
Experience in Azure: 4+ Years
Experience in Azure ML: 3+ Years
Azure ML, Azure ML Pipeline, Azure ML Workspace
Develop, experiment, train & tune AI/ML Models
Supervised, Unsupervised, Re-enforced
Model Formats - Pickle, PMML, ONN
Language - Python, R, etc
IDE - Jupyter, VS, Pycharm etc
Frameworks - Tensorflow, Pytorch, Keras etc
If you have Delivered, Solutions using AI/ML ,Please book your appointment at 9898791075.

Perks and Benefits

5 Days + Flexishifts + Fringe Benefits

Salary: Not Disclosed by Recruiter

Keyskills
Data ScienceRtensorflowPickleArtificial IntelligencePMMLML ModelsPython
Desired Candidate Profile
Please refer to the Job description above

Education-

UG:B.Tech/B.E. - Computers, BCA - Computers

PG:MCA - Computers, M.Tech - Computers, MS/M.Sc(Science) - Computers

Doctorate:Doctorate Not Required

Company Profile

eInfochips Limited

eInfochips, an Arrow company, is a leading global provider of product engineering and semiconductor design services. With over 500+ products developed and 40M deployments in 140 countries, eInfochips continues to fuel technological innovations in multiple verticals. The company€™s service offerings include digital transformation and connected IoT solutions across various cloud platforms, including AWS and Azure.

Along with Arrow€™s $27B in revenues, 19,000 employees, and 345 locations serving over 80 countries, eInfochips is primed to accelerate connected products innovation for 150,000+ global clients. eInfochips acts as a catalyst to Arrow€™s Sensor-to-Sunset initiative and offers complete edge-to-cloud capabilities for its clients through Arrow Connect.

Founded in 1994, our work culture is built over years of experience in providing innovative solutions to our clients and our indomitable spirit to excel in all aspects of our engagement. We believe that our success lies upon the skills and quality of our people we work with.

Silicon engineering services: ASIC / FPGA Design & Development, Design Verification & Validation, Physical Design & DFT
Embedded systems engineering services: Hardware Design, System Software, System Verification & Validation, Multimedia
Software engineering services: Cloud Enablement, IoT & Mobility, Application Software, QA and Test Automation, BI and Data Visualization
Extended services: New Product Development, Lifecycle Management, Product Sustenance
IPs: DevOps for IoT, IoT Gateway Framework, IoT Device Lifecycle Management, Video Management Software, Reusable Camera Framework, Test Automation Framework
Industry

IT-Software / Software Services

Functional Area

IT Software - Application Programming, Maintenance

Role Category

Programming & Design

Role

Team Lead/Technical Lead

Employment Type

Full Time, Permanent",3.3,"e-Infochips
3.3",Bengaluru,"Ahmadabad, India",1001 to 5000 employees,1994,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Machine Learning Engineer
Job Description
SUMMARYOFROLE:
The IT Digital Supply Chain Data & Analytics team is organized around world-class data, advanced data science and automation to drive business value for the K-C organization. We are a group of curious people and critical thinkers focused on solving the problems of the day and opportunities of the future through applied intelligence and data science. As part of this team, the Machine Learning Engineer is responsible for integrating business, information, and technology architecture to create artificial intelligence and machine learning solutions for supply chain and manufacturing capabilities. This role is viewed as a solution innovator and expert in complex analytical and digital platform environments, encompassing both business process understanding and technical expertise.
Scope/Categories:
Role will report to a Manager in the IT Digital Supply Chain organization. Role will not have any direct reports.
Key Interfaces: Data Scientists, Business Customers, Functional Engineers, Solution Engineers, Enterprise Data Management teams, Analytics Designers, Project Manager.
External Interfaces: Consultants, Vendors, Managed Services Providers (onshore/offshore). Travel may include approximately 15% of work time.
Key Accountabilities:
Drive a rigorous approach leveraging data science including artificial intelligence and machine learning to solve problems in the context of growing Kimberly Clark brands, increasing sales, and enabling operational excellence.
Partner with Data Scientists to design and develop innovative, machine learning solutions for important, highly complex strategic and operating problems. Has strong knowledge in business and technical functions that are touch points within their area of expertise. Provide technical consulting on complex projects.
Collaborate with functional and solution engineers to develop data and model pipelines including understanding lineage and granularity of data required to perform data science and helping prepare, profile, and cleanse data needed for data science.
Assist in embedding machine learning AI outputs into key business applications including analytical and transactional solutions.
Scale up existing data science solutions (deploy to additional regions, apply to additional areas/attributes)
Support the iterative data science implementation cycle by assisting with research, design, experimentation, development, deployment, monitoring, and maintenance as required.
Communicate complex processes to business leaders explain outputs of machine learning in business language
Produce project outcomes and isolate issues with models through continuous improvement
Research and implement best practices to enhance existing machine learning infrastructure. Contribute to new and existing data science architecture patterns.
Analyze large and complex data sets to derive valuable insights
Document solutions in appropriate service management applications and collaborate with Solution Engineers, Enterprise Architecture, and Analytics Designers to make sure that the data science solution fits within enterprise context.
Coordinate engagements with vendors as they relate to evaluation, design and delivery of business capabilities. Contribute to the evaluation and selection of software products.
Acts as a source of direction, training and guidance for other team members. Is knowledgeable in industry best practices in their area of expertise and uses resources outside of K-C to deliver the end-to-end machine learning solutions.
Influences and moves the K-C culture to one that values and uses cross-business and functional data and analytics to power business performance.

Key Qualifications and Experiences:
Bachelor's degree required, Masters degree preferred. Relevant fields include computer science/engineering, statistics, mathematics, artificial intelligence, or operations research.
Three or more years of experience in building and deploying Machine Learning solutions using various supervised/unsupervised ML algorithms such as Linear/Logistic Regression, Support Vector Machines, Neural Networks, Random Forest, etc.
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark, Python, R, Gurobi, MySQL, etc.) Proficiency in SQL and Python is important.
Understanding of data structures, data modeling and software architecture. Experience designing and implementing data science solutions on Azure is helpful.
Familiarity with machine learning frameworks and libraries
Experience in applying machine learning, predictive analytics and classification techniques towards real product and problems
Ability to write robust code in Python or Java or equivalent modern programming language
Experience with data integration methods and tools including ETL and virtualization.
Excellent written and verbal communication skills along with strong desire to work in cross functional teams
Consumer products experience in retail/manufacturing environment is preferred. Basic functional knowledge in key CPG Supply Chain Area capabilities (Planning, Procurement, Manufacturing, Logistics, Safety & Sustainability, Quality, etc.) is a big plus.
Experience collaborating with data scientists, solution architects, and engineers to identify, design, and implement highly complex, end-to-end solutions.
Broad range of business and IT experiences; Has achieved technical and/or business certification(s).
Ability to operate in a digital workplace utilizing modern technologies to connect, collaborate, communicate and cooperate across a global organization and across organizational boundaries.
Ability to work in a virtual team which may work across distance (remote), cultures and time zones, in a matrix with multiple reporting lines, and may extend outside the K-C organization including suppliers, partners and customers.
Ability to communicate strategies and processes around machine learning and data architecture to cross functional groups and senior levels.
Thought leader with strong connection to industry and technology user groups and networks. Keeps abreast of leading trends in digital, cloud, artificial intelligence, machine learning, block chain, virtual reality, augmented reality and combinations of technology that matter in AI & ML.
High level of communication is required. Must be self-motivated, self-disciplined and have strong time management skills. Embraces learning agility to keep abreast of new technologies and strategies.
Possesses strong leadership skills and exhibits creative thinking to be able to design inventive solutions which solve business challenges. Cultivates networking opportunities within the organization.

Kimberly-Clark and its well-known global brands are an indispensable part of life for people in more than 150 countries. Every day, 1.3 billion people - nearly a quarter of the world's population - trust K-C brands and the solutions they provide to enhance their health, hygiene, and well-being. With brands such as Kleenex, Scott, Huggies, Pull-Ups, Kotex, and Depend, Kimberly-Clark holds No.1 or No. 2 share positions in more than 80 countries. With a 135-year history of innovation, we believe in recruiting the best people and putting them in the right jobs so that they can do their best work. If fresh thinking and a passion to win inspire you, come Unleash Your Power at Kimberly-Clark.

Kimberly-Clark is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation, gender identity or any other characteristic protected by law.

The statements above are intended to describe the general nature and level of work performed by employees assigned to this classification. Statements are not intended to be construed as an exhaustive list of all duties, responsibilities and skills required for this position.
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship. This position is subject to drug and alcohol testing, including pre-employment testing.
Global VISA and Relocation Specifications:
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship.
This role is available for local candidates already authorized to work in the roles country only. K-C will not provide relocation support for this role.
Primary Location
IT Centre Bengaluru GDTC
Additional Locations
Worker Type
Employee
Worker Sub-Type
Regular
Time Type
Full time",3.9,"Kimberly-Clark Corporation
3.9",Bengaluru,"Irving, TX",10000+ employees,1872,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),"Procter & Gamble, Georgia-Pacific, Unilever"
Scientific Research Data Scientist R&D,-1,"We are looking for self-motivated scientists & engineers to join a supercharged workplace and build a first-generation analytical product. If you are a geek about anything – algorithms, math, machine learning, data wrangling/visualizing, high performance computing, scientific computing & tools, or anything else you can convince us about – we want to talk to you!

Experience
4 - 7 Years of Experience

Qualification

Bachelors or Masters in CS / Electronics from a premier institute with 4-7 years of industry experience
Solid design, excellent programming and debugging skills on a Unix-based OS (Ubuntu, Fedora, OSX) and fluency with a DVCS like Git.
Programming Languages: Python, C++
Deal-clinchers

Any of these – more the better!
Skilled with python packages: scikit-learn, pandas, numpy and scipy
Understanding of common algorithms and their application in solving real-world problems
Strong mathematical background in linear algebra, optimization and descriptive & inferential statistics
Understanding of machine learning concepts like generalization, regularization, linear models, neural network and expertise with using data to build systems based on machine learning techniques
Responsibilities

Individual technical contributor with self-drive to understand problem statements and make design decisions – ‘own’ what you do, make your calls, and defend them
Build a first generation analytical software product – design, code, test (unit & functional) and maintain the software, while proving that your implementations ‘work’
Implement software engineering processes and discipline for fast and reliable development of high-quality software product – make the software ‘elegant’
Work as a team player in a high performance environment that rewards ownership – make your opinion count within the team and the organization
Write to deepa.m@careerxperts.com to get started!

Job Location
Bengaluru",-1,CareerXperts,Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Science Engineer,-1,"Data Science Engineer

With about 4,500 employees, Siemens Technology and Services Private Limited (STS) combines five units: Corporate Technology India, Functional Shared Services, Corporate Finance, Corporate Finance Audit, and Siemens Management Consulting.

Corporate Technology (CT) in India has over 3,000 professionals working in the area of software Research and Development. CT is a part of Siemens Corporate Technology, which is an innovation partner for the Siemens Divisions and shares a point of view in areas of strategic importance to Siemens, thereby ensuring its technological future.

What you need to make real what matters

Responsible for the development and delivery of parts of a product, in accordance to the customers requirements and organizational quality norms. Activities to be performed include:

• Requirement analysis and design of software solutions based on requirements and architectural /design guidelines.

• Improving user experience, scalability and performance.

• Implementation of features and/or bug-fixing and delivering solutions in accordance with coding guidelines and on-time with high quality.

• Ensuring integration and submission of solution into software configuration management system, within committed delivery timelines.

• Performing regular technical coordination / review with stake holders and ensuring timely reporting and escalations if any.

• Supporting Project Manager for planning, ensuring risk identification and initiating steps towards risk mitigation.

• Identification and implementation of unit and integration tests to ensure solution addresses customer requirements, and quality, security requirements of product are met.

• Good at communicating within the team as well as with all the stake holders

• Strong customer focus and good learner.

• Highly proactive and team player

What do I need to qualify for this job?

• 4-6 years work experience in Software Engineering especially in professional software product development.

• Proven skills in R and Python is a must

• Involved in Probabilistic Data analysis of any domain specific data.

• Strong knowledge in frameworks like shiny, Dplyr, Ggplot2, Esquisse etc.

• Strong knowledge in frameworks like NumPy, SciPy, Pandas etc.

• Expertise in programming and usage of any unit testing framework.

• Expertise in integration testing and continuous integration.

• Knowledge of Software Engineering processes. Experience with Agile/Lean practices is preferred

• Knowledge of design patterns

• Knowledge of source code management tools like git

• Knowledge for JIRA and Confluence will be a plus

Make your mark in our exciting world at Siemens

This role is based in Bangalore. Youll also get to visit other locations in India and beyond, so youll need to go where this journey takes you. In return, youll get the chance to work with teams impacting entire cities, countries and the shape of things to come.

Were Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Organization: ADVANTA

Company: Siemens Technology and Services Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.0,"Siemens
4.0",Bengaluru,"Munich, Germany",10000+ employees,1843,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),"GE, ABB, Philips"
Specialist Data Scientist,-1,"Position: Data Scientist

Location: Pune, India

NICE Actimize is comprised of talented, creative and dedicated individuals with a passion for delivering innovative solutions to the market. At NICE Actimize, we recognize that every employee’s contributions are integral to our company’s growth and success. To find and acquire the best and brightest talent around the globe, we offer a challenging work environment, competitive compensation and benefits, and rewarding career opportunities. Come share, grow and learn with us – you’ll be challenged, you’ll have fun and you’ll be part of a fast growing, highly respected organization.

NICE Actimize is currently seeking an experienced Data Scientist to join our dynamic and growing Fraud & AML Analytics Services team.

Responsibilities
Perform analysis to support the deployment of fraud prevention analytical models
Analyze fraud cases obtained from clients
Research data patterns in order to find patterns predictive of fraud
Improve the quality and actual implementation of computational algorithms and tools
Optimize the detection performance of NICE Actimize Fraud products and improve customers’ experience with our Fraud solutions
Define product requirements for analytics and provide feedback to the product team on ways in which product may be improved
Develop and enhance our solution-specific risk scores
Measure the quality of the analytical performance of Fraud Products
Develop tools to support model tuning, performance tracking and automation
Develop custom detection logic for specific clients
Help maintain and improve model development methodologies/practices.
Experience: 3 to 6 Years

Qualifications:
Advanced degree in a quantitative area (statistics, mathematics, physics, computer science, engineering)
Strong general analytical skills, Experience with statistical model development. Deep and diverse experience with multiple statistical procedures and data mining algorithms.
Strong experience with using SQL and EXCEL.
Strong programming skills in Python and ability to rapidly learn new programming tools.
Exposure to other programming languages: R, SAS, Scala, Java, Python, Matlab, SPSS, VBA, including procedures, macros, and scripting.
Experience of building and deploying classification and regression machine learning models at an enterprise level.
Good oral and written communications skills, and ability to interact with engineers, software developers, project managers, business analysts, product managers and with clients.
Ability to work in multi-disciplinary agile teams.
Strong commitment to quality
Customer facing experience – a plus
Innovative aptitude.
Additional Desired Qualifications:
Experience in development of risk management models, particularly in the fraud, AML, or financial trade compliance areas.
Knowledge of national and international financial systems and data standards.
Experience with Business Intelligence platforms, methodologies (e.g. OLAP), and tools.",4.0,"NICE Actimize
4.0",Pune,"Hoboken, NJ",501 to 1000 employees,1999,Subsidiary or Business Segment,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"SAS, Feedzai"
SENIOR DATA SCIENTIST,-1,"Data Scientist
About Happiest Minds
Technologies

Happiest
Minds, the Mindful IT Company, applies agile methodologies to
enable digital
transformation for enterprises and technology providers by delivering
seamless customer experience, business efficiency and actionable insights. We
leverage a spectrum of disruptive technologies such as: Big
Data Analytics, AI
& Cognitive Computing, Internet
of Things, Cloud, Security, SDN-NFV, RPA, Blockchain, etc.
Positioned as Born Digital . Born Agile, our capabilities spans across
product engineering, digital business solutions, infrastructure management
and security services. We deliver these services across industry sectors such
as retail, consumer packaged goods, edutech, e-commerce, banking, insurance,
hi-tech, engineering R&D, manufacturing, automotive and
travel/transportation/hospitality.

Headquartered in Bangalore, India; Happiest Minds has
operations in USA, UK, The Netherlands, Australia and Middle East.

Skills

Required Skills: Data
Science, Machine Learning, Deep Learning, Python, Computer Vision

Desired Skills:

Roles and responsibilities

·
Experience
in Data Modelling, R, Python, SQL, Data Science, Machine Learning, Deep
Learning, Computer vision, Statistics

·
Have
ability to solve Business problems using Data

·
Should possess extensive knowledge of and
experience in applying data mining and machine learning techniques on large
amount of datasets

·
High level of proficiency in statistical tools like
R, Python

·
Candidate will be expected to communicate
analytical results in a way that is meaningful for business stakeholders and
provides actionable insights.

·
Have the ability
to discover new opportunities where advanced analytical techniques can be
leveraged for solving business problems

Good to Have

·
Expertise
in programming languages like Java/C/C++/Python

·
Experience
with relational databases and SQL is good to have

·
Experience
in audio and video analytics

·
Relevant
experience in Big Data platforms like Hadoop eco-system

·
Come up
with innovative algorithms and solutions

Staffing Type: Permanent",4.1,"Happiest Minds Technologies
4.1",Bengaluru,"Bengaluru, India",1001 to 5000 employees,2011,Company - Public,IT Services,Information Technology,₹5 to ₹10 billion (INR),-1
Data Engineering - Partner,-1,"We, at TheMathCompany, enable data analytics transformations for Fortune 500 organizations across the world. We enable our clients to build core capabilities that set them on a path to achieve analytics self-sufficiency.
Over the last three years, we have been consistently doubling in size year-on-year with 300 (and counting…) Data Scientists & Engineers, Consultants and Visualization experts
TheMathCompany has won multiple awards recognizing us as a global Data and Analytics firm – We ranked #23 in the Deloitte Technology Fast 500™ Asia Pacific 2019 and #2 in Deloitte Technology Fast 50™ India 2019.
35+ Fortune 500 Companies, from almost 10 different industries and countries, trust us to power their analytical transformation.
WHAT’S IN IT FOR YOU:

An exciting opportunity to be a part of the growth journey of one of the fastest growing AI & ML firms – scope for experimentation, the big & small victories, the learnings and everything in between
Our in-house learning and development cell - Co.ach, run by world-class data analytics experts, enables our folks to stay up to date with the latest trends and technologies
At TheMathCompany, we insist on a culture that provides us all with enough flexibility to accommodate our personal lives without compromising on the dream of building a great company
We are changing the way companies go about executing enterprise-wide data engineering and data science initiatives, and we’d love to have you grow with us on this journey


ROLE DESCRIPTION

As a data engineer, you’ll have an opportunity to work on the universe of data and solve some very interesting problems by creating and maintaining scalable data pipelines dealing with petabytes of data. All our projects entail working on cutting edge technologies, petabyte scale data processing systems, data warehouses and data lakes to help manage the ever-growing information needs of our customers.

The responsibilities are detailed as below:
Experience in understanding and translating data, analytic requirements and functional needs into technical requirements while working with global customers
Build and maintain data pipelines to support large scale data management in alignment with data strategy and data processing standards
Experience in Database programming using multiple flavor of SQL
Deploy scalable data pipelines for analytical needs
Experience in Big Data ecosystem - on-prem (Hortonworks/MapR) or Cloud (Dataproc/EMR/HDInsight)
Worked on query languages/tools such as Hadoop, Pig, SQL, Hive, Sqoop and SparkSQL.
Experience in any orchestration tool such as Airflow/Oozie for scheduling pipelines
Exposure to latest cloud ETL tools such as Glue/ADF/Dataflow
Understand and execute IN memory distributed computing frameworks like Spark (and/or DataBricks) and its parameter tuning, writing optimized queries in Spark
Hands-on experience in using Spark Streaming, Kafka and Hbase
Experience in latest cloud ETL tools such as Glue/ADF/Dataflow
Experience in any orchestration tool such as Airflow/Oozie
Experience working in an Agile/Scrum development process
REQUIRED QUALIFICATIONS

We are looking for individuals who are curious, excited about learning, and navigating through the uncertainties and complexities that are associated with growing a company. Some qualifications that we think would help you thrive in this role are:
BE/BS/MTech/MS in computer science or equivalent work experience.
8+ years of experience in building data processing applications using Hadoop, Spark and NoSQL DB and Hadoop streaming
PREFERRED QUALIFICATIONS

Expertise in data structures, distributed computing, manipulating and analyzing complex high-volume data from variety of internal and external sources
Experience in developing ETL designs and data models for structured/ unstructured and streaming data sources
Experience in building large scale data pipelines in batch and real time mode
Experience in data migration to cloud (AWS/GCP/Azure)
Proficient in programming language such as Python/Scala
Good understanding of in relational/dimensional modelling and ETL concepts
Good understanding of data analysis techniques
Solid working knowledge of SQL and scripting
Understanding of any reporting tools such as Tableau, Qlikview or PowerBI",3.6,"TheMathCompany
3.6",Bengaluru,"Bengaluru, India",201 to 500 employees,2016,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Junior Data Scientist,-1,"MS/PhD in computer science, statistics, or operations research or related technical discipline
Knowledge of machine learning, statistics, optimization or related field
Experience with R, Python, Matlab is required
Experience building machine learning application in areas like time series forecasting, classification models
Experience in Microsoft Azure Stack in the Cloud with focus on Data Factory, Data Bricks, BLOBs, Data Lake Storage
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark, Python, R)
Broad range of business and IT experiences; Has achieved technical and/or business certification(s)
Extensive experience collaborating with Enterprise Architects and infrastructure engineers to identify, design.
00-10.00 Years",-1,Flexi Careers India Private Limited,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Analytics Scientist,-1,"Designation: Analytics Scientist
Experience: 1- 3 Years
Location: Bangalore
Commitment: Full-Time
Functional Team: Analytics
Number of opening: 1

Job Description:
Coming up with data driven solutions to control risk and collections
Finding opportunities to acquire more customers by modifying/optimizing existing rules
Doing periodic upgrades of the underwriting strategy based on business requirements
Evaluating 3rd party solutions for predicting/controlling risk of the portfolio
Running periodic controlled tests to optimize underwriting
Monitoring key portfolio metrics and take data driven actions based on the performance
Building models to predict risk and other key metrics
Do You Know? (Technical Skills and Experience)
1 – 2 years of experience in Financial Services/Analytics Industry
Strong Analytical aptitude and logical reasoning ability
Knowledge of analytical tools such as R/Python
Dexterity with SQL/MySQL, MS Excel
Strong presentation and communication skills.
Understanding of the financial services business
Established competency in statistics
Experience in handling complex data sources and working on advanced machine learning techniques

If you’re interested in applying for this position, please mail your resume to Careers@oyefin.com",4.8,"OYE Loans
4.8",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
"Data Scientist, Advanced",-1,"Overview:
Who we are:
Global Supply Chain and Services organization in Zebra is responsible for Managing Supply Chain and Services for all Zebra Hardware. Global Managed Support and Services(GMSS) organization within GSCS is inspiring change through its Services and Solutions. We supervise and lead devices using cloud-based diagnostics, and provide visibility into their operation using groundbreaking technologies. We all proudly live by Zebra values viz – Accountability, Teamwork, Innovation, Agility and Integrity.

Our Data Science team's primary focus is on conceiving and deploying robust data science constructs, algorithms and decision support systems to build tangible impact in driving success factors and wow experience for our customers and end-users.

About you:
As a senior member of the team, you are required to play an integral part in this cross-functional effort and generate valuable impact by using data science on structured, unstructured, diverse “big data” sources of machine and human acquired data to generate meaningful insights, foresights and recommendations/prescriptions.

You will work very closely with engineering, product and services team to ensure that the data science solutions are ingrained into various product and service offerings.

You will be sought for direction, advice and mentorship by experienced and novice Data Scientists alike. Your knowledge and experience, big-picture view, leadership and communication skills would allow you to answer directly to the senior management.

Responsibilities:
You are responsible for

Translating high level business problems of Internal and External Customers operations team into meaningful and tangible Data Science projects to build augmented intelligence systems using ML, AI and IoT capabilities applied on large data and metadata sources.
Actively driving discussions to improve the product by working across multiple teams and chip in for decisions for crafting and improving architecture across applications.
Driving innovation by encouraging open, high energy, collaborative environment; lead participation in innovation summit and expos, recommend relevant training and conference for employees to attend, publish papers and patent disclosures.
Supervising trends and tools (Business Intelligence Tools, Graphics Libraries, Data modelling tools, ML / Data Science platforms) in Data Science, Machine Learning, Augmented Intelligence, Artificial Intelligence and IoT space to make build/buy/partner recommendations.

Additional responsibilities will be

Mentoring, guiding, leading and developing emerging data scientists and specialists within the team
Influence product requirements & operational plans while working with product managers & other work partners during requirements and Planning cycles.
Meet with customers, partners, product managers and business leaders to present findings, predictions, foresights; Capture customer specific requirements of business problems/processes.

Qualifications:
Does this role excite you? Then grab this opportunity if you are a super mind with

B.Tech/M.Tech/PhD in CS/ML/Statistics.
12+ experience with proven track record as an Individual Contributor at product-based companies.
Preferably 8+ experience as Data Scientist or related field (Statistics / Operation Research / Actuarial sciences)
Good at strong fundamentals across Data Science techniques, spaning across one or more of clustering, compression, classification, matrix factorization, probabilistic graphical models, network algorithms, topic modelling, image processing, deep learning, linear and mixed-integer programming.
Strong expertise in at least one programming language (Python, R, C++) along with Cloud Computing Tools and frameworks.

You can excel in this role if you have

Knowledge of Retail/Transportation/Logistics/Warehousing/Healthcare Business Process and market.
Planning, execution skills on full life cycle model development and deployments
Self motivated and self starter with high degree of work ethic with ability to thrive in a fast-paced, results-oriented, high-energy environment that requires multi-tasking capabilities and implement high priority initiative.

What we offer you

We are nurturing and encouraging our employee’s growth through career shadowing, mentorship, flexible work arrangements and Zebra’s GEM appreciation/recognition program

Zebra’s culture is encouraging and collaborative where our employees are encouraged to learn and grow together. As we celebrate our 5 decades of success, this is a phenomenal time to be part of our team of Builders, Doers and Problem Solvers and make your mark for the 6th one!!! We are excited to hear from you!

Zebra is waiting for you!",3.7,"Zebra Technologies
3.7",Bengaluru,"Lincolnshire, IL",5001 to 10000 employees,1969,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),-1
Data Analyst (Intern) - India UHR,-1,"Job Description – Data Analyst

In Cisco, we have an outstanding opportunity where we actually get to use the technology we build!

We are Innovators

We drive innovation to propel business transformation while maintaining operational quality.

We are Accelerators

We accelerate digital solutions to generate cost savings and efficiency gains for enterprise growth and success.

We are Transformers

In Supply Chain Operations we have an opportunity and the responsibility to enable Cisco's business now and prepare for the future. Our vision and strategy continue to emphasize the importance of providing our customers an unrivaled customer experience by delivering a flexible, innovative and scalable supply chain while continuing to build upon our strong operational foundation. Cisco is also committed to social and environmental responsibility in our supply chain. We work with our suppliers to maintain a sustainable supply chain that meets our standards for ethics, labor practices, health and safety, and the environment.

We encourage you to become a part of this dynamic organization where on a daily basis we leverage Cisco's aggressive competitive spirit and accelerate time to market by empowering our employees to use their expertise to take good business risks. As Cisco expands into new technologies, and geographies, it's become an exciting time to be part of the Supply Chain Operations team.

Who You Are

Desired Degree: Master's Degree (MS/MBA/MA etc) Program

Desired Major: Business, Industrial Engineering, Operations Research, Supply Chain Management or equivalent.

Minimum CGPA of 3.0 out of 4.0

The requirement is for 2021/22 passout only

Analyse business processes, find gaps and identify improvement opportunities

Strong Data analytics and visualization skills: Work with large amount of data and having business context to derive meaningful insights from the analysis of the data

Present data and insights in a logical, influential manner to drive data driven business decisions

Capture the inventory of Supply Chain data sources, dashboards, measurements and metrics to prepare and manage integrated data architecture

Perform data mapping, lineage, classification and data dictionary to create Master Data Catalogue

Conduct Periodic data health monitor & cleansing

Assist with retiring unused data elements and rationalizing/enabling future data elements

Enable data discovery and various analytics platform with self-service model (predictive and prescriptive analytics

Partner with the functional owners on analysis of data flows, data stores, and measurements/metrics integration

Perform metrics analysis as required to provide actionable information to end users

Active participation in Data Scientist role & skills development across Supply Chain Operations.

Lead and drive Supply Chain cross functional teams to become analytics driven discipline

Why Cisco

At Cisco, each person brings their unique talents to work as a team and make a difference. Yes, our technology changes the way the world works, lives, plays and learns, but our edge comes from our people.

We connect everything – people, process, data and things – and we use those connections to change our world for the better.

We innovate everywhere - From launching a new era of networking that adapts, learns and protects, to building Cisco Services that accelerate businesses and business results. Our technology powers entertainment, retail, healthcare, education and more – from Smart Cities to your everyday devices.

We benefit everyone - We do all of this while striving for a culture that empowers every person to be the difference, at work and in our communities.

So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture enthusiast? Many of us are. Passion for technology and world changing? Be you, with us!

Disclaimer - “Please note this posting is to advertise potential job opportunities. The requirement is for 2021 /22 passout only. This exact role may not be open today, but could open in the near future. When you apply, a Cisco representative may contact you directly if a relevant position opens.”",4.3,"Cisco Systems
4.3",Bengaluru,"San Jose, CA",10000+ employees,1984,Company - Private,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Alcatel-Lucent, Juniper Networks"
Finance Analytics-Data Scientist,-1,"What we are looking for

Must-Have:
Should have hands on experience with Machine learning models like Logistics regression, Survival analysis model, Gradient Boost, Collaborative filtering, Bayesian, SVM, Random Forest etc.
Prior experience in predictive model building using R/ Python
Excellent knowledge of R &-or Python (must) and other statistical tools
Masters Statistics, Mathematics, Computer Science or another quantitative field
Minimum 2-3 yearsâ€™ experience in programing in R/ Python. Excellent programming skills must
Minimum 1-2 years documentation/dashboarding skills using R Markdown (knitting in both PDF and HTML), RShiny
Minimum 1-2 years documentation skills using GitHub based data science solution development
Minimum 1-2 yearsâ€™ experience in exploratory data analysis with time series and non-time series data
Minimum 1-2 yearsâ€™ experience in time series concepts like stationarity, auto correlation, cross correlation, trend analysis, ARIMA/ ARMA and statistical modelling like regression and classification
Minimum 1-2 yearsâ€™ experience in statistical concepts like Normal, Poisson and Weibull Distribution, hypothesis testing, maximum likelihood estimation
Minimum 2 yearsâ€™ experience in Design of Experiment (DOE), Simulation and Optimization.
Minimum 1-2 yearsâ€™ experience in distributed agile
Good to Have:
Minimum 2 â€“ 3 years of core data sciences experience entailing programing in R/ Python, performing Exploratory Analysis and sound knowledge in statistics with strong documentation background.
Excellent knowledge of Data Visualization in R/ Python/ Power BI / QlikView etc. and interpretation of Graph / Charts.
Excellent Knowledge of Excel functions and VBA Automation.
Exceptional analytical and technical aptitude.
Excellent attention to detail.
The ability to manage time, prioritize tasks and work under tight deadlines.
Concise and clear written and verbal communication when presenting and explaining results and findings.
8. Knowledge of Platforms: R (Mandatory)/ Python

Responsibilities:
Ability to translate Business Problem to a Statistical Problem and Statistical solutions to a viable Business solution.
Ability to perform statistical modelling (predictive, regression, hypotheses testing, multivariate analysis, Time Series, Cluster, forecasting, ARIMA) using R/ Python.
In-depth knowledge of Statistics and Machine Learning concepts and should be able to apply them to business problems
Experience in col laborating with technology team and support the development of analytical models with the effective use of data and analytic techniques.
Data Extraction from EDW/Big Data Platform, Dataset Preparation (creation of base data, aggregation, transformation), performing EDA.
To validate the model results, Monitor model performance, and articulate the insights to the business team.
Ability to create good visualization with the output generated from the model
Write complex SQL queries to perform data extraction from various data sources
Prepare client consumable presentations with actionable insights for data driven decision making.
Ability to build use cases for the business and present them to client as well as Project IT stakeholders
Self-motivated with the ability to take direction and work independently
Document the model requirements in a suitable doc
Proven ability to mentor juniors and take full ownership for end-to-end deliverables related to project/program
Driving the E2E execution starting from Business interaction to deploy & support
Engage with internal/external stakeholders in collaborative data science project management.
Minimum Qualification:
â€¢ 15 years of full-time education;

â€¢ Minimum percentile of 50% in 10th, 12th, UG & PG (if applicable)
00-12.00 Years
PhD, Bachelor Of Technology (B.Tech/B.E), Masters in Technology (M.Tech/M.E/M.Sc), Bachelor Of Computer Application (B.C.A), Bachelor of Science (B.Sc)",3.8,"TATA Consultancy Services Ltd.
3.8",Mumbai,"Mumbai, India",10000+ employees,1968,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Accenture, IBM, Infosys"
Marketing Analytics-Data Science Manager,-1,"Job Title
Marketing Analytics-Data Science Manager
Job Description


About the organization

Philips Global Business Services LLP is a limited liability partnership organization with Royal Philips of the Netherlands. Royal Philips is a diversified technology company, focused on improving people's lives through meaningful innovation in the areas of Health Systems and Personal Health.

Royal Philips (NYSE: PHG, AEX: PHIA) is a leading health technology company focused on improving people's health and enabling better outcomes across the health continuum from healthy living and prevention, to diagnosis, treatment and home care. Philips leverages advanced technology, deep clinical, and consumer insights to deliver integrated solutions. Headquartered in the Netherlands, the company is a leader in diagnostic imaging, image-guided therapy, patient monitoring and health informatics, as well as in consumer health and home care. Philips' health technology portfolio generated 2017 sales of EUR 17.8 billion and employs approximately 74,000 employees with sales and services in more than 100 countries.

For information on Royal Philips, please visit www.philips.com

JD: Data Science Manager/Deputy Manager

Job location: Bangalore

Responsibilities
Analyzes, measures, and facilitates optimization of our marketing return on investments and tactics across multiple channels. Drive excellent practices and technical standards for establishing KPIs and goals for Marketing, developing information suites (Dashboards, reports, visualizations) fit for C-level consumption, and marketing campaign tracking and measurement.
Leverage machine learning models to address key growth challenges such as lifecycle marketing, predictive LTV, cross-channel spend allocation, response modelling, campaign/channel performance measurement methodologies, Program effectiveness and media attribution.
Develop and improve marketing mix and A&P models and frameworks to assign credit for traffic and conversions across a variety of Marketing channels and touchpoints.
Leverage Philips’ data to scale our ability to optimize marketing across the customer journey to optimize return on investment through analysis, modelling, experiments and pre-post analyses.
Develop and implement marketing data management practices
Ability to use data for Exploratory, descriptive, Inferential, Prescriptive, and Advanced Analytics - Mandatory
Ability to share dashboards, reports, and Analytical insights from data – Mandatory
Technical Knowledge and Skills required
Econometrics, Market mix modeling, some Operations research and affinity modeling experience is mandatory
Track record in delivering strong and impactful; competitor and market tracking insights
High affinity with applying new IT platforms / dash boarding software tools for reporting and Experience in a consumer focused, complex, matrixed, multinational environment, e.g. consumer goods, online services, e-commerce, or mobile applications
Competitor insight generation
Strong background into Database design, modeling and architecture – preferred Fluency in web analytics and deep technical understanding of how data are created from first party and third-party web beacons
Proficiency with R and/or Python libraries commonly used in data science

Soft Skills Required
Good communication and presentation skills
Highly driven, energetic, flexible, resourceful & ability to multitask
Clarity of thoughts and vision
Ability to ideate and bring solutions to the table
Adherence to timelines, without sacrificing quality of output
Hands on and detail oriented, with a strong ability to co-ordinate across different Geographies and with different stakeholders at Exec and Director levels
Straightforward, honest and succinct communicator. Can organize, clarify and communicate complex ideas quickly, succinctly and accurately.
Creative. Demonstrated ability to think innovatively—connecting the dots where others cannot when it comes to consumer/ customer and user data to create business building insights

Work Experience
Minimum 3-8 years of increasingly responsible experience in high impactful marketing analytics individual contributor roles
Can be from e-Commerce companies like Amazon, Flipkart etc.
In depth knowledge of multivariate statistical techniques including marketing mix modeling, attribution modelling, TURF, RAD, clustering, churn, customer scoring, neural networks amongst others
High affinity with AI powered insight tools and engines and application of data science to marketing problems
Rich experience in Marketing analytics with a strong understanding of the full range of online marketing channels, how they work, how they can be integrated, and how to evaluate them
Academics
Master’s degree in a quantitative discipline, e.g., Math, Statistics, Physics, Operations Research, Economics, Econometrics
MBA /BTech-BE from IIT/NITs or Tier 1 engineering schools only, , MS Analytics from Tier 1 schools; special preference to MBA from Mudra Institute of Communication, Ahmedabad or MBA schools that excel in Marketing
Strong exposure to Statistics – Predictive Analytics – Mandatory
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Data Scientist III,-1,"General Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation, Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions\
Experienced in proposing ROI based solutions to business",3.8,"General Mills
3.8",Mumbai,"Minneapolis, MN",10000+ employees,1866,Company - Public,Food & Drink Manufacturing,Manufacturing,₹500+ billion (INR),-1
Data Science Consultant,-1,"Hewlett Packard Enterprise advances the way people live and work. We bring together the brightest minds to create breakthrough technology solutions, helping our customers make their mark on the world.

You will join the HPE Global Operations Advanced Analytics team housed in Bangalore. You will work closely with HPE Global Operations Advanced Analytics organization in working on and managing different aspects of Business planning, reporting and analytics.

Your Role:

Designs, develops and applies programs, methodologies and systems based on advanced analytic models (e.g. advanced statistics, operations research, computer science, process) to transform structured and unstructured data into meaningful and actionable information insights that drive decision making.
Uses visualization techniques to translate analytic insights into understandable business stories (eg. descriptive, inferential and predictive insights).
Embeds analytics into clients business processes and applications. Combines business acumen and scientific methods to solve business problems.

Responsibilities:

• Formulates and defines analytics solution objectives and technical requirements based on user needs, an understanding of business processes, industry requirements, and advanced analytic models (statistical, operations research, computing, process).

• Conceptualizes, builds, develops and enhances a client's analytic model. Selects the relevant analytic modeling methodology for the use case, available structured and unstructured data, cost and timing constraints to solve the business issue and deliver clear business focused insights.

• Embeds analytic models in an enhanced business process of operational system by collaborating with Application Developers. Responsible for measuring business performance based on the model.

• As a fully functioning analytics team member, applies best practices to analytics solutions and contributes to the development of improved best practices. Leads the model enhancements.

• Summarizes complex ideas by developing visual models to display insights to simplify user experience.

• Communicate the analytics solution to the appropriate stakeholders.

Education and Experience Required:

PhD degree in Statistics, Operations Research, Computer Science or equivalent preferred. Or Master´s Degree in these areas and at least 4-12 years of relevant experience.

Knowledge and Skills:

• Advanced knowledge of advanced data science methodologies including but not limited to classical regression, neural nets, CHAID, CART, association rules, sequence analysis, cluster analysis, and text mining.

• Ability to translate business requirements into mathematical models and data science objectives to achieve measurable business outcomes.

• Advanced understanding of analytics software (eg. R, SAS, SPSS, Python). Advanced understanding of analytics deployment architectures.

• Advanced machine learning, data integration, and mathematical modeling skills and ETL tools (eg. Informatica, Ab Initio, Talend).

• Advanced communication and presentation skills.

• Strong interpersonal skills and effectiveness in working across geographical boundaries.

• Working knowledge of programming languages such as Python, SQL, R, SAS, Java, Unix Shell scripting. Working knowledge of Hadoop framework desired.

• Advanced knowledge of data visualization techniques and software tools (eg. Spotfire, SAS, R, Qlikview, Tableau, HTML5, D3).

Join us and make your mark!

We offer:

• A competitive salary and extensive social benefits

• Diverse and dynamic work environment

• Work-life balance and support for career development

• An amazing life inside the element! Want to know more about it?

Then lets stay connected!

https://www.facebook.com/HPECareers

https://twitter.com/HPE_Careers

1061305",4.1,"Hewlett Packard Enterprise
4.1",Bengaluru,"Palo Alto, CA",10000+ employees,2015,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Oracle, Accenture"
Senior Data Scientist,-1,"Summary


Do you get excited by intellectually stimulating problems? The Senior Data Scientist has to have a mix of advanced technology, customer and strategic business acumen. You will work in and lead teams as technical domain expert addressing statistical, machine learning and data understanding problems. You will be part of a data science or cross-disciplinary team on commercially-facing development projects, typically involving large, complex data sets. These teams typically include statisticians, computer scientists, software developers, engineers, product managers, and analysts

What you get to do

Develop analytics solutions to address customer needs and opportunities
Work alongside software developers and data engineers to translate algorithms into commercially viable products and services
Work in technical teams in development, deployment, and application of analytics solutions, leveraging technical components
Take responsibility for insights, reports, annotated code, and other projects artifacts to document, archive, and communicate outcomes to client and prospects based on these
Be responsible for entire solutioning and implementation cycle: From definition of business questions and hypotheses, to data sourcing and preparation, model development, and insight generation. Output of these analyses will be the basis for strategic resource allocation by BU and Leadership
Collaborate closely with other functions to advise, and support Business leadership in various types of advanced quantitative analyses, including but not limited to: Marketing Mix Analysis, Advanced Segmentation & Targeting, Personalization, Chatbot & Personal Assistant, CLTV etc
Lead and mentor a highly motivated team with exceptional talent
Work with the Business Development team in the pre sales & pilot engagements for analytics engagements
Evangelize TEG’s vision through case studies, participation at conferences, and creating thought leadership articles

What you will need to make an Impact
Should maintain high standards of quality and thoroughness. Should be able to monitor accuracy and quality of others work
Ability to lead new initiatives, prepare project plans and other supporting information
Experience across verticals will be a plus
Strategic business acumen, focus on results, passion for keeping up with media and technology trends
Ability to influence cross-functional and upper management to impact decision-making
Ten years of progressive advanced analytics work experience
Experience in marketing mix modeling, promotional response and price modeling, forecasting, optimization, simulation, and/or decision analysis
Post-graduate degree (Master’s/Ph.D) in a quantitative field (Statistics, Management Science, Operations Research, Engineering, Finance, Applied Mathematics, Mathematics, Business Administration etc, from Tier-1 institute",3.1,"TEG Analytics
3.1",Bengaluru,"Bengaluru, India",51 to 200 employees,2008,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Research Scientist - IBM Research,-1,"Introduction
IBM Research Scientists are charting the future of Artificial Intelligence, creating breakthroughs in quantum computing, discovering how blockchain will reshape the enterprise, and much more. Join a team that is dedicated to applying science to some of today's most complex challenges, whether its discovering a new way for doctors to help patients, teaming with environmentalists to clean up our waterways or enabling retailers to personalize customer service.

Your Role and Responsibilities
Who you are:
We are seeking candidates with deep knowledge of computer science or related fields, with passion and demonstrated expertise in building large scale systems on cloud environments. Ability to learn quickly and work with a global team in an agile fashion are desirable traits.

What youll do:

Advances in network virtualisation, 5G and edge computing are ushering in a new era of enterprise computing at the edge, with tremendous activity in a number of open source projects as well as academic publications over the last few years. As a Research Scientist, you will:
Engage in cutting-edge research in building the next generation compute infrastructure in telecom networks and edge clouds.
You will engage in research in host networking and Kubernetes networking concepts, data plane acceleration techniques, aspects of multi-cluster and multi-cloud management, edge computing and network slicing.
You will demonstrate the ability to define research plans and publish research results through academic conferences and patents.
You will be expected to organise meaningful problems, develop new solutions, and work with business & development teams to ensure these solutions have a significant impact for business including contributions to open source.
How well help you grow:
Youll work with global research and industry teams on cutting edge research and building large scale systems of the future
Youll have access to all the technical and management training courses you need to become the expert you want to be
Youll learn directly from expert researchers and developers in the field; our SME's love to mentor.
With the breadth of on-going research in the lab, there will be plenty of opportunity for interdisciplinary research

Required Technical and Professional Expertise
0 3 years of relevant industry experience.
We are seeking interested candidates with good programming skills and experience in one or more of the following:
Cloud computing
Container networking and kubernetes
Network function virtualisation
Distributed systems and applications
Performance analysis of systems with a focus on optimisation
Preferred Technical and Professional Expertise
Qualifications:
Masters or Ph.D. in Computer Science/Electrical Engineering or related fields is required.
3+ years of experience building systems
Interest in building industry-scale complex software systems and flexibility for multi-disciplinary work in a global team-oriented environment
Experience publishing original research in top conference venues
About Business Unit
With more than 3,000 researchers in 12 labs located across six continents, IBM Research brings together hundreds of researchers who possess unparalleled industry expertise to address some of the world's most challenging problems. Join us as we do pioneering work in areas such as cognitive computing, augmented intelligence, quantum computing, and blockchain, to name a few.

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data scientist web crawler,-1,"Position Title
Data scientist web crawler

28-Jul-2020

Job ID
297628BR

Job Description
70 tactical buyers are supporting both commercial and NTO towers out of Prague NGSC, covering region Europe, Switzerland, Middle East and North Africa.

To establish and maintain a global process across the entire enterprise by managing the implementation program, including all planning, resourcing and budgeting requirements, and ensuring future changes to the process and enabling system are properly managed.

Your responsibilities include, but are not limited to:

●Think creatively, conceptualize and lead projects resulting in substantial long-term impact on the company’s vision in many key strategic areas such as drug discovery/manufacturing, product launches, determining optimal treatment plans/courses, expanding patient access, predictive/precision medicine, risk mitigation, business growth, brand management, product life cycle, data strategy etc
●Design, develop and deliver various data science based insights, outcomes and innovation (using mathematics, computer science, statistics, engineering, management science, technology, economics, etc) and create “proof of concepts & blueprints” to drive faster, timely, highly precise, workable and proactive decision making based on data based insights and science and shape strategic glidepath of the company
●Lead successful cross-functional collaborations with significant execution rigor, customer focus and “Data to Decision” thinking
●Demonstrate a comprehensive view of science and technology and deliver a compelling enterprise vision of how Data, Digital & Artificial Intelligence can contribute to providing quantum in leap in building foundational/groundbreaking capabilities transcending a wide spectrum of areas such as research/science, drug discovery/development, commercial, procurement, technology, product, brand, business, strategy, analytics, operations, risk/compliance, legal, etc and propel growth and performance
●Own adoption, execution and integration of data science based solution end to end all the way from discovery to launch/post-launch and also into business, design, product, delivery, operations, marketing, brand management, research and technology roadmaps.

https://www.youtube-nocookie.com/embed/Mo1vwtVPVA0

Minimum requirements
•M.S/Ph.d in Computer Science, Robotics, Mathematics, Statistics, Operations Research, Cognitive Sciences, Psychology, Engineering, Finance, Economics, Medicine, Technology, Management Science, Quantitative Methods and other related disciplines.
•6 -10 years of overall experience with demonstrated track record in data science solutioning
•Strong coding experience in Python (knowledge of Java, Javascripts is a plus)
•Solid foundation in HTML data structures
•Develop a deep understanding of our vast data sources on the web and know exactly how, when, and which data to scrape, parse and store
•Strong knowledge of scraping frameworks such as Python (Request, BeautifulSoup), Web-Harvest and others
•Prior exposure to DOM, XPATH and hands on experience with selenium/automated testing is a plus
•Exposure in Selenium, XPATH, Scrapy, Webcrawl, WEB Scraping, Web Data Extraction
•Hands on experience with deep learning, data mining - concepts, techniques and implementation.

Why consider Novartis?
799 million. That’s how many lives our products touched in 2019. And while we’re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people’s lives?

We believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you’re given opportunities to explore the power of digital and data. Where you’re empowered to risk failure by taking smart risks, and where you’re surrounded by people who share your determination to tackle the world’s toughest medical challenges.

Imagine what you could do at Novartis!

Commitment to Diversity & Inclusion:
Novartis embraces diversity, equal opportunity and inclusion. We are committed to building diverse teams, representative of the patients and communities we serve, and we strive to create an inclusive workplace that cultivates bold innovation through collaboration, and empowers our people to unleash their full potential.

Join our Novartis Network: If this role is not suitable to your experience or career goals but you wish to stay connected to learn more about Novartis and our career opportunities, join the Novartis Network here: https://talentnetwork.novartis.com/network

Job Type
Full Time

Country
India

Work Location
Hyderabad, AP

Functional Area
Procurement

Division
NBS

Business Unit
PROCUREMENT NBS

Employment Type
Regular

Company/Legal Entity
Nov Hltcr Shared Services Ind

Shift Work
No",3.9,"Novartis
3.9",Hyderabad,"Basel, Switzerland",10000+ employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
Hiring for Sr/Jr Data Scientist in Chennai,-1,"Role Description
Role involves a combination of hands-on contribution, customer engagement and technical team management.
Lead data science aspects of client engagements on their own end to end, effortlessly switching between roles of an Individual Contributor, team member and data science manager as demanded by each project
Work closely with project team, Customer stakeholders and internal Business Units in devising creative analytical approaches to solve business problems
Developing and enhancing algorithms and models to solve business problem
Maintaining all models along with developing and updating code and process documentation
Demonstrated analytic, quantitative, and programming skills
Proficiency in a structured programming language is a must - knowledge of one of statistical/general purpose scripting languages software such as R, python is mandatory.
Strong SQL, Microsoft Excel, PowerPoint skills
Experience in designing data science solution approaches to unstructured problems, conducting quantitative analyses and interpreting results
Excellent written and verbal communication skills
Organized, structured and reliable while being an effective problem solver
Proficiency in data science approaches, machine learning algorithms and statistical methods.Â
Qualification and Experience
8+ years exp of which 5 years of relevant data science experience including hands-on programming in one (or more) of the above languages. Minimum 5 years spent with Analytics teams of reputed consultants and IT/ITES companies doing statistical modelling using above tools
B.Tech from Tier-1 college (IITs, NITs, IIITs etc.)
M.S or M.Tech is preferred
00-11.00 Years
Bachelor Of Technology (B.Tech/B.E), Masters in Technology (M.Tech/M.E/M.Sc)",-1,Avenues Consulting,Bengaluru,"Mumbai, India",1 to 50 employees,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"Job Description
Looking for Sr. Data Scientist from tier-1 institute who can perform data-driven research, solve real-world problems and optimize algorithms through the systematic application of mathematics, statistics and computer science.
Responsibilities
Take ownership for the product and work independently with little technical supervision to ensure itslaunch
Enhance current product features
Suggest improvements in algorithms currently deployed in the company and implement the same
Work to improve text analysis to find meaningful information
Analyze huge data to train ML models and evaluate them with right metrics
Partner with product managers to make data driven decisions and help solve problems for our users
Champion the culture of experimentation
Requirements
Btech/ Mtech from a top-tier engineering college India or abroad
Atleast 5 years of data science and machine learning experience
Strong programming experience in the languages - Python
Experience in machine/deep learning tools such as Tensor Flow, Keras, Theano (Must - TensorFlow) and good understanding of concepts like CNN, RNN, LSTM.
Extremely comfortable in Text analysis tools and libraries such as NLTK, Spacy, Syntaxnet and Natural Language Processing -Information retrieval, Named Entity Recognition (NER), word embedding, Stanford CoreNLP (Must have a basic understanding)
Familiar with front-end building – PHP, HTML, CSS (Required)
Familiar with Back-end building –Flask, uwsgi, MySQL (Required)
Strong problem solving skills
Readiness to learn new concepts and apply them to find practical solutions to complex problems
Ability to work in a fast-paced start up with strict deadlines",3.7,"VMock Inc
3.7",India,"Palo Alto, CA",51 to 200 employees,2009,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Planning COE Data Scientist,-1,"Supply Chain Planning and Materials CoE Data is a new role to HPEs Planning and Materials Management organization residing in Bangalore, India. This role will be key in driving the organization through data-based recommendations/actions to achieve better results in all metrics related to Demand, Supply, and Inventory/ Materials Management and cost. The Data Scientist will be leveraging advanced analytic, technical, and business skills to drive innovative methodologies for driving improvements for the business.

Roles and Responsibilities
Defines and develops the value proposition for supply chain analytics solutions based on user needs, business value, industry requirements and understanding of advanced analytic models (statistical, operations research, predictive and prescriptive).
Conceptualizes, builds, develops, and enhances analytic models using right modeling methodology, available structured and unstructured data, cost and timing constraints to solve the large and complex business issues, discovers and delivers compelling and clear business insights across the planning and materials management organization.
Embeds analytic models into enhanced large scale business processes and operational systems by collaborating with Application Developers.
Drives improvements in planning metrics such as forecast accuracy, inventory management, service to our customers, and cost metrics.
Using unique visualization techniques, condenses large volumes of complex ideas into elegant and simple visual models.
As a data evangelist, leads weekly meetings with Planning Leaders to provide key insights and align action plans to improve business results.
Collaborates with stakeholders in Demand, Supply, and Inventory and supplier / materials Management to ensure analysis of data considers ongoing business activities including HPE strategies, existing projects, new product introductions, etc.
Participates in supply chain design strategy for resilience and digital transformation.
Develops agile and scalable models to provide end to end and real time visibility of supply chain
Provides ad hoc analytics support to planning and materials management functions as needed
Provides thought leadership on the design of visual management tools and the usage of data science, machine learning, artificial intelligence and other tools to advance supply chain performance.


Skills and Experience
10+ years of experience in data analytics
Strong analytical and problem solving skills
Ph.D or Masters in Statistics / computer science / operations research / data science / industrial engineering / supply chain / manufacturing systems
Deep understanding of machine learning/data mining algorithms and techniques
Experiences in processing and analyzing both structured and unstructured data
Proven ability to leverage analytical skills and knowledge for business value
Solid knowledge of big data processing framework and tools, such as Spark, Hadoop, MapReduce, etc.
Proficiency in one or more programming languages including but not limited to: Python, Java, Scala, R
Proficiency in statistical tools such as R, SAS
Proficiency in visualization tools such as libraries in R, Power BI, Tableau, Qlikview (PowerBi preferred)
Ability to effectively communicate analysis results to customers and negotiate options at management levels
Experience in working with supply chain, (demand planning, materials management, or inventory management preferred)
Hewlett Packard Enterprise Values:

Partner. Innovate. Act.

We live by three core values that drive our business.

Simplified, we are good partners, great innovators and we make things happen.

Extensive social benefits, flexible working hours, a competitive salary and shared values, make Hewlett Packard Enterprise one of the world´s most attractive employers. At HPE our goal is to provide equal opportunities, work-life balance, and constantly evolving career opportunities.

If you are looking for challenges in a pleasant and international work environment, then we definitely want to hear from you. Apply now below, or directly via our Careers Portal at www.hpe.com/careers

You can also find us on:
https://www.facebook.com/HPECareers
https://twitter.com/HPE_Careers

1065569",4.1,"Hewlett Packard Enterprise
4.1",Bengaluru,"Palo Alto, CA",10000+ employees,2015,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Oracle, Accenture"
Principal Data Scientist,-1,"Location:: Anywhere in India (remote)
Key skills:: Machine Learning Algorithms

Desired Candidate Profile::
We are looking for AI engineers who are as passionate as we are about artificial intelligence, advancing science, and inventing the next generation of intelligent machines.
We are hiring for candidates with 4+ years hands on development in experience in ML/AI.
Knowledge in a broad range of machine learning areas, including: Deep learning, including novel architectures with attention and memory, supervised learning, semi-supervised and unsupervised learning, including generative models, Reinforcement learning, Meta-learning, Multi-task learning, transfer learning, few-shot learning, continual/lifelong learning, Interpretability, fairness, accountability of machine learning models, Brain-inspired machine learning algorithms, Optimization for AI/ML, Bayesian learning, graphical models, and causal models. Familiarity with Big Data ML toolkits, such as Tensorflow, Spark ML, or H2O
You will work on the most cutting-edge, exciting projects that have immediate use in the industry. Your creativity and innovative problem solving will be essential to the success of our team and the company.
Reach out to us if you have solved real-life problems at scale utilizing message queueing (Apache Kafka, MS EventHub, or equivalent) and streaming event processing technologies (Apache Storm, Apache Spark, or equivalent), applied machine learning and AI algorithms to very large datasets at scale.
Education:: - Bachelors/ Masters / Phd
We think the knowledge acquired by earning a doctorate or master’s degree in Computer Science with AI as a specialization would be of great value in this position, but if you're smart and have the experience that backs up your abilities, for us, talent trumps degree every time
Company Profile: This is the right place for you, if want to work in
A Data Science and Big Data technology start-up.
A place where you would want to create value for yourself, and our customers
An environment that supports your personal growth
Culture that believes the greater priorities in life are family, health and integrity
Group of the best in class professionals who are excited about the work they do
Contact::
Sangeetha: sangpraman@gmail.com, +919655998843",-1,CereSight,India,"Tiruchirappalli, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"We're looking for a
Data Analyst (Pune, India)


Role: Data Analyst (Pune, India)

We are seeking a data analyst with exceptional bookkeeping, accounting, and financial variance analysis skills. This position will help to drive the success of the business by providing detailed department level expense data in real-time (using NetSuite). This role will report to the manager of the Company's finance and accounting team in India and would be supporting various functions within the Finance department, with the FP&A team being the primary customer. Additionally, the person will also have to liaise closely with the US/Canada based Accounting team, as well as operations managers in the various functional areas (R&D, Sales & Marketing, G&A). We are looking for a fast learner who is focused, intelligent, dependable, detail-oriented and possesses a “can-do” attitude. We provide an attractive environment for career advancement in a fast growing, dynamic technology company.

In this role you will…

· Develop a thorough understanding of the business and conduct detailed investigation of expenses booked in the general ledger daily.

· For major categories of expenses that appear in the G/L without adequate “expense purpose” description fields being populated, you will investigate and populate these data fields with standardized inputs that add more color to the expenses incurred.

· Gain a deep understanding of departmental budgets, as well as perform analytics on Coups purchase orders to support the FP&A team.

· Assist in the ongoing preparation of monthly, quarterly, and annual (multi-year) US GAAP forecasts, including budget to actual variance analysis, scenario/sensitivity analysis, rolling forecasts, etc.

· Assist in preparation of monthly reports; including sales analysis, bookings analysis, P&L, Balance Sheet, Cash Flow, and supporting schedules, as needed.

· Provide support and assist with ad-hoc requests and special projects to support business initiatives.

· Analyze current internal business processes and improve efficiency.

· Consideration for privacy and security obligations

You’ve got what it takes if you have…

· Bachelor’s degree in Accounting, Finance, Business Administration, Economics, or equivalent working experience

· 2+ years’ work experience in accounting, corporate finance, financial planning & analysis, or other related fields.

· Strong working knowledge of Excel

· Formulas and Functions, including: Pivot tables, Vlookups, Nested IF statements, Logic statements, etc. are a major plus.

· Experience in cash flow reporting, financial close processes, and accounting principles in computer software or related industries.

· Strong research, analytical skills, pro-active problem-solving skills, and self-motivation to perform tasks above and beyond responsibility, in a timely manner.

· Must be capable of working in fast-paced and changing environment; be self-directed; and work well as a team player.

· Excellent written and verbal communication skills in English

Extra Dose of Awesome if you have…

· Ready to work in EMEA Shifts

· Netsuite Experience

· Coupa and Salesforce.com knowledge

· An interest in working for a technology company and are familiar with the SaaS business model

· Experience in a start-up environment

· Financial modeling experience in Excel

Our Culture:

Our mission is to empower people, businesses and communities. A culture created less by what we do and more by who we are. When people are asked to describe the team, the answer is always the same: smart, cool, dependable, and visionary. We are not a typical tech company (paid sabbaticals, generous stock units, education reimbursement, and 100% paid employee health coverage), because, well, our employees aren't your typical techies...
We're always on the lookout for new, curious and capable people who can help us achieve our goal. So if you want to work for a friendly, global and innovative company, we'd love to meet you!

What We Do:

Cornerstone OnDemand (NASDAQ: CSOD) was founded with a passion for empowering people through learning and a conviction that people should be your organization’s greatest competitive advantage. Cornerstone is a global human capital management (HCM) leader with a core belief that companies thrive when they help their employees to realize their potential. Putting this belief into practice, Cornerstone offers solutions to help companies strategically manage and continuously develop their talent throughout the entire employee lifecycle.

Cornerstone’s HCM platform is successfully used by more than 75 million people in 180+ countries and in 40+ languages.

Check us out on Linkedin, The Muse, Glassdoor, and Facebook!",3.9,"Cornerstone OnDemand
3.9",Pune,"Santa Monica, CA",1001 to 5000 employees,1999,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹50 to ₹100 billion (INR),"SAP, Oracle, Workday"
DATA SCIENTIST,-1,"Profile Brief/ Responsibilities
Keep up-to-date with latest technology trends.
Work closely with Project/Business/Research teams for identifying the best model for a given problem
Research and build highly efficient and state-of-the art models
Selecting features, building and optimizing models using machine learning techniques.
Requirements
2-5 years of relevant industrial experience in Machine Learning and Deep Learning with: Strong working knowledge in Python, C, C++, Linux.
Excellent understanding of Machine Learning Techniques and Algorithms.
Excellent understanding of Text Analytics concepts and methodologies - Named Entity Recognition, Text Classification, Event Detection, Sentiment Analysis, POS Tagging, Bag of Words.
Hands-on experience with Neural Networks (CNN/, RNN,/ DNN, /BNN,/LSTM, SSD, etc), Support Vector Machine, Conditional Random Field etc.
Experience with GPU/DSP/ISP/SoC architecture and system software
Python, Tensorflow/Caffe/CUDA/Keras
Ability to see big picture, think innovative and suggest out of box solutions.
Ability to write high performance structured code.
Exposure to recent developments in Deep Learning domain",4.3,"Innefu Labs Pvt. Ltd.
4.3",New Delhi,"New Delhi, India",51 to 200 employees,2010,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"Job Title:
Senior Data Scientist

Location:
India, Bangalore
Role Overview:


As a senior data scientist of the Business Intelligence team, reporting into Senior Engineering Manager of Business Intelligence, the focus of this opportunity is to understand the business, product and develop insights using advanced data science algorithms from a cloud data infrastructure. You will work with global teams, engage with product, marketing and leadership teams to create insights out of data from cloud data store. You will work on data analysis, drive insights using statistical models, communicate insights around opportunities and anamolies.



Company Overview


From device to cloud, McAfee provides market-leading cybersecurity solutions for both business and consumers. We help businesses orchestrate cyber environments that are truly integrated, where protection, detection, and correction of security threats happen simultaneously. For consumers, McAfee secures your devices against viruses, malware, and other threats, both at home and away. We want to continue to shape the future of cybersecurity by working together to build best in class products and solutions.

About the Role:
You will understand the product, business and data processes.
You will perform data analysis, discuss with leadership and partners to determine the focus area
You will develop insights into opportunities of business growth, customer centricity, obsession and product insights using advanced data science statistical models
Develop machine learning models that use our unique combination of threat data, user behaviour and subscription data to improve consumer value from our products
Provide data-based intelligent personalization in all our touch points consumer including marketing, product and customer service
Mine, analyse and build predictive and descriptive machine learning models on structured and unstructured data sources
Use code (Python, R, Scala) for analysing data and building statistical models.
Apply or design creative models for predictive learning, forecasting, recommendations, content ranking, and anomaly detection.
Use machine learning to help us anticipate and cater to consumer's personalised needs for threat protection.
Use data and machine learning to create unique and personalised experiences for consumers across multiple touch points with McAfee.
Create algorithms for optimising consumer journey and increasing conversion and monetization
Perform statistical analysis on the outputs of these machine learning models to help update, re-train, and then deploy new ML models
Contribute to the creation, deployment, and scaling of machine learning and predictive algorithms in a production environment
You will report to Engineering Manager
Help identify new opportunities for applying machine learning and statistics-based models for improved customer and outcomes
About You:
You have 5+ years of experience as a data scientist.
You are proficient in designing, analysing and troubleshooting controlled experiments (causal A/B tests, multivariate tests).
You have knowledge and specialist at mentoring other team members in the use of data science tools such as R, Python, SQL, MapReduce, Hadoop, Hive and Big Data technologies.
Experience with applied machine learning (like scikit-learn) and deep learning frameworks (like Keras, tesorflow or PyTorch).
Experience in optimization mathematics (linear programming, nonlinear optimization)
Experience working with large amounts of structured and unstructured data in a consumer-facing online business required.
You have experience with machine learning.
Experience with natural language processing (NLP) and text mining.
Experience with statistical modelling, and hypothesis testing.
A track record for creating raw data and analysis into well-written content.
You are a specialist in gathering requirements, prioritisation, and leading projects.
Company Benefits and Perks:


We work hard to embrace diversity and inclusion and encourage everyone at McAfee to bring their authentic selves to work every day. We offer a variety of social programs, flexible work hours and family-friendly benefits to all of our employees.
Pension and Retirement Plans
Medical, Dental and Vision Coverage
Paid Time Off
Paid Parental Leave
Support for Community Involvement
We're serious about our commitment to diversity which is why McAfee prohibits discrimination based on race, color, religion, gender, national origin, age, disability, veteran status, marital status, pregnancy, gender expression or identity, sexual orientation or any other legally protected status.

Job Type:


Experienced Hire

Primary Location:
India, Bangalore

Additional Locations:",3.6,"McAfee
3.6",Bengaluru,"Santa Clara, CA",5001 to 10000 employees,1987,Company - Private,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Palo Alto Networks, NortonLifeLock, CrowdStrike"
IBM Quantum Data Scientist,-1,"Introduction
Quantum computers are incredibly powerful machines that take a new approach to processing information. Built on the principles of quantum mechanics, they exploit complex and fascinating laws of nature that are always there, but usually remain hidden from view. By harnessing such natural behavior, quantum computers can run new types of algorithms to process information more holistically. They may one day lead to revolutionary breakthroughs in materials and drug discovery, the optimization of complex manmade systems, and artificial intelligence. We expect them to open doors that we once thought would remain locked indefinitely.

IBM Services is looking for a Quantum Data Scientist who will interface with research and algorithm experts to implement quantum approaches, which includes data pre-/post-processing, running numerics and visualizing data. Working with quantum industry experts, you will be a key member of a multi-discipline squad focused on building quantum capabilities and researching quantum application development for clients within Communication sector industries including specific focus on telecommunications.

Your Role and Responsibilities
Work with IBM Q Start team on active exploratory research engagements to prepare for future use case commercialization within specific industry
Engage and educate client data science teams to define promising areas for quantum exploration
Implement quantum approaches, which includes data pre-/post-processing, running numerics and visualizing data
Collaborate with industry and solutioning experts to design and shape experiments to demonstrate quantum-enabled advantage
Define best practices related to information architecture, including collection, integration, organization, analysis and visualization of data for quantum-enabled impact
Engage in practice development initiatives focused on building employee knowledge and skills in specific areas of expertise through coaching and development of training course material
Required Technical and Professional Expertise
PhD/Masters in STEM-related fields with knowledge in Quantum Computing.
5+ years of data engineering and data science experience
2+ years of consulting experience within specific industries with strong domain expertise and business acumen
Proficiency with classical approaches to machine learning and linear algebra, including Support Vector Machine (SVM) for linear categorization and Singular Value Decomposition (SVD) to reduce dimensionality of data
Familiar with Qiskit software, including Qiskit Aqua for domain applications and Qiskit Terra for quantum circuit design and optimization
Excellent ideation, facilitation and communications skills
Detail-oriented team player with strong interpersonal skills and ability to take a leadership role when necessary
Willingness to travel globally up to 40% once we return to a travel-safe environment.
English: Fluent
Preferred Technical and Professional Expertise
2+ years of experience in at least one of the industries, with knowledge of industry trends, R&D areas, and computationally intensive processes (e.g. optimization)
Familiarity with Qiskit
About Business Unit
IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter business by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world. What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Scientist AI ML Team,-1,"Come aboard our growing global team and work for a category leader with a market presence in 15 countries. You will work with some of the leading financial institutions worldwide who rely on our product innovation in helping them shield themselves against the global $4 trillion problem of financial fraud. We create ‘customer-centric predictable enterprises’ and we do this by directing intelligence to the heart of every customer interaction. In real-time.

We are seeking sharp, energetic Data Scientists to help us keep pace with our global expansion. You’ll be core member of a specialist team working on our Artificial Intelligence & Machine Learning stream. You bring your skills, experience and passion and we will give you the springboard for your ambitions.

The Role:
Work as part of Clari5.ai team in defining, prototyping and implementing data science models/algorithms as part of the product.

Take ownership of the data science model end-to-end from data collection to model building to monitoring the model in production.

Along with product managers and domain experts, own the business outcomes/metrics which the data science model/algorithm drives.

Work with the product managers and engineering to define best practices for the team.

Mentor junior colleagues and conduct internal workshops.

Help to make data science and data-driven decision making a part of the organisation’s DNA.

Your Skills:
Must have 3 – 8 years of experience working on model building.

Solid understanding of the mathematics related to data science – probability, statistics, linear algebra etc.

Ability to understand business concerns and formulate them as technical problems that can be solved using data and math / stats / ML.

Experience working as part of a product team, along with engineers and product managers, to define the problem and execute the data science solution.

Must have built 2-3 end to end ML projects in the past.

Knowledge of R or Python is a must.

Strong hands on experience in working with SQL databases.

Experience working with large data sets, coming from varied sources, is a plus

Conceptual understanding of big data technologies (Hadoop / HDFS / Spark) is a plus.

Prior experience in Natural Language Processing, Recommender Systems or Social Network Analysis is a huge plus.

Your Education / Qualification:
Bachelor’s degree or equivalent combination of education and 3 years or more of experience.
Bachelor’s degree in Computer Science, Masters in Mathematics / Statistics preferred.
About Us
Endorsed Category Leader in Financial Crime Risk Management Systems for Enterprise Fraud by Chartis Research, Winner of Best Fraud Detection Product by Risk.net and ranked consistently in Chartis’ RiskTech100 rankings, CustomerXPs redefines real-time, cross-channel banking Enterprise Fraud Management using AI like a central nervous system to fight financial crime. The company’s flagship product Clari5 harnesses the combined power of Automation, AI, Decision Sciences & Real-time Decisions. Clari5 currently processes over 10 billion transactions, manages over 450 million accounts and reliably secures 4% of the global population’s banking transactions. With 200 million accounts at a single site, Clari5 has the world’s largest implementation of a fraud management solution. Tier 1 banking customers across 15 countries who trust Clari5 for driving their fraud management strategy are recipients of global industry acclaim, including Banking Technology’s Best Use of IT in Risk Management/Regulation and Celent’s Model Bank of the Year.",3.0,"CustomerXPs
3.0",Bengaluru,"Bengaluru, India",201 to 500 employees,2006,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),-1
Data Analyst,-1,"The position is full-time and would be based at the company’s Chennai office. The successful applicant would have 1 - 2 years' relevant experience and be responsible for collection, validation & analysis of Mutual fund data.

Key Areas of Responsibility
Collection, validation, analysis of mutual fund information.
Updating the mutual fund information into our databases in a timely manner.
Perform quality checks.
Communicate with UK and Offshore asset management companies via email/telephone.
Provide clarifications to clients’ queries based on priority and urgency levels.
Extract and provide various project-related reports as required by the manager.
Key Skills

Key Technical Skills
Possess basic knowledge of Mutual funds and/or of the financial sector.
Proficient in MS Office (including MS Outlook)
Key Behavioural Skills
Very good written and spoken English communication skills.
Good Analytical and Problem solving skills.
Ability to work independently and come up with ideas to enhance the process.
Ability to achieve the defined SLA standards with regard to Turn Around Time, Work accuracy etc. and maintain them throughout one’s tenure in the department.
Ability to quickly learn new concepts relating to Mutual funds and be able to apply them in the work.
How to Apply

To apply for this job, click here

If you have any questions regarding this job, please feel free to email india.jobs@financialexpress.net

FE UK",4.1,"FE UK
4.1",Chennai,"Woking, United Kingdom",501 to 1000 employees,1996,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,-1
Data Scientist - Machine Learning/Artificial Intelligence/ Python -BFSI,-1,"Experience 4 - 10 Years
Salary 8 LPA - 16 LPA
Job Location Bengaluru

Industry:
IT-Software / Software Services

Keywords:
Data Scientist

About Job:
Core Responsibility :
Strong experience in delivering projects in using Python.
Strong experience in developing models using Image Processing and Computer Vision algorithms
Designing, developing, and deploying deep learning models on AWS environment.
Experience and Skills :
4 - 6 years- experience in Designing and Deploying Deep Learning Solutions
Excellent knowledge of Deep Learning Architectures/Convolutional Neural Networks
Excellent knowledge of Supervised Learning, Adversarial Learning
Excellent Python Coding Skills with at least 4 years of Python coding
Robust working knowledge with deep learning frameworks (like Tensorflow, Keras, PyTorch)
Hands on experience on Image Processing and Computer Vision algorithms
Experience with GPU/CUDA programming
Deep knowledge of mathematics, probability, statistics and algorithms
Understanding of data structures, data modelling and software architecture
Excellent communication skills
Ability to work in a team
Outstanding analytical and problem-solving skills
Must Have :
Aware of the Software Development Life Cycle and Quality concepts
Excellent experience in Python programming language for data analysis.
Excellent verbal and written communications skills; Strong interpersonal skills
Managing available resources such as cloud services, data
Good to Have :
Experience with System Development Life Cycle methodologies (CMMI)",4.1,"Careerera
4.1",Bengaluru,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"The Company

Hitachi Vantara, a wholly-owned subsidiary of Hitachi, Ltd., guides our customers from what’s now to what’s next by solving their digital challenges. Working alongside each customer, we apply our unmatched industrial and digital capabilities to their data and applications to benefit both business and society. More than 80% of the Fortune 100 trust Hitachi Vantara to help them develop new revenue streams, unlock competitive advantages, lower costs, enhance customer experiences, and deliver social and environmental value.

The Role

We are seeking Machine Learning Engineer

Responsibilities
Perform machine learning, text analytics, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods.
Selecting features, building and optimizing classifiers using machine learning techniques.
Implement algorithms and software needed to perform analyses.
Communicate results and educate others through reports and presentations. Skills Required â€¢ Expertise in Data Mining, Data wrangling, and data munging using one or more of the most commonly used data science tools: R, Python, SAS, SPSS, Weka â€¢ Experience in end-to-end data science and engineering activities.
Qualifications
BE / B Tech / ME / M Tech
We are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.",2.7,"Hitachi Vantara
2.7",Hyderabad,"Santa Clara, CA",5001 to 10000 employees,1989,Subsidiary or Business Segment,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"Bottomline is at the forefront of digital transformation. We are a growing global market leader uniquely equipped to address the changing needs of how businesses pay and get paid. Our culture of Working with and for each other enables us to delight our customers. We empower our teams to think like owners driving customer delight, helping them grow their business and win in their markets.

We are looking for Senior Data Scientist to innovate, win, and grow with us in Bangalore, India.

As a member of Central Data & Analytics Team, you will be developing software to be used for a range of machine learning and data mining techniques, including predictive modeling, anomaly detection, customer profiling and segmentation, recommendations, text analytics, and big data analytics in solving our business problems. You will take an idea from conception and experimentation to design and implementation to deployment and production. In this role, you will interact with a team of experts in Machine Learning and Data Mining.

How you'll contribute:
Research and identify optimal new machine learning solutions to complex business problems with focus on improving inference and reducing costs
Collaborate closely on a cross-functional team and mentor, support the team of data scientists and analysts
Assist lines of businesses in evaluating scenarios and plan scope, feasibility, and approaches of potential ML solutions for each scenario
Assist business groups in performing exploratory data analysis related to their use cases
Provide best practices and technical support for implementation, focused on stated business outcomes
Ideation and assistance on the use of AWS Services, in particular Amazon SageMaker and AWS Managed Services for development of Deep Learning and Transfer Learning with Natural Language Processing (NLP)
What will make you successful:
At least 4 years' professional experience in with major programming languages such as Java, Python, Scala
A completed graduate degree in Computer Science, Engineering or any other heavily numerate subject
Understanding of the full software development lifecycle (conduct data analysis and build large-scale machine-learning models/pipelines)
Ability to present suggested approaches and results focused on business value
Experience in optimizing space/time trade-offs for computationally expensive processes
Familiar with Agile software development process as well as Dual Track Agile
Experience in Big Data technologies (Hadoop, Spark), large relational and NoSQL databases
Extensive knowledge in data processing, Machine Learning, and data analysis frameworks such as scikit-learn, NumPy, Pandas, TensorFlow, NLTK
Experience in quantitative analysis and translation of findings into actionable insights
You'll love Botttomline because in everything we do we seek to delight our customers and we are passionate about building a company of which we can all be proud, and this starts with building amazing teams filled with team members that challenge you every day.

Start your #LifeAtBT

Public cloud AWS, ML, DL, NPL, Python, Java, Scala, Hadoop, Spark",3.7,"Bottomline Technologies
3.7",Bengaluru,"Portsmouth, NH",1001 to 5000 employees,1989,Company - Public,Computer Hardware & Software,Information Technology,₹10 to ₹50 billion (INR),-1
Scientist- Fermentation,-1,"Position: Scientist- Fermentation

Location: Bangalore, India

Contact: Please email admin@stringbio.com

No of Openings: 1

Fermentation scientist will play a significant role in the upstream process development. Core responsibilities include executing bench-scale fermentation with the goal of maximizing yields. Scientist will be responsible for evaluating fermentation performance of new strains. The ideal candidate will also possess a strong background in computational science and bacterial physiology.

POSITION RESPONSIBILITIES

Design, execute, and analyze scientific experiments for production of small molecules using fermentation and other techniques.

Reliable execution and management of fermentation runs as per company SOPs
Develop and optimize fermentation processes using DOE/Statistical analysis.
Seek and qualify new technologies that are enabling for accomplishing project objectives.
Collaborate with research teams for maximizing strain performance and enabling process scale up
Leverage computational modeling for developing algorithms for clustering and ranking unit operations and predicting performance
Implement Design-of-Experiment & Statistical Process Control principles for efficiently studying response variables and assessing data quality
Test product designs using models and computer-aided design technology
Possess knowledge on leveraging computational fluid dynamics for design of efficient bioprocesses
Identify new systems and processes to drive quality, efficiency and save costs
Maintain accurate and timely records of laboratory work. Evaluate data, prepare technical reports and make scientific presentations.
Be a conscientious laboratory citizen, adhere to EH&S standards, and use knowledge of laboratory procedures to advance projects.
The position is full-time. Work schedule may occasionally include weekend.

CANDIDATE PROFILE

EDUCATION AND EXPERIENCE

Advanced degree in Biotechnology/Chemical Engineering or Mechanical engineering field.
PhD plus a minimum of 2 years of experience in a scientific or engineering discipline
MTech in chemical/Mechanical Engineering/Biotechnology Engineering discipline with 5 years of experience
Proven ability to work with colleagues of diverse training, background, and experience level
Effectiveness as both a team player and while working independently
Capacity to organize and manage multiple tasks and relationships simultaneously
Keen problem-solving skills and a strong work ethic
Ability to align technical work plans with business and customer objectives.
Digital fluency, including experience with MS Office, statistical analysis and DOE and CFD tools.
Schedule flexibility necessary to support occasional problem-solving during off-hours
Readiness to shoulder responsibility
Demonstrated ability to deliver results in a fast-paced and dynamic environment

PERSONAL QUALITIES

Driven, dedicated team player with attention for detail

Ability to work independently and deliver on project objectives

Capacity to be proactive and take initiatives

Good organizational skills

Effective interpersonal skills

Strong oral and written communication skills

Creative, out of the box thinker with strong analytical and problem-solving capabilities

Ability to adapt to changing drivers",4.7,"String Bio
4.7",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"Experience: 0 to 3 Years
Role and Responsibilities
Primary role will be to understand the daily challenging problems, perform analysis and help team make informed decisions with data and visualizations.
Responsible for monitoring IoT devices and finding patterns that can help identify anomaly and device failures.
Monitoring and analysing important metrics.
Scripting and automating the processes and reports.
Every day is a new challenge; hence you will always be learning new things and tools to help solve the problems.
Essential Skills
Good knowledge in Mathematics, Statistics and Computer Science.
Ability to communicated findings in a clear and intuitive way.
Strong hold on python and data analysis libraries – pandas, numpy (scikit-learn is an added advantage)
Good understanding of data bases and SQL.
Well versed with MS office tools mainly Excel.
Experience in delivering data analysis and visualization projects – experience in machine learning is a bonus.
Ability to understand, articulate the problem and come up with mathematical solutions.
Motivated and natural curiosity in solving problems.
Knowledge of these tools is an added advantage – Tableau, Python-Dash, any other Visualization tools.
Qualifications and Education Requirements

BE/ BTECH/MSc in a related field (M. Tech. preferred)

Preferred Skills

Participation in online projects or competitions on data analysis",3.9,"Netradyne
3.9",Bengaluru,"San Diego, CA",1 to 50 employees,-1,Contract,-1,-1,₹10 to ₹50 million (INR),-1
Analyst - Data Science,-1,"Responsibilities :
Data Scientist with Machine Learning, Python & R Programming Experience.
Good Attitude and Communication skills, SQL, Excel Macros.
Good to have exposure Reports and Risk analysis.
Strong hands on SQL (RDBMS)- Data mining.

Required Skills :
Experienced in Data Science and Data Analysis.
Hands on R Programming/ Basic SQL.
Knowledge on Investment Banking Domain (BFSI) added Advantage.
Good knowledge into reporting.
Good knowledge in Excel/PIVOT/MACROS/ Excel functions.

Primary Skills :
Data Science
Machine Learning
Python & R programming

Good to have :
SQL Seam framework
Excel Macros
BFSI Vertical knowledge
Experience 3 to 6 Years
Industry Type IT Software, Software Services
Role Software Developer/Senior Software Developer
Functional Area Application Programming, Maintenance
Education UG – Any Graduate – Any Specialization PG – Any PG Course – Any Specialization
Location Bangalore
Email referral@nuware.com
Website www.nuware.com",3.6,"Nuware Systems
3.6",Bengaluru,"Iselin, NJ",51 to 200 employees,1994,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Data Science Engineer,-1,"We are looking for a Data Scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company's data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance

Skills and Qualifications
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. (excellence in at least one of these is highly desirable)
Great communication skills
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills in Ruby and Python
Data-oriented personality",3.9,"Involvio
3.9",Bengaluru,"New York, NY",1 to 50 employees,-1,Company - Private,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Data Scientist II,-1,"Position Title
Data Scientist II

30-Jun-2020

Job ID
291180BR

Job Description
20+ brands catering to 50+ disease areas! The team of Novartis specialists within Insights & Analytics are on a data and digital transformation journey, leveraging analytics to generate actionable insights for Novartis medicines impacting more than 500 million patients worldwide. The team is poised to enable easier, faster and reliable decisions for Novartis divisions across the globe.

• Understand complex and critical business problems from Country/Regional/Global business functions, formulate integrated analytical approach to mine data sources, employ statistical methods and machine learning algorithms to discover actionable insights and automate process for reducing effort and time for repeated use. Able to use business presentations, smart visualization tools and contextual story-telling to translate findings back to business users with a clear impact on ROI Through strong subject matter expertise and role modelling skills, guide the Business Analytics team in Hyderabad to enable delivery of analytical insights to the commercial stakeholders worldwide. Coach and mentor aspirant SMEs in Business Analytics team at Hyderabad in line with Novartis people development requirements and Novartis Values and Behaviours. No direct team management.

• Provide solutions for a variety of business applications including but not limited to: Customer Segmentation & Targeting, Event Prediction, Propensity Modelling, Churn Modelling, Customer Lifetime Value Estimation, Forecasting, Recommender Systems, Modelling Response to Incentives, Marketing Mix Optimization, Price Optimization. Develop automation for repeatedly refreshing analysis and generating insights. Collaborates with globally dispersed internal stakeholders and cross-functional teams to solve critical business problems, drive operational efficiencies, and deliver successfully on high visibility strategic initiatives. Understands commercial data sources including sales, contracting, promotions, social media, patient claims and Real World Evidence. Makes right choices from a breadth of tools, data sources and analytical techniques to answer a wide range of critical business questions. Articulates solutions/recommendations to business users. Presents analytical content concisely and effectively to non-technical audiences and influences non-analytical business leaders to drive major strategic decisions basis analytical inputs. Project manages critical initiatives: plans proactively, anticipates and actively manages change, sets stakeholder expectations as required, identifies operational risks and independently drives issues to resolution, balances multiple priorities and minimizes surprise escalations. Works closely with MES Function Head, Business Analytics Group Head and Regional Account Directors to shape strategy and build capability (including hiring and training) for advanced analytics delivery. Works with other teams (Forecasting, Sales Force Effectiveness, Pricing and Access etc.) at PLS Hyderabad to leverage cross-functional learnings and synergies. Ensures exemplary communication with all stakeholders including internal PLS associates and senior business leaders across Novartis. Acts as an evangelist and catalyst for innovation in BI & Analytics . Grooms Subject Matter Experts, and mentors associates for higher responsibilities. Identifies learning needs for analyst teams and plans for training implementation in alignment with training manager to expand NGSC capabilities. Identifies key skill requirements for the Business Analytics team and facilitates design and content creation for knowledge repositories and training material
• Quality of insights generated and solutions provided, with quantified business impact / ROI .Effective communication with PLS and Country/Regional/Global stakeholders .Executes agreed targets for self .Define and execute development plans for potential Subject Matter Experts . Find creative ways to build team capabilities and play a direct role in driving a culture of innovation. Values and Behaviours: in line with leadership standards of Novartis

Minimum requirements
• Graduate or Post-graduate or Ph.D. in any quantitative discipline, e.g. Statistics, Applied Mathematics, Econometrics, Computer Science, Engineering, Operations Research. MBA preferred English
• 8+ years of hands-on experience in analytics. Experience with a leading pharma or service provider highly desirable
• Extensive experience in Statistical and Machine Learning techniques like Regression (Linear/Logit/Gamma), Clustering (K-Means/Modes/Hier), Decision Trees, Text Mining and Natural Language Processing, Stochastic models, Bayesian Models, Markov Chains, Monte Carlo Simulations, Non-linear Time Series, Dynamic Programming and Optimization techniques,Design of Experiments, Neural Networks, Statistical Inference,Collaborative Filtering, Feature Engineering, etc.
• Extensive experience in working with large-scale datasets (in bigdata architecture, data lake, data mart, data warehouse). Demonstrateduse of analytical packages and query languages such as SAS, R, SQL,SPSS, Matlab, Alteryx
• Experience in Big Data platforms like Hadoop eco-system (i.e. Hive, Pig, Sqoop, Mahout), other large scale computing systems (e.g. COSMOS,MapReduce) or modern coding languages

799 million. That’s how many lives our products touched in 2019. And while we’re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people’s lives?

We believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you’re given opportunities to explore the power of digital and data. Where you’re empowered to risk failure by taking smart risks, and where you’re surrounded by people who share your determination to tackle the world’s toughest medical challenges.

Job Type
Full Time

Country
India

Work Location
Hyderabad, AP

Functional Area
BD&L & Strategic Planning

Division
NBS

Business Unit
PLS NBS

Employment Type
Regular

Company/Legal Entity
Nov Hltcr Shared Services Ind

Shift Work
No",3.9,"Novartis
3.9",Hyderabad,"Basel, Switzerland",10000+ employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
Data Engineer (New Grad) - India UHR,-1,"Job Description – Data Engineer


In Cisco, we have an outstanding opportunity where we actually get to use the technology we build!

We are Innovators


We drive innovation to propel business transformation while maintaining operational quality.

We are Accelerators


We accelerate digital solutions to generate cost savings and efficiency gains for enterprise growth and success.

We are Transformers


As customer zero, we transform the customer experience by being our own customer first with agility, quality, and security, we continuously deliver business outcomes for our clients.

What You’ll Do


Builds / oversees platforms and systems to manage and store data from internal and external sources by leveraging both distributed and local structures

Establishes processes / structures based on business and technical requirements to channel data from multiple inputs and route appropriately using data structures available

Develops tools to facilitate data integration, analytics, data cleaning / transformation, and the deployment of ML/AI models

Creates and establishes design standards and assurance processes for software, systems and applications development to ensure compatibility and operability of data connections, flows and storage requirements

Participate in a variety of professional development opportunities, network with senior executive leadership team, give back to your local community, and socialize with a community of global technologists.

Who You Are
Currently pursuing a Masters of Engineering degree in Computer Science or Information Science
CGPA of 8.0 (out of 10) and above
The requirement is for 2021/22 passout only.
Excellent written and verbal communication skills. Must be fluent in English.
Savvy problem-solving instincts and abilities
Comfortable in fast-paced and multidimensional environments
Ability to work efficiently as part of a collaborative team
Diligent to detail
Proficient in software development with a focus in data/data systems (Java, C/C++), databases (SQL, Postgres, Mongo) and development technologies (GIT, JIRA)
Possesses knowledge of data pipelining, data integration, data warehouses, and databases
Why Cisco


At Cisco, each person brings their unique talents to work as a team and make a difference. Yes, our technology changes the way the world works, lives, plays and learns, but our edge comes from our people.

We connect everything – people, process, data and things – and we use those connections to change our world for the better.

We innovate everywhere - From launching a new era of networking that adapts, learns and protects, to building Cisco Services that accelerate businesses and business results. Our technology powers entertainment, retail, healthcare, education and more – from Smart Cities to your everyday devices.

We benefit everyone - We do all of this while striving for a culture that empowers every person to be the difference, at work and in our communities.

So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture enthusiast? Many of us are. Passion for technology and world changing? Be you, with us!

Disclaimer - “Please note this posting is to advertise potential job opportunities. The requirment is for 2021 /22 passout only. This exact role may not be open today, but could open in the near future. When you apply, a Cisco representative may contact you directly if a relevant position opens.”",4.3,"Cisco Systems
4.3",Bengaluru,"San Jose, CA",10000+ employees,1984,Company - Private,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Alcatel-Lucent, Juniper Networks"
Data Analyst,-1,"Data Analyst, Operational Data Intelligence


The Who, What, Why and Where

Twilio is growing rapidly and seeking a Data Analyst to be a key member of the Observability organization's Operational Intelligence Engineering team in Bangalore, India. You will be joining one of the first teams of engineers in our new Bangalore office and as the first Data Analyst, with an opportunity to help define our technical and team culture in India. You will also help us build solutions that deliver actionable intelligence from a number of mission-critical systems, ensuring that Twilio is the leader in trusted communications. A successful candidate will be a self-starter, embody a growth mindset, collaborate effectively, can mentor junior engineers and operate highly resilient services.

Who?

Twilio is looking for a strong data analyst who lives the Twilio Magic and has a demonstrated track record of working with data, specifically; sourcing and integrating data from multiple disparate backend data sources, developing business intelligence solutions and applying a deep analytics background to assess business performance and deliver actionable insights to improve efficiency and increase productivity. You should also have:
You have a Master's Degree or equivalent in Information Systems, Business, Industrial Engineering, Statistics, or Computer Science
You have 5+ years experience in a data analyst role and have proficiency in statistical tools to do descriptive, predictive and diagnostic analyses
You have 5+ years experience creating complex SQL statements.
You have 5+ years experience in custom ETL design, implementation and maintenance.
You have 5+ years experience working with BI tools like Looker, Tableau.
You have 5+ years of experience working with Hive, Presto, Redshift, Snowflake etc.
You have 5+ years experience with schema design and dimensional data modeling.
You have a proficiency in AI and ML.
You are proficient in at least one major language such as Python, Scala, or Java.
You have strong analytical skills with the ability to collect, organise, analyse, and disseminate significant amounts of information with attention to detail and accuracy
You have strong communication skills, and can effectively partner with analysts, product managers, engineers from across the business (Finance, Sales, Marketing, etc.)
What?

As a Data Analyst on the Operational Data Intelligence team, you will:
Work directly with the business (primarily GMs, engineers and product managers) to define the datasets, reports, dashboards they need to run their product engineering organizations
Build and launch robust data processing pipelines and integrations, while simultaneously optimizing for performance and stakeholder requirements.
Build data sets that provide trends and insights into engineering operational data: quality, performance, defects, deployment velocity, etc
Ensure uptime and performance of data warehouse system.
Why?

Twilio has democratized communications channels like voice, text, chat, and video by virtualizing the world's telecommunications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world's most demanding applications.

The Operational Intelligence Engineering team is central to Twilio's continued growth. Our mission is to provide actionable insights from a vast number of different systems leveraged by product engineering teams to build, deliver, and operate their globally distributed services, arming them with the knowledge they need to continuously improve their quality, security, velocity, and efficiency. To do this we need to continue to develop and evolve our products and services and ensure they are able to scale; driving Twilio to new heights of scale.

Twilio is a company that is empowering the world's developers with modern communication in order to build better applications. Twilio is truly unique; we are a company committed to your growth, your learning, your development, and your entire employee experience. We only win when our employees succeed and we're dedicated to helping you develop your strengths. We have a cultural foundation built on diversity, inclusion, and innovation and we want you and your ideas to thrive at Twilio.

Where?

This position will be located in our office in Bangalore, India. You will enjoy our office perks: catered meals, snacks, game room, ergonomic desks, massages, bi-weekly All Hands and more. What you will also get to experience is a company that believes in small teams for maximum impact; seeks well-rounded talent to ensure a full perspective on our customers' experience, understands that this is a marathon, not a sprint; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves.

About Us

Millions of developers around the world have used Twilio to unlock the magic of communications to improve any human experience. Twilio has democratized communications channels like voice, text, chat, video and email by virtualizing the world's communications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world's most demanding applications. By making communications a part of every software developer's toolkit, Twilio is enabling innovators across every industry — from emerging leaders to the world's largest organizations — to reinvent how companies engage with their customers.",4.0,"Twilio
4.0",Bengaluru,"San Francisco, CA",1001 to 5000 employees,2008,Company - Public,Internet,Information Technology,₹100 to ₹500 billion (INR),-1
Data Engineer (New Grad) - India UHR,-1,"Job Description – Data Engineer


In Cisco, we have an outstanding opportunity where we actually get to use the technology we build!

We are Innovators


We drive innovation to propel business transformation while maintaining operational quality.

We are Accelerators


We accelerate digital solutions to generate cost savings and efficiency gains for enterprise growth and success.

We are Transformers


As customer zero, we transform the customer experience by being our own customer first with agility, quality, and security, we continuously deliver business outcomes for our clients.

What You’ll Do


Builds / oversees platforms and systems to manage and store data from internal and external sources by leveraging both distributed and local structures

Establishes processes / structures based on business and technical requirements to channel data from multiple inputs and route appropriately using data structures available

Develops tools to facilitate data integration, analytics, data cleaning / transformation, and the deployment of ML/AI models

Creates and establishes design standards and assurance processes for software, systems and applications development to ensure compatibility and operability of data connections, flows and storage requirements

Participate in a variety of professional development opportunities, network with senior executive leadership team, give back to your local community, and socialize with a community of global technologists.

Who You Are
Currently pursuing a Masters of Engineering degree in Computer Science or Information Science
CGPA of 8.0 (out of 10) and above
The requirement is for 2021/22 passout only.
Excellent written and verbal communication skills. Must be fluent in English.
Savvy problem-solving instincts and abilities
Comfortable in fast-paced and multidimensional environments
Ability to work efficiently as part of a collaborative team
Diligent to detail
Proficient in software development with a focus in data/data systems (Java, C/C++), databases (SQL, Postgres, Mongo) and development technologies (GIT, JIRA)
Possesses knowledge of data pipelining, data integration, data warehouses, and databases
Why Cisco


At Cisco, each person brings their unique talents to work as a team and make a difference. Yes, our technology changes the way the world works, lives, plays and learns, but our edge comes from our people.

We connect everything – people, process, data and things – and we use those connections to change our world for the better.

We innovate everywhere - From launching a new era of networking that adapts, learns and protects, to building Cisco Services that accelerate businesses and business results. Our technology powers entertainment, retail, healthcare, education and more – from Smart Cities to your everyday devices.

We benefit everyone - We do all of this while striving for a culture that empowers every person to be the difference, at work and in our communities.

So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture enthusiast? Many of us are. Passion for technology and world changing? Be you, with us!

Disclaimer - “Please note this posting is to advertise potential job opportunities. The requirment is for 2021 /22 passout only. This exact role may not be open today, but could open in the near future. When you apply, a Cisco representative may contact you directly if a relevant position opens.”",4.3,"Cisco Systems
4.3",Bengaluru,"San Jose, CA",10000+ employees,1984,Company - Private,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Alcatel-Lucent, Juniper Networks"
CIEL/SEL/13974: Data Scientist,-1,"Manage a team of data scientists, machine learning engineers and big data specialists
Lead data mining and collection procedures
Proven experience as a Data Scientist or similar role
Solid understanding of machine learning
Knowledge of data management and visualization techniques
A knack for statistical analysis and predictive modeling
Good knowledge of R, Python and MATLAB
Experience with SQL and NoSQL databases
Strong organizational and leadership skills
Excellent communication skills
A business mindset
Ensure data quality and integrity
Interpret and analyze data problems
Conceive, plan and prioritize data projects
Build analytic systems and predictive models
Test performance of data-driven products
Visualize data and create reports
Experiment with new models and techniques
Align data projects with organizational goals
Degree in Computer Science, Data Science, Mathematics or similar field",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
"Associate Analytics consultant, Analytics consultant, Senior Analytics consultant (DS)",-1,"If you are interested, please email your resume to us at recruitment@quantzig.com
Job Location: Bangalore

Experience: 1+ years

Key Skills: Data science, machine learning, SQL, python, RR / Python. Master-level skills in SQL and query languages Sound knowledge of the fundamentals of machine learning statistics

Roles & Responsibilities:
Individuals who are passionate to make an impact with high degree of work ownership and are self-driven.
You should be creative and passionately curious about exploring data to deliver impactful business insights
Experience in delivery and client facing roles from major analytics service providers in the industry are preferred
You should possess customer-centric thought process and is able to understand client’s business processes with ease, identify problems with precision and develop customized, accurate analytical solutions

Desired Profile:
Should have 4+ years of experience in executing analytics assignments across industries
Be a consultant to our clients. Think out-of-the-box and develop visualization solutions which help clients in solving their business problems
Tremendous passion towards learning is a must. You must be able to merge the art of consulting and the science of Design in visualization
Drive and energy to work hard and achieve success in an entrepreneurial environment
Should have hands-on experience in delivering projects across multiple industries and analytics areas (e.g. Supply chain analytics, Marketing Analytics, Customer Analytics, Digital Analytics, Pricing Analytics etc.)
Deep understanding of analytics/statistical models, tool kits and visualization tools. Should have working knowledge of a variety of classification and predictive models (Lasso regression, Ridge regression, decision trees, gradient descent models, etc
Strong communication, storyboarding and presentation skills
Understand the statistical mechanics behind modeling techniques
Understand efficient coding standards and has a knack to plan for QC checks before coding.
Added advantage if you understand Cloud hosting, customizing visualization tools using DAX, data integration with analytical data-streams",3.3,"Quantzig
3.3",Bengaluru,"London, United Kingdom",Unknown,-1,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
"QA Lead for Machine Learning( Engineer,Sr Staff/Mgr)",-1,"Company:
Qualcomm India Private Limited
Job Area:
Engineering Group, Engineering Group > Software Engineering
Job Overview:


Qualcomm is a company of inventors that unlocked 5G ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5Gs potential into world-changing technologies and products. This is the Invention Age - and this is where you come in.

Join a new and growing team at Qualcomm focused on advancing state-of-the-art in Machine Learning. The team uses Qualcomm chips extensive heterogeneous computing capabilities and engineers them to allow the running of trained neural networks on device without a need for connection to the cloud. Our inference engine is designed to help developers run neural network models trained in a variety of frameworks on Snapdragon platforms at blazing speeds while still sipping the smallest amount of power. See your work directly impact billions of mobile devices around the world.
In this position, you will lead 20+ member strong technical team and responsible for the QA (test development and execution) and CI/CD infrastructure of Qualcomm ML Software. You will work with neural network frameworks like Caffe, Caffe2 and TensorFlow and develop the validation framework to gauge functionality, performance, precision and power of SNPE (Snapdragon Neural Processing Engine). You will work with the latest and greatest DNNs emerging from the research community. You will also have to keep up with the fast pace development happening in the industry and academia to continuously enhance our benchmarking and validation infrastructure from software engineering as well as machine learning standpoint. In addition, youd be responsible to ensure to setup the CI/CD infrastructure that integrates/validates/releases all the changes for a smooth nightly quality assurance. The team strives to minimize manual interventions and looks to use state of the art in the field of DevOps to achieve the most resilient and reliable infrastructure for this. Youll be required to not only maintain/enhance the existing infrastructure but also bring in your ideas to remove any inefficiencies in the process. You are responsible for SNPE, ANN (Android Neural Network) and other product releases from Qualcomm across multiple chipsets.

Minimum Qualifications
Live and breathe quality software development with excellent analytical, and debugging skills
Experience with at least one machine learning framework like TensorFlow, Caffe, Pytorch, etc.
Well versed in version control tools, CI tools like git, repo, Jenkins
Expert in DevOps fundamentals, lives by Infrastructure-as-code principles
Strong understanding of Deep Learning fundamentals
Strong development skills in Python
Excellent communication skills (verbal, presentation, written)
Ability to collaborate across a globally diverse team and with stakeholders/ leads across geographies
12 to 14 years of relevant work experience in software test development and DevOps
3 to 4 years of experience in leading the teams technically and handling line management responsibilities

Preferred Qualifications
Experience with ML Application development
Experience with Docker and orchestration frameworks like ansible, chef etc..
Experience in Android(AOSP) or embedded Linux application development
Development experience in C++

Applicants: If you need an accommodation, during the application/hiring process, you may request an accommodation by sending email to accommodationsupport

To all Staffing and Recruiting Agencies: Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications.",4.0,"Qualcomm
4.0",Hyderabad,"San Diego, CA",10000+ employees,1985,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Intel Corporation, MediaTek, Broadcom"
Data Analyst,-1,"x
Data Analyst

Designation : Senior Data Scientist
Experience : 7-9 years of experience of which at least 6-7 must be hands on in DataScience related work
Location: Bangalore

Desired Skills and Experience

Expert understanding and demonstrated skills of using ""R"". Exposure to SAS, Python, SPSS,Julia etc also an advantage.
Excellent ability to assimilate multi-disciplinary problems across industries, createhypotheses and craft solutions using data science skills and techniques.
Bring together different technologies to solve a problem.
Strong understanding of databases, file systems (big data stores, especially) anddatabase/SQL languages.
Very strong articulation skills. Articulation skills are both oratory and written.

Responsibilities

The individual will be a designer of solutions that address specific business outcomes. These will be across industries and functions and must be designed generically to handle reuse. Sometimes the questions will be unknown, which theindividual must creatively discover and solve.
Solutions will be complete packages of BI and advanced data science related models in ""R"".
The individual will understand the nanobi platform and lead the integration of the models and deliver the solutions on the nanobi platform for client deployment.
Work very closely with sales, pre-sales and consulting to understand customer problem specifics and solve them for wider application. In this, the individual mayhave to spend time closely at customer locations.
Must provide direction and leadership to Jr. Data Scientist in their model development.
Will also have to work with functional experts in other teams to build out businessrepresentations of the data science Work.",3.0,"Nanobi Data & Analytics
3.0",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"You will design and operationalize various kinds of descriptive, predictive and prescriptive analytics and data science relevant in the planning space. Understand business; identify areas of improvement opportunities; collect and analyze data; build models in R/Python, and present results & insights using the o9 platform.

About o9 team
Who is o9?
Smart. Simple. Fun. All words to describe our environment at o9 Solutions. An exciting and high energy environment that drives us to grow and AIM 10x. The perfect place to be innovative, collaborative and dynamic as an organization. We are always looking for great talent to join our o9 team.

Company Overview
o9 is the premier AI-powered platform for driving digital transformations of integrated planning and operations capabilities. We help enterprises to digitally transform their supply chain with a cloud-based platform that connects the supply chain end-to-end. Whether it is driving demand, aligning demand and supply, or managing P&L, any process can be made faster and smarter with o9’s AI-powered digital solutions.

Our headquarters is located in Dallas, and we currently have offices in Amsterdam, Barcelona, Bangalore, Tokyo, and Seoul. We expanded our value-adding activities to companies including Google, Nike, Walmart, Starbucks, Bridgestone, Caterpillar, Pirelli, General Electric, etc.
Job description:

What you’ll be doing:
Own End to end discovery, design, configuration, testing and deployment of analytical models and communication with internal and external stakeholders
Apply a variety of machine learning techniques (clustering, regression, ensemble learning, neural nets, time series, optimizations etc.) to their real-world advantages/drawbacks
Develop and deploy models for demand sensing/forecasting, optimization (Heuristic, LP, GA etc), Anomaly detection, Simulation and stochastic models, Market Intelligence etc.
Use latest advancements in AI/ML to solve business problems
Analyse problems by synthesizing complex information, evaluating alternate methods, and articulating the result with the relevant assumptions/reasons
Application of common business metrics and the ability to generate new ones as needed
Work collaboratively with Clients, Project Management, Solution Architects, Consultants and Data Engineers to ensure successful delivery of o9 projects
Guide junior data scientists and oversee their activities to ensure proper alignment/execution of their activities, and maintain high coding standards and best practices within an organization
What you are/need:

Mandatory:
5+ years of experience in the field of Data Science and Analytics
Strong programming skills and experience in using Python and/or R for Data Science
Strong analytical techniques, data mining knowledge and proficiency in handling and processing large amounts of data is needed
Deep Knowledge of statistical and machine learning algorithms
Experience in time series forecasting in scale using heuristic based hierarchical best-fit models using algorithms like exponential smoothing, ARIMA, prophet and custom parameter tuning
Experience in building scalable ML frameworks for demand sensing including Identifying and collecting relevant input data, feature engineering, tuning and testing.
Experience in applied analytical methods in the field of Supply chain and planning, like demand planning, supply planning, market intelligence, optimal assortments/pricing/inventory etc.
Strong presentation and communications skills with the ability to communicate complex analytical or technical concepts to audiences with a limited analytical or technical background
Bachelors Degree in Computer Science, Mathematics, Statistics, Economics, Engineering or related field

Nice to have:
Experience with SQL, databases and ETL tools or similar is optional but preferred
Exposure to distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, or related Bid Data technologies
Experience with Deep Learning frameworks such as Keras, Tensorflow or PyTorch is preferable but not essential
Experience in implementing planning applications will be a plus
Understanding of Supply Chain Concepts will be preferable
Masters Degree in Computer Science, Applied Mathematics, Statistics, Engineering, Business Analytics, Operations, or related field


What you get:
Exposure to the biggest brands in the world
Work on the development and application of cutting-edge technology and data science concepts
International working environment
Flexible working schedule
A flat organization with a very strong entrepreneurial culture (and no corporate politics)
A great team to support you and that you can support
Possibility to really make a difference in a scale-up environment
o9 is an equal opportunity employer and seeks applicants of diverse backgrounds and hires without regard to race, colour, gender, religion, national origin, citizenship, age, sexual orientation or any other characteristic protected by law.",3.2,"o9 Solutions, Inc.
3.2",Bengaluru,"Dallas, TX",501 to 1000 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹5 to ₹10 billion (INR),-1
Data Scientist - QuantumBlack,-1,"As a data scientist at QuantumBlack:

You will work in multi-disciplinary environments harnessing data to provide real-world impact for organisations globally. You will influence many of the recommendations our clients need to positively change their businesses and enhance performance.

Role responsibilities
Work on complex and extremely varied data sets from some of the world’s largest organisations to solve real world problems
Develop data science products and solutions for clients as well as for our data science team
Write highly optimized code to advance our internal Data Science Toolbox
Work in a multi-disciplinary environment with specialists in machine learning, engineering and design
Add real-world impact to your academic expertise; you will be encouraged to write ‘black’ papers and present at meetings and conferences should you wish
Attend conferences such as NIPS and ICML as one global team and data science retrospectives where you will have the opportunity to share and learn from your colleagues
Work within one of the largest and most advanced data science teams in London, and support the lead data scientists to develop data science products
What you’ll learn
How successful projections on real world problems across a variety of industries are completed through referencing past deliveries of end to end machine learning pipelines
Build products alongside the core engineering team and evolve the engineering process to scale with data, handling complex problems and advanced client situations
Be able to focus on modelling by working alongside the Data Engineering team which focuses on the wrangling, clean-up and transformation of data.
Best practices in software development and productionise machine learning by working with our Machine Learning Engineering teams which optimise code for model development and scale it
Work with our UX and Visual Design teams to interpret your complex models into stunning and user-focused visualisations
Using new technologies and problem-solving skills in a multicultural and creative environment
You will work on the frameworks and libraries that our teams of Data Scientists and Data Engineers use to progress from data to impact. You will guide global companies through data science solutions to transform their businesses and enhance performance across industries including healthcare, automotive, energy and elite sport.
Real-World Impact – No project is ever the same; we work across multiple sectors, providing unique learning and development opportunities internationally.
Fusing Tech & Leadership – We work with the latest technologies and methodologies and offer first class learning programmes at all levels.
Multidisciplinary Teamwork - Our teams include data scientists, engineers, project managers, UX and visual designers who work collaboratively to enhance performance.
Innovative Work Culture – Creativity, insight and passion come from being balanced. We cultivate a modern work environment through an emphasis on wellness, insightful talks and training sessions.
Striving for Diversity – With colleagues from over 40 nationalities, we recognise the benefits of working with people from all walks of life.
Our projects range from helping pharmaceutical companies bring lifesaving drugs to market quicker to optimising a Formula1 car’s performance. At QuantumBlack you have the best of both worlds; all the benefits of being part of one of the leading management consultancies globally and the autonomy to thrive in a fast growth tech culture:
Healthcare Efficiency – We helped a healthcare provider improve their clinical trial practices by identifying congestion in diagnostic testing as a key indicator of admissions breaches.
Environmental Impact – We designed and built the first data-driven application for a state of the art centre of excellence in urban innovation by collecting real-time data from environmental sensors across London and deploying proprietary analytics to find unexpected patterns in air pollution.
Product Development – We worked with the CEO of an elite automotive organisation to reduce the 18-month car development timeframe by improving processes, designs and team structures.
Visit our Careers site to watch our video and read about our interview processes and benefits

As an equal opportunity employer, QuantumBlack encourages applications from all backgrounds regardless of gender, race, disability, pregnancy, marital status, age, sexual orientation, gender reassignment, religion or belief. We maintain a sense of community rooted in respect and consideration for all employees where any evaluation is based simply upon individual work and team performance.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Science & Machine Learning Internship,-1,"About the company:
MyWays is a startup by IIT Delhi alumni. We offer a career guidance platform that uses psychometric to help students explore themselves as well as the opportunities in order to make better decisions.

About the internship/job:
MyWays is looking for a machine learning (ML) intern with experience in designing software architecture to help us with product development. Selected intern's day-to-day responsibilities include: 1. Handling big projects in software development in machine learning/data science 2. Understanding data mining, machine learning, deep learning, data structures, data modeling, and software architecture Perks: 1. Challenging growth environment 2. Quality mentorship 3. Ownership of the work 4. PPO with handsome ESOPs (for the right startup enthusiast)

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 6th Jul'20 and 10th Aug'20
are available for duration of 6 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Other requirements:
Candidate needs to be passionate about technology and a staunch believer of state-of-the-art engineering and software practices with excellent analytical skills Technical understanding of NLP techniques, data mining, statistics, and artificial intelligence is necessary Knowledge about databases (SQL, MongoDB) is a big plus Deep knowledge of maths, probability, statistics, and algorithm design Ability to write robust code in Python Familiarity with machine learning frameworks (like TensorFlow or PyTorch), libraries (like sci-kit-learn, Pandas, NumPy) and for deployment frameworks(flask or Django, FastAPI) Should be familiar with AWS services, deployment and have basic knowledge of shell scripting (Linux) Familiarity with Big Data Technologies (Hadoop, Apache Spark, etc.) is a plus

Number of internships/jobs available: 1

Categories: Data Science,Machine Learning",5.0,"MyWays
5.0",New Delhi,"New Delhi, India",1 to 50 employees,2018,Company - Private,Colleges & Universities,Education,₹10 to ₹50 million (INR),-1
Data Analyst,-1,"Employment Type
Permanent
Closing Date
13 Aug 2020 11:59pm
Job Title
Data Analyst
Job Description


Telstra is Australia’s leading telecommunications and technology company, with operations in more than 20 countries, including in India where we’ve launched our new Innovation and Capability Centre (ICC) in Bangalore.

We’re combining innovation, automation and technology to solve the world’s biggest technological challenges in areas such as Internet of Things (IoT), 5G, Artificial Intelligence (AI), Machine Learning, and more. Join us on this exciting journey, and together, we’ll reimagine the future.

Our Software Engineering teams are building a new platform to support Microservice APIs, developed by our teams of developers spread across the globe. We're using industry leading technologies and design principles to encourage best practice application design / development and operation, such as automation and CI/CD.

As a Data Analyst, you thrive on collaborating with your team and providing valuable data analysis to support stakeholders and team members to deliver technical analysis and research that enables successful business initiative/mission design and delivery, and ongoing technical capability operational performance. You will be responsible to interpret data and turns it into information which can offer ways to improve a business, thus affecting business decisions. You need to gather information from various sources and interpret patterns and trends. Once data has been gathered and interpreted, the you will report back what has been found in a comprehensive study to the wider business/relevant colleagues. As a member of the team and data custodian, you will have a big impact on supporting the delivery of customer value in the data integration and platform extension space.

In this role, your key responsibilities are…
Contribute to the delivery of data engineering and design across multiple projects and functional areas to enable the execution of the data strategy.
Take ownership of your own work to contribute to the creation of robust and automated pipelines to ingest and process structured and unstructured data from source systems into analytical platforms.
Contribute to proposals for better system designs / architecture to build reliable data flows, combining analytical batch processing, real-time data flows and low-latency APIs.
Apply a breadth of knowledge within data engineering to contribute to the management and maintenance of data and automation platforms through their lifecycles. Ensure information security by adhering to security guidelines.
Create high quality, readable, testable, scalable and extensible code that is sustainable.
Collaborate with business users and technical resources, with support/direction from more experienced team members, to evaluate new features and architecture, contributing to solving challenging problems at scale. Collaborate with other specialists (e.g. data architects and business analysts) to understand the business goals and contribute to the design of optimal data modes that enable access to data for different types of users.
Participate in improving data quality across our data pipelines and supporting the implementation of system controls for managing data quality, supporting, remediating and updating platforms (DevOps).
Seek input from others to research data questions and provide suggestions for intelligent approaches to help detect and root cause the outliers in data models.
Actively contribute to a culture of continuous delivery and agile development by supporting team-based planning activities, writing scrum team stories and collaborating with other scrum team members to estimate and deliver work inside of a sprint.
Seek out expertise and best practice models inside and outside the team to grow and develop depth / advanced levels of knowledge in data engineering.
To be successful in the role, you must have…
Degree level IT qualifications in Software or Systems Engineering.
Minimum 5 years of experience in experience in analyzing and solving complex business problems by analysing data.
Extensive experience in Hortonworks on Hadoop.
Extensive experience in SQL, Hive, Spark, Ambari, Zeppelin.
Ability to develop understanding of system and process consumption of data under analysis.
Proficient in Agile / Scrum practices.
Experience in SQL Programming and Multi-tenant Databases.
Ability to perform data profiling and derive insights to inform business and solution design decisions.
Ability to prepare data remediation inputs for automated and manual remediation.
Ability to establish & monitor data governance and quality process to identify opportunities for enhancement and automation.
Excellent problem solving and analytical skills.
Desirable to have experience on:
MS Azure
Power BI
Our people in India will be at the forefront of technological change as they work collaboratively with, and learn from, world-class experts and have access to the latest training programs and insights for their field.

Alongside your work on leading edge projects, working with us means you'll have access to company perks and benefits that'll reward you for the great work you do. We’re growing, fast, and for you that means many exciting opportunities to develop your career with us at Telstra.

Interested?

If you're excited about the opportunity to be part of a team, committed to delivering amazing experiences for our customers – your next step is to apply!

We’re committed to building a diverse and inclusive workforce. To enable everyone to participate, we’ve developed an ‘All Roles Flex’ policy to consider flexible ways of working for every role. To learn more, visit our Telstra Careers Website: tel.st/allrolesflex

We’re committed to building a diverse and inclusive workforce. To enable everyone to participate, we’ve developed an ‘All Roles Flex’ policy to consider flexible ways of working for every role. To learn more, visit http://tel.st/allrolesflex. We welcome applications from Indigenous Australians, people from diverse cultural and linguistic backgrounds and people living with a disability. We encourage you to talk to us about how we can support you through the recruitment process.",3.6,"Telstra
3.6",Bengaluru,"Melbourne, Australia",10000+ employees,1901,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Optus, Vodafone, Macquarie Telecom Group"
Data Scientist - SaaS (Work from Home),-1,"OnceHub (www.oncehub.com) is an innovative and thriving Software-as-a-Service company that provides a feature-rich scheduling platform to businesses. At OnceHub were all about powering organizations with smart scheduling solutions that shorten time-to-engagement in all phases of the customer lifecycle.

We are a team of passionate and driven individuals living and working across seven countries and five continents. We have ambitious growth plans and right now, we already have team members in the UK, India, Ireland, Israel, New Zealand, South Africa, and the USA. In India, we have established a thriving R&D center of excellence based in three locations - Noida, Gurgaon and Dehradun and we are growing rapidly.

OnceHub is looking for a results-driven Data Scientist who can dive into our data and provide useful insights to help bring our acquisition and growth efforts to the next level.

If you get excited about data-driven decision making, wed love to hear from you.

This role can be based remotely anywhere in India.

Responsibilities:
Identify, analyze, and interpret trends or patterns in complex data sets.
Integrate data from various different sources, including MsSQL, PostgreSQL, BigQuery, MongoDB
Build predictive models to prevent churn, increase retention, and increase engagement.
Filter, clean, and interpret data.
Provide insights about potential avenues for growth.
Analyze results using statistical techniques and provide ongoing reports.
Create and maintain dashboards to support product and business decision making.
Enrich the data pipeline.
Extract, transform, and load (ETL).
Contribute toward optimizing data collection systems, statistical efficiency and data quality.
Work closely with marketing and product to build features that enhance the user experience.
Work closely with management to prioritize business and information needs, opportunities, and troubleshooting issues based on data.

Requirements:

Relevant Bachelors degree from a leading university.
At least 4-5 years of professional experience in a Data Scientist role.
Fluent in SQL.
Good knowledge of data-centric programming languages such as Python and R.
Deep understanding of statistical analysis, and experience with standard techniques including linear regression, time series analysis, experimental design, hypothesis testing, and A/B testing.
Strong analytical skills with the ability to collect, organize, and analyze significant amounts of data.
Ability to derive insights from complex data and make recommendations that drive meaningful business impact.
Experience managing operational projects and/or processes from identification to implementation to execution.
Excellent verbal and written communication skills - clear and articulate communicator.
Self-driven and can work independently but also part of a team.

This is a remote, work from home role which saves you commuting time and allows flexibility. Since we are an international company, our standard business days are Monday to Friday. We are looking for an individual located in India who is flexible and can work with stakeholders located around the world.

We offer a competitive salary, development opportunities, and provide work equipment. You will also have the opportunity to participate in our bi-annual company retreat. If you want to contribute directly to the growth of an innovative SaaS company, please send us your resume!",-1,OnceHub Technologies,Gurgaon,-1,-1,-1,-1,-1,-1,-1,-1
Data Science-Data Visualization,-1,"Job Skill: Data Visualization
Designation: Career Level - 10-Analyst
Job Location: Mumbai
Qualifications: Any Graduation
Years of Experience: 5-7 years
About Accenture


Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions underpinned by the worlds largest delivery network Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com



Job Summary


You will be aligned with our Insights & Intelligence vertical and help us generate insights by leveraging different analytics tools and techniques to deliver value to our clients. You will also help us apply your expertise in building world class solutions, conquering the business problems, addressing technical challenges using AI Platforms and technologies. You will be required to utilize the existing frameworks, standards, patterns to create architectural foundation and services necessary for AI applications that scale from multi-user to enterprise class and demonstrate self as an expert by actively blogging, publishing research papers and creating awareness in this emerging area.

In the Data Science team, you will manage and analyze data in order to build data driven business insights and high impact data models to generate significant business value. This will involve creating models and processes to collect, distill and interpret data with a view to aid more informed decision making, examine and explore data from multiple sources with the goal of discovering insights which in turn can provide competitive advantage for our client.

In Data Visualization, you will be using tools and methods to create a visual representation of data, communicating information clearly and effectively through graphical means, patterns, trends and correlations.

Roles and Responsibilities


In this role you are required to do analysis and solving of increasingly complex problems. Interaction is with peers within Accenture before updating supervisors. Likely has some interaction with clients and/or Accenture management. Minimal instruction on daily work tasks and a moderate level of instruction on new assignments will be provided. Decisions made by you impact your own work and may impact the work of others. In this role the person would be an Individual contributor and/or oversees a small work effort and/or team. Please note that this role may require you to work in rotational shifts.",3.9,"Accenture
3.9",Mumbai,"Dublin, Ireland",10000+ employees,1989,Company - Public,Consulting,Business Services,₹500+ billion (INR),"Cognizant Technology Solutions, EY, McKinsey & Company"
DATA SCIENTIST,-1,"ORGANIZATION SUMMARY
Weatherford
Weatherford is one of the largest multinational oilfield service companies providing innovative solutions, technology and services to the oil and gas industry. The Company operates in more than 80 countries and has a network of approximately 700 locations, including manufacturing, service, research and development, and training facilities and employs approximately 20,000 people.
Weatherford delivers innovative technologies and services designed to meet the world’s current and future energy needs in a safe, ethical, and sustainable manner. Grounded by our core values and inspired by our world-class people, we are committed to being a trusted business partner to those we serve.

JOB DESCRIPTION
Job Purpose
Weatherford’s Production business is seeking a Data Scientist who is passionate about data and wants to apply machine learning techniques to solve problems for our customers. This person is expected to be proficient in the exploration and understanding of structured and unstructured data, machine learning techniques, statistical modeling methods, predictive analytics, anomaly detection, and supervised and unsupervised learning. The successful candidate will work with stakeholders to leverage data to solve critical business problems in the oil & gas production domain.
The Data Scientist will work on all aspects of the design, development and delivery of machine learning enabled solutions including problem definition, data acquisition, data exploration, feature engineering, experimenting with various ML algorithms, evaluating metrics, deploying models and iteratively improving the total solution. He or she will work with data from diverse, unstructured formats including numerical, time series, text, and image.
Duties & Responsibilities
Formulate meaningful hypothesis that are relevant to the business objectives.
Design and train models for use in production environments.
Mine structured and unstructured data for patterns.
Utilize data from databases, historians, and/or data lakes.
Rigorously build, analyze and compare machine learning or statistical models; there is a strong emphasis on programming using the most popular machine learning languages such as Python.
Work with application developers to develop data-analytics products that are deployed to end-users as part of packaged solutions.
Visualize and report findings of deployed data analytics solutions to provide insights to the organization and our customers.
Deploy machine learning model and integrate model predictions in business
Setup infrastructure for machine learning, model deployment
Deploy CI/CD framework to frequently deliver code/features to production

QUALIFICATIONS
Experience & Education

Required:
B.S. or higher in Engineering, Mathematics, Statistics or Computer Science with significant experience in data analytics.

Preferred:
MS degree with 5+ years’ experience is preferred.
Knowledge, Skills, & Ability

Required:
Expertise in predictive modeling, machine learning and statistics.
Software development skills in one or more high level languages (Python/Java/R/Scala).
Experience using one or more of the following common ML software packages: scikit-learn, TensorFlow, NumPy, pandas, jupyter.
Well-versed in machine learning algorithms and their suitability for solving various problems: Regression, Bayesian, Support Vector Machines, Decision Trees, Random Forest, Clustering, Neural Networks.
Experience in using SQL/No SQL databases is an advantage
Experience working in Linux is an advantage
Experience with Big Data technologies is an advantage (Hadoop, Hive, Spark, Cassandra).
Experience with building and deploying data pipelines
Good critical thinking, technical, data collection and user interviewing skills.
Ability to work as a team member in a fast-paced environment.
Experience with Agile software development processes is preferred.
Experience with Cloud service offerings from AWS, Azure or GCP is a plus.

Preferred:
Knowledge of DataOps.
Knowledge of data versioning tools such as git, DVC
Knowledge of ML environments such as MLflow, databricks
Knowledge of ML deployment tools such as Kubeflow, Kubernetes
]]>",3.2,"Weatherford
3.2",Mumbai,"Houston, TX",10000+ employees,1987,Unknown,Oil & Gas Services,"Oil, Gas, Energy & Utilities",₹500+ billion (INR),-1
Data Science Internship,-1,"About the company:
AI Claim was started with a vision to bring automation to the Insurance, Banking & Healthcare industry. Our flagship product claim assessment brings automation to the claim processes by automating data entry, data verification & damage assessment processes. It is being used by leading insurance companies of India.

About the internship/job:
Selected intern's day-to-day responsibilities include working on deep learning models for challenging problems of the object-detection and image-classification category (end-to-end from data-preprocessing to automated retraining of models).

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 20th Jul'20 and 24th Aug'20
are available for duration of 3 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Other requirements:
Candidate must have experience with ML/DL frameworks like Keras, PyTorch, etc. Candidate must be proficient in Python Candidate must have familiarity with pandas, NumPy, and basic scripting Candidate pursuing graduation from IIT/NIT would be preferred

Number of internships/jobs available: 2

Categories: Data Science",1.0,"AI Claim
1.0",Bengaluru,"Blackpool, United Kingdom",201 to 500 employees,-1,Company - Public,Insurance Agencies & Brokerages,Insurance,₹10 to ₹50 billion (INR),-1
Applied Scientist Intern,-1,"Excited by Big Data, Machine Learning and Predictive Software? Interested in creating new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?
At Amazon, we are developing state-of-the-art large-scale Machine Learning Services and Applications on the Cloud involving Terabytes of data. We work on applying predictive technology to a wide spectrum of problems in areas such as Amazon Retail, Seller Services, Customer Service, Alexa, Chatbots and so on. We are looking for talented and experienced Machine Learning Scientists (Masters/Ph.D. in a related area preferred) who can apply innovative Machine Learning techniques to real-world e-Commerce problems. You will get to work in a team dedicated to advancing Machine Learning technology at Amazon and converting it to business-impacting solutions.
Major responsibilities
- Use machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
- Analyze and extract relevant information from large amounts of Amazons historical business data to help automate and optimize key processes
- Design, develop and evaluate highly innovative models for predictive learning
- Establish scalable, efficient, automated processes for large scale data analyses model development, model validation and model implementation
- Research and implement novel machine learning and statistical approaches




Basic Qualifications

- A Masters and/or PhD in Computer Science, Machine Learning, Operational research, Statistics or in a highly quantitative field
- Experience in predictive modelling and analysis, predictive software development
- Strong problem-solving ability
- Good skills with Java/Scala or C++, Perl/Python (or similar scripting language)
- Experience in using R, Matlab, or any other statistical software
- Strong communication and data presentation skills



Preferred Qualifications

- Experience handling gigabyte and terabyte size datasets
- Experience working with distributed systems and grid computing
- Knowledge of the latest and state of the art ML technology
- Publications or presentation in recognized Machine Learning and Data Mining journals/conferences",4.3,"Amazon
4.3",Hyderabad,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Engineer,-1,"Introduction
At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. To lead in this new era of technology and solve some of the world's most challenging problems.

Your Role and Responsibilities
As a Data Engineer, you play a vital role in building the right infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Expert in setting up effective pipelines to capture data from multiple sources into the enterprise centric storage.
Comfortable in building effective analytical tools that utilize the data pipeline to provide actionable insights into data synchronization, reporting, operational efficiency and related areas.
Work with stakeholders including the product owner, data and design teams to assist with data-related technical issues and support their data infrastructure needs.
Create and maintain optimal data pipeline architecture.
Identify, design, and implement process improvements aimed at automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Assemble large, complex data sets including legacy structured data warehouse that meet functional / non-functional business requirements.
Collaborate with DevOps team to develop Continuous Integration/Continuous Delivery pipelines using containerization technologies.
Solve Big Data and Distributed Data Streaming problems using latest technologies.
Perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Manipulate, process and extract value from large disconnected datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management
Work on State-of-the-Art cloud technologies provided by IBM Public Cloud, RedHat, AWS & others.
Be part of open, transparent agile teams who always thrive for continuous learning and contribute towards continuous improvement.
Required Technical and Professional Expertise
Possess strong knowledge in designing database models to store structured & unstructured data efficiently and in creating effective data tools for analytics experts.
Knowledge in technologies like Hadoop, Spark, Kafka, Scala, Python, etc. Knowledge in relational model databases (like DB2, MySQL, Oracle, ...) and no-SQL databases (MongoDB, Elastic Search, ...)
Knowledge on enterprise data lakes, data analytics, reporting, in-memory data handling, enterprise integration tools, etc.
Good understanding of industry best practices for data governance and security.
Good communication skills and fluent in English.
Preferred Technical and Professional Expertise
None
About Business Unit
We at IBM Chief Information Office (CIO) are a dynamic group of Business, Strategy and Technology professionals - a specific source of market-leading Industry Consulting, Application and Business process delivery following Agile values and principles. CIO is at the forefront of Digital Reinvention of key applications used within IBM providing value-led and asset-powered end to end solutions.

CIO mission is to create a productive environment for everyone at IBM. We do this by leading with Design to drive simplicity and ease of use, Engineering the systems that run the business, and Innovating to transform the business. Key focus areas are to secure the Enterprise in network security, endpoint security and data security
Transform IBM and improve collaboration and practice a culture of agile way of working.

Within the CIO, we represent the Analytic Solutions area of the Sales & Marketing Systems. Our mission is to provide business insights to our partners in sales and marketing to win in the market place through analytics solutions delivered using latest technology and based on real time, consolidated and cloud-based data.

Your Life @ IBM
We at IBM Chief Information Office (CIO) are a dynamic group of Business, Strategy and Technology professionals - a specific source of market-leading Industry Consulting, Application and Business process delivery following Agile values and principles. CIO is at the forefront of Digital Reinvention of key applications used within IBM providing value-led and asset-powered end to end solutions.

CIO mission is to create a productive environment for everyone at IBM. We do this by leading with Design to drive simplicity and ease of use, Engineering the systems that run the business, and Innovating to transform the business. Key focus areas are to secure the Enterprise in network security, endpoint security and data security
Transform IBM and improve collaboration and practice a culture of agile way of working.

Within the CIO, we do represent the Analytic Solutions area of the Sales & Marketing Systems. Our Mission is to provide business insights to our partners in sales and marketing to win in the market-place through analytics solutions delivered using latest technology and based on real time, consolidated and cloud based data.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"About Us

HealthifyMe was founded in 2012 by Tushar Vashisht and Sachin Shenoy, and incubated by Microsoft Accelerator. Today, we are India and South East Asia's largest and most loved health & fitness app, with over 16 Million users from 300+ cities in India+SEA and rated over 4.6/5. The HealthifyMe mobile app has been rated as the top Health/Fitness app on Play Store by Google for the last 3 years, and has received the prestigious 'Editor's Choice' badge by Google.Our coaching services are delivered by a world class team of over 500 coaches including nutritionists, trainers and yoga instructors. We combine the power of artificial intelligence and human empathy to deliver measurable impact in the lives of our consumers. We launched the world's first AI nutritionist 'Ria' with learnings developed from billions of data points on consumer lifestyles, coupled with 400 man-years of nutritionist/fitness intelligence.

HealthifyMe has raised over $25 Million in funding from marquee investors such as Sistema, IDG, Inventus, Blume and Samsung Next. HealthifyMe works with over 75 corporates across the country to deliver employee wellness solutions. We aspire to be a leading health and fitness platform across the globe.

We at HealthifyMe are looking to hire a Data Analyst for our sales & services Team to work closely on business prospects.

About Us -

We were founded in 2012 by Tushar Vashisht and Sachin Shenoy, and incubated by Microsoft Accelerator. Today, we happen to be India's largest and most loved health & fitness app with over 4 million users from 220+ cities in India. What makes us unique is our ability to bring together the power of artificial intelligence powered technology and human empathy to deliver measurable impact in our customers' lives. We do this through our team of elite nutritionists & trainers working together with the world's first AI powered virtual nutritionist - ""Ria"", our proudest creation till date. Ria references data from over 200 million food & workout logs and 14 million conversations to deliver intelligent health & fitnesssuggestions to our customers. Ria also happens to be multi-lingual, ""she"" understands English, French, German, Italian & Hindi.

Designation: Data Analyst

Experience: 1-3 Yrs

Location: Bangalore

Requirement:
Work closely with the business stakeholders for enabling data-driven decision making.
Explore large datasets and give meaningto numbers by identifying insights.
Post each major event, collate information, and present data in a cohesive succinct manner such as to evolve the construct significantly with each iteration.
Understand the performance of various teams - basis several key parameters on a day to day basis
Prepare reports for the business heads & update key metrics on a daily basis
Skill :
Expert in SQL DML queries.
Good Knowledge on Database concepts, Data Warehousing Models.
Should be proficient in Spreadsheets and visualization tools like Tableau.
Knowing Python language is an added advantage.
Strong Analytical, Problem Solving & Communication skills.
Should have strong business acumen to understand the key business KPIs
Should have an entrepreneurial mindset to be able to navigate between different teams & coordinate for any data gathering requirements
Look forward to
Working with a world-class team.
Fun & work at the same place with an amazing work culture and flexible timings.
Get ready to transform yourself into a health junkie.",3.7,"HealthifyMe Wellness Private Limited
3.7",Bengaluru,"Bengaluru, India",501 to 1000 employees,2012,Company - Private,Healthcare Services & Hospitals,Healthcare,Unknown / Non-Applicable,-1
Lead R&D Engr/Scientist,-1,"Innovate to solve the world's most important challenges


Job Description: Lead Modeling Specialist



Summary:

An excellent career opportunity is currently available for a Lead Modeling Specialist within R&D Modeling group located in Gurgaon, India. The group hosts modeling capabilities in kinetic modeling, CPS, CFD modeling, and molecular modeling. The role is accountable for the development of reactor and process models, which are critical to the commercialization and ongoing support of PMT technology. This position reports to the Manager of Applications Research & Modeling, HITC

Detailed Responsibilities:
Develop and deliver reactor, kinetic and process models which meet the needs of R&D, Engineering, and Sales Support
Use understanding of kinetics, mass transfer and reaction engineering to make innovative contributions to PMT technology development efforts
Mentor team members on modeling principles and drive productivity of projects.
Good statistics background with emphasis in non-linear parameter estimation, experimental design, optimization and data reconciliation
Model assisted experimentation and reactor design
Mastery of process simulation and numerical methods to solve ODEs, PDEs and perform optimization
Develop enhanced work processes and modeling techniques
Excellent computer programming skills (Fortran, C#, Visual Basic, UNISIM)
Monitors scientific and modeling literature to understand the state of the art, and makes recommendations for acquisition of new modeling equipment or tools.
Excellent communication skills to understand and document customer requirements and to effectively convey recommendations to other disciplines.
Deploy Open Innovation to leverage relevant skills and capabilities that are not available at HITC / UOP
Ensure alignment and synergy with other R&D centers (DP/Rvsd/China/Mobile) to avoid re-work, minimize duplication and benefit from lessons learned.
Basic Candidate Requirements:

• A PhD in Chemical Engineering with 8-10 years experience in modeling, process simulation, process development or reaction engineering, or:

Additional Qualifications
Knowledge of UOP technologies: Refining/Petrochemicals/Gas Processing applications
Understanding data science principles is a plus
Familiar with Six-Sigma tools and their application
Ideal candidate is high-energy, creative, and a self-starter, who demonstrates technical excellence and is comfortable working in a team environment
Additional Information
JOB ID: HRD97209
Category: Engineering
Location: Sector 36,Pace City II,Gurgaon,HARYANA,122004,India
Exempt
Business Services",3.7,"Honeywell
3.7",Gurgaon,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
Surveillance Data Scientist,-1,"Job Description

Experience
Range - 7-14 yrs

Role
Overview -As
a Data Scientist, you will contribute towards the identification of
opportunities for innovation in alignment with R&D strategy.

What
we are Looking for :

Must
Have:

Good
understanding of Data Science and analytics.

Demonstrated
ability to undertake Data Science projects in BFS domain with client
data.

Experience
in working with big banks, preferably in the regulatory function.

Good
understanding of one or more of the following – Python, Impala,
NEO4js, Java, Pyspark, SQL, Graph data bases.

Good
to Have:
Product
firms like Scila, Nice-Actimize, FICO, SMARTS etc.
Consultancy
Firms like PWC, McKenzy, Accenture, EnY etc.
Captive
functions with similar coverage.
Responsibilities:

M ust
understand advanced analytics techniques like Neural Networks,
Network Analytics, Quantitative finance (optional)

Able
to work with multiple datasets of both structured/unstructured
nature.

Demonstrated
ability to work with clients and successfully deliver projects with
minimal supervision.

Should
have development experience in production environment.

Minimum
Qualification:
15
yrs of Full Time education
Minimum
percentile of 50% in 10th, 12th, UG & PG (if Applicable).

Job Function

TECHNOLOGY

Role

Scientist

Job Id

159089

Desired Skills

Data Science | Data scientist

Desired Candidate Profile

Qualifications :
BACHELOR OF ENGINEERING",3.8,"Tata Consultancy Services
3.8",Pune,"Mumbai, India",10000+ employees,1968,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Accenture, IBM, Infosys"
Data Scientist Sales & Channel,-1,"HP is the world’s leading personal systems and printing company, we create technology that makes life better for everyone, everywhere. Our innovation springs from a team of individuals, each collaborating and contributing their own perspectives, knowledge, and experience to advance the way the world works and lives.
We are looking for visionaries, like you, who are ready to make a purposeful impact on the way the world works.
At HP, the future is yours to create!
If you are our Data Scientist in India, you will get an opportunity to work on below.

o Mines data using modern tools and programming languages.
o Defines and implements models to uncover patterns and predictions creating business value and innovation.
o Works with the business to understand the business domain perspective.
o Effectively tells stories with the data using visualization tools/methods to demonstrate insight impact and business value.
o Assures accuracy, integrity, and compliance of cleansed data.
o Maintains proficiency within the data science domain by keeping up with technology and trend shifts.
o Leads a project team of data science professionals
o Collaborates and communicates with project team regarding project progress and issue resolution.
o Represents the data science team for all phases of larger and more-complex development projects.
o Provides guidance, training and mentoring to less experienced staff members.

Are you a high-performer? We are looking for an individual with:

o Using statistics, mathematics, algorithms and programming languages.
o Understanding of how to manage disparate unstructured and structured data in a distributed environment.
o Fluent in structured and unstructured data and modern data transformation methodologies.
o Ability to create models to pull valuable insights from data.
o Create stories and visualizations to describe and communicate data insights.
o Ability to use creativity to spot trends and tease out patterns in large datasets.

#LIPOST",3.3,"HP
3.3",Bengaluru,"Houston, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Junior Data Analyst,-1,"Role: Junior Data Analyst

Location: Gurgaon, India

GroundTruth is the leading global location platform that leverages data and insights to drive business performance. Using its proprietary Blueprints technology, GroundTruth is able to learn about mobile users and reach them at the right place and right time, ultimately helping companies make smarter marketing decisions, increase sales, and grow their businesses. Since its foundation in 2009, GroundTruth has launched several innovative products and won numerous awards, including Inc. 5000’s Fast Growing Private Companies and Deloitte's Fast 500 Technology companies. Today, we're proud to employ over 400 employees across three continents and serve millions of marketers across 21 countries. Learn more: www.groundtruth.com

This will be an exciting and challenging role that will enable you to work with very large data sets, expose you to cutting edge analysis techniques, work with the latest components in cloud architecture and gain experience in the usage of location data to drive businesses. As an early member you will have significant opportunities for growth within the organization. A successful applicant will be passionate about technology and developing a deep understanding of human behavior in the real world. They would also have excellent communication skills, be able to synthesize and present complex information and be a fast learner.

You will:
Learn about location-driven marketing and how companies are using location signals to drive their business
Work closely with marketing, growth strategy and sales teams based out of our offices in USA, Germany
Develop re-usable tools and templates to quickly create data driven narratives
Gather requirements, design analyses, identify data sources and define measurement metrics to present insights and recommendations for ready consumption
Be responsible for managing your work pipeline and creating re-usable analysis and documentation
You have:
BA/BSc/B.E./BTech degree in Computer Science, Statistics, Mathematics, Economics, Physics or related fields from Tier 1/Tier 2 colleges
6 months - 2 years of experience in working with data and conducting statistical and/or numerical analysis
Strong understanding of how data can be stored and accessed in different structures
Experience with writing computer programs to solve problems
Strong understanding of data operations such as sub-setting, sorting, merging, aggregating and CRUD operations
Ability to write SQL code and familiarity with R/Python, Linux shell commands
Be willing and able to quickly learn about new businesses, database technologies and analysis techniques
Ability to tell a good story and support it with numbers and visuals
Strong oral and written communication
How you can impress us:
Experience working with large datasets
Experience with AWS analytics infrastructure (Redshift, S3, Athena, Boto3)
Experience building analytics applications leveraging R, Python, Tableau, Looker or other • Experience in geo-spatial analysis with POSTGIS, QGIS
We operate in a fast paced, dynamic environment where everyone on the team is committed to the success and growth of GroundTruth. Our culture is highly entrepreneurial and our success comes from our employees who voice their opinions and ideas to facilitate growth to our bottom line. We reward hard work, support career development, offer comprehensive benefits, and foster a fun and friendly work environment.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",3.4,"GroundTruth
3.4",Gurgaon,"New York, NY",201 to 500 employees,2009,Company - Private,-1,-1,Unknown / Non-Applicable,-1
AI/ML Data Science - Intern,-1,"Do you have an inquisitive mind, an ability for self-learning and abstraction along with a risk appetite for experimentation and failure? Come join us t for a unique 3 months Data Science internship at our Gurgaon office. You will work with real-time data streams from IOT devices installed across India. Collaborate with cross-functional teams including but not limited to Engineering (hardware, mobile, web), Products, Operations, Sales, Marketing, etc. to breakdown complex problems and recommend data driven solutions
ZunRoof is a home-tech company, powered by a mix of Image Processing, VR, IOT and Data Analytics. With a founding team of IIT Kharagpur, IIT Delhi and IIT Kanpur alumni, we are solving energy issues of India by using un-utilised rooftops for solar, and by providing sense and control of every appliance in one's house. Our design and delivery applications are ensuring all-time high adoption and higher output per kW of solar - within 30 months of starting up, we are already the #1 choice for residential and SME clients in India for solar
Intern’s day to day responsibilities include -
Assess the effectiveness and accuracy of new data sources and data gathering techniques
Research data models and develop custom models and algorithms to apply to data sets
Use machine learning and analytical techniques to create scalable solutions for problems
Contribute to the development/deployment of machine learning algorithms
Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes
What we need?
Strong problem solving skills with an emphasis on product development
Able to work with and create data architectures
A very clear understanding of probability and statistics, analytical approach to problem solving, and capability to think critically on a diverse array of problems
Familiarity with some Supervised Machine Learning Algorithms: Predictive Analytics, Logistic Regression, Bayesian Approach, Decision Trees, Support Vector Machines. Neural Networks etc.
Understanding of advanced algorithms (i.e. Deep Learning, Probabilistic Graph Models) will be good to have
Familiarity with statistical methods such as hypothesis testing, forecasting, time series analysis, etc - gained through work experience or graduate level education
Knowledge of one or more of Python, Java, C++, R etc.
Experience with relational databases, NoSQL databases such as MongoDB, Elastic Search, Redis or any graph database
Skilled at data visualization and presentation",3.0,"ZunRoof Tech
3.0",Gurgaon,"Gurgaon, India",51 to 200 employees,2016,Company - Private,Consumer Electronics & Appliance Shops,Retail,Unknown / Non-Applicable,-1
Data Science Engineer - Image Database,-1,"Senior Data Architect

Summary

We are looking for a technical lead who will design, build and maintain the data pipeline for creating training datasets for our AI research engineers. Additionally he or she will be responsible for automating the large dataset creation process. The ideal candidate should have 6-10 years of industrial experience in related field as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence/Data/DW Engineer, Data Scientist etc.) and 1-2 years of experience in leading a team.


Responsibilities
Lead the data pipeline setup, operation and maintenance.
Assemble large, complex data sets that are analysis/training ready for the machine learning engineers/researchers
Design and build scalable and reliable data pipeline that collects, transforms, loads and curates data from internal systems. Ensure high data quality for pipelines you build and make them auditable. Support design and deployment of distributed data store that will be central source of truth across the group.
Develop, customize, configure automation scripts/tools that help engineers to extract and analyze data from our internal data store. Develop reporting and data visualization solutions, as well as looking to build out a dynamic platform
Evaluate new technologies and build prototypes for continuous improvements in data engineering. Creation of new capabilities and modules in our data pipeline. Develop and maintain expertise in advanced and/or emerging data management and analytical information technologies such as data warehouse, data lake and Big Data
Build data connections to company's internal IT systems
Design, implement and continuously optimize the group’s data strategy. Provide thought leadership and lead efforts to design data integration and implement extract, transform and load (ETL) jobs/processes, detailed data warehouse models and data mappings. Provide consultation on best practices and standard practices to internal team members
Perform performance optimization and tuning on new and/or existing data warehouse implementations.
Requirements
5 years of hands on industry experience with a track record of manipulating, processing, and extracting value from large data sets.
Demonstrated ability in building data pipelines, data modeling, ETL development and familiarity with design principles. Experience building data products incrementally, integrating, and managing data sets from multiple sources. Knowledge of data warehouse technologies and relevant data modeling best practices. Experience with a DW technology (Redshift, SQL Server, etc.) and relevant data modeling. Experience processing large amounts of data, in various formats and processing data in batch mode and streaming mode
Excellent SQL skills. Proficiency in a scripting language (Python, Ruby, Perl etc.) and/or a major programming language (C , Java etc.). Knowledge of R is a plus.
Experience with working in Spark/Hadoop and/or other distributed computing frameworks is required
Experience working in a multi-layered distributed architecture is essential. Experience with scalable service architecture and design
Exposure and knowledge of Data Security and Governance. Awareness of best practices to secure data and processes from unauthorized access.
Knowledge and direct experience using business intelligence reporting tools (Tableau, PowerBI etc.) is a plus.
Understanding of data science, machine learning, and AI is a plus.
Strong analytical and problem solving skills (data analysis and requirement documentation)
Excellent project management skills and ability to prioritize issues
Excellent oral and written communication, organizational and client facing skills.
Academic Qualification Profile:


B.E. / B. Tech in Computer Science

Certification or Masters in Big Data Science",3.4,"Mercedes-Benz Research and Development India Private Limited
3.4",Bengaluru,"Chakan, India",1001 to 5000 employees,1996,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Volkswagen, Tata Motors"
Data Analyst,-1,"Our Team

PharmEasy was founded in 2015 with the sole purpose to make healthcare easily available, accessible and affordable to all through the extensive use of new-age cutting-edge technology. Today, we are one of India's largest healthcare aggregators connecting lakhs of patients to licensed pharmacies & diagnostic centres online for all their medical needs. We are particularly catering to the chronic-care segment, and offer a range of services including medicine delivery, tele-consultation, sample collection for diagnostic tests as well as subscription-based services for all these categories.

Our highly efficient and technology led Consumer and Supply-chain platforms ensure that medicines are delivered from a licensed pharmacy within six hours of the validation of prescriptions submitted by our customers. And such customer promises are improving with the increasing scale of our business, and continuous product innovation.

By extensively leveraging the latest in hardware and software technology, we are also committed to eradicate fake medicines from the Pharma ecosystem that contribute to roughly 30% of drug volumes in India. Our product innovations have allowed for complete data transparency in the entire Pharma supply-chain to empower even the end-users to validate the authenticity and genuineness of the medicines for every medicine sold, using constructs such as unique barcoding of information like expiry dates, origination of drugs etc.

With our scalable technology and processes, we are now reliably delivering healthcare services and medicines to every single pin code in the country.

Analytics @ Pharmeasy:
Pharmeasy wants to enable data driven decision-making for achieving the core business objective of the company to make healthcare accessible & affordable to everyone. This would essentially require rigorous efforts being put into all domains of analytics from data collection to data extraction to data cleaning to data wrangling to descriptive analytics and eventually drawing business insights and communicate the same to the relevant business teams. We want to make analytics an integral part of every decision making at Pharmeasy because in today’s world subjectivity is something that is limited to academia and data can answer most of the questions.

Responsibilities :
A Data Analyst would be responsible for supporting the Business Teams for any kind of Data Reporting and Adhoc Data Analysis. The role would include extraction, cleaning, reporting, analysis and visualization of data.

Creating Dashboards/Reports and communicating the same to business team

Identification, Reporting & Tracking of Key Business Metrics at hourly, daily, weekly, monthly frequency

Coordination with Business Teams to identify new reporting requests and enhancing the existing one, business users to be communicated and explained the details if need arises

Testing all new reports/deliverables and periodically reviewing them for maintaining data quality

Data validation and attention to detail is required as the individual will be accountable for quality of all the numbers delivered through dashboards or otherwise

What are we looking for ?

1 to 3 years of work experience in the relevant field, preferably in a consumer facing company

Well versed in MS Excel (vlookup, hlookup, if-else, index, match, countif, sumifs, string operations, Pivot Table & Pivot Table Chart etc.)

Proficient in writing SQL queries and the candidate should be able to handle complex queries

Structured thought process and problem solving skills are a must have

Prioritization of tasks, organised work ethics, high work efficiency are expected

VBA, Macros are an advantage and good-to-have",3.9,"PharmEasy
3.9",Bengaluru,"Mumbai, India",1001 to 5000 employees,2015,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Senior Producer-Analytics and Data Science,-1,"Senior Producer – Senior Project Manager, Analytics and Data Science


Zynga is looking for a highly motivated PROJECT MANAGER to help evolve our execution processes and take on project management for our analytics and data science team. He or she will work closely with analytics leadership, product management, engineering leadership, other project managers and game teams to balance a set of commitments and milestones to predictable execution, facilitating tough trade offs along the way. Tactical enough dive deep on daily execution, proactively spot areas for improvement, then energetically drive those improvements broadly, resulting in all peers feeling collaboratively led into changes that solve confusion, miscommunication and differing expectations.

Responsibilities:
Take on project management responsibility for machine learning, data science and analytics projects
Define scope, determine resources required, develop schedule and milestones in collaboration with engineering leadership and product management
Passionately articulate goals and team principles to help form a stimulating and fun work environment and culture
Ensure that the project deliverables are timely, within budget and at the required level of quality
Lead technical scrums and agile project implementation, evolve the project management methodology to align with work-product of analytics teams
Monitor and report progress weekly, oversee risks and mitigations and aggressively work to remove blockers; deliver bi-weekly, monthly and quarterly summary of project delivery; extract analytics on execution, and deliver a data-driven evolution of execution and prioritization
Identify process pain points and collaborate with analytics leadership, engineering leaders, product managers and other project managers to motivate change that improves both quality and transparency to external groups
Initiate, develop, maintain and lead others toward positive working relationships with internal and external organizations critical to both current and future development process
Collaborate with other project managers in the central data organization to deliver and evolve a consistent project management methodology
Required skills:

5+ years experience working in multi-functional development teams.
At least 3 years experience as a Project Manager within the tech industry, games preferred
Experience working in an agile environment and implementing processes for agile development
Outstanding written and verbal communication skills
Ability to work in a team environment with maturity and leadership
Preferred skills:

3+ years experience as a technical project manager
Experience working in the advertising and/or mobile gaming sectors
Familiarity with analytics, data science, machine learning and AI
Computer science, statistics or technical degree
Scrum Master or Agile Coach certification
WHAT WE OFFER YOU:

Work in a studio that has complete P&L ownership of games
Competitive salary, discretionary annual bonus scheme and Zynga RSUs
Full medical, accident as well as life insurance benefits
Catered breakfast, lunch and evening snacks
Child care facilities for women employees and discounted facilities for male employees
Well stocked pantry
Generous Paid Maternity/Paternity leave
Employee Assistance Programs
Active Employee Resource Groups – Women at Zynga
Frequent employee events
Additional leave options for most employees
Flexible working hours on many teams
Work with cool people and impact millions of daily players!",3.8,"Zynga
3.8",Bengaluru,"San Francisco, CA",1001 to 5000 employees,2007,Company - Public,Video Games,Media,₹50 to ₹100 billion (INR),-1
Technical Team Member Distributed Data Science & Machine Learning,-1,"Position: Technical Team Member – Distributed Data Science & Machine Learning (Full Time)
Location: Kolkata, India
Status: Open

Overview
Agnik, is a global connected car technology company (www.agnik.com) operating in 38 countries headquartered in USA with major consumer brands like Vyncs (https://www.vyncs.com) and several B2B products. Agnik is looking for several full-time members of its Technical Team for Distributed Data Science and Machine Learning in its New Town, Kolkata office. If you want to join a top notch technical team that develops novel algorithms/systems and very well familiar with statistics, machine learning, image analysis, and distributed systems then send a copy of your complete resume to jobs@agnik.com with a subject line “Technical Team Member - Distributed Data Science & Machine Learning”.

Responsibilities
As an employee of Agnik’s Distributed Data Science & Machine Learning Technical team Member, the primary focus of this position would be to design, develop, and implement novel data analysis and machine learning algorithms for connected car and mobility applications. Successful candidates must be knowledgeable and passionate about latest developments in field of machine learning and data science, should be a hands on developer. The position does not require extensive travel.

Duties Include
Develop real-time and off-line data analysis and machine learning algorithms/systems for embedded systems, mobile platforms, and cloud-based distributed environments.
Dealing with big data management problems in real-time applications.
Writing and reviewing code using Java/C#/C language for embedded and in-cloud environments for predictive modeling, control, and scene analysis.
Developing geo-spatial data management and analysis software.

Required Qualifications

B.Tech/BS/M.Tech/MS/PhD. from a reputed University in Computer Science, Electrical/Electronic engineering (or other engineering/Science) with relevant experience.
1 – 5 years of experience in building data analysis, signal processing, and machine learning applications using Java/C/Python language, web-services in dot net environment, relational/non-relational databases, and developing distributed systems.
Ability to communicate in fluent English. Effective communications skills and strong interpersonal skills, both orally and in written form.
Distributed data management environments such as Hadoop and Spark.
Ability to juggle multiple projects simultaneously.
Attention to details, ability to prioritize and meet aggressive deadlines.

Salary

Commensurate with qualifications. Benefits, possible overseas trip.

Location

New Town, Kolkata",4.8,"Agnik
4.8",Kolkata,"Columbia, MD",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,₹10 to ₹50 million (INR),-1
Business Intelligence Analyst,-1,"Anaplan is looking for a passionate BI Analyst to join our global Product team. Our traditional offices are located across Minneapolis, San Francisco, London, and York, UK. You'll base out of Bangalore India and report to the Director of Customer Insights and Product Operations. This position will be co-located with an existing Anaplan Data Analytics team that support corporate Marketing. This is a stellar opportunity to get involved in a highly visible, large scale cloud company.

Are you a data driven, curious professional with the ability to see the forest not just the trees? The Product team is looking a strong BI/Data analyst who will thrive executing in a fast paced, global, rapidly growing SaaS organization.

As a BI/Data Analysts, you'll partner with product leaders and Anaplan model builders to surface valuable insights from product usage and customer data sets to create KPIs for senior and executive leaders. Your work will provide critical insights about product adoption, usage trends and product related customer feedback. You will be responsible for the implementation of the analytical capabilities, their use, and best practices.

We're a team that embraces and respects different perspectives towards our work. We're not afraid to try new ideas. We're passionate about helping our customers and each other succeed. We work hard, but we also don't wait for an excuse to have fun.

It's a challenging and varied role. Anaplan is a challenging and dynamic company. You'll need to be comfortable with multitasking, ready for constant change, and able to adapt quickly

This role is an immediate full-time position. If you're ready to roll up your sleeves and tackle unique problems that no one is solving in the tech space yet, keep reading.

What you'll be doing:
Work directly with Product teams on strategic projects to measure and drive product adoption within our customer base and help surface new product ideas that will delight our customers
On a monthly planning cadence help to identify and call attention to meaningful data trends.
Monitor KPIs, web analytics dashboards, Splunk and Heap reports to point out key areas of importance in accordance to company goals
Opportunities to participate in team wide initiatives such as portfolio planning, release planning, interacting with customer facing organizations to stretch beyond model building and data analytics
More about you:
Bachelor's Degree in Mathematics, Engineering, Economics, Business or a field with a quantitative focus or a technical discipline or equivalent experience
6+ years of relevant professional experience, ideally a combination of professional services/consulting and high-tech experience
Highly analytical mindset with the ability to look at vast amounts of data and synthesize that information into intelligence that can be acted upon by the business
Database query proficiency with a working understanding of data models
Consultative style; skilled in supporting internal and external customers
Experience performing advanced analytics, segmentations and data mining, modeling
Strong quantitative, analytical, and reporting skills
Strong project/time management and organizational skills
Exceptional attention to detail
Self-motivated and deadline driven with the ability to self-manage
Technologies you'll work with:
Anaplan
Atlassian cloud: Jira and Confluence
Splunk
Salesforce
Heap
Workday
Bonus Points:
Experienced at working with R&D orgs, preferably for a SaaS company (Extra kudos if you've worked across a globally distributed team)
Expertise working with any product analytics tool (New Relic, Heap, mixpanel, Pendo, etc)
What we offer:
A rewarding, progressive career with a company that values diversity, flexibility and understands the need for a good work/life balance.
Market-leading salaries combined with generous bonuses, equity and a range of comprehensive benefits.
3 days of paid leave every year to help support the charity or cause of your choice.
Huge problems to solve you will constantly be learning and pushing boundaries, working with some of the most committed people around!
Do you align with Anaplan's Values?

Collaborative: We go out of our way to help others succeed

Explore all of our Values on Anaplan.com/careers

#AnaplanLOVE

About Anaplan

We're building a truly unique technology. From our calculation engine and in-memory data store, to apps and predictive analytics; amazing technology is being developed every day.

We're addressing a $100B/year problem that all global businesses face. Our mission is to break the traditional business planning mold, currently performed through spreadsheets or legacy systems.

Anaplan's Connected Planning platform is enabling customers to improve decision-making by turning response time into real time. With 1100+ customers and 175+ partners globally, Anaplan's platform is solving some of the most complex challenges in business. CEOs, analysts, and the press agreeAnaplan is changing the way the world does business. Learn about our history, see our recognitions and achievements, and take a look at what it's like to work at Anaplan. Get to know more about working at Anaplan by checking out our social channels.

Facebook

Twitter

Instagram

YouTube

CAN'T FIND THE PERFECT ROLE FOR YOU? NEW OPPORTUNITIES ARE OPENING UP DAILY:

ANAPLAN.COM/CAREERS",3.8,"Anaplan
3.8",Bengaluru,"San Francisco, CA",1001 to 5000 employees,2006,Company - Public,Computer Hardware & Software,Information Technology,₹10 to ₹50 billion (INR),-1
Data Scientist (Premium College),-1,"About Zycus :

Zycus is a leading global provider of A.I. powered Source-to-Pay suite for procurement, finance, and AP organizations. Our comprehensive product portfolio includes eProcurement, eInvoicing, Spend Analysis, eSourcing, Contract Management, Supplier Management, Financial Savings Management, Project Management, Request Management, Supplier Network, Insight Studio, and Merlin A.I. Suite.

The Merlin A.I. Suite is a unique platform of pre-packaged intelligent BOTs to automate run-of-the-mill procurement and A.P. tasks with intelligent and predictive suggestions. It enables teams to improve productivity through optimal efforts, enhance accuracy with minimal human intervention, and focus on strategic activities. Driven by Artificial Intelligence, Zycus’ Merlin A.I. BOTs introduce cutting edge technologies in procurement operations, making it truly autonomous and cognitive.

Our spirit of innovation and passion to help organizations create a more significant business impact is reflected among the hundreds of procurement solution deployments that we have undertaken over the years

Role : Data Scientist

Location : Bangalore

Drive Timings : 9 AM to 2.00 PM

Education : Any Engineering From IIT ,NIT , IIIT ,VIT , BITS Pilani

Venue Details :

ZYCUS INFOTECH PRIVATE LIMITED

SEZ UNIT,6TH FLOOR,GARNET Building,

Bagmane Developers Pvt Ltd SEZ II,

Bagmane World Technology Centre SEZ,

Mahadevapura,Outer ring Road,

KR Puram Hobli, Bengaluru (Bangalore) Urban,

Karnataka, 560048

Contact Person : Priyanka

Contact Number : 7899408877

Please carry your original ID proof along with Hard Copy of Resume

Requirements

We are especially looking for applicants with a strong background in Analytics and Data mining (Web, Social and Big data), Machine Learning and Pattern Recognition, Natural Language Processing and Computational Linguistics, Statistical Modelling and Inferencing, Information Retrieval, Large Scale Distributed Systems and Cloud Computing, Econometrics and Quantitative Marketing, Applied Game Theory and Mechanism Design, Operations Research and Optimization, Human Computer Interaction and Information Visualization. Applicants with a background in other quantitative areas are also encouraged to apply. If you are passionate about research and developing innovative technologies of interest to Zycus and the research community at large, the BigData Experience Lab may be the right place for you.

All successful candidates are expected to dive deep into problem areas of Zycus’s interest and invent technology solutions to not only advance the current products, but also to generate new product options that can strategically advantage Zycus

Skills
Master’s or Ph.D. in statistics, mathematics, or computer science
Only from Tier 1 Colleges
Experience using statistical computer languages such as R, Python, SQL, etc.
Experience in statistical and data mining techniques, including generalized linear model/regression, random forest, boosting, trees, text mining, social network analysis
Experience working with and creating data architectures
Knowledge of machine learning techniques such as clustering, decision tree learning, and artificial neural networks
Knowledge of advanced statistical techniques and concepts, including regression, properties of distributions, and statistical tests
1- 10 years of experience manipulating data sets and building statistical models
Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
Experience visualizing/presenting data.
Data Scientist will report in to Director Engineering - Data Scentist & the roles & responsibilities are as below:
Work as the data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with the engineering team to strategize and execute the development of data products
Execute analytical experiments methodically to help solve various problems and make a true impact across various domains and industries
Identify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variables
Devise and utilize algorithms and models to mine big data stores, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracy
Analyze data for trends and patterns, and Interpret data with a clear objective in mind
Implement analytical models into production by collaborating with software developers and machine learning engineers.
Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems
Benefits

Along with a competitive compensation structure, Zycus believes in an open culture learning environment, where everyone gets a chance to share their ideas and deliver par excellence. Here's a sneak peek to our life at Zycus.",3.3,"Zycus
3.3",Bengaluru,"Princeton, NJ",501 to 1000 employees,1998,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),"SAP Ariba, GEP, Coupa Software Inc"
DATA SCIENTIST,-1,"Should have a Master’s degree in Statistics, Mathematics, Computer Science

Responsibilities Include:
Interacting with the stakeholders, within the company and the customers, to understand the needs
Exploratory analysis from the existing data
Formulating the questions to be answered and hypotheses to be tested
Identifying additional data to be collected and third-party data sources that will help the analysis
Developing data presentations, models and algorithms required
Using data analysis tools and algorithms and to build “prototypes” to obtain stakeholders’ feedback
Providing inputs and support to software / firmware developers to build the required software components, data structures and dashboards
Interact with other project team members to adhere to overall project schedules
Ensure Adherence to internal development policies and participating in continually improving existing processes

Mandatory Technical Abilities:
Strong problem-solving skills with an emphasis on product development
Experience using statistical computer languages (R, Python…) to manipulate data and draw insights from large data sets
Experience of working with and creating data architectures
Experience of analyzing data from 3rd party providers (Google Analytics, SiteCatalyst, Coremetrics, Crimson Hexagon…)
Experience with data analytics and visualization tools (Tibco Spotfire, Business Objects…)
Proficiency in using query languages such as SQL, Hive
Experience with NoSql databases (MongoDB, Cassandra…)
Knowledge of machine learning techniques (classification, clustering, decision tree, artificial neural networks, etc.) and their real-world applications, advantages/drawbacks
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, Bayesian statistics, Inferences...) and experience with applications
Good written and verbal communication skills for coordinating across teams
Ability to learn and master new technologies and techniques",3.8,"Alpha ICT LLP
3.8",Maharashtra,"Pune, India",51 to 200 employees,-1,Other Organisation,-1,-1,Unknown / Non-Applicable,-1
Principal Data Scientist,-1,"10+ years of experience in machine learning, data mining, mathematical optimization.
PhD or Masters in Computers Science, Computer Engineering, or mathematics
Expert level knowledge in Hadoop/Mahout/MapReduce frameworks
Strong knowledge of NoSQL and Relational database systems including HBase, CouchDB, PostgreSQL, MySQL, Oracle etc.,
Background in predictive, diagnostic, operations analytics for engineering/industrial/M2M applications is strongly desired.
Good understanding of distributed systems
Knowledge of R, Matlab, SAS or other open-source/proprietary statistical packages

Overall: Recognized as the ‘go to’ expert in Analytics domain within the organization

Build design/code/test frameworks and rapid prototyping of new hypothesis
Assist engineering leadership in hiring and interviewing top talent
Steer Scrum reviews and stand-up meetings
Mentor junior staff, conduct design/code/test reviews
Contribute strongly to IP portfolio of the company in the form of patent disclosures, whitepapers, and blogs.

Roles and Responsibilities:
Drive architecture and design of in-house IP and customer solutions in the area of engineering analytics
Responsible for analyzing large data sets to develop custom models and algorithms to drive business solutions
Build complex data sets from multiple data sources and build learning systems and algorithms to analyze and filter continuous data flows and offline data analysis
Conduct statistical analysis and build models to determine trends, patterns and significant data relationships

Immediate joiner or short joiner is highly invited.

Contact
Bangalore - Corporate Office
Novel Tech Park, 46/4, GB Palya, Hosur Road, Bangalore, India - 560068.
+91 636 023 - 5133

Chennai
#408, Plot #2,1st Extn Street,Andal Nagar,AGS Colony, Velachery,Chennai, India - 600042.
+ 91 900 326 - 2287
info@continuesintelligence.com
Global Presence
Guidance Management W.L.L , #201,Opp Qatar Navigation Plaza, P.O.Box 30606, Doha - Qatar.
+ 974 443 19 651 (Board)
+ 974 662 59 283
+ 1 (972) 591 - 8280 (US)

Share

Connect and share.

Subscribe

Subscribe to our newsletter to receive news, updates, free stuff and new releases by Email.

© Copyright 2020, All Rights Reserved - Continues Intelligence Lab
Privacy Policy | Terms of Use

Home
Brief
About
Services
Solutions
Lab
Contact",-1,Continues Intelligence Lab,Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist (Machine Learning),-1,"Qualification : MCA or Bachelor's Degree in Computer Science, Information Technology, Engineering or a related field.

Key skill requirements are

Total experience - 2-4 years of experience
Excel , Machine Learning , Predictive Modeling , Python , R

2-4 years experience of building and deploying Machine Learning models, preferably in internet industry

Sound knowledge of R, Python and different data mining tools (Advanced Excel, MySQL,SQL etc.)

Deep knowledge of various predictive modeling and machine learning algorithms and underlying Maths and Stats behind them.

Bachelors / Masters degree / in CS/IT/Mathematics/Statistics.

Strong analytical, numerical, interpersonal skills and business acumen.
Forward your CV at esconinfosystems@gmail.com",-1,Escon Info Systems,Barabanki,"Lucknow, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist / Engineer,-1,"Division : Machine Learning /AI
Education :MSc(IT/Maths) /BCA /MCA /BE(IT)
Relevant Exp : 2 years
At : Ahmedabad

ML Engineer with atleast 2 year experience in design and development of machine learning algorithms and active involvement in deep learning systems. To do this job successfully, you need exceptional skills in statistics, mathematics and programming. Your ultimate goal will be to shape and build efficient self-learning applications.

key Skills & Attributes
Python
PyTorch
Numpy
SciPy
Matplotlib
Pandas
MySql
Statastics
Lineer Algebra",-1,FrankPro Consulting [OPC],Ahmedabad,"Ahmedabad, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"Entering customer and account data from source documents within time limits
Compiling, verifying accuracy and sorting information to prepare source data for computer entry
Reviewing data for deficiencies or errors, correcting any incompatibilities and checking output
Data Entry Operator job description should contain the following duties and responsibilities
Transfer data from paper formats into database systems
Type in data provided directly from customers or other parties
Create and manage spreadsheets with large numbers of figures
Verify data by comparing it to source documents
Update existing data
Produce reports
Retrieve data as requested
Perform regular backups to ensure data preservation
Sort, organize and store paperwork after entering data
Expected Start Date: 1/7/2020

Job Type: Full-time

Education:
Higher Secondary(12th Pass) (Preferred)
Work Remotely:
No",-1,Prilities Technologies,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"Job Overview
The successful candidate will be responsible for developing solutions using state-of-the-art machine-learning & computer vision techniques. They will work in a team to research, develop and deliver software/algorithms to make our products AI capable.

Education and Experience:
• At least 5 years of experience in Computer Vision and Machine Learning.
• MS/MTech in Computer Science or equivalent knowledge and experience is required.
• Demonstrated record of research and development in Computer Vison and Machine Learning.

Job Responsibilities
• Research, develop and prototype algorithms to solve problems in video content analysis.
• Document and demonstrate working prototype on benchmark datasets and real world scenarios.
• Interface with other teams within the business to ensure timely delivery of high quality products.
• Innovate to come up with new solutions and improve existing solutions.
• Be an enthusiastic and motivated member of the team.
• Maintain knowledge of new technologies in the field of Computer Vision and Machine Learning.
Essential Competencies & Skills
Integrity, Excellence, Accountability, Communication, Innovation, Problem Solving & Analysis, Teamwork
• Knowledge of state-of-the-art techniques in Computer Vision and Machine Learning.
• Hands on experience with designing, training and fine tuning deep learning algorithms.
• Comfortable using multiple deep learning frameworks like Caffe, PyTorch, TensorFlow etc.
• Experience in software development using C/C /Python in a Unix/Linux Environment.
• Excellent diagnostic and troubleshooting skills.
• Ability to work in an agile software development environment.
• Excellent written and verbal communications, and interpersonal skills.

Desirable Competencies & Skills
• Experience with working on object detection/recognition/tracking using machine learning.
• Experience with scripting languages (e.g. Matlab, Bash, Perl).
• Experience with HTML/JavaScript.
• Experience of video streaming technologies (e.g. gstreamer, ffmpeg)",3.4,"Johnson Controls
3.4",Bengaluru,"Cork, Ireland",10000+ employees,1885,Company - Public,Industrial Manufacturing,Manufacturing,₹500+ billion (INR),"Honeywell, Trane Technologies, Siemens"
Principal Data Scientist - AI Reasoning (Global AI Accelerator,-1,"Date: Jul 22, 2020

Ericsson is one of the leading providers of Information and Communication Technology (ICT) to service providers. We enable the full value of connectivity by creating game-changing technology and services that are easy to use, adopt, and scale, making our customers successful in a fully connected world. Headquartered in Stockholm, Sweden, Ericsson is proud of its global presence across 100+ countries and market areas. With a strong focus on innovation, we possess 49 thousand registered patents and a global strength of over 95 thousand competent professionals. We also take pride in supporting networks that cater to a capacity of 40 percent of the world’s mobile traffic, thereby connecting more than 2.5 billion subscribers and counting. We are a world leader in the rapidly changing environment of communications technology – by providing hardware, software, and services to enable the full value of connectivity.

Exciting Opportunity:

The complexity of emerging 5G networks makes manual management and operations of these networks impossible. AI technologies, including AI Reasoning, are increasingly being used to drive intelligent automation and autonomous operation of 5G networks that will drive economic and social transformation. Towards this, we have setup a Global AI Accelerator (GAIA) in the US, Sweden and India, with 300 experts, to fast-track our strategy execution.

We use a combination of Artificial Intelligence technologies to drive thought leadership to automate and transform Ericsson offerings and operations, including new and emerging business. This includes development of models, frameworks and infrastructure where we not only drive AI based product innovation, but also push the AI technology frontiers. We engage in both academic and industry collaborations and drive the digitalization of Ericsson and the industry by developing state of the art solutions that simplify and automate processes in our products and services and build new value through data driven insights.

Machine Learning can produce highly impactful results, however, to build truly autonomous intelligent systems, we also need symbolic knowledge in our systems. Future applications will use a combination of machine learning and AI reasoning to build truly intelligent and intent based autonomous systems. Further, for mission critical telecom systems, safety and trust in the underlying AI algorithms will be paramount. Responsible AI, which is fast emerging as a major research topic, will be key to address issues around bias, safety, security, explainability and trustworthiness of AI algorithms in telecom systems.

Ericsson is now looking for Principal Data Scientists with a strong background in AI Reasoning for our team in Bangalore.

Role Summary:

As a Principal Data Scientist in AI Reasoning, you will build reasoning systems/frameworks for telecom that leverage the vast telecom knowledge base. This will span the range of designing simpler reasoning systems that can operate in near real time in edge/constrained environments to large/complex reasoning systems that can continually analyze the end to end network performance/KPIs to ensure optimal network operation. Such frameworks will incorporate principles of trustworthy AI systems, including safety and explainability. The solutions designed will work at the scale of large telecom systems and be highly reliable. You will interface with business stakeholders to define and formulate the right business problems.

Your knowledge and experience in AI methodologies will be applied to solve challenging real-world problems as part of a highly dynamic and global team. You will work in a highly collaborative environment where you communicate and plan tasks and ideas. You will be working on high impact initiatives with other experts in AI reasoning to drive growth and economic profitability for Ericsson and its customers by accelerating current Ericsson offerings. Your contribution will also help to create new offerings in the areas of AI driven 4G and 5G network, distributed cloud, IoT and other emerging businesses.

Key Responsibilities:
Lead multiple projects with a focus on AI reasoning
Manage communication, planning, collaboration with business stakeholders.
Work with huge datasets including petabytes of 4G/5G-networks, IoT and exogenous data
Model the business problem statement into an AI problem.
Define the data sourcing strategy and work with stakeholders to procure data.
Contribute to the AI Intellectual Property creation for Ericsson
Design APIs for AI/ML models with focus on business, modularity and versioning; and build standard/canonical data models by combining multiple data sources.
Lead functional and technical analysis within Ericsson businesses and for strategic customers to understand AI-driven business needs and opportunities
Contribute to rapid and iterative development of validated minimum viable solutions addressing these needs. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical models, deep learning, reinforcement learning and other machine learning systems
Collaborate with product development teams and partners in Ericsson Businesses to industrialize AI Reasoning frameworks and solutions as part of Ericsson offerings including providing source code, workflows and documents
Work with new technologies and be the ambassador for them in AI Communities within Ericsson, nurturing the communities and mentoring junior data scientists.
Provide AI Competence build-up in Ericsson Businesses and Customer Serving Units
Develop new and apply/extend existing, concepts, methodologies, techniques for cross functional initiatives
Engage with external ecosystem (academia, technology leaders, open source etc.) to develop the skills and technology portfolio for AI needs
Present and be prominent in AI related forums and conferences, e.g., publishing patents, presenting papers, organizing sessions etc.
Key Qualifications:
Bachelors/Masters/Ph.D. in Computer Science, Data Science, Artificial Intelligence, Machine Learning, Electrical Engineering or related disciplines from any of the reputed institutes.
Applied experience: 8+ years of AI production level experience; and an overall industry experience of about 15+ years.
Strong knowledge and hands-on experience in one or more of the following areas:
Probabilistic graphical models - Bayesian networks, Markov networks
Semantic Graphs/Knowledge graphs, knowledge representation, ontology
Symbolic AI, logical reasoning
AI planning, Multi-objective Optimization
Explainable AI
Reinforcement Learning
Experience with logic programming or rule-based systems for knowledge representation & reasoning
Experience working with semantic web technologies such as RDF/OWL/SPARQL
Experience working with graph databases
Strong analytical skills and ability to ability to formulate problems and solve them independently even when the requirements are ambiguous
Ability to understand the problem domain quickly and ask the right questions
Strong Programming skills (R/Python) with proficiency in at least one
Strong grounding in mathematics, probability, statistics needed for data analysis and experiments
Proven ability to lead AI projects from conception to deployment
Experience in implementing new algorithms and methodologies from leading open source initiatives and research papers
Extensive experience in model development and life-cycle-management in one or more industry/application domain
Experience in Trustworthy AI including safety and building explainable models (XAI)
Experience in writing and presenting white papers, journal articles and technical blogs on the results
Soft Skills:
Good communication skills in written and spoken English
Great Team worker and collaborator
Creativity and ability to formulate problems and solve them independently
Self-driven and ability to work through abstraction
Ability to build and nurture internal and external communities
Additional Requirements:
Applications/Domain-knowledge in Telecommunication and/or IoT, a plus.
Experience with data visualization and dashboard creation is a plus
Ability to work independently with high energy, enthusiasm and persistence
Experience in partnering and collaborative co-creation, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence
What’s in it for you?

With over 90,000 employees across 180+ countries, we have a culture that respects and supports your ambitions, in alignment with our values of Respect, Professionalism and Perseverance. Ericsson is extremely focused on learning and development, supports mobility and flexible working hours. We are also committed to diversity and inclusion and to be a responsible and relevant driver of positive change. We also offer some awesome benefits, amazing career development and training programs to provide an empowered career in a connected world.

Next Steps:

What happens next once you apply? Read about the next steps here

For your prep and reference, here is our overall Brand video and some insights about our innovations in 5G

Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development. Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information",3.9,"Ericsson-Worldwide
3.9",Bengaluru,"Stockholm, Sweden",10000+ employees,1876,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Huawei Technologies, IBM, Cisco Systems"
Data Engineer,-1,"Can data really help local businesses around the world thrive?

Are you ready to test your skills using massive amounts of information to make critical business decisions?

Groupon’s mission is to become the daily habit in local commerce and fulfill our purpose of building strong communities through thriving small businesses by connecting people to a vibrant, global marketplace for local services, experiences and goods. In the process, we’re positively impacting the lives of millions of customers and merchants globally. Even with thousands of employees spread across multiple continents, we still maintain a culture that inspires innovation, rewards risk-taking and celebrates success. If you want to take more ownership of your career, then you're ready to be part of Groupon.

As a part of our Commercial organization, our Revenue Management Analytics and Platform teams strive to be the voice of the customer in the decisions Groupon makes. We develop and use cutting-edge data technologies to sift through large amounts of data and distill it into information about our customers' wants and needs. We then integrate these insights into our automated decision-making systems to constantly improve our services.

As a Data Engineer you will be part of our Revenue Management Analytics Data COE, tasked with improving the data and reporting infrastructure that guides decision-making across Marketing, Merchandising, Sales & Ops, Product, and the broader Revenue Management team. You will partner closely with the Analytics team to create data-driven solutions to business problems. The ability to conceptualize and create user-friendly self-service solutions is critical to be successful in this role. Our business is evolving quickly and we need you to think long term, but deliver incrementally.

We're a ""best of both worlds"" kind of company. We're big enough to have resources and scale, but small enough that a single person has a surprising amount of autonomy and can make a meaningful impact. We're curious, fun, a little intense, and kind of obsessed with helping local businesses thrive. Does that sound like a compelling place to work?

You’ll spend time on the following:
Developing and maintain new data sources that help drive the business

Architecting a new modern event driven architecture to fit AWS processing model (EMR + Spark, S3)

Working on Big Data technologies including Hadoop/Hive, PySpark, and Presto

Other technologies you’ll get to work with include Snowflake for reporting and Airflow for orchestration

Operating in an agile model leveraging scrum methodologies and Jira tools

Migrating existing data pipelines from on-prem regional data centers to AWS cloud

Leading the entire software lifecycle including hands-on development, code reviews, testing, deployment, and documentation for batch ETL's

We’re excited about you if you have:
Bachelor’s degree in Computer Science or equivalent with substantial data engineering experience

At least 3+ years of recent hands-on SQL programming experience in a Big Data environment is required; Hadoop/Hive experience is preferred

3+ years of recent hands-on experience with a modern programming language (Scala and/or Python) is required; Spark/Pyspark is preferred

Experience working in AWS cloud landscape is required

Experience developing and maintaining ETL applications and data pipelines using big data technologies is required; Airflow experience is a plus!

Ability to manage multiple stakeholders with excellent communication and interpersonal skills is a must

Understanding of full software development life cycle, agile development and continuous integration

Excellent understanding of data warehousing and modeling concepts (E.g., Star and snowflake schemas)

Ability to model data and and develop reporting solution from scratch

Prior e-commerce experience is a big plus

Groupon's purpose is to build strong communities through thriving small businesses. To learn more about the world's largest local ecommerce marketplace, click here for the latest Groupon news. Plus, be sure to check out the values that shape our culture, guide our strategy and make our company a great place to work. And just don't take our word for it. Hear from real Groupon team members and learn more about our inclusive employee groups. If all of this sounds like something that's a great fit for you, then click apply and let's see where this takes us.

Groupon is an Equal Opportunity Employer

Qualifications for employment, promotion, and other terms and conditions of employment are based upon the ability to perform the job. Equal-employment opportunities are provided to all applicants and employees without regard to race, creed, religion, color, age, national origin, sex, disability, medical condition, sexual orientation, gender identity or expression, genetic information, ancestry, marital status, military discharge status (excluding dishonorable discharge), veteran status, citizenship status, or other legally protected status. We are all responsible for maintaining this policy. Groupon is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may email us at hraccommodations at groupon.com. If you have concerns related to Groupon’s equal employment opportunities, you may contact Groupon's Ethics Reporting Service Ethicspoint.",3.4,"Groupon, Inc.
3.4",Bengaluru,"Chicago, IL",5001 to 10000 employees,2008,Company - Public,Internet,Information Technology,₹100 to ₹500 billion (INR),"Amazon, Google, Facebook"
Senior Data Scientist,-1,"Your Day-to-day Will Involve
Using modeling and analytics to understand how business decisions impact our bottom line. This may include assessing risks of new products, determining fraud policies, or identifying inefficiencies in existing operations.
Ensuring the team is delivering on our KPIs by using various data mining and data visualization tools to monitor portfolio performance and identify improvement opportunities
Developing hypotheses and set up your own problem frameworks to test for the best solutions. You will also scope the operational feasibility, lead implementation efforts, and monitor the success of your solutions.
Leveraging data analysis tools and technologies. For example, using machine learning to determine how we identify fraud.
Creating new solutions rooted in empathy and research that assist all customers as they work to better manage their finances.
Collaborating in a team environment. As part of our crew, you will learn to energetically rally diverse groups in pursuit of a common goal.

The Ideal Candidate Is
Innovative & Curious - You have the desire and ability to connect and empathize with our customers. You have an entrepreneurial spirit and get excited about creating new businesses and reinventing current ones. You ask why, explore, and bring your unique perspective to the table.
Analytical& Action-Oriented - You are data driven and outcome focused. You grow comfortable with ambiguity, fueled by a hunger to learn and constantly seeking out new challenges. You have a desire to take action, try new things, and sometimes fail. You persevere but know when to change course and are up for juggling multiple deliverables.
Collaborative & Team-Oriented- You always keep the people around you in the loop and are excited to communicate complex ideas clearly to make sure your co-workers understand the why behind their work and their key priorities.
Inclusive- You will empathize with those around you and care about their success, as you bring people together around whats possible.
Basic Qualifications
Bachelors degree or higher in a quantitative field (Business, Math, Economics, Finance, Statistics, Science, Engineering)
At least 1 year of work experience in analysis or consulting
Experience with or willingness to learn tools such as SQL, R, Python, Tableau
We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors, which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.
PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities.",3.7,"PayPal
3.7",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Data Engineer (ETL),-1,"We are looking for a Data Engineer who will work on the collecting, storing, processing, and analyzing of huge sets of data (ETL). The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Roles & Responsibilties
Design, develop and support data platform with large dataset for realtime and batch processing.
Implement ELT/ETL processes from a wide variety of data sources using best practices while working with other technology teams
Work with business and product teams to understand their data needs, gather requirements and delivering dataset
Work on automating/improving existing data sets, ETL/ELF pipelines
Identify the opportunities to improve data storage and query performance and implement them
Basic Qualifications

• Comprehensive knowledge of the Data Collection, Transformation, Storage and Query technologies' landscape.

• Hands on expert experience with at least a few of these systems.

• 2-4 years of strong hands-on development experience

• 1+ years experience of hands-on big data experience

• Should be able to write high quality code - preferably in Java/Python/Ruby

• Should have excellent written and verbal communication skills

• Data modelling, SQL and Databases knowledge

• Good understanding of HDFS, Hive, Spark, Kafka

Good to Have

• Exposure to Amazon Web Services

• Exposure of BI tools like Tableau/Qliksense/Superset

• Experience of building applications with streams and complex event processing

• Should be able to prioritize in fast-moving complex environment and produce solutions despite complex requirements",3.5,"Doubtnut
3.5",Gurgaon,"Gurgaon, India",51 to 200 employees,2016,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
DATA ANALYST,-1,"The Data Analyst is part of the consulting and data science team of the organization and will be responsible for project delivery on data science and data analysis projects and solutions specific to the manufacturing industry. The Data Analyst will be expected to be skilled in the retrieval, preparation and analysis of data of various kinds. The Data Team offers high-impact work with diverse opportunities for data analysts to grow skills in the areas of data science, advanced analytics and related areas.
Hands on programming skills in one interpreted programming language and one compiled programming language are required for this role.

Key Skills and Experience

Good working knowledge of interpreted object-oriented programming in languages such as Python or R is required
Working knowledge of one compiled programming language, such as Java or C++ is desired
Good working knowledge of SQL data transformations is required. Exposure to data visualization, data summarization, aggregations, filters and other data transformations is desired
A working level understanding of machine learning techniques is required. Those with strong fundamentals in the underlying mathematics - linear algebra, optimization or statistics of machine learning will be considered favorably.
Knowledge of statistical data analysis or signal processing as applied to continual improvement, engineering system design, evaluation and testing are good to have
Exposure to topics such as large scale data management, cloud based compute and storage technologies are good to have
Good interpersonal, presentation and written communication skills .

Education and Work Experience Requirements

Bachelor’s degree in electrical/electronics, mechanical, industrial or computer science/engineering
Prior work experience or internships in industries such as engineering, power, construction, manufacturing or oil and gas will be considered favorably
Master’s degree in any engineering field is considered a plus
Freshers and those with less than 2 years of experience in the industry
Relevant certifications in data science, statistics, machine learning and deep learning are good to have.",4.2,"The Data Team
4.2",Bengaluru,"Singapore, Singapore",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
NLP & Text Mining Data Scientist,-1,"Job title

NLP & Text Mining Data Scientist
Department

Analytics & Data Science
Report To

Deepthi Devarakonda / Simhan Ramakrishnan
No of yrs. of exp

4+ years
Work Location

Pune, MH, India
No of Positions

2
Assigned Recruiter
Talent Partner

Version Control
Version No.

Date

Remark

Updated by
1.0

5/7/2020

Initial Version

SR

It’s Time For A Change…

Your Future Evolves Here

Evolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Our pursuit of this mission is the driving force that brings us to work each day. We believe in embracing new ideas, challenging ourselves and failing forward. We respect and celebrate individual talents and team wins. We have fun while working hard and Evolenteers often make a difference in everything from scrubs to jeans.

Are we growing? Absolutely—56.7% in year-over-year revenue growth in 2016. Are we recognized? Definitely. We have been named one of “Becker’s 150 Great Places to Work in Healthcare” in 2016 and 2017, and one of the “50 Great Places to Work” in 2017 by Washingtonian, and our CEO was number one on Glassdoor’s 2015 Highest-Rated CEOs for Small and Medium Companies. If you’re looking for a place where your work can be personally and professionally rewarding, don’t just join a company with a mission. Join a mission with a company behind it.

Position summary

The NLP and Text Mining scientist will support building of AI products in Agile fashion that empower healthcare payers, providers and members to quickly process medical data to making informed decisions and overall reduce health care costs. As a research scientist/engineer part of Data Science and Artificial Intelligence team you will be working primarily on unstructured text data to build machine learning models for information retrieval applications. These applications include but are not limited to optical character recognition, understanding the contents of the medical documents using natural language processing, and integrating processes into the overall AI pipeline to mine healthcare and medical information with high recall and other relevant metrics. We ingest claims, medical charts, etc. from providers containing unstructured data which will be transformed into structured data to support automated entry into our storage layers for downstream applications. The results will be used dually for real-time operational processes with both automated and human-based decision making as well as contribute to reducing healthcare administrative costs. We work with all major cloud and big data vendors offerings including but not limited to (Azure, AWS, Google, IBM, etc.) to achieve AI goals in healthcare and support Evolent business.

Essential functions

The NLP Text Mining Scientist / Engineer will have the opportunity to shape team culture and operating norms as a result of the fast-paced nature of a new, high-growth organization.
4+ years of Industry experience primarily related to Unstructured Text Data and NLP (PhD work and internships will be considered if they are related to unstructured text in lieu of industry experience but not more than 2 years will be accounted towards industry experience)
Develop Natural Language Medical/Healthcare documents comprehension related products to support Evolent Health business objectives, products and improve processing efficiency, reducing overall healthcare costs
Gather external data sets; build synthetic data and label data sets as per the needs for NLP/NLR/NLU
Apply expert software engineering skills to build Natural Language products to improve automation and improve user experiences leveraging unstructured data storage, Entity Recognition, POS Tagging, ontologies, taxonomies, data mining, information retrieval techniques, machine learning approach, distributed and cloud computing platforms
Own the Natural Language and Text Mining solutions — from platforms to systems for model training, versioning, deploying, storage and testing models with creating real time feedback loops to fully automated services
Work closely and collaborate with Data Scientists, Machine Learning engineers, IT teams and Business stakeholders spread out across various locations in US and India to achieve business goals
Provide training to other Data Scientist and Machine Learning Engineers in your speciality
Strong understanding of mathematical concepts including but not limited to linear algebra, Advanced calculus, partial differential equations and statistics including Bayesian approaches
Strong programming experience including understanding of concepts in data structures, algorithms, compression techniques, high performance computing, distributed computing, and various computer architecture
Good understanding and experience with traditional data science approaches like sampling techniques, feature engineering, classification and regressions, SVM, trees, model evaluations
Additional course work, projects, research participation and/or publications in Natural Language processing, reasoning and understanding, information retrieval, text mining, search, computational linguistics, ontologies, semantics
Experience with developing and deploying products in production with experience in two or more of the following languages (Python, C++, Java, Scala) (4+ years)
Strong Unix/Linux background and experience with at least one of the following cloud vendors like AWS, Azure, and Google for 2+ years
Hands on experience with one or more of high-performance computing and distributed computing like Spark, Dask, Hadoop, CUDA distributed GPU (2+ years)
Thorough understanding of deep learning architectures and hands on experience with one or more frameworks like tensorflow, pytorch, keras (2+ years)
Hands on experience with libraries and tools like Spacy, NLTK, Stanford core NLP, Genism, johnsnowlabs for 2+ years
Understanding business use cases and be able to translate them to team with a vision on how to implement
Identify enhancements and build best practices that can help to improve the productivity of the team.


Nice to Have
Medical concepts with codes from standard ontologies (SNOMED CT, LOINC, RxNorm, ICD, etc.)
Lucene, Solr, Elastic Search experience
Experience with Kubernetes and dockers
Experience building REST API’s for AI work and knowledge of microservices architecture
Participation in open source community projects
Academic Qualification:
Master’s degree or above in Computer Science, Computational linguistics, Mathematics, Physics or electrical engineering with research experience from a strong academic program along with thesis (No Post Graduate diplomas and undergraduate degrees)
Completion of thesis/research is required as part of graduation in computer science, artificial intelligence, Mathematics, Physics, Electrical Engineering or statistics
A PhD degree in Computer Science, Artificial Intelligence, Computational Linguistics, Machine Learning, or related technical field is preferred from a strong academic program
Publication record in top NLP conferences (NIPS, ICLR, ACL, NAACL, EMNLP, SIGIR, WWW etc) is preferred",2.9,"Evolent Health
2.9",Pune,"Arlington, VA",1001 to 5000 employees,2011,Company - Public,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),-1
Senior Data Scientist - Data Sciences,-1,"GEP is a diverse, creative team of people passionate about procurement. We invest ourselves entirely in our client’s success, creating strong collaborative relationships that deliver extraordinary value year after year. Our clients include market global leaders with far-flung international operations, Fortune 500 and Global 2000 enterprises, leading government and public institutions.
We deliver practical, effective services and software that enable procurement leaders to maximise their impact on business operations, strategy and financial performance. That’s just some of the things that we do in our quest to build a beautiful company, enjoy the journey and make a difference. GEP is a place where individuality is prized, and talent respected. We’re focused on what is real and effective. GEP is where good ideas and great people are recognized, results matter, and ability and hard work drive achievements. We’re a learning organization, actively looking for people to help shape, grow and continually improve us.
Are you one of us?
GEP is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, ethnicity, color, national origin, religion, sex, disability status, or any other characteristics protected by law. We are committed to hiring and valuing a global diverse work team.
For more information please visit us on GEP.com or check us out on LinkedIn.com.

Working on Computer Vision, Natural Language processing, Deep Learning related problems in supply chain

MS/PHD
5 years of experience post MS/PHD
Ability to solve complex open ended problems",3.9,"GEP
3.9",Hyderabad,"Clark, NJ",1001 to 5000 employees,1999,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Data Analyst,-1,"Job description :

Research Analyst / Sr. Research Analyst
In a nutshell :
As an analyst, you will have to develop an in-depth understanding of user journeys on our Platform and generate data-driven insights recommendations to help product business in meticulous decision making.
Professional Qualifications:
Minimum of 1-2 years for Data analyst
Ability to frame a research plan, gather insights from secondary & primary research
Design appropriate solutions to drive meaningful insight for clients’ needs and their business
Executing quantitative analysis that translates data into actionable insights.
Being responsible for conducting and working on the A/B testing and manual testing of the features launched in the product.
Exp in GA, Google tag Manager, GA certified
Understanding of Javascript, proficient with debugging tools, understanding of digital marketing, ability to connect GA & A/B testing tools.
Regular audit of GA & its requirements.
Knowledge of SQL/Python / big data analytics. Working knowledge of Tableau will be an advantage.
Pulling data from various sources
Identifying the effort vs Impact metrics for the features in the product.
Relevant experience
Minimum of 3 years of user research, market research and qualitative / UX research experience
Mapping of user journeys from different sources based on their lifetime value & retention.
Might have worked on pulling data from sources to create the journey.
Ability to frame a research plan, gather insights from secondary research, lead fieldwork, and conduct in-context interviews and observations
Ability to interpret data to gather insights on user behaviors
Experience of using qualitative and quantitative methods in an applied, professional context to drive insight and understanding in service of design and decision making
Experience with research methods – interviews, observation, diary studies, prototyping, surveys, user testing, and experiments – at different stages of the design process: to inspire early design work, inform the initial opportunity, collect formative feedback to support iteration, and validate a go-to-market solution
Exceptional communication and storytelling skills. Fluency in multiple media for storytelling–while grounding storytelling in research–a bonus

Job Type: Full-time

Experience:
work: 2 years (Preferred)
total work: 3 years (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.2,"Embibe
4.2",Bengaluru,"Bengaluru, India",501 to 1000 employees,2012,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
Dev - Data Scientist,-1,"Requirements:
Qualification: Master’s Degree in Computer Science, Statistics, Applied Math or related field.
7+ years’ practical experience with SAS, ETL, Data Processing, Database Programming and Data Analytics.
Excellent understanding of Machine Learning and Artificial Intelligence Techniques and Algorithms.
Experience with common data science tools like (but not limited to) R, Weka, NumPy, MatLab, etc.
Good knowledge of statistics.
Experience with programming languages such as Java and Python.
Skilled in Reporting and Data Visualization Software, with strong presentation skills.
Experience with SQL (Structured Query language) programming.
Extensive background in data mining and statistical analysis.
Ability to understand various data structures and common methods in data transformation.
Excellent pattern recognition and predictive modeling skills.
NoSQL and BigData experience preferred.
Skills Required
Java, Python, SQL, SAS, ETL, Data Processing, Database Programming, Data Analytics.
Research and develop statistical learning and Machine Learning models for data analysis.
Understanding information needs and extracting data from a variety of sources in order to create analytics deliverables that meet those needs.
Leverage models to address key growth challenges, cross-channel spend allocation, response modeling and marketing program attribution.
Collaborate with Product Management to understand Business needs and devise possible solutions.
Ideas to generate key decision making KPIs.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.",4.8,"Diamondpick
4.8",Bengaluru,"Chennai, India",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst / Data Scientist | Internship | Tech-Savvy|,-1,"Job role:

As a data analyst, you will be responsible for compiling actionable insights from data and assisting program, sales and marketing managers build data-driven processes. Your role will involve driving initiatives to optimize for operational excellence and revenue.

Job Location: Indore | Full-Time Internship | Stipend - Performance Based |

About the company:

Anaxee Digital Runners is building India's largest last-mile verification & data collection network of Digital Runners (shared feet-on-street, tech-enabled) to help Businesses & Consumers reach remotest parts of India, on-demand. KYC | Field Verification | Data Collection | eSign | Tier-2, 3 & 4

Sounds like a moonshot? It is. We want to make REACH across India (remotest places), as easy as ordering pizza, on-demand. Already serving 11000 pin codes (57% of India) | Website: www.anaxee.com

Important: Check out our company pitch (6 min video) to understand this goal - https://www.youtube.com/watch?v=7QnyJsKedz8

Responsibilities:
Ensure that data flows smoothly from source to destination so that it can be processed
Utilize strong database skills to work with large, complex data sets to extract insights
Filter and cleanse unstructured (or ambiguous) data into usable data sets that can be analyzed to extract insights and improve business processes
Identify new internal and external data sources to support analytics initiatives and work with appropriate partners to absorb the data into new or existing data infrastructure
Build tools for automating repetitive tasks so that bandwidth can be freed for analytics
Collaborate with program managers and business analysts to help them come up with actionable, high-impact insights across product lines and functions
Work closely with top management to prioritize information and analytic needs
Requirements:
Bachelors or Masters (Pursuing or Graduated) in a quantitative field (such as Engineering, Statistics, Math, Economics, or Computer Science with Modeling/Data Science), preferably with work experience of over [X] years.
Ability to program in any high-level language is required. Familiarity with R and statistical packages are preferred.
Proven problem solving and debugging skills.
Familiar with database technologies and tools (SQL/R/SAS/JMP etc.), data warehousing, transformation, and processing. Work experience with real data for customer insights, business, and market analysis will be advantageous.
Experience with text analytics, data mining and social media analytics.
Statistical knowledge in standard techniques: Logistic Regression, Classification models, Cluster Analysis, Neural Networks, Random Forests, Ensembles, etc.",3.5,"Anaxee Digital Runners Pvt Ltd
3.5",Indore,"Indore, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:

Whatfix is disrupting the way Application Support and Learning content is consumed by providing Contextual and Interactive WalkThroughs inside enterprise applications at the exact time a task is being performed.

We provide enterprises with a Software Platform that allows them to create Interactive Guides or Flows that sit as an overlay inside any web application. Flows are Contextual - appear based on where you are in the application (location) and who you are (role). Optimal performance and adoption of any web application is attained when there is easy access to Contextual Information - inside the application at the time a task is being performed.

Your Opportunity:

As a part of the Whatfix Data Engineering team, you will be responsible for creating the Data Lake infrastructure from scratch and get your hands dirty by working on cutting edge tech stack.

Primary Requirement:
Strong experience in schema design and SQL
Knowledge of frameworks & distributed systems, good at algorithms, data structures, core java, design pattern.
Understanding & experience in technologies like Cassandra/Redshift/Hive
Must have built fault tolerant ETL pipelines
Worked with distributed data processing frameworks - Apache Spark, Apache Flink or Hadoop.
Knowledge of service oriented architecture
Deploying systems on the public cloud
Good analytical skills is a plus
Requirements
Bachelor’s/Master’s degree in Computer Science
Overall 3+ years of experience with at least minimum 1 year working experience on any data driven company/platform.
Strong understanding of different storage architectures and their appropriate application.
Exceptional problem solving, analytical and organisation skills with a detail-oriented attitude.
Passion for learning new technologies
A self-motivated learner and builder with strong customer focus and obsession with quality
Database performance concepts like indices, segmentation, projections, and partitions.
Good to have
Previously worked in a SaaS company
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status",4.1,"Whatfix
4.1",Bengaluru,"Bengaluru, India",51 to 200 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"Who are we?

LIDO is an ed-tech company revolutionizing the formal classroom education through a unique and immersive online classroom for every child in India. With our exciting and fun online classes for our students, we are building the Lido experience: cutting edge content like animated videos and interactive games, a personalized platform for homework, tests, challenges, and inspiring teachers.

Why to be a part of Lido?

Lido’s goal is to inspire and empower every child for the future. In order to achieve this goal, we invite you to be a part of our ever-growing LIDO family. Grab the opportunity to work with passionate individuals, from Stanford, Duke, IIT and BITS, as we open the door to engaging and impactful learning!

Job Description:
We are looking for a data analyst to help us make better business decisions using information from our available data. Your task is to gather and prepare data from multiple sources, run statistical analyses, and communicate your findings in a clear and objective way.

Responsibilities:
Understanding the business requirements so as to formulate the problems to solve and restrict the slice of data to be explored.
Collecting data from various sources.
Performing cleansing, processing, and validation on the data subject to analyze, in order to ensure its quality.
Exploring and visualizing data.
Performing statistical analysis and experiments to derive business insights.
Clearly communicating the findings from the analysis to turn information into something actionable through reports, dashboards, and/or presentations.

Skills:
Experience solving problems in the edtech domain or consumer analytics.
Experience with data integration from multiple sources.
Proficiency in SQL.
Experience with popular statistical and machine learning techniques, such as clustering, linear regression, KNN, decision trees, etc.
Good scripting skills with python or R
Proficiency in at least one data visualization tool, such as Matplotlib, Plotly, D3.js, ggplot, etc.
Experience with BI tools such as Tableau, Metabase and Power BI.
Great communication skills.

Analytics Stack: (stackshare link):
Amazon Kinesis, PostgreSQL, Salesforce, Metabase, Amazon SageMaker",4.1,"Lido Learning
4.1",Mumbai,"Mumbai, India",501 to 1000 employees,2019,Company - Private,Primary & Secondary Education,Education,Unknown / Non-Applicable,-1
DATA SCIENTIST / MACHINE LEARNING EXPERT,-1,"Relevant Experience
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Excellent understanding of Machine learning techniques and algorithms
ETL Knowledge (data cleansing)
Data Visualization
Expereience in BI poject
Experience in Agile/ SCRUM projects
Experience in supply chain is an added advantage
Key Technical Requirements
Required
R / Mathlab / Octave
NoSQL database such as MongoDB, DocumentDB, CosmosDB, etc
Git
Desirable
JavaScript, Angular 2/4, Node JS
Azure and AWS",4.0,"Spectrus
4.0",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr.Data Scientist,-1,"Job Description

Experience: 5+ yrs

Location: Bangalore

Roles and Responsibilities

Experience in statistical modelling, machine learning, data mining, unstructured data analytics, natural language processing.
Experience in variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.)
Experience in Processing, cleansing, and verifying the integrity of data used for analysis
Experience in Selecting features, building and optimizing classifiers using machine learning techniques
Experience in automating scoring using machine learning techniques
Experience in building recommendation systems
Experience in building high quality prediction systems
Experience in Selecting features, building and optimizing classifiers using machine learning techniques
Develop processes and tools to monitor and analyze model performance and data accuracy

Qualifications

An Engineering Degree - B.E/B.Tech/MS/ in any stream – Computer Science preferred with 4+ years of experience.
Experience with Python preferably with Jupyter notebook
Experience with data science libraries such as Scikit-learn, Pandas, Numpy, Scipy, Spacy, NLTK.
Experience with Deep learning libraries such as Tensorflow, PyTorch
Good applied statistics skills, such as distributions, statistical testing, regression, etc.",3.6,"Antal International
3.6",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Analyst,-1,"Position Title
Data Analyst

28-Jul-2020

Job ID
299739BR

Job Description
70 tactical buyers are supporting both commercial and NTO towers out of Prague NGSC, covering region Europe, Switzerland, Middle East and North Africa.
Your responsibilities include, but are not limited to:

•Assemble large, complex data sets that meet functional / non-functional business requirements & Identify, design, and implement internal process improvements, automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
•Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, NoSQL and AWS ‘big data’ technologies & Interpreting data, analysing results using statistical techniques & Developing and implementing data analyses, data collection systems and other strategies that optimize statistical efficiency and quality.
•Acquiring data from primary or secondary data sources and maintaining databases & Provide guidance and support to the regions and countries and identify areas requiring process improvements to standardize data governance.
•Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
•Ability to perform data mining, data modeling, and data production. Create custom software components and analytics applications. Research new uses for existing data.
•Create and maintain optimal data pipeline architecture with IT team & performing initial analysis to assess the quality of the data, further analysis to determine the meaning of the data & performing final analysis to provide additional data screening to prepare reports based on analysis and presenting to management & Work with data and analytics experts to strive for greater functionality in our data systems.
•Lead global projects to ensure standardization, harmonization and reliability of the procurement data to enable procurement data analysis & Lead the process super user community, ensuring regular engagement, training (including process & tool demo) and collection of feedback.

https://www.youtube-nocookie.com/embed/Mo1vwtVPVA0

Minimum requirements
•5 years of experience working with data in the procurement domain & 3 years of data steward experience in pharmaceutical industry is preferred.
•Experience in MDM, BI, SAP ,A high level of mathematical ability & Programming languages, such as SQL, Oracle and Python,
•big data tools: Hadoop, Spark, Kafka, relational SQL and NoSQL databases, including Postgres and Cassandra,
•Data pipeline and workflow management tools: Azkaban, Luigi, Airflow, AWS cloud services: EC2, EMR, RDS, Redshift, stream-processing systems: Storm, Spark-Streaming, object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
•Strong understanding of procurement data lifecycle (generation through end use) & Experience executing defined data governance models.

Why consider Novartis?
799 million. That’s how many lives our products touched in 2019. And while we’re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people’s lives?

We believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you’re given opportunities to explore the power of digital and data. Where you’re empowered to risk failure by taking smart risks, and where you’re surrounded by people who share your determination to tackle the world’s toughest medical challenges.

Imagine what you could do at Novartis!
Commitment to Diversity & Inclusion:
Novartis embraces diversity, equal opportunity and inclusion. We are committed to building diverse teams, representative of the patients and communities we serve, and we strive to create an inclusive workplace that cultivates bold innovation through collaboration, and empowers our people to unleash their full potential.

Join our Novartis Network: If this role is not suitable to your experience or career goals but you wish to stay connected to learn more about Novartis and our career opportunities, join the Novartis Network here: https://talentnetwork.novartis.com/network

Job Type
Full Time

Country
India

Work Location
Hyderabad, AP

Functional Area
Procurement

Division
NBS

Business Unit
PROCUREMENT NBS

Employment Type
Regular

Company/Legal Entity
Nov Hltcr Shared Services Ind

Shift Work
No",3.9,"Novartis
3.9",Hyderabad,"Basel, Switzerland",10000+ employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
Data Engineer,-1,"Due to the current health crisis related to COVID-19 and the escalating visa/travel restrictions in place, we're currently unable to extend offers to anyone who cannot work from India due to lockdown visa/travel restrictions, or other restrictive measures until further notice. Consequently, we will be prioritizing candidates who can start in this location by set date as expected. We're keeping the situation under review and would adjust our position should the restrictive measures be removed later on.

Minimum qualifications:
Bachelor's degree in Computer Science or related technical field, or equivalent practical experience.
3 years of industry experience in software development, data engineering, business intelligence, data science, or related field with experience in manipulating, processing, and extracting value from datasets.
Preferred qualifications:
Master's degree in Computer Science, or related field.
Understanding of Big Data technologies and solutions (Spark, Hadoop, Hive, MapReduce) and multiple scripting and languages (YAML, Python).
Understanding of Google Cloud Platform (GCP) technologies in the big data and data warehousing space (BigQuery, Cloud Data Fusion, Dataproc, Dataflow, Data Catalog).
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.
Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to research scientists, engineering teams and business audiences.
About the job


At Google, we work at lightning speed. So when things get in the way of progress, the Business Systems Integration team steps in to remove those roadblocks. The team identifies time-consuming internal processes and then builds solutions that are reliable and scalable enough to work within the size and scope of the company. You listen to and translate Googler needs into high-level technical specifications, design and develop recommended systems and consult with Google executives to ensure smooth implementation. Whether battling large system processes or leveraging our homegrown suite of Google products for Googlers themselves, you help Googlers work faster and more efficiently.

Data Engineers understand internal processes and what it takes to run Google at speed with its ever growing scale. As a Data Engineer, you'll focus on solving problems and creating value for Googlers by building solutions that are reliable and scalable to work with the size and scope of the company.

You will play a major role in developing, deploying, and supporting Google’s internal business applications. You will be tasked with creating custom-built software on google stack, and you will be part of teams that implement vendor sourced enterprise software, configuring that software, customizing it, and integrating with other internal systems.

Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.
Responsibilities
Design, build and deploy internal applications to support our technology life cycle, collaboration and spaces, service delivery management, data and business intelligence among others.
Work closely with analysts and business process owners to translate business requirements into technical solutions.
Build internal solutions, with custom front ends (web, mobile) and backend services that automate business processes.
Maintain highest levels of development practices including: technical design, solution development, systems configuration, test documentation/execution, issue identification and resolution, writing clean, modular and self-sustaining code, with repeatable quality and predictability.

Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form.",4.4,"Google
4.4",Bengaluru,"Mountain View, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Microsoft, Apple, Facebook"
Senior Data Scientist,-1,"Role Summary:
We are looking for a highly motivated individual, passionate about technology to join Baker Hughes Digital team. As the Senior Data Scientist, in Baker Hughes Digital, you will focus on developing impactful and innovative analytics products for the O&G industry. The candidate will be responsible for designing analytics for products and solutions, leverage strong machine learning expertise to develop new analytics for driving growth in asset, application & industry coverage and lead engagements with external/internal customers. The candidate is also expected to mentor other engineers in analytics methods.

Essential Responsibilities:
Work in cross-functional teams to translate algorithms into commercially viable products and services.
Contribute to technical teams in development, deployment and application of applied analytics, predictive analytics and prescriptive analytics capabilities.
Develop self-learning systems that can predict failures and autocorrect based on multiple data sources
Work with the engineering team to incorporate your analyses and solutions, including working with the visualization team to create intuitive UI and rich UX stories. Partner with data engineers on data quality assessment, data cleansing and data analytics efforts
Gather and analyze data, devise innovative data science solutions and build prototypes to enable development of high-performance algorithms in scalable, product-ready code.
Initiate and propose unique and promising modeling features, develop new and innovative algorithms and technologies, pursuing patents where appropriate
Stay current on published state-of-the-art algorithms and competing technologies.
Contribute to the development of software and data delivery platforms that are service-oriented with reusable components across teams (multiple teams) that can be orchestrated together into different methods for different businesses.
Research and evaluate emerging technology, industry and market trends to assist in project development and/or operational support activities to for multiple teams or complex scenarios.

Qualifications/Requirements:
MS Degree in Computer Science or in “STEM” Majors (Science, Technology, Engineering and Math)
A minimum of 2 years as data scientist
A minimum of 3 years of technical hands-on coding experience

Eligibility Requirements:
Legal authorization to work in India. We will not sponsor individuals for employment visas, now or in the future, for this job
Any offer of employment is conditioned upon the successful completion of a background investigation and drug screen
Must be willing to travel

Desired Characteristics:
PhD in Computer Science or in “STEM” Majors (Science, Technology, Engineering and Math)
Strong distributed systems and architecture knowledge, and experience with multitier architecture
Mission critical systems experience is preferred
Ability to manage complex technical projects.
Demonstrates expertise in problem solving and technical innovation.
Demonstrated experience of delivering on commitments to clients.
Demonstrates capability of 'rolling up sleeves and getting hands dirty'.
Works well in fast paced growing environment.
Provides excellent influential communication skills and business acumen to both an arbitrator and advocate for technical issues.
Experience developing applications in an agile/DevOps environment would be a distinct advantage
Solid understanding of software development tools & infrastructure

Effective teaming and problem-solving abilities

Strong interpersonal and leadership skills
Able to interface effectively with all levels of the organization and external customers

Technical Expertise:
Proven experience coding in Machine Learning/AI techniques including Deep learning techniques (RNN, CNN, GAN, etc), Support Vector Machines; Regularization Techniques; Boosting, Random Forests, Ensemble Methods, image/video/audio processing, Bayesian modeling, time series modeling
Demonstrated experience in Parallel programming frameworks for GPUs, TPUs
Demonstrated ability to develop containerized solutions (Docker/Mesos etc)
Strong implementation experience with high-level languages and frameworks such as R, Python, Perl, Ruby, Scala, Apache Spark, Storm, SAS
Demonstrated ability to work with a variety of Deep learning frameworks including TensorFlow, Keras, Caffe, CNTK, etc…
Strong hands-on skills in sourcing, cleaning, manipulating and analyzing large volumes of data including SQL and NoSQL databases
Experience with end-to-end modeling projects, from research to solutions to analytic products
Proven experience in using well-established supervised and unsupervised machine learning methods for large industry-strength data analysis problems.
Participates in enterprise strategy development, including environmental analysis, opportunity identification, value cases and business innovation portfolio development. Reviews and/or analyzes and develops architectural requirements at domain level, aligning architectural requirements with software development strategy.
Leads and facilitates the domain’s architecture governance process based on EA’s governance structure.
Leads teams in developing plans and assessing improvement options.

Business Acumen:
Create, analyze and manage projects that provide direct business benefit; demonstrate detailed knowledge of business operations and strategic direction, including merger & acquisition opportunities
Understand industry trends and competitive landscape and the implications for your business
Partner with business leaders to align projects with business goals and needs.

Leadership:
Recommends allocation of budget to meet architectural initiatives critical to business/mission success.
Develops the business case for approval.
Provides leadership, technology guidance and mentors others throughout their domain.
Define the skills, competencies in the skills and talents for architecture team members.
Facilitates dialogues that produce new perspectives and trigger recommendations for substantial innovative / enhancements, and analysis of consequences.
Influences through others.
Uses experts or other third parties to influence.
Builds direct and ""behind the scenes"" support for ideas, uses chains of indirect influence.

Personal Attributes:
Challenges conventional thinking and traditional ways of operating and invites stakeholders to identify issues and opportunities.
Takes a holistic systems perspective.
Envisions, compares and contrasts multiple potential long-range enterprise-wide futures.
Empathizes with multiple points of view

Locations:
Bangalore, India",3.5,"Baker Hughes
3.5",Bengaluru,"Houston, TX",10000+ employees,-1,Company - Public,Oil & Gas Services,"Oil, Gas, Energy & Utilities",₹500+ billion (INR),-1
Principal Data Scientist - Global AI Accelerator,-1,"Date: Jul 14, 2020

Ericsson is one of the leading providers of Information and Communication Technology (ICT) to service providers. We enable the full value of connectivity by creating game-changing technology and services that are easy to use, adopt, and scale, making our customers successful in a fully connected world. Headquartered in Stockholm, Sweden, Ericsson is proud of its global presence across 100+ countries and market areas. With a strong focus on innovation, we possess 49 thousand registered patents and a global strength of over 95 thousand competent professionals. We also take pride in supporting networks that cater to a capacity of 40 percent of the world’s mobile traffic, thereby connecting more than 2.5 billion subscribers and counting. We are a world leader in the rapidly changing environment of communications technology – by providing hardware, software, and services to enable the full value of connectivity.

At Ericsson, you can be a game changer! Because working here isn’t just a deal. It’s a big deal. This means that you get to leverage our 140+ years of experience and the expertise of more than 95,000 diverse colleagues worldwide. As part of our team, you will help solve some of society´s most complicated challenges, enabling you to be ‘the person that did that.’ We’ve never had a greater opportunity to inspire change; setting the bar for technology to be inclusive and accessible; empowering an intelligent, sustainable, and connected world.

Are you in?

Our Exciting Opportunity

It will be practically impossible for human brains to understand how to run and optimize next generation of wireless networks, i.e., 5G network with distributed edge compute, that will drive economic and social transformation for all aspects of society. Machine Learning (ML) and other Artificial Intelligence (AI) technologies will be vital for us to handle this opportunity. We are setting up a Global AI Accelerator (GAIA) in the US, Sweden and India, with 300 specialists, to fast-track our strategy execution!

You will,

As a Principal Data Scientist, you shall build and deploy AI models into production with focus on scaling, monitoring and performance. You shall build effective AI models using stacking/ensemble techniques; and provide prediction explainability and prescriptive capability in ML models.
Define the Data sourcing strategy and works with partners to procure data. Contribute to IP creation for Ericsson in AI/ML
Contribute to rapid and iterative development of validated minimum viable solutions addressing these needs. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical models, deep learning, reinforcement learning and other machine learning systems.
Lead studies and creative usage of new and/or existing data sources. Work with Data Architects to leverage existing data models and build new ones as needed.
Work with new technologies and be the ambassador for them in MI Communities within Ericsson, nurturing the communities and mentoring junior data scientists.
Engage with external ecosystem (academia, technology leaders, open source etc.) to develop the skills and technology portfolio for MI’s needs.
To be successful in the role, you must have:
Applied experience: 8+ years of ML and/or AI production level experience; and an overall industry experience of about 15+ years.
Strong Programming skills (R/Python) with proficiency in at least one.
Proven skills in building AI/ML based solutions using a variety of frameworks such as Python, R, H2O, Keras, TensorFlow, Spark ML etc.
Hands-on experience in designing and building AI models using Deep Neural Networks for applicable scenarios.
What's in it for you?

With over 90,000 employees across 180+ countries, we have a culture that respects and supports your ambitions, in alignment with our values of Respect, Professionalism and Perseverance. Ericsson is very passionate about learning and development, supports mobility and flexible working hours. We are also committed to diversity and inclusion and to be a responsible and relevant driver of positive change. We also offer some awesome benefits, amazing career development and training programs to provide an empowered career in a connected world.

What happens next once you apply?

Read about the next steps here. For your preparation and reference, here is our overall Brand video and some insights about our innovations in 5G

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

Do you believe that an organization fostering an environment of cooperation and collaboration to execute with speed creates better business value? Do you value a culture of humanness, where fact based decisions are important and our people are encouraged to speak up? Do you believe that diverse, inclusive teams drive performance and innovation? At Ericsson, we do.

We provide equal employment opportunities without regard to race, color, gender, sexual orientation, transgender status, gender identity and/or expression, marital status, pregnancy, parental status, religion, political opinion, nationality, ethnic background, social origin, social status, indigenous status, disability, age, union membership or employee representation and any other characteristic protected by local law or Ericsson’s Code of Business Ethics.

Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact.

This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development.

Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information.",3.9,"Ericsson-Worldwide
3.9",Bengaluru,"Stockholm, Sweden",10000+ employees,1876,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Huawei Technologies, IBM, Cisco Systems"
Data Engineer,-1,"42733

Job Summary
You will be part of Enterprise Data & Analytics team responsible for identifying analytical needs, exploring new technologies, and applying data sciences/machine learning concepts to maximize value from data assets. Senior Data Engineer will work closely with key stakeholders both IT and Business to turn data into critical information and knowledge that can be used to make sound business decisions. The individual must have an in-depth understanding of the business environment, an interest in going beyond the obvious, aptitude for new tools/technologies, and obsession for customer success

Essential Functions
Organize, lead, and facilitate multiple teams on highly complex, cross-functional, enterprise data and analytics initiatives
Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in demand for various types of data
Collaborate with key stakeholders to define KPI and build data metrics to measure KPI’s
Define and develop cognitive solutions for business needs, incorporating technologies in Machine Learning, AI, and Analytics
Identify, evaluate and suggest new technology opportunities (including open source) that will have an impact on the enterprise-wide BI systems, machine learning, and predictive analytics
Work with vendors to provide cost estimates and general project management guidance
Job Requirements
Must possess strong subject matter expertise in at least two domains of Sales, Marketing, Install Base, Finance, and Customer Support areas.
Data modeling experience in Enterprise Data Warehouse and DataMart
Hands-on experience in SQL, Python, NoSQL, JSON, XML, SSL, RESTful APIs, and other related standards
Hands-on emphasis with a proven track record of building and evaluating data pipes, and delivering systems for final production
Exposure to Big Data Analytics (data and technologies), Data Sciences, predictive analytics, modelling, machine learning, in-memory applications
Experience with various data systems like Oracle Data Warehouse, SAP HANA, Hadoop/Hive, Vertica, Redshift, Presto, Mangodb
Strong understanding devops, on-premise, and cloud deployments - AWS, Google, Azure
Education
Minimum of 8 to 12 years of experience with Bachelor of Science Degree in Computer Science, Management Information Systems, or Business, or related field is required

Job Segment:
Database, Warehouse, ERP, Information Systems, Developer, Technology, Manufacturing

Apply now »",4.2,"NetApp
4.2",Bengaluru,"Sunnyvale, CA",10000+ employees,1992,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹500+ billion (INR),"Nimble Storage, Pure Storage"
Patient Safety Scientist 1,-1,"Patient Safety Scientist 1 works collaboratively with the Global Safety Physician (GSP) and Senior/Principal PV Scientist with the review of safety data and related documents for potential safety issues. He/she has the ability to provide authoring and PV input to safety documents and regulatory reports. PV Scientist also has the ability to lead meetings and present safety data and analyses

Accountabilities/Responsibilities
Perform all Surveillance activities including monthly signal-detection activities and SIRC activities for established products with minimal supervision.
Able to draft the periodic regulatory documents (PBRERs, PSURs, DSURs) according to the agreed process and timelines for established products with minimal supervision.
Able to draft production of high-quality and timely responses to safety queries with minimal supervision.
Identifies and uses appropriate sources of information and database searches to retrieve relevant data for evaluation of signals in partnership with the GSP, for all products in area of responsibility.
Support a performance-driven culture
Raises appropriate concerns/issues to senior staff in a timely manner.
Has the ability to perform duties as a Safety Strategy and Management Team (SSaMT) leader for smaller or less complex projects
Ensure compliance with global and local procedural documents and local implementation of Patient Safety objectives, policies, processes and procedures
Compliance with relevant procedural documents
Ensure good communication and guidance to AZ products
Liaise effectively and maintain excellent relationship with external contacts
Support a performance-driven culture
Minimum Requirements Education and Experience
Qualified to degree level in biosciences or an equivalent healthcare or pharmaceutical industry background, with proven competency in patient safety/clinical development
Comprehensive understanding of applicable Patient Safety regulatory obligations in EU
Awareness of Patient Safety policies, processes and procedures
Awareness of medico-legal aspects of patient safety
Up to 4 to 6 years Patient Safety experience (with clear evidence of delivery
Total of 7 to 9 years of experience
Skills and Capabilities


The role holder will have:
Ability to work effectively as a member of a cross-functional or global team
Ability to acquire and assimilate knowledge in different disciplines, disease and therapeutic areas
Good communication skills with ability to work across cultures
High ethical standards, including a commitment to AstraZeneca values and behaviors
Ability to appreciate diversity and work as equals with global and cross-functional teams
Internal and External Contacts/Customers
Patient Safety personnel at all levels
Regulatory Affairs and other AstraZeneca personnel
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status.",4.0,"AstraZeneca
4.0",Karnataka,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
Data Scientist: Freshers or 1+ Yrs of Experienced,-1,"Responsibilities
Provide analytic support by using various tools to perform detailed quantitative analysis
Execute research and analysis, including data gathering, processing and modeling from different data sources
Process and verify integrity of data used for analysis to correct discrepancies and ensure quality
Implement data analysis/visualization and explain complex solutions to people from multiple functions and hierarchical levels
Understand business needs and objectives
Generate regular reports and insights for relevant divisions (e.g. product, marketing, gaming, AI)

Requirements
Deep knowledge of Excel, Python, SQL and at least project level experience of
analytics coding in iOS and/or android
Familiarity with business analytics and visualisation tools (e.g. Google Analytics, Mixpanel, Tableau, Graphana)
Superb communication skills and strong organizational abilities
Attention to detail and problem-solving aptitude",3.7,"3RI TECHNOLOGIES
3.7",Pune,"Pune (India), India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist - NLP,-1,"Position Title
Data Scientist - NLP

28-Jul-2020

Job ID
297627BR

Job Description
70 tactical buyers are supporting both commercial and NTO towers out of Prague NGSC, covering region Europe, Switzerland, Middle East and North Africa.

To establish and maintain a global process across the entire enterprise by managing the implementation program, including all planning, resourcing and budgeting requirements, and ensuring future changes to the process and enabling system are properly managed.
Your responsibilities include, but are not limited to:

●Think creatively, conceptualize and lead projects resulting in substantial long-term impact on the company’s vision in many key strategic areas such as drug discovery/manufacturing, product launches, determining optimal treatment plans/courses, expanding patient access, predictive/precision medicine, risk mitigation, business growth, brand management, product life cycle, data strategy etc
●Design, develop and deliver various data science based insights, outcomes and innovation (using mathematics, computer science, statistics, engineering, management science, technology, economics, etc) and create “proof of concepts & blueprints” to drive faster, timely, highly precise, workable and proactive decision making based on data based insights and science and shape strategic glidepath of the company
●Lead successful cross-functional collaborations with significant execution rigor, customer focus and “Data to Decision” thinking
●Demonstrate a comprehensive view of science and technology and deliver a compelling enterprise vision of how Data, Digital & Artificial Intelligence can contribute to providing quantum in leap in building foundational/groundbreaking capabilities transcending a wide spectrum of areas such as research/science, drug discovery/development, commercial, procurement, technology, product, brand, business, strategy, analytics, operations, risk/compliance, legal, etc and propel growth and performance
●Design and develop state-of-the-art, data-driven analysis, models and decision strategies to solve science and business problems. Choose and apply appropriate predictive analytic technologies (such as statistical modeling, neural networks, scorecards, machine learning, pattern recognition and artificial intelligence) heavily injected with domain expertise. Appropriately question the veracity and business relevance of data, assumptions, and results and use of solution at all steps of the process. The outcome is improved performance through the design, development, and deployment of project deliverables.
●Own adoption, execution and integration of data science based solution end to end all the way from discovery to launch/post-launch and also into business, design, product, delivery, operations, marketing, brand management, research and technology roadmaps.

https://www.youtube-nocookie.com/embed/ggbnzRY9z8w

Minimum requirements
•M.S/Ph.d in Computer Science, Robotics, Mathematics, Statistics, Operations Research, Cognitive Sciences, Psychology, Engineering, Finance, Economics, Medicine, Technology, Management Science, Quantitative Methods and other related disciplines.
•6 -10 years of overall experience with demonstrated track record in data science solutioning.
•Programming environments: java/python/Hive/Hadoop/HBase/C++/CSharp/Unix/Map Reduce/Perl/ Matlab/Xml
•A solid foundation in AI Methodologies like Information Retrieval and Extraction, NLG, NLU
•Exposed to concepts in Natural Language Processing & Statistics, esp., in their application such as Sentiment Analysis, Contextual NLP, Dependency, Parsing, Chunking, Summarization, etc.
•Experience in some of the following domains: object detection / recognition / segmentation, visual similarity, text detection & OCR, human / face detection, generative models, reinforcement learning, video analytics, model compression / optimization
•Comfortable in using Python or R to build automated dashboards using, D3.js, Plotly, Dash, Flask, Django, R-Shiny
•Basic understanding of deep learning frameworks (e.g. Caffe, tensorflow, pytorch)
•Expertise in 1) Java and 2) Django, Dash, ML, Image processing (in Python) will also be an added advantage
•Experience in working with data science cloud platforms AWS, Azure, Google Cloud will also be an added advantage
•Proficient in at least one of: PyTorch, TensorFlow, MxNet
•Experience in OpenCV, TensorFlowServing, MxNet Model Server or TensorRT Inference Server is a bonus

Why consider Novartis?
799 million. That’s how many lives our products touched in 2019. And while we’re proud of that fact, in this world of digital and technological transformation, we must also ask ourselves this: how can we continue to improve and extend even more people’s lives?

We believe the answers are found when curious, courageous and collaborative people like you are brought together in an inspiring environment. Where you’re given opportunities to explore the power of digital and data. Where you’re empowered to risk failure by taking smart risks, and where you’re surrounded by people who share your determination to tackle the world’s toughest medical challenges.

Imagine what you could do at Novartis!
Commitment to Diversity & Inclusion:
Novartis embraces diversity, equal opportunity and inclusion. We are committed to building diverse teams, representative of the patients and communities we serve, and we strive to create an inclusive workplace that cultivates bold innovation through collaboration, and empowers our people to unleash their full potential.

Join our Novartis Network: If this role is not suitable to your experience or career goals but you wish to stay connected to learn more about Novartis and our career opportunities, join the Novartis Network here: https://talentnetwork.novartis.com/network

Job Type
Full Time

Country
India

Work Location
Hyderabad, AP

Functional Area
Procurement

Division
NBS

Business Unit
PROCUREMENT NBS

Employment Type
Regular

Company/Legal Entity
Nov Hltcr Shared Services Ind

Shift Work
No",3.9,"Novartis
3.9",Hyderabad,"Basel, Switzerland",10000+ employees,1996,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),-1
Data Engineer,-1,"Snowflake started with a clear vision: develop a cloud data platform that is effective, affordable, and accessible to all data users. Snowflake developed an innovative new product with a built-for-the-cloud architecture that combines the power of data warehousing, the flexibility of big data platforms, and the elasticity of the cloud at a fraction of the cost of traditional solutions. We are now a global, world-class organization with offices in more than a dozen countries and serving many more.

We're looking for a strong Data Engineer to build state of the art Data pipelines for snowflake . In this role, you will work closely with many cross-functional teams to build a data pipeline to ingest data into our internal Snowflake environment . This is a strategic, high-impact role that will also help shape the future of Snowflake products and services.

RESPONSIBILITIES:


Architect & build data pipelines for snowflake .
Manage and improve the data integrity and reliability of data services.
Build data frameworks to onboard new data into our snowflake data warehouse
Foster collaboration among engineering teams, IT & other business groups to ensure data access is secure & are audit-able.
Train distributed team members in data pipelines.
WHAT YOU WILL NEED:


5+ years of experience in Data warehousing, data modeling, and SQL .
3 + years of experience in working on public cloud (AWS, Azure or GCP)
3+ years of experience in MPP or Cloud data warehouse solutions like Snowflake, Redshift, BigQuery or Teradata
Experience in ELT based data pipeline build outs is useful..
Experience with sourcing and modeling data from application APIs.
Strong communication and cross functional collaboration skill

PREFFERED QUALIFICATIONS:


B.S or MS in Computer Science or equivalent practical experience.
5 + years experience in building data pipelines using Python/Java & SQL
Experience in ETL tools is nice to have.
Snowflake is growing fast, and we're scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.

How do you want to make your impact?

Snowflake is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, color, gender identity or expression, marital status, national origin, disability, protected veteran status, race, religion, pregnancy, sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.",4.1,"Snowflake
4.1",Pune,"San Mateo, CA",1001 to 5000 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Amazon, Google, Microsoft"
Data Analyst,-1,"Job Overview
Search and Identify Companies and Decision Makers who are looking for Software developers (software vendors) from the US, UK.
Source and Verify contact details of such prospects and create excel databases.
Proficient in gathering contact data including phone numbers & emails for companies and/or their decision makers.
Proficient in Social media lead generation such as- LinkedIn, Factiva, Google, Yahoo, inside view etc.
Minimum Qualifications
Proven working experience as a data analyst.
Technical expertise regarding data models, database sources & data mining.
Adept at queries, report writing and presenting findings.
Expertise in B2B data mining.
Responsibilities
Interpret data, analyze results using statistical techniques and provide data on regular basis.
Develop and implement data collection systems and other strategies that optimize statistical efficiency and data quality.
Acquire data from primary or secondary data sources and maintain databases in CRM.
Locate and define new process improvement opportunities for data mining.
To be considered for this role, send your application, CV and earliest possible start date to career@credencys.com",2.9,"Credencys Solutions
2.9",India,"La Palma, CA",51 to 200 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"Myntra’s Engineering team builds the technology platform that empowers our customers’ shopping experience and enables the smooth flow of products from suppliers to our customers’ doorsteps. We work on areas such as building massive-scale web-applications, engaging user-interfaces, big-data analytics, mobile apps, workflow systems, inventory-management etc. We are a small technology team where each individual has a huge impact. You will have the opportunity to be part of a rapidly growing organization and gain exposure to all the parts of a comprehensive ecommerce platform.

You will be part of: Data Science

Data Sciences team at Myntra uses data and algorithms to build large scale systems to enable better decision making for the business as well as render better customer experience. Some of the areas of our focus are Personalisation, Pricing, Demand Sensing, Recommendation Systems,
Search etc. Some of the cool things we are working on !

Decoding Fashion Contexts using Word Embeddings. Building novel algorithms for fashion Personalization & Recommendations. Building dynamic pricing models and novel metrics to evaluate to improve the experience. Building prediction models to improve delivery promise times. Building optimization models to improve supply chain cost

Your Responsibilities:
Technical Guidance : As a data scientist, you will have the opportunity to leverage Myntra’s rich data to develop data products that are used by millions of users and propel the growth of our business. You will collaborate with a strong team of engineers, product managers and fellow
data scientists in defining the frontier of data products. Data scientists will work on how to evaluate potential approaches, build features,statistical/machine learning models and determine metrics. You will communicate insights/recommendations to a wide spectrum of
stakeholders across the company.
Execution and Delivery : You will be expected to instill and follow good software development practices and ensure timely delivery of high-quality products. You should be familiar with agile practices as well as be able to adapt these to the needs of the business, with a constant focus on product quality.

Desired Skills and Experience:
Must have a Phd or a related field. Strong understanding of object-oriented programming, concurrency and fundamentals of computer-science.
2 years industry experience developing machine learning models sat scale from inception to business impact.
Deep understanding of modern machine learning techniques and their mathematical underpinnings such as classification, recommendation systems , and natural language processing.
Proven ability to tailor machine learning solutions to business problems in a cross-functional team.
Experience with distributed machine learning and computing framework (Spark, Hadoop, Mahout or equivalent) . Applied experience preferred.
Strong programming skill (Python, R, or Scala preferred).
Experience productionizing machine learning models is a plus.
High proficiency in at least one of the following broad areas:, Machine learning, Computer vision, Statistical modeling/inference, Information retrieval, Data mining or NLP

Requirements

Technical depth : You have the strong technical competence required to gain credibility. Ability to architect, design and code yourself. Technical experience in building and operating web-based applications. Deep understanding of all layers of the web-stack work (from the client
interface to the database. ) Knowledge of multiple technology stacks/languages/tools and their pros/cons.
Execution ability : Focus on delivering products in a timely manner with high quality. Familiarity with multiple software development practices and tools, and the proven ability to adapt, champion and institute good practices and tools.",4.0,"Myntra.com
4.0",Bengaluru,"Bengaluru, India",1001 to 5000 employees,2007,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,"Amazon, Snapdeal, Voonik"
Data Analyst/Scientist,-1,"We are looking for a Data Analyst/Scientist to analyze large amounts of raw information to find patterns/outliers that will help improve our company. We will rely on you to build data products to extract valuable business insights. In this role, you should be highly analytical with a knack for analysis, math, and statistics. Critical thinking and problem-solving skills are essential for interpreting data. We also want to see a passion for machine-learning and research. Your goal will be to help our company analyze trends to make better decisions.

Responsibilities

Identify valuable data sources and automate collection processes
Undertake preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams

Requirements

5+ years of experience
Proven experience as a Data Scientist or Data Analyst
Experience in data mining
Understanding of machine-learning and operations research
Working knowledge of Machine Learning algorithms ( GLM, GBM, XGBoost)
Knowledge of deep learning models and frameworks
Knowledge of SQL and Python; familiarity with Scala, Java or C++ is an asset
Experience using business intelligence tools (e.g. Tableau, Data Studio) and data frameworks (e.g. Hadoop, Spark)
Familiarity with Python libraries (Pandas, Celery, MultiProcessing)
Familiarity with machine learning frameworks (like H2O, scikit-learn)
Analytical mind and business acumen
Strong math skills (e.g. statistics, algebra)
Problem-solving aptitude
Excellent communication and presentation skills
BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or other quantitative field is preferred",-1,hudsondata.com,Gurgaon,-1,-1,-1,-1,-1,-1,-1,-1
"Senior Data Engineer, Platform (APAC)",-1,"MongoDB is the top tier modern, general purpose database platform, designed to unleash the power of software and data for developers and the applications they build. Developers around the world are using MongoDB to build software to create new businesses, modernize existing businesses, and transform the lives of millions of people around the world.

Headquartered in New York, with offices across North America, Europe, and Asia-Pacific, MongoDB has more than 17,000 customers, which include some of the largest and most sophisticated businesses in nearly every vertical industry, in over 100 countries.

MongoDB is growing rapidly and seeking a Senior Data Engineer to be a key contributor to the overall internal data platform at MongoDB. You will build data driven solutions to help drive MongoDB's growth as a product and as a company. You will tackle complex data-related problems using very diverse data sets.

Our ideal candidate has experience with
Several programming languages (Python, Scala, Java, etc.)
Data processing frameworks like Spark
Streaming data processing frameworks like Kafka, KSQ, and Spark Streaming
A diverse set of databases like MongoDB, Cassandra, Redshift, Postgres, etc.
Different storage format like Parquet, Avro, Arrow, and JSON
AWS services such as EMR, Lambda, S3, Athena, Glue, IAM, RDS, etc.
Orchestration tools such as Airflow, Luiji, Azkaban, Cask, etc.
Git and Github
CI/CD Pipelines


You might be an especially great fit if you
Enjoy wrangling huge amounts of data and exploring new data sets
Value code simplicity and performance
Obsess over data: everything needs to be accounted for and be thoroughly tested
Plan effective data storage, security, sharing and publishing within an organization
Constantly thinking of ways to squeeze better performance out of data pipelines
Nice to haves
You are deeply familiar with Spark and/or Hive
You have expert experience with Airflow
You understand the differences between different storage formats like Parquet, Avro, Arrow, and JSON
You understand the tradeoffs between different schema designs like normalization vs. denormalization
In addition to data pipelines, you're also quite good with Kubernetes, Drone, and Terraform
You've built an end-to-end production-grade data solution that runs on AWS
You have experience building machine learning pipelines using tools like SparkML, Tensorflow, Scikit-Learn, etc.
Responsibilities

As a Senior Data Engineer Platform, you will:
Estimate task complexity, report progress, and voice risks to peers and managers
Both learn from and teach peers and junior engineers
Develop and maintain expertise in bigdata best practices
Design and build large-scale batch and real-time data pipelines with data processing frameworks like Spark on AWS
Help drive best practices in continuous integration and delivery
Help drive optimization, testing, and tooling to improve data quality
Collaborate with other software engineers, machine learning specialists, and partners, taking learning and leadership opportunities that will arise every single day


Success Measures

In 3 months

you will have familiarized yourself with much of our data platform, be making regular contributions to our codebase, will be collaborating regularly with partners to widen your knowledge and helping to resolve incidents and respond to user requests

6 Months

you will have successfully investigated, scoped, executed, and documented a small to medium sized project and worked with partners to make sure their data needs are satisfied by implementing improvements to our platform

12 Months

You will have become the key person for several projects within the team and will have contributed to the data platform's roadmap. You will have made several sizable contributions to the project and are regularly looking to improve the overall stability and scalability of the architecture

Do you know, Why MongoDB is a fantastic place to work and build your career?
Disrupting a $64 Billion market
Top NoSQL database in the world
Largest Ecosystem and the fastest growing database in the world
Close to 17,000 customers in over 100 countries and over 90+ million downloads
>120% net ARR expansion rate over each of the last twenty quarters
Sequoia Capital and a number of other Top VC firms have invested in MongoDB. Sequoia Capital calls us out as one of their flagship portfolios; Sequoia has also invested in Apple, Google, Youtube, and WhatsApp
9-figure revenue company, with very high double-digit growth rates
Be a part of the company that's reinventing the database, passionate about innovation and speed
Enjoy a fun, inspiring culture that is engineering focused
Work with talented people around the globe
Learn, contribute, and make an impact on the product and community.


Life at MongoDB

Our India office culture
180+ people, with teams in Sales, Engineering, HR, Finance, IT & Marketing
Regular group outings and opportunities to get to know your colleagues
Employee affinity groups


Our Benefits
Competitive salary and equity
Comprehensive Health cover, dental cover, travel insurance & Life Insurance.
Free lunch twice per week and a fully stocked kitchen with healthy and sweet treats.
Macbooks are company standard
26 weeks Maternity & 20 Paternity leave to spend time with new arrivals.",4.5,"MongoDB
4.5",Gurgaon,"New York, NY",1001 to 5000 employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist & Business Development,-1,"We are looking for individuals who can turn data into information, information into insights and insights into business decisions.

Key Responsibilities:
You will be working on unique data consisting of around 1000 events per day. You will continuously drive data culture and evangelize use of data science in all possible aspects of business.
You will make sure that product is having end to end data points for partners and all stake holders to required information to grow the business.
Researching and developing algorithms/ models/ strategies for personalizing the product. Make sure developed algorithms drive significant lift in reality and refine as required
Help building ML/predictive framework to draw insights at scale for different aspects of business, for example understanding drivers of various customer behaviour or understanding points of failure
Develop strategies for effective data analysis and reporting
Help build and enhance sophisticated algorithms and various analytical tools to transform raw data into actionable business insight
Preparation and analysis of performance reports
Monitor the success of the clients and advise them by applying industry knowledge to interpret data and improve performance
Keep abreast of industry news and trends

Knowledge, Skills & Experience:
Excellent problem solving skills, with ability to communicate even complex ideas in succinct manner
Proven experience as a data scientist or data analyst
Strong work ethics like sense of collaboration and ownership, result orientation, being team player
Understanding of Python, Tableau, Power Bi, related tools used from data handling to modelling to implementation is preferred
Master’ or equivalent degree in Computer Science, Mathematics, Statistics and Information Systems.
Knowledge in SQL & Java script is a huge plus
Ability to display complex quantitative data in a simple, intuitive format and to present findings in a clear and concise manner
Understanding in machine learning, general statistics and data science principles",4.7,"Grid Logic Software Private Limited
4.7",Hyderabad,"Gurgaon, India",501 to 1000 employees,2010,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist-ONWARD,-1,"Data Scientist-ONWARD
Job Description


At Kimberly Clark, we believe in a truly diverse and inclusive culture and towards this end a brand new initiative – ONWARD, Career Restart Program has been recently launched .

The vision of the program is to broaden and diversify candidate talent pools by empowering experienced professionals to restart their careers, following a hiatus, with Kimberly Clark. Seasoned professionals (often women) with a career break are highly skilled and are an untapped pool of experienced talent. Through this program we will provide a road to re entry, strengthening our workforce diversity and maximizing women’s workforce participation.

If you think you qualify for this program and have the skills, check out the following open job with us-

IT Data Scientist -ONWARD

Job Description Summary

The ITS Data Scientist is responsible for integrating business, information, and technology into analytical models that help drive business performance and competitive advantage and providing the business with answers to questions. The role collaborates with Business, IT Functional Engineers and Platform architects to create value from varied data sources. Creating value from data requires a range of talents: from data integration and preparation, to architecting specialized computing/database environments, to data mining and intelligent algorithm development.

This role is viewed as an expert in making sense of complex data environments, encompassing both business data and process understanding and technical expertise. Leads in developing innovative, technical solutions to important, highly complex strategic and operating problems. Has strong knowledge in business and technical functions that are touch points with their area of expertise. Provides technical consulting on complex projects. Acts as a source of direction, training and guidance for other team members. Is knowledgeable in industry best practices in their area of expertise and uses resources outside of KC to deliver solutions.

Duties and Responsibilities:Job Details
Development of advanced analytics to help drive competitive advantage from data with accountabilities across multiple functional and technical areas with wide range of complexity.
The Data Scientist must understand complex data types (integrate, manipulate, prepare), know advanced analytics (appropriate techniques, interpret data and diagnose models, meet business requirements), and focus on the business outcomes (goals, constraints, decisions while communicating outcomes via presentations).
Develop models and algorithms that drive innovation throughout the organization. This may include marketing, supply chain, inventory planning and deployment, network planning, order routing, and order fulfillment and delivery.
Conduct advanced statistical analysis to provide actionable insights, identify trends, and measure performance.
Build learning systems that monitor data flows and react to changes in customer preferences, network constraints, and business objectives Collaborate with engineers to implement and deploy scalable solutions.
Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders.
Partners as a bridge between the business and the information management teams to make sure that the solution fits within the data management principals.
Coordinates data science implementations while leading design variances based upon business needs while ensuring artifacts and repositories are documented.
Manages engagements with vendors as they relate to evaluation, design and delivery of business capabilities.
Contributes to the evaluation and selection of software product standards Leader in industry representation, policy formation, User Groups, and strategic direction
Mentors others to complete Continuous Improvement (CI) initiatives; consults and shares knowledge across org; awareness of industry trends.
Education required/ preferred:
B.A. or B.S. in Information Technology, Data Science, or related field.
At least 8 years of IT experience and at least 4 years or more of work experience in data scientist discipline.
Deep knowledge of machine learning, statistics, optimization or related field.
Experience with R, Python, Matlab is required.
Experience building machine learning application in areas like time series forecasting, classification models, clustering models, multivariate regression models etc.
Experience in Microsoft Azure Stack in the Cloud with focus on Data Factory, Data Bricks, BLOBs, Data Lake Storage, ML Studio, Azure Analysis Services, Azure Data Warehouse, Power BI etc.
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark, Python, R, Gurobi, MySQL, etc.).
Excellent written and verbal communication skills along with strong desire to work in cross functional teams.
Consumer products experience in an online and/or retail/manufacturing environment is preferred.
Possess strong leadership skills and exhibit creative thinking to be able to come up with inventive solutions to solve business challenges.
Provide thought leadership while keeping up with industry trends and disseminating information across the organization.
Experience working with blended teams consisting of employees, vendors, and consultants with both onshore and offshore resources.
Strong Technical leadership of advanced analytics teams and vendors.
Extensive experience collaborating with Enterprise Architects and infrastructure engineers to identify, design, and implement highly complex, end-to-end solutions
Cultivates networking opportunities within the organization
Broad range of business and IT experiences; Has achieved technical and/or business certification(s).
Travel may include less than 10% of work time. Travel may also include travel via aircrafts and motor vehicles to various locations, if applicable. Varying working conditions may include prolonged sitting, typing and viewing computer/laptop screens, along with occasional bending, reaching, lifting, carrying, climbing, twisting, stooping, walking and standing.

Global VISA and Relocation Specifications:
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship.
This role is available for local candidates already authorized to work in the role’s country only. K-C will not provide relocation support for this role.
Primary Location
IT Centre Bangalore GDTC
Additional Locations
Worker Type
Employee
Worker Sub-Type
Regular
Time Type
Full time",3.9,"Kimberly-Clark
3.9",Bengaluru,"Irving, TX",10000+ employees,1872,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),"Procter & Gamble, Georgia-Pacific, Unilever"
Data Engineer I,-1,"The Datalytics Platform team is building a brand new data warehouse for digital goods processed by the Appstore and Alexa teams, and also a few other digital good providers.
As a part of this team, you will be building and enhancing this new data platform, and be the owner of data ingestion, processing and presentation. In this role, you will be working with multiple people across the org and geographies to cater to their data needs. You will get deep understanding of the business requirements, and own the transformation and storage of the data that can be consumed by the customers to drive the business forward. In a data driven company like Amazon, this role would come with a lot of responsibilities and exciting challenges.

Roles and Responsibilities:

Own data processes; write queries that meet stakeholder business requirements, lead work with SDEs for full-scale automation.
Mentor engineers on Data Engineering concepts.
Liaise with stakeholders to understand the requirements and translate into data model, processes, and tie them back to source
Have the capability to handle large data sets in analysis through the use of additional tools/scripts
Define analytical approach; review and vet analytical approach with stakeholders.
Proactively and independently work with stakeholders to construct use cases and associated standardized outputs.

Basic Qualifications

· 1+ years of experience as a Data Engineer or in a similar role
· Experience with data warehousing, and building ETL pipelines
· Experience in SQL
Bachelors degree or higher in an engineering or technical area such as Computer Science, Physics, Mathematics, Statistics, Engineering or similar.
5+ years of experience as a Data Engineer dealing with large complex data scenarios.
High level of aptitude with SQL, Excel (pivot tables) required
Strong understanding of BI technologies and their application including database warehousing and dashboarding experience.
Experience on at least one data visualization tools such as OBIEE and Tableau .
Experience with Big data technologies like S3, Hadoop, Spark, PIG
A self-starter who loves data!

Preferred Qualifications

Masters degree at a well-regarded institution in an analytical field with deep understanding of underlying technologies preferred
High degree of comfort to own/lead statistical/quantitative analysis and reach sound conclusions and disseminate findings to key stake holders and/or senior management",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Sr Data Scientist - Product Development,-1,"Date: Mar 12, 2020

Ericsson enables communications service providers to capture the full value of connectivity. The companys portfolio spans Networks, Digital Services, Managed Services, and Emerging Business and is designed to help our customers go digital, increase efficiency, find new revenue streams, and create new user experiences. Ericssons investments in innovation have delivered the benefits of telephony and mobile broadband to billions of people around the world ensuring our solutions and our customers are at the forefront of innovation. We support networks that connect more than 2.5 billion subscribers. With over 90,000 employees and customers in 180 countries, we combine global scale with technology and service leadership. 40 percent of the worlds mobile traffic is carried over an Ericsson network. And, our Technology for Good and Connect to Learn programs include creating technology that makes it easier to save lives, feed societies, bring technology to emerging markets and connectivity to remote areas, and grow businesses and prosperity.

At Ericsson, we give our employees the freedom to think big and navigate their career, on a global scale. We create technology that helps others, from helping people enjoy their favourite content to helping people recover from natural disasters by enabling better communications between rescue workers. Your ideas and innovations can turn into achievements that impact society and change the world, creating new connections, new possibilities, and new capabilities. We find that Ericsson is at its best when we bring together the diverse skills of our people. Working across business areas, across cultures, across geographical borders, across technical disciplines. More often than not, across ground-breaking solutions. Next generation technology can be staggeringly complex. But the simpler it is to use; the more people benefit from it. Join us and help build technology that makes it simple to connect with information, business, societies, and each other.
Job Summary

As a Data Scientist, you will need to have strong programming skills and deep understanding of data science and Machine Learning tools. Have proven experience in Data Science methodologies and how to apply them to solve challenging real-world problems as part of a highly dynamic and global team. You have strong communication, collaboration and planning skills. You will be working on high impact initiatives with other specialists in Machine Intelligence to drive growth and economic profitability for Ericsson and its customers by accelerating current Ericsson offerings as well create new offerings in the areas of MI driven 4G and 5G network, distributed cloud, IoT and other emerging businesses.

Key Qualifiications
Education: Bachelor in Engineering (B.E/ B.Tech in IT, Telecom)
Minimum years of exp-12+years
Proven skills and track record (Github, open source etc.) in the use of current state of the art machine learning frameworks such as Keras, TensorFlow, Scikit-Learn, H2o, Spark etc. in developing ML/AI applications
Experience of data wrangling and data munging, using Big Data technologies
Strong analytical skills and ability to acquire new knowledge and apply it in the job
Programming skills in various languages (C++, Scala, Java, R) with proficiency in Python and/or C++
Good communication skills in written and spoken English
Creativity and ability to formulate problems and solve them independently
Ability to develop and drive new ways of working, to produce deliverables in a more efficient way
Key Responsibilities
Experience with data visualization and dashboard creation
Certifying MI MOOCS, a plus
Applications/Domain-knowledge in Telecommunication and/or IoT, a plus.
Ability to build and nurture internal and external communities
Experience in writing and presenting white papers, journal articles and technical blogs on the results
Ability to work in a collaborative environment, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence

Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development. Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information.",3.9,"Ericsson-Worldwide
3.9",Chennai,"Stockholm, Sweden",10000+ employees,1876,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Huawei Technologies, IBM, Cisco Systems"
Senior Data Scientist,-1,"Senior Data Scientist-832962

At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.

What is the Senior Data Scientist – Mathematical Finance – Client Analytics group responsible for?

Works individually in support of a Fintech (Wealth Management) initiative.

Designs, develops and programs methods, processes, and systems to consolidate and analyze structured or unstructured, diverse “big data” sources to generate actionable insights and solutions for on-going research and product enhancement.

Develops and codes software programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources.

What are the ongoing responsibilities of an Senior Data Scientist – Mathematical Finance?

Mathematical Modelling:
Demonstrates Expertise in advanced mathematics, especially mathematical finance
Demonstrates a good grasp of probability distributions and stochastic calculus
Designs and validates mathematical models to find interlinkages and applications of academic models within a business context
Works on mathematical optimization modules similar to Traveling salesman problems under multivariate constraints. Familiarity with Lagrangian multivariate optimization problems a plus
Analyzes and interprets the results of research experiments through statistical models Solves analytical problems utilizing large structured, semi-structured and un-structured data in a distributed processing environment

Data Analysis:
Collects data from disparate systems, analyzes and delivers the data as intelligence that is actionable
Uses distributed and parallel processing frameworks like Spark for the analysis
Statistical Analysis (Data Mining and Advanced Analytical Techniques)
Develops predictive, statistical, behavioral, or other models using supervised and un-supervised machine learning / statistical modeling techniques
Performs ad hoc statistical and data mining analyses
Training, Research and Development

What ideal qualifications, skills & experience would help someone to be Successful?

Master’s degree in Mathematical Finance / Quantitative Finance / Financial Engineering from Tier-1 or Tier -2 Institutes highly preferred
Ph.D in Mathematics, Statistics, Econometrics, Engineering or related disciplines, from Tier-1 or Tier -2 Institutes. (Mandatory)
4-6 years of experience in data science.
Certifications in Financial Mathematics or related subjects from institutes such as IIQF, IFMR, TIFR etc would be highly valued.

Experience:
4-6 years of experience in data science
Understanding and prior experience with financial markets (Mandatory)
Knowledge of and Experience with Stochastic calculus, Simulations, Linear Algebra, statistical modeling, Time series analysis (especially state space models) (Mandatory)
Knowledge and experience of key machine learning and deep learning framework, e.g. Keras, TensorFlow
Hands on Experience in Python (Mandatory)
Proven Experience in Statistical and Mathematical modelling
Experience in SQL

Other Skills:
Proven ability to take initiative and work under pressure in a changing/growing environment
Should be self-driven and be able to work in an unstructured environment
Proven ability to work with ambiguous (not well defined) challenges
Excellent written and verbal communication skills
Displays curiosity to learn and learns independently
Ability to translate business challenges into analytical problems
Able to cultivate interpersonal customer and co-worker relationships
Ability to articulate and explain statistical / machine learning techniques to business partners
Ability to work individually or as a team as task requires
What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:
Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.

JOB FUNCTION: Data Science and Analytics

PRIMARY LOCATION: India-Andhra Pradesh-Hyderabad

SCHEDULE: Full-time

JOB POSTING DATE: May 14, 2020, 6:04:02 AM",3.8,"Franklin Templeton Investments
3.8",Andhra Pradesh,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
Senior Data Scientist,-1,"Location : Pune
AlgoAnalytics is looking for a Senior Data Scientist who has the passion for hardcore ML and AI work. Minimum 3 years of experience in AI/MI including Deep Learning is required. Deep understanding & proficiency in developing Deep Learning models will be an added advantage. The candidate is expected to manage multiple data science projects from technical as well delivery perspective.

Role and Responsibility :
Transform business problems into data problems and identify relevant and meaningful solutions
Prepare proposals for client projects: detailed description about technical aspects of the proposals such as approaches/algorithms to be tried out as a solution, describing input/output interfaces, tools and technologies to be used/explored, efforts estimation, etc.
Attending client calls in the initial phase of the projects: to understand the problem and discuss approaches, data availability, issues/questions from our side, etc.
Creating PPTs (e.g. to include technical contents)
Designing a solution (for internal or client projects) from technology and algorithm perspective
Research and build machine-learning models
Understanding and implementing recent research work/papers in deep learning
Contribute to the development of research that is based on key insights and findings from the studies
Project management (both client-facing as well as team-facing)
Troubleshooting for any project (related to machine learning / programming / technology) whenever required
Identifying resources for various tasks like mentoring, hiring, initiatives, tech support, project management, skill management, etc.
Provide guidance and training to team members and less experienced data scientists
Participate in management level efforts if and when required
Qualifications :
3+ years of experience in Machine Learning
Bachelors/Masters in Computer Engineering/Science.
Bachelors/Masters in Engineering/Mathematics/Statistics with sound knowledge of programming and computer concepts.
Skills :
Strong Python/ programming skills
Good conceptual understanding of Machine Learning/Deep Learning/Natural Language Processing
Strong verbal and written communication skills.
Should be able to manage team, meet project deadlines and interface with clients.
Should be able to work across different domains and quickly ramp up the business processes & flows & translate business problems into the data solutions
If you have the above skills, desire to keep learning, and would like to grow in a dynamic environment, drop your cv to hr@algoanalytics.com",4.3,"ALGOANALYTICS
4.3",Pune,"Pune, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
AI/Machine Learning Engineer (Premium Colleges only),-1,"Requirements

We are looking for applicants with a strong background in Analytics and Data mining (Web, Social and Big data), Machine Learning and Pattern Recognition, Natural Language Processing and Computational Linguistics, Statistical Modelling and Inferencing, Information Retrieval, Large Scale Distributed Systems and Cloud Computing, Econometrics and Quantitative Marketing, Applied Game Theory and Mechanism Design, Operations Research and Optimization, Human Computer Interaction and Information Visualization. Applicants with a background in other quantitative areas are also encouraged to apply.

We are looking for someone who can create and implement AI solutions. If you have built a product like IBM WATSON in the past and not just used WATSON to build applications, this could be the perfect role for you.

All successful candidates are expected to dive deep into problem areas of Zycus’ interest and invent technology solutions to not only advance the current products, but also to generate new product options that can strategically advantage the organization.

Skills:
Experience in predictive modelling and predictive software development
Skilled in Java, C++, Perl/Python (or similar scripting language)
Experience in using R, Matlab, or any other statistical software
Experience in mentoring junior team members, and guiding them on machine learning and data modelling applications
Strong communication and data presentation skills
Classification (svm, decision tree, random forest, neural network)
Regression (linear, polynomial, logistic, etc)
Classical Optimization(gradient descent, newton raphson, etc)
Graph theory (network analytics)
Heuristic optimisation (genetic algorithm, swarm theory)
Deep learning (lstm, convolutional nn, recurrent nn)
Must Have:
Experience: 1-9 years
The ideal candidate must have proven expertise in Artificial Intelligence (including deep learning algorithms), Machine Learning and/or NLP
The candidate must also have expertise in programming traditional machine learning algorithms, algorithm design & usage
Preferred experience with large data sets & distributed computing in Hadoop ecosystem
Fluency with databases
Benefits",3.3,"Zycus
3.3",Bengaluru,"Princeton, NJ",501 to 1000 employees,1998,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),"SAP Ariba, GEP, Coupa Software Inc"
ML Engineer/Statistician/Data Scientist – Pre-IPO Unicorn,-1,"As a Data Scientist / ML specialist you will focus on building next-generation platform services to identify right business problems that will be more effectively solved with Machine Learning techniques

Then you will apply your algorithmic/statistical skills, analytical skills, knowledge of ML techniques and distributed systems to solve the problem in the simplest possible way.

Experience

3 to 12 years

Qualification

A Bachelor’s degree or a higher degree in Computer Science, Statistics, Mathematics or a related field.
A strong grounding in Data structures and algorithms, Database concepts
Solid understanding of mathematical underpinnings behind Machine Learning algorithms and proficiency in probability, statistics, linear algebra, calculus, and optimization.
Prior experience in building and deploying ML systems and familiarity with Machine learning algorithms
Experience with NLP, Distributed Systems, large scale computing, Big Data technologies like Hadoop and Spark are plus.

Responsibilities

Collaborate with product and business teams to understand all aspects of the problem
Deliver scalable, low latency, and high-performance ML solutions for different
Apply knowledge of ML, statistics, and advanced mathematics to conceptualize, experiment and design an intelligent system
Drive solutions and implementation leveraging different open source libraries and distributed systems
Work with engineers to build the system end-to-end including Big Data pipelines and ensure the serving system is scalable and highly performant.

We value intellectual curiosity, open communication and creative thinkers who know how to stand up and be counted. If this sounds like who you are, we should talk.

Write to deepa.m@careerxperts.com to set up this adventure! #HighBarOfEntry

Job Location

Bengaluru",-1,CareerXperts,Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Junior Data Scientist/ta,-1,"Gurgaon, Bangalore, Mumbai, Pune, Chennai, Hyderabad

candidate should qualify checklist written below:
Ques: Does the candidate has strong knowledge in Data Science/ Machine Learning/ Artificial Intelligence ? Please mention

Ques: Is the candidate willing to work full time as a Data Science program Manager/ Academic and content delivery/ End to End Curriculam delivery and management ?

Ques: Does the candidate has Data Science/ Machine learning content development and academic delivery experience/ Faculty Development programs in any Teaching Institution or E - Learning Companies?

Job Specifications

Exp. 1.0 - 5.0 Year(s)
Annual Fixed CTC Min : 7.0 Lacs Max: 15.0 Lacs
Qualification B.Tech/B.E. , Any Post Graduation
No of openings 3
Additional Doc/Msg

Experience 1 - 5 Years
Salary 7 Lac To 15 Lac P.A.
Industry IT Software - Application Programming / Maintenance
Qualification Other Bachelor Degree, MD/Medicinae Doctor, Other Doctorate Degree
Key Skills Data Scientist

About Company

Company Name

Great Learning

About Company Great Learning is an online and hybrid learning company that offers high-quality, impactful, and industry-relevant learning programs to working professionals. These programs help them master data-driven decision-making regardless of the sector or function they work in and secure their career growth into the future. These programs are delivered through a convenient and robust technology-enabled experience with no disruption to their careers.
Contact Person Pramod Kumar
Address Gurgaon
Mobile 8506010400
Email ID jobwsd@gmail.com",-1,WSD Consultant,India,"Ghaziabad, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"We required Senior Data Scientist who will work as leader, set the direction for the team, deciding on the best methodology to address complex business problem, generating models pipelines and pulling useful insights to make decisions.
One will be an expert in data science, machine learning and statistics, with extensive hands-on experience and the ability to balance technical and business considerations to make the right decisions. They will be a self-starter, with strong attention to detail, an ability to work in a fast-paced and ever-changing environment. They will have excellent oral and written communication skills to communicate effectively with both technical and non-technical stakeholders.

Responsibilities
Work closely with business of Finance, Retail, Automotive etc. to understand requirements effectively
Applying Statistical, Data Science, Machine Learning or other innovative methods to specific business problems and data
Provide technical leadership, research new machine learning approaches to drive continued scientific innovation.
Working with other engineers to solve technical problems.
Skills and Experience
M.S. or Bachelor in Computer Science, Machine Learning, Statistics, Applied Mathematics or related discipline
PhD in quantitative field (Computer Science, Mathematics, Machine Learning, AI, Math, Statistics, or equivalent) is big plus
Extensive knowledge and practical experience in machine learning, statistics, NLP, deep learning, information retrieval
Good communication skills and ability to work with a team
Ability to manage and quantify improvement in customer experience or value for the business resulting from research outcomes
Are you ready ?

What are you waiting for, if above mentioned job details match to skills, send us your updated resume at hello@crossml.com",-1,CrossML,Chandigarh,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"We required Senior Data Scientist who will work as leader, set the direction for the team, deciding on the best methodology to address complex business problem, generating models pipelines and pulling useful insights to make decisions.
One will be an expert in data science, machine learning and statistics, with extensive hands-on experience and the ability to balance technical and business considerations to make the right decisions. They will be a self-starter, with strong attention to detail, an ability to work in a fast-paced and ever-changing environment. They will have excellent oral and written communication skills to communicate effectively with both technical and non-technical stakeholders.

Responsibilities
Work closely with business of Finance, Retail, Automotive etc. to understand requirements effectively
Applying Statistical, Data Science, Machine Learning or other innovative methods to specific business problems and data
Provide technical leadership, research new machine learning approaches to drive continued scientific innovation.
Working with other engineers to solve technical problems.
Skills and Experience
M.S. or Bachelor in Computer Science, Machine Learning, Statistics, Applied Mathematics or related discipline
PhD in quantitative field (Computer Science, Mathematics, Machine Learning, AI, Math, Statistics, or equivalent) is big plus
Extensive knowledge and practical experience in machine learning, statistics, NLP, deep learning, information retrieval
Good communication skills and ability to work with a team
Ability to manage and quantify improvement in customer experience or value for the business resulting from research outcomes
Are you ready ?

What are you waiting for, if above mentioned job details match to skills, send us your updated resume at hello@crossml.com",-1,CrossML,Chandigarh,-1,-1,-1,-1,-1,-1,-1,-1
Associate Architect - Data Science,-1,"Icertis, the leading enterprise contract management platform in the cloud, helps companies unlock the full business value of their contracts to increase revenue, reduce cost, accelerate cash flow and minimize risk. The adaptable, AI-infused Icertis Contract Management (ICM) platform quickly turns contracts from static documents into strategic assets. Today, Icertis, the analyst-validated industry leader, is used by innovative companies like Airbus, BASF, Cognizant, Daimler, Johnson & Johnson, Microsoft and Sanofi across 90+ countries to manage 7.5 million contracts governing more than $1 trillion.

Responsibilities:
· Partner with Business Stakeholders to translate business objectives into clearly defined analytical Projects
· Own the end-end process, from recognizing the problem to implementing the solution.
· Identify opportunities for text analytics and NLP to enhance core product platform, select best ML technique to the specific business problem and then build model to solve the problem
· Define the variables and their inter-relationships and extract the data from our data repositories, leveraging infrastructure including Cloud computing solutions and relational database environments.
· Build predictive models that are accurate and robust and that help our customers to utilize the core platform to the maximum extent.
· Guide and mentor team members on the technical activities of the project

Skills and Qualifications:
· 8+ years of experience.
· An advanced degree in predictive analytics, machine learning, artificial intelligence; or a degree in programming and significant experience with text analytics/NLP. He shall have a strong background in machine learning (unsupervised and supervised techniques). In particular, excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, logistic regression, MLPs, RNNs, etc.
· Experience with text mining, parsing, and classification using state-of-the-art techniques.
· Experience with information retrieval, Natural Language Processing, Natural Language Understanding and Neural Language Modeling.
· Ability to evaluate quality of ML models and to define the right performance metrics for models in accordance with the requirements of the core platform.
· Experience in the Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK, Gensim, etc.
· Excellent verbal and written communication skills, particularly possessing the ability to share technical results and recommendations to both technical and non-technical audiences.
· Ability to perform high-level work both independently and collaboratively as a project member or leader on multiple projects.
· Ability to own solutions for design and architecture and negotiate requirements with global customers
· Experience with Enterprise Software Design is a plus
Icertis is not open to 3rd party solicitation or resumes for our posted FTE positions. Resumes received from 3rd party agencies that are unsolicited will be considered complimentary.

Icertis, Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.",4.3,"Icertis
4.3",Pune,"Bellevue, WA",1001 to 5000 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Selectica, SAP Ariba"
Sr Data Analyst - copy,-1,"Join a team recognized for leadership, innovation and diversity


Sr Data Analyst - MDM

JOB DETAILS:

Position: Sr Data Analyst - MDM

Experience: 8+ years

Key Job Responsibilities

· Very strong implementation experience in Master Data Management tools specialized in the areas like Customer, Vendor, Locations, Product, Materials etc.,

· Lead large MDM implementation for full SDLC lifecycle using Informatica MDM

· Provide Subject Matter Expertise on data architecture and data integration implementation for Enterprise Architecture

· Perform review of Informatica MDM low level design configuration monitoring deployment and implementation of Informatica MDM Platform Version 10.x

· Point of Contact for MDM strategy Process, Design high level MDM architecture requirement and the implementation plan

· Participate in requirements elicitation, Performance tuning of Application Database and Informatica MDM platform

· Collaborate with various technical teams and business users for Development, QA and Operations Support

· Responsible for overall MDM solution with proven system development experience in defining architectural framework standards processes in the master data functions

· Architecture selection criteria (Alternate design, parameter selection, evaluation methods etc.)

· Deliver business value through Right and Fast partnership

· Join a high-performing team and distinguished talent pipeline

· Build strong relationships with leadership to effectively deliver contemporary data analytics solutions and contribute directly to business success

· Implement error and exception handling, auditing, data purging and restoration in ETL jobs.

· Assisting deployment teams with migrating ETL jobs to higher environments.

· Partners with Business/Requirement and Analyst Lead

· Understand overall enterprise architecture and technical requirements for building up a data management platform.

Must have

· Overall IT experience of over 10 years with a minimum of 5 years in the capacity of master data management implementation and technical responsibilities

· Very strong implementation experience in Master Data Management tools specialized with Informatica MDM and suite of tools

· Good knowledge of Informatica MDM, Exits Match HM IDD E360 BES SIF

· Expert in SIP calls and MDM API for create, search and CRUD functionalities

· Good Knowledge of ETL and Data Quality Concepts, knowledge of basic concepts of Java PL SQL. Awareness of MDM trends MDM Concepts and other MDM tools

· Ability to create and analyze unit and system test cases. To be able to debug ETL workflows, SQL code snippets and defect fixing.

· Must possess a strong background in database systems like Oracle, SQL Server, DB2 or Teradata with SQL scripting.

· Deep knowledge in Data Integration, Data Quality, Metadata Management and Data Governance.

· Experience in Requirement Analysis. Strong ability to analyze user requirements into technical solutions as per the specifications.

· Ability to design the System, Data and ETL architecture based upon the requirements

· Knowledge on Data Modeling / Architecture

· Proven experience working with Service Oriented and Event Driven Architectures SOA EDA JMS messaging SOAP and RESTful services

· Ability to predict and quantify technical risks in the project

· Analytical and communication skills (both verbal and written)

· Ability to architect and design, define standards and follow industry best practices for ETL development.

· Experience in creating ETL jobs with delta detection, SCD implementations, bulk loads, real-time integration.

We Value

· B.E in Computer Science or equivalent

· Expertise in the concepts of data warehousing and dimensional modeling.

· Critical Thinking, excellent Communication, Detail Oriented, Creative and Adaptive.

· Ability to work independently and in a team with good analytical, debugging and problem solving skills

· Strong communication skills, both oral and written, with the ability to convey thoughts and ideas clearly.

· Good experience and knowledge on Agile methodology.

· Excellent communication and interpersonal skills.

· Hands-on experience in Informatica Power Center, Big Data technologies and Cloud implementations.

""CORPIT2020""

Additional Information
JOB ID: req238088
Category: Information Technology
Location: Devarabisanahalli Village, KR Varturhobli,,East Taluk - Phase I,Bangalore,KARNATAKA,560103,India
Exempt
Business Services",3.7,"Honeywell
3.7",Bengaluru,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
Senior Business and Data Analyst,-1,"Locations: Bangalore, Data Science & Analytics, Mountain View, New Jersey

We are looking for a Business and Data Analyst for a growing portfolio of customers. As a member of the TV Retargeting products, analytics and business operations team, you will have a huge impact on our business and the success of our customers. You will be one of the early members of the team and will help shape the growth of this team. You should have interest in solving business challenges using data, gathering requirements, analyzing use cases and working towards efficient solutions.

Responsibilities:
Work with our Sales and Account Managers to understand customers’ KPIs and goals
Work with Business Operations team to launch new and optimize ongoing TV Retargeting digital media campaigns
Create case studies by analyzing past viewership and exposure data
Work closely with the data engineering team to understand the underlying drivers of positive and negative performance across our customers
Develop and run data science experiments and interpret the results
Implement the insights gained from your experiments across customers
Proactively communicate the key insights from the performance to the relevant internal teams: sales, account management and engineering
Communicate your ideas for improvement for our internal toolset within the TV Retargeting product and engineering team
Lead an industry vertical like automotive, entertainment, CPG, and others
Mentor team of Business Analysts

Requirements:
Strong analytical background and critical thinking
Strong organizational skills and attention to detail
Ability to thrive in a fast-paced, high-volume, and deadline-driven environment
Engineering and Technical degree preferred.
Marketing / Advertising / Analytics related experience is preferred but not necessary
Familiarity with the TV or Digital advertising ecosystem is helpful, but not required
Experience with a scripting programming language and SQL is helpful, but not required
Experience leading a vertical and managing teams",4.1,"Alphonso
4.1",Bengaluru,"Mountain View, CA",51 to 200 employees,2012,Company - Private,TV Broadcasting & Cable Networks,Media,Unknown / Non-Applicable,-1
Data Analyst,-1,"Job Responsibility -

Work with a variety of data sources - extracting knowledge and actionable information from massive datasets

Build and flesh out data models in our database for use in regular and/or automated reporting and analysis

Be a passionate problem solver - breaking down problems and developing analytical insights

Evaluate operations for inefficiencies and identify areas where you can create, automate, and develop tools (SQL-based or otherwise)

Diagnose data-related bugs and ensure they are resolved in a timely manner

Support the business with ad hoc reporting

Continuously strive for a deeper understanding of our business drivers

Offer insight to all aspects of the organization – product, marketing, engineering and finance

- Analyse large and complex data sets from multiple sources
Develop and evaluate data analytics models, algorithms and solutions
Analyse the information, identify patterns and trends
Understand/implement ML algorithms, performance tuning and reporting
Implement algorithms to mine targeted data and the ability to convert data into a business story
Translate business requirements into technical requirements
Data extraction, preparation and transformation
Identify, develop and implement statistical techniques and algorithms that address business challenges and adds value to the organisation
Gather requirements and communicate findings in the form of a meaningful story with the stakeholders
Create and implement data models

Job Type: Full-time

Salary: ₹100,000.00 - ₹200,000.00 per year

Experience:
Data Analyst: 1 year (Preferred)
Database Management: 1 year (Preferred)
Education:
Diploma (Preferred)
Location:
Nanded, Maharashtra (Preferred)
Required travel:
50% (Preferred)
Benefits:
Travel allowance
Flexible work hours
Phone / Internet reimbursement
Industry:
Agriculture & Forestry
Work Remotely:
Temporarily due to COVID-19",-1,Gopal Trading Company,Nanded,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist III,-1,"Bachelor’s or Master’s degree in a quantitative field such as Statistics, Applied Mathematics, Physics, Engineering, Computer Science, or Economics
4+ years' of experience with data querying languages (e.g. SQL), scripting languages (e.g. Python, R), or statistical/mathematical software (e.g. R, SAS, Matlab, etc.)
2+ years of relevant working experience in an analytical role involving data extraction, analysis, and communication
A natural curiosity and desire to learn
Experience articulating business questions and using quantitative techniques to arrive at a solution using available data
Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to research scientists, engineering teams, and business audiences
Description
Amazon.com strives to be Earth's most customer-centric company where people can find and discover anything they want to buy online. We hire the world's brightest minds, offering them a fast paced, technologically sophisticated and friendly work environment.

We need an expert in econometric and statistical tools to extract insights at scale by building models with our world class data systems, designing advanced new experimental methods, and investigating complex behavioral patterns.

Team Introduction
Amazon Search creates powerful, customer-focused product search solutions and technologies. Whenever a customer visits an Amazon site worldwide and types in a query or browses through product categories, our systems go to work. Our Search Engine team designs, builds, and delivers high performance, fault-tolerant, scalable distributed search engine used by millions of Amazon customers every day.

We are looking for a highly motivated Data Scientist who can help ensure our experience on Amazon Search is creating long-term value for our customers. This person will be responsible for architecting insights and systems to anticipate which features will improve customer’s search experience. This person will also be responsible for designing experiments and devising frameworks that measure the short-term and long-term impact of our product initiatives. Finally, this person would also derive insights using our existing data and experiments to inform new innovation and direction for Search Technologies and internal partner teams.

The ideal candidate will be an expert in the areas of data science, machine learning and statistics, having hands-on experience with multiple improvement initiatives as well as balancing technical and business judgment to make the right decisions about technology, models and methodologies. You will leverage data, experimental design, and analytics to help define new ways to evaluate, visualize and predict to understand outcome and decisions on how to improve customer engagement across customer lifecycle segments. The candidate needs experience with data science / business intelligence, analytics, and reporting systems while striving for simplicity, and demonstrating significant creativity and high judgment backed by statistical proof.

The ideal candidate should have deep expertise in the design, creation, management, and business use of large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and use appropriate statistical and econometric techniques to derive insights and recommendations to leadership. You should excel at bringing large datasets together to answer business questions and drive change.

Responsibilities Scientists at Amazon are expected to develop new techniques to process large data sets, address quantitative problems, and contribute to design of automated systems around the company. Major responsibilities include:
Measure / Quantify / Expand
Design, size, and analyze field experiments at scale.
Apply econometric or statistical knowledge to improve Amazon Search (using machine learning techniques is a plus)
Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance.
Analyze historical data to identify trends and support decision making.
Explore / Enlighten
Formalize assumptions about how Amazon Search is expected to work.
Given anomalies, whether anecdotal or identified automatically, deep dive to explain why they happen, and identify fixes.
Decide / Recommend
Build decision-making models and propose solution for the business problem you defined
Implement models based on findings in production back end systems
Analyze A/B tests and recommend ways to making them faster and more robust
Conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication.
Utilize code (python or another object oriented language) for data analyzing and modeling algorithm
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment
Experience with data visualization and presentation, turning complex analysis into insight
Experience collaborating with software development teams, data scientists, business intelligence or other technical roles
Masters or PhD in applied quantitative field
Strong background in statistics methodology, applications to business problems, and/or big data.
Ability to work in a fast-paced business environment.
Experience processing, filtering, and presenting large quantities (Millions to Billions of rows) of data
Experience designing experiments, and ability to infer causal relationships",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Analyst,-1,"The thrill of working at a start-up that is starting to scale massively is something else.

Simpl (getsimpl.com) was formed in 2015 by Nitya Sharma, an investment banker from Wall Street and Chaitra Chidanand, a tech executive from the Valley, when they teamed up with a very clear mission - to make money simple, so that people can live well and do amazing things. Simpl is the payment platform for the mobile-first world, and we’re backed by some of the best names in fintech globally (folks who have invested in Visa, Square and Transferwise), and has Joe Saunders, Ex Chairman and CEO of Visa as a board member.

Everyone at Simpl is an internal entrepreneur who is given a lot of bandwidth and resources to create the next breakthrough towards the long term vision of “making money Simpl”. Our first product is a payment platform that lets people buy instantly, anywhere online, and pay later. In the background, Simpl uses big data for credit underwriting, risk and fraud modelling, all without any paperwork, and enables Banks and Non-Bank Financial Companies to access a whole new consumer market.

We are looking to hire a data analyst (Can be considered for a lead role depending on fit) who can work closely with product, investment, operations and marketing team on analytics.

The candidate would be a business aware self-starter responsible for enabling data driven decisions by setting up a reporting framework for daily/weekly metrics, helping with ad-hoc analysis and any fundamental research exercise.

This Role Requires Applicant To
Have passion for sourcing, manipulating and visualizing data
Apply direction and confidence to design qualitative and quantitative analysis
Stand before stakeholders, including senior leaders to clearly communicate strategic findings and recommendations
Partner with key members from technical and non-technical teams to build and enable high quality decisions
Prioritize and manage multiple priorities simultaneously
Advocate for working backwards from the customer
All basic qualifications, plus the following:
Degree in Computer Science, Engineering, Statistics, Mathematics, Statistics or a related field
SQL, Python/R (EDA experience), Visualisation tools (Qlik/Tableau) is must
Experience with AWS solutions
Experience working in very large data warehouse environments
Experience conducting large scale data, regression, and predictive analysis to support business decision making
Strong verbal/written communication and data visualization skills, including an ability to effectively communicate with both business and technical teams
We promise a culture of ownership coupled with competitive compensation and generous equity",4.3,"Simpl
4.3",Bengaluru,"Bengaluru, India",51 to 200 employees,2015,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1
Data Science Engineer,-1,"Job Description :


Minimum qualifications :
Prototype ideas, research and develop statistical models, and run experiments
Iterate in order to design data-driven solutions that help solve critical business problems
Better understand company needs and contribute innovative ideas to enhance or develop products using new or existing data streams
Improve and support existing data science products
Develop custom data models and algorithms
Build tools and processes that help monitor and analyse performance and data accuracy
Leverage predictive modeling to optimize targeting, revenue generation, customer experiences, and more
High-level of proficiency in SQL
Experience in data mining techniques
Knowledge of advanced statistical methods and concepts
Extensive knowledge of predictive modelling algorithms and frameworks
Experience working with machine learning techniques (for example, artificial neural networks, clustering, and decision tree learning)
Experience developing automated workflows (Python or R)
Must be able to visualize data with the aid of data visualization tools such as ggplot, d3.js and Matlab, and Tableau etc.
Must be able to discern which problems are important to solve for the business is critical, in addition to identifying new ways the business should be leveraging its data.
Should focus on delivering value and building lasting relationships through communication.
Preferred qualifications:
Candidate needs to be proficient in one or more analytic software tools or languages (e.g., R, Python, Hadoop) with at least 1.5+ Years of work on live projects.
Experience in applying data mining and machine learning techniques
Strong programming knowledge in Python is preferred.
Key Job Attributes :


data mining
data modeling

Educational Qualifications :


B.E/B,Tech

Key Skills :


R
Python
Hadoop
SAS

Contact Details :


Email Id : anbu@handigital.com",3.6,"Han Digital Solution
3.6",Pune,"Bengaluru, India",51 to 200 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Senior Data Scientist (Text Mining),-1,"Title Senior Data Scientist (Text Mining)

Category IT

Education Graduate or Post Graduate

Experience Relevant Work experience of 3 to 5 Years

Location Bangalore


Details

3 – 5 years of industry or research experience in text mining.

Lead and engage a team of engineers and curators to deliver text mining solutions to external or internal customers.

Lead internal R&D projects to envisage the development of new products and services.

Experience or thorough understanding of named entity recognition, semantic indexing and retrieval, text classification, relationship extraction, and sentiment analysis.

Keep up-to-date with scientific and business developments in the market.

Experience in working with text and data analytic platforms such as OpenNLP, LingPipe, UIMA, Solr, Lucene, MALLET, KNIME and WEKA.

Exposure to text mining and AI APIs like Alchemy, TensorFlow and Google Cloud Natural Language AP.

Experience or thorough understanding of applications of machine learning techniques such as CRFs, SVM.

Exposure to Semantic Web standards from W3C: RDF, RDFS, OWL, SPARQL etc.,

Large scale data visualizations on the lines of d3js, Graphviz.

Good understanding of biomedical databases, ontologies, and controlled vocabularies is a plus.

Good communication, writing and presentation skills.

Qualification

Post-Doc, PhD or Masters in Computer Science, Biomedical Informatics, Natural Language Processing, Bioinformatics, Artificial Intelligence or related disciplines.

Please submit your application for the above opening(s) to hiring.technology@molecularconnections.com.",3.0,"Molecular Connections
3.0",Bengaluru,"Bengaluru, India",1001 to 5000 employees,2001,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"This is not a project-based position. This is a full-time, long-term position with the opportunity to travel to the client’s office in Silicon Valley two times per year.

You will be responsible for implementing machine learning and predictive modeling techniques that will have a major impact on the company.

This is an excellent opportunity for smart machine learning engineers who want autonomy and the freedom to turn their big data ideas into reality.

What You’ll Be Doing

Implement machine learning and predictive modeling techniques (e.g. recommending content to users & ranking content to users based on multiple variables).

Tune SQL queries for Redshift/Hadoop.

Analyze data and performance of data products.

Implementing machine learning and predictive modeling techniques (e.g. recommending content to users & ranking content to users based on multiple variables).

Who You Are (Experience & Skills)

Commercial machine learning experience, not just academic or research experience.

Experienced in machine learning techniques.

Experience with a variety of Big Data tech, distributed machine learning and computing frameworks (S3, Spark, Hadoop, Elasticsearch, etc.)

Experienced in creating high-performance algorithms, prototypes and predictive models.

Experience with deploying solutions in AWS

Experience with Python data science ecosystem - Pandas, SciPy, scikit-learn, NLTK, Gensim, etc.Experience with full-stack development, building large distributed systems and large scale data pipelines

What We Offer

Competitive salary.

Challenging work on complex and very innovative projects.

Work in an international environment.

Generous benefits package with all kinds of great stuff.

Trainings accustomed to your needs.

Flexible working environment.

Cozy and friendly atmosphere.

How To Apply

To apply email your resume to sid.baker@whizzystack.com with the subject line “Machine Learning”.

When applying please provide a resume and any links to your technical blog, github/bitbucket and other reviewable code examples.",4.7,"Whizzystack
4.7",Noida,"Jersey City, NJ",1 to 50 employees,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1
Data Engineering - Associate,-1,"Responsibilities
You will be responsible for maintaining large-scale data processing systems, data warehouses and data lakes to help manage the ever-growing information needs of our clients.
Your technical challenge will be to test and optimize systems that ingest, aggregate and visualize terabytes of data that solve business relevant problems of our customers.
Work with business users to refine analytical requirements for quantitative data (view-through, clickstream, acquisition, product usage, transactions), qualitative data (survey, market research) and unstructured data (blog, social network).
Designing and developing schema definitions and support data warehouse/mart to enable integration of disparate data sources from within Client environment and outside, aggregate it and make it available for analysis.
As a key member of the team drive adoption of new technologies, tools, and process improvements to build world class analytical capabilities for web analytics, optimization, experimentation and personalization.
Develop high performance, scalable implementations of the statistical/machine learning models developed by our Data Scientists.
Qualifications
BS/MS in computer science or equivalent work experience.
4 to 6 years’ experience in developing Data Models, DB schemas, creating ETLs, and familiar with Hadoop Ecosystem
2+ years experience with data ingestion through batch and streaming methodologies using open source or public tools like Kafka, Airflow, Azure Data Factory etc..
Experience with databases both RDBMS and NoSQL (Vertica, Netezza or Oracle and AWS data services tech). Through understanding of SQL (any variant)
Good understanding of Data Ware House methodologies.
Hands on experience in any of the programming languages (Shell scripting, Python, Scala, Java, etc)
Good to have
Knowledge of Big Data ecosystem like Hadoop M/R, Pig and Hive is a strong plus.
Understanding of IN memory distributed computing frameworks like Spark (and/or DataBricks) and its parameter tuning, writing optimized queries in Spark
Scheduling and Monitoring of Hadoop and Spark jobs
Good understanding of any reporting tools such as Tableau, Pentaho or Jasper is a big plus.
Experience in design, development and deployment of one or more tools - ETL (Informatica, OWB, ODI), reporting (Business Objects, QlikView, Tableau)",3.6,"TheMathCompany
3.6",Bengaluru,"Bengaluru, India",201 to 500 employees,2016,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Data Scientist - Remote Work,-1,"General Duties & Responsibilities
Working across a number of business areas providing development, maintenance and support
Working as part of a squad and occasionally solo developments as the business needs arise
Discuss/Meet business stakeholders to understand the problems they wish to address
Collaborate with architects, analysts, business representatives, infrastructure specialists to jointly develop proposals for technical solutions including implementation deployment, support and troubleshooting overviews
Scope and conduct Proof of Concepts when necessary
Help identify probable causes and provide immediate solution during an incident
Provide assistance to other developers/projects as needed
Work within an agile environment following agile standards and principles and ceremonies
Complete tasks & deliver projects on-time and to the highest standards and best practices
Contribute significant ideas for making the applications better and easier to use
Skills and Experience
Text parsing, stemming/lemmatization, and vocabulary selection
Vector-space decomposition/embedding
ML model construction to match customer selected topics
Dataset & model validation
ialogFlow agent construction
Knowledge of distributed SOA/microservices and event driven architectures
Experience in Python and Java frameworks such as Flask, Dialogflow, gensim, spaCy, NLTK, TensorFlow
Experience in multi-threading, message queues, websockets
Experience with Cloud platforms such as Google cloud platform
Experience with automation of the development and test processes through CI/CD pipeline (Git, Docker containers)
· Proving track record in building high performance, highly available and scalable systems
Job Types: Full-time, Contract

Experience:
Data Scientist: 10 years (Required)
Education:
Bachelor's (Required)
Language:
English (Required)",3.7,"Bayview Technologies Inc.
3.7",Bengaluru,"MAKATI, Philippines",1001 to 5000 employees,-1,Company - Private,Video Games,Media,Unknown / Non-Applicable,-1
Data Engineer,-1,"Atlassian is continuing to hire with all interviewing and on-boarding done virtually due to COVID-19. Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices.

Job Description

Atlassian is looking for a Senior Data Engineer to join our GTM Data Engineering team and build world-class data solutions and applications that powers crucial business decisions throughout the organization. We are looking for an open minded, structured thinker who is passionate about building systems at scale. You will enable a world-class engineering practice, drive the approach with which we use data, develop backend systems and data models to serve the needs of insights, and play an active role in making Atlassian data driven. You love thinking about the ways the business can consume this data and then figuring out how to build it.
On a typical day, you may be consulted on the information architecture of our data lake, and help design and/or optimize the event collection infrastructure. You will be working with different stakeholders to understand the business reporting needs and architect/build the data models, ETL processes and data applications that can help answer those needs. You have got industry experience working with large datasets and are interested in reporting platforms and data visualization. Constantly striving to optimize the data pipelines/infrastructure with the goal of providing data with quality and trust. As the data domain expert, you will be partnering with our technology teams, analytical teams, and data scientists across various initiatives
You'll own a problem end-to-end, so those skills will come in handy not just to collect, extract, and clean the data, but also to understand the systems that generated it, and automate your analyses and reporting. On an on-going basis, you'll be responsible for improving the data by adding new sources, coding business rules, and producing new metrics that support the business. Requirements will be vague. Iterations will be rapid. You will need to be nimble and take smart risks.

More about you
As a senior data engineer, you will have the opportunity to apply your strong technical experience on building analytics data models that supports a broad range of analytical requirements across the company. You will work with other teams to continually evolve solutions as business processes and the requirements change. You enjoy working in a fast paced environment and you are able to take vague requirements and transform them into solid solutions. You are motivated by solving challenging problems, where creativity is as crucial as your ability to write code.
On your first day, we'll expect you to have
8+ years professional experience as a data engineer or in a similar role
Strong programming skills (some combination of Python, and Node.js preferred)
Experience building platforms, micro services, and REST APIs
Experience writing GraphQL, structuring data, and data storage practices
Experience working on Amazon Web Services (in particular using S3, SQS and the like)It's preferred, but not technically required, that you have:• Experience building self-service tooling and platforms
Experience building data pipelines using Spark and/or Hive
Experience working in a technical environment with the following technologies: AWS data services (Redshift, Athena, EMR) or similar, Apache projects (Spark, Flink, Hive, Kafka)
You’re well versed in modern software development practices (Agile, TDD, CICD) and how they can apply to data engineering
Experience writing and tuning SQL, Experience in data warehouse modeling
A willingness to accept failure, learn and try again
An open mind to try solutions that may seem crazy at first
A BS in Computer Science or equivalent experience
We’d be super excited if you have:
Experience working on Apache Airflow (or similar tools) for orchestrating data pipelines
Experience building MDMs and other enterprise data integration solutions
Deployed ML models and know when best to use them
Experience in developing, publishing and maintaining advanced reporting, analytics and dashboards using Tableau
Above all else, as a senior data engineer you will be leading the development process, driving architectural decisions, and incorporating business and technology strategy. You will be earning the trust of other developers in the team and then coaching and influencing them into the right behaviors to build the ultimate analytical data model and pipelines.
More about the team
The data engineering team is responsible for managing multiple analytical data models and data pipelines all across Atlassian, including finance, growth, product analysis, customer support, sales, marketing, etc - so there are endless opportunities for growth. We maintain Atlassian's data lake and build creative and reliable analytics data model that provides a unified way of analyzing our customers, our products, our operations and the interactions among them.
You’ll be joining a team that is crazy smart and very direct. We ask hard questions and challenge each other to constantly improve our work. We are self-driven but team oriented. We're all about enabling growth by delivering the right data and insights in the right way to partners across the company.

More about our benefits

Whether you work in an office or a distributed team, Atlassian is highly collaborative and yes, fun! To support you at work (and play) we offer some fantastic perks: ample time off to relax and recharge, flexible working options, five paid volunteer days a year for your favourite cause, an annual allowance to support your learning & growth, unique ShipIt days, a company paid trip after five years and lots more.

More about Atlassian

Creating software that empowers everyone from small startups to the who’s who of tech is why we’re here. We build tools like Jira, Confluence, Bitbucket, and Trello to help teams across the world become more nimble, creative, and aligned—collaboration is the heart of every product we dream of at Atlassian. From Amsterdam and Austin, to Sydney and San Francisco, we’re looking for people who want to write the future and who believe that we can accomplish so much more together than apart. At Atlassian, we’re committed to an environment where everyone has the autonomy and freedom to thrive, as well as the support of like-minded colleagues who are motivated by a common goal to: Unleash the potential of every team.

Additional Information

We believe that the unique contributions of all Atlassians is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.",4.4,"Atlassian
4.4",Bengaluru,"Sydney, Australia",1001 to 5000 employees,2002,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,GitHub
Senior Data Scientist - AWS Professional Services,-1,"Excited by using massive amounts of data to develop Machine Learning (ML) and Deep Learning (DL) models? Want to help the largest global enterprises derive business value through the adoption of Artificial Intelligence (AI)? Eager to learn from many different enterprises use cases of AWS ML and DL? Thrilled to be key part of Amazon, who has been investing in Machine Learning for decades, pioneering and shaping the worlds AI technology?
At Amazon Web Services (AWS), we are helping large enterprises build ML and DL models on the AWS Cloud. We are applying predictive technology to large volumes of data and against a wide spectrum of problems. Our Professional Services organization works together with our AWS customers to address their business needs using AI.

AWS Professional Services is a unique consulting team. We pride ourselves on being customer obsessed and highly focused on the AI enablement of our customers. If you have experience with AI, including building ML or DL models, wed like to have you join our team. You will get to work with an innovative company, with great teammates, and have a lot of fun helping our customers.

If you do not live in a market where we have an open Data Scientist position, please feel free to apply. Our Data Scientists can live in any location where we have a Professional Service office.

A successful candidate will be a person who enjoys diving deep into data, doing analysis, discovering root causes, and designing long-term solutions. It will be a person who likes to have fun, loves to learn, and wants to innovate in the world of AI. Major responsibilities include:
· Understand the customers business need and guide them to a solution using our AWS AI Services, AWS AI Platforms, AWS AI Frameworks, and AWS AI EC2 Instances .
· Assist customers by being able to deliver a ML / DL project from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models to deliver business impact to the organization.
· Use Deep Learning frameworks like MXNet, Caffe 2, Tensorflow, Theano, CNTK, and Keras to help our customers build DL models.
· Use SparkML and Amazon Machine Learning (AML) to help our customers build ML models.
· Work with our Professional Services Big Data consultants to analyze, extract, normalize, and label relevant data.
· Work with our Professional Services DevOps consultants to help our customers operationalize models after they are built.
· Assist customers with identifying model drift and retraining models.
· Research and implement novel ML and DL approaches, including using FPGA.

This role is open for Mumbai/Pune/Bangalore/Chennai/Hyderabad/Delhi/Pune.


Basic Qualifications

· A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent experience
· 10+ years of industry experience in predictive modeling, data science and analysis
· Previous experience in a ML or data scientist role and a track record of building ML or DL models
· Experience using Python and/or R
· Knowledge of SparkML
· Able to write production level code, which is well-written and explainable
· Experience using ML libraries, such as scikit-learn, caret, mlr, mllib
· Experience working with GPUs to develop models
· Experience handling terabyte size datasets
· Track record of diving into data to discover hidden patterns
· Familiarity with using data visualization tools
· Knowledge and experience of writing and tuning SQL
· Past and current experience writing and speaking about complex technical concepts to broad audiences in a simplified format
· Experience giving data presentations
· Extended travel to customer locations may be required to deliver professional services, as needed
· Strong written and verbal communication skills

Preferred Qualifications

·
· PhD in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
· 12+ years of industry experience in predictive modeling and analysis
· Good skills with programming languages, such as Java or C/C++
· Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
· Consulting experience and track record of helping customers with their AI needs
· Publications or presentation in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
· Experience with AWS technologies like Redshift, S3, EC2, Data Pipeline, & EMR
· Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customers organization
· Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment",4.3,"Amazon
4.3",India,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Senior Data Scientist,-1,"Senior Data Scientist - Machine Learning/artificial Intelligence

Must possess at least 8 years of total experience with recent & relevant experience and at least 4 years as a Data Scientist.

Responsible for Exploratory Data Analysis with Basic and Advanced data exploration

Design and Build ML models basis Solution approach agreed by Lead/Manager that are explainable and anomaly detection models

Experience in feature engineering, hyper parameter tuning, model evaluation - use diagnostics of developed model to accept or reject the model, retraining of the model might be necessary etc.

Integration, production, and scaling analytics solutions for big data problems

Must have strong applied skills in Math/ Statistics Descriptive statistics, Probability & probability distributions (Gaussian/non-Gaussian), univariate and multivariate statistical analysis.

Strong expertise in Machine Learning(Regression(linear/GLM/non-linear) techniques, Classification techniques (Tree based methods - decision trees, random forests, etc., Ensemble- bagging, boosting, CRFs, SVM) Unsupervised learning - clustering (K-means, hierarchical, DBScan, feature Selection Algorithms).

Experience in building and scaling models for time series, Market basket analysis

Strong expertise in Deep Learning, NLP and Artificial Intelligence Technologies-Neural Networks- sequential models - LSTM, CNN, etc.,

Experience or thorough understanding of named entity recognition, semantic indexing and retrieval, text classification, relationship extraction, and sentiment analysis.

Good to have experience in working with text and data analytic platforms such as OpenNLP

Strong expertise in Image processing and video analytics

Exposure to text mining and AI APIs like chatbots, Alchemy, TensorFlow and Google Cloud Natural Language API.

Experience in SQL (Basics) SQL (advanced), NoSQL databases

Experience in coding Tools (R, Python, IBM SPSS, SAS), Machine learning concepts (Pandas/Numpy/ScikitLearn) Deep Learning concepts (OpenCV and Tensor Flow/ Keras, Pytorch), Pyspark, Javascript, AWS/Azure and equivalent programming languages

Good to have knowledge on data visualizations Tableau, looker, Power BI, qlikview, Business objects BI tools, Graphviz.

Possess strong analytical skills and are comfortable dealing with numerical data, structured and unstructured data

Lead and engage a team of engineers and curators to deliver text mining solutions.

Keep up to date with scientific and business developments in the market.

Help in peer review and document the test results in the in-house tools.

Good to have knowledge in AI Ops and in building models to reduce noisy alerts, automated root cause detection, self-healing etc..

Should have passion for playing with data, pay strong attention to detail and deliver work that is of a high standard

You have strong interpersonal and communication skills and are adept at working with globally located stakeholders to understand business problem, available data and how both can be brought together to generate insights

Co-ordinate with different teams to develop custom algorithms, implement and monitor

Experience of applying data science in life sciences or pharma industries will be an added advantage

Competencies

Systematic problem-solving approach coupled with a strong sense of ownership and drive.

Should be a creative problem solver and can multitask in fast-paced environments

Good communication, writing and presentation skills.

Teamwork and collaboration skills

Education

UG :BCA in Computers, B.Tech/B.E. in Any Specialization, B.Sc in Any Specialization

PG :Any Postgraduate in Any Specialization",3.9,"Techwave Consulting Inc.
3.9",Hyderabad,"Houston, TX",1001 to 5000 employees,2004,Company - Private,IT Services,Information Technology,₹5 to ₹10 billion (INR),"NTT DATA, itelligence, Infosys"
Senior Data Scientist,-1,"Job Description

Looking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data science techniques, doing statistical analysis, text mining and building high quality prediction systems integrated with our products.

Responsibilities
Analyze data using state-of-the-art methods
Selecting features, building and optimizing classifiers using machine learning techniques
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Skills and Qualifications
Bachelor’s Degree OR Post Graduate degree in Statistics, Operations Research, Economics, Mathematics, Computer Science.
4+ years of experience in machine learning techniques and algorithms.
Excellent understanding of algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
3+ years of experience with common data science toolkits, such as R and Python. Excellence in at least one of these is highly desirable
Excellent understanding of neural networks, decision systems, and experience in text mining is a big plus.
Very good applied statistics skills, such as distributions, statistical testing, regression, etc.
Experience with data visualization tools such as Tableau would be desirable.
Ability to learn and build competencies in new tools and statistical techniques whenever required
Ability to explain and defend his/her ideas and analysis, while still able to understand the merits of others’ opinions.
Strong analytical and problem-solving skills
Excellent verbal & written communication skills
Highly motivated, organized, proactive self-starter and a team player.
Data-oriented personality
All Locations:
IND-Pune-Old Mumbai Pune Hwy",3.2,"Wolters Kluwer
3.2",Pune,"Alphen aan den Rijn, Netherlands",10000+ employees,1836,Company - Public,Consulting,Business Services,₹100 to ₹500 billion (INR),"Thomson Reuters, Pearson, RELX"
Associate Data Analyst,-1,"Role:?Partner with stakeholders to understand data requirements ?Develop tools and models such as segmentation, dashboards, data visualizations, decision aids and business case analysis to support the organization and leadership. ?Producing and managing the delivery of activity and value analytics to external stakeholders and clients. ?Team members will typically use business intelligence, data visualization, and query, analytic and statistical software to build solutions, perform analysis and interpret data. ?Work on predominately descriptive and regression-based analytics and tend to leverage subject matter expert views in the design of their analytics and algorithms.Primary job responsibilities include:?Conducting analysis, performing normalization operations and assuring data quality. ?Creating specifications to bring data into a common structure ?Creating product specifications and reporting models ?Experience in developing reporting solutions to support analyses ?Experience in creating data reports, dashboards, scorecards and Matix that matter most with extensive use of data visualization.?Performing data analysis and interpreting data/business insights ?Developing actionable insights and presenting recommendations for use across the internal/external stakeholder and leadership. ?Experience database design, programming, testing and implementation using SQL with standard practices and procedures?Develop and maintain data preparation and validation routines to support data mining and have experience in creating complex data mining algorithms.?Analytical - Synthesizes complex or diverse information; Collects and researches data; Uses intuition and experience to complement data; Designs work flows and procedures.?Establish, refine and integrate development and test environment tools and software as needed?Identify production and non-production application issues?Ability to quickly analyze existing code, identify performance/reliability/scalability issues, propose solutions, and code optimization/updates as required.?Provide technical support and consultation database and infrastructure questions?Experience and understanding on Database Performance Tuning, Database Management, Requirements Analysis, Software Development Fundamentals?Excellent Problem Solving, Documentation Skills, Written & Verbal Communication skills",3.4,"UnitedHealth Group
3.4",Gurgaon,"Minnetonka, MN",10000+ employees,1977,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"Aetna, Humana, WellPoint"
Senior Data Scientist,-1,"LocationIndia / US / EuropeExperience5 YearsAcademic Qualification:B.E., B.Tech/MBA from top-tier Engineering /B-School ORMasters in Statistics/Economics from leading UniversityOverviewContinuous, growth opportunities for career progression and personal developmentProfessional, stimulating, continuous learning, work environment based on camaraderie, individual mentorship, on-the-job and corporate trainingCompetitive and performance-oriented compensation and employee benefits packageIndustry benchmarked HR policies and practices, particularly in areas such as Performance Management, Learning and Professional Development, Career Planning and Compensation and Rewards.Roles and responsibilitiesWill involve teamwork as well as work in which individual contribution will be neededWork directly with multinational clients, using advanced analytics to solve real-world business problems.The role will require a sound understanding of business functions, statistical concepts and algorithm design/implementation skills.Core responsibilities include leveraging data science to solve business cases, training other team members, and contributing to pre-sales through quick execution of PoCs. Typical activities will include:Interacting with business stake holders for gathering requirementsAnalysing data to develop key insights on business trends and performanceApplying statistical/mathematical algorithms as needed to address specific business problemsStrategizing and proposing creative solutions based on data insightsBe a brand ambassador for the company and represent the company in seminars and other public events related to data sciencePreferred experience of working in some of the following data science techniques: Descriptive Statistics, Predictive Modelling, Linear regression, Logistic Regression, Tests of Hypothesis, Pattern Recognition, Clustering, Decision Tree, Time Series, Principal Component Analysis, Neural Networks, SVM, k-NN, etcLeading Analytics consulting projectsAdditional Skills (preferred)Will involve teamwork as well as work in which individual contribution will be needed.Intermediate querying and scripting skills in SQLExperience in relevant field such as Statistics, Computer Science or Applied Math.SPOCBuddhadeb BhattacharjeeMail toBuddhadeb.bhattacharjee@tcg-digital.com",3.0,"TCG Digital
3.0",India,"Somerset, NJ",201 to 500 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist - Quality Assurance,-1,"Brief about the role:

Data Science Quality Assurance is a client facing role where the resource is expected to perform testing and validation on machine learning analytical models and interface with stakeholders including customers on results / quality.

Experience level of 3-5 years would be ideal for this role. Strong inclination towards Quality Assurance and testing will be advantageous.

Main Responsibilities and Deliverables:
Set up test environment on NICE Actimize products.
Deploy Machine Leaning Analytical models on various environments.
Quality test Machine Learning Analytical Models on defined set of criteria’s.
Produce client facing quality reports on performance and data analysis.
Validate results and provide constructive feedback to Data Scientists
Analyze Data and provide actionable insights for multiple customers.
Support Data Science function on data preparation and data cleaning aspects.
Qualifications / Education:
E./B.Tech from a reputed institute/university
Very good verbal and written English skills.
Proven experience in operating within a global environment.
Experience working in a complex matrix environment in a fast-paced organization.
Technical Skills

Must Have
Programming Languages: Python (must), PL/SQL (must), Java Script (good to have).
Good understanding of JAR files creation and distribution techniques.
Databases: Oracle, SQL Server, Data Warehousing (ETL, OLAP).
Skills around Data Manipulation and Data Pre-Processing.
Experience of dealing with large enterprise data sets.
Good understanding of Testing Methodologies and Test Reports.
Good understanding & Experience on Extract, Transform Loading of data.
Good to have
Actimize: Understanding of AIS-RCM & IFM Products will be an added advantage.
Experience of working in Fraud Management / Anti Money Laundering using Analytics will be an added advantage.
Personal Leadership
Ability to work and deliver independently.
Actively seeks information, and shares knowledge with others.
Actively engages others in work done, to expand and broaden professional domain knowledge and know-how.
Has high-attention to details and works well in a dynamic and high paced environment
Mentors junior members of the team
Flexibility of working hours for supporting global clients",4.0,"NICE Actimize
4.0",Pune,"Hoboken, NJ",501 to 1000 employees,1999,Subsidiary or Business Segment,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"SAS, Feedzai"
Data Science Developer,-1,"At Ajira AI, we focus on developing smart products that leverage artificial intelligence algorithms. We build complex cloud based and mobile business applications. However make no mistake, we solve very significant systems problems along the way. Our products work across our customers ecosystems to help people.

We’re very pleased to be expanding our development team. We’re a close knit group of innovators that have previously launched very successful start-ups. Our track record building successful technology businesses and reputation is helping us grow and we’re now looking to add experienced Data Science Developers to our team in Pune.

You have hands-on experience using AI frameworks such as Tensor Flow and Keras in a work setting. You have at least a couple of years of work experience using Python/R. You’ve used multiple classification models and Pandas, Numpy, Matlab etc. You are proficient at using algorithms such as Logistic Regression, Multiple Linear Regression, Random Tree, Support Vector Machine, Naive Bayes etc. You have a track record of demonstrated success in business problem solving. Data visualization experience is a plus.

You are the kind of developer that other developers seek out to solve their technical difficulties. You keep up to date with what’s happening in the data science world and know the differences between classification, regression, clustering and time series. You know the limitations of each algorithm. You are motivated to learn new technologies.
That’s a high level summary of what we’re looking for but before we dive into the detail, you’ll probably want to know who you are going to be working for and what your work environment will be like:

Who we are:
We are an Insurtech company with a core mission of leveraging artificial intelligence algorithms and techniques to solve complex business problems. We like to think that solving these business issues for our customers helps make them better at serving their customers. Some of our applications help people who may be injured or have been in an accident. In our opinion that’s a worthwhile pursuit. While our current business vertical is insurance, we see our technology expanding to other business verticals with time. Our founders have a solid track record of starting technology companies and making them successful.

We love what we do and not the least of which is that we have the opportunity to try out and ‘play’ with the latest advances in tools and technology.

Who you’ll be working with:
We are a collaborative, tight knit group of contributors. While we’re headquartered in the Chicago area in Lisle, our software lab is located in Pune, India. We have decades of experience working with remote teams. We’re looking to expand our Developer positions in Pune, India.

You’ll find our CTO a joy to work with; someone with excellent technical skills, always willing to mentor, roll up his sleeves and get deep into the technical issues. He possesses rare technical insight and no matter the day or time he’s always willing to contribute to move things forward. Our CEO is a rare combination of technical and business skills with remarkable vision and the ability to easily cut through the most complex issues to find the simplest answer. You’ll be working side by side with them and the rest of our technical team in what will be an amazing opportunity for you.

Your work environment:
We are a group of talented and dedicated individuals and through we are a start-up, we have a ‘no insane hours’ rule.

We are not clock watchers. If you need to take off for a couple of hours to visit the doctor or dentist go ahead. We look at what you’re accomplishing not how many hours you spend in the office. We conduct meetings on a daily basis with our Chicago office so some overlapping hours are necessary.

Our Pune office space is modest. We prefer to pay you more than prevailing market wages rather than spend money on fancy office space.

Our work is performed using the latest technology and tools. We’re constantly innovating and improving our delivery capability by building our own components and tools as well as licensing new tech that we’ve tried and works in our environment.

We are an open, collaborative work environment and suggestions are not just welcome, they are appreciated. You’ll find our product roadmap is exciting and full of opportunity.

Your skills:
You keep up with technology changes and trends

You are a top notch Developer whose code not only solves complex issues but is written in such a way that the rest of your team is able to understand. This means that you’re not shy about documenting your code and you understand the need for coding standards and why everyone should use them

You are motivated. You have amazing debugging skills and are quick at identifying and fixing bugs

You are skilled at development with Python/R and using Ai frameworks such as Tensor Flow and Keras

Proficient in the use of Pandas, Numpy, Matlib, MatPlotlib and commonly used libraries
You understand ML algorithms such as Support Vector Machine, Naïve Bayes, Logistic Regression, Multiple Linear Regression, Random Tree, XgBoost etc thoroughly

You are quick to understand business problems and understand how to classify problems that exist in large datasets

Any data visualization experience is a plus as is any background in statistics

You have developed, implemented and supported a ML application successfully at work

How to apply:
Send a pdf of your resume to careers@ajiraai.com

This post can also be found at http://www.ajiraai.com/careers

We look forward to hearing from you

If you’re not available or interested in this position but know someone who might be a good fit, please pass this along

Ajira AI is an equal opportunity employer and we do not discriminate on basis of caste, creed, gender, religion, state of origin, color, race or personal orientation. You are an Indian citizen or authorized to work legally in India.",5.0,"Ajira AI
5.0",Pune,"Lisle, IL",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist - Advanced Analytics,-1,"Introduction
As a Data Scientist at IBM, you will help transform our clients’ data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether it’s investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities
Combines deep data and analytics skills with strong business acumen to solve business problems by understanding, preparing, and analyzing data to predict emerging trends and provide recommendations to optimize business results. Responsibilities include working with business leaders to solve business problems by understanding, preparing, and analyzing data to predict emerging trends and provide recommendations to optimize business results. Skills include mathematical optimization, discrete-event simulation, rules programming and predictive analytics. Expected to have knowledge and/or experience in the following skills with focus on data science: Data Science, Apache Ambari, MapReduce, Spark, Labmda, Resilient Distributed Dataset, Java, Zookeeper, Knox, Big Data, IBM BigInsights, Apache Hadoop, SQL, RDBMS, Python, Big SQL, BigSheets+E5Big R, Text Analytics, GPFS, HDFS, Platform Symphony, Structured And Unstructured Data, Open Source, R, POSIX, Yarn, Sqoop, Flume, JSON, XML, NoSQL, HBase, Pig, Hive, Oozie, Apache Solr, JSqsh, Data Server Manager, AQL, Data Security, Data Governance, Networking, Neural Net.

Required Technical and Professional Expertise
Domain about Watson Explorer and other Watson Analytics products
Domain in text mining (characterization, summarization, aggregation)
NoSQL Database Domain
Mastery in natural language processing algorithms, machine learning, information retrieval / retrieval and advanced analytics
Cloud platform knowledge
""Twelve Factor""
Desirable specialization in one of the following areas: Natural Language Processing, Image Processing, Video Processing, Voice Processing and Watson technologies | WEX, WDC, WEA, Big Data analytics-R, Python, Spark, Weka, Mahout, Hadoop, Hive and HBase
**All positions are eligible for people with disabilities or rehabilitated.***
Preferred Technical and Professional Expertise
N/A

About Business Unit
IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM
What matters to you when you’re looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bihar,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Senior Manager - Data Scientist,-1,"With a startup spirit and 90,000 curious and courageous
minds, we have the expertise to go deep with the world’s biggest brands—and we
have fun doing it. Now, we’re calling all you rule-breakers and risk-takers who
see the world differently, and are bold enough to reinvent it. Come, transform
with us.

Are you the one we are looking for?

We are inviting applications for the role of Senior Manager, Data
Scientist with Python/R skills

This Role includes writing and testing existing models in
excel based environments with strong exposure to coding tools like R or Python.
Should have mindset to transform or migrate existing processes into updated
analytical tools. Strong communication and team player.

Location – Noida
Sector 135

Work Timing –
Typical work timings are 12noon to 9 pm

Responsibilities
Strong technical knowhow
to understand business problem and use analytical tools like R or Python
for scripting
Perform data manipulation,
wrangling, cleansing, and analysis and be responsible for the complex and
large-scale datasets to be used for statistical modeling and data mining.
Must be proficient with one
of the tools like Anaconda or RStudio
Provide support and
assistance for the implementation of predictive or forecasting models
already in production
Hands-on experience in
forecasting, usage of different models like Time Series/ARIMA, holt
winters etc. is a must
Experience in predictive
modeling techniques like GLM, Linear Regression, Survival Analysis,
Segmentation/Cluster Analysis, Decision Trees & Random Forests will
be preferred
Hands on python or R experience
is a must
Experience writing SQL
queries and stored procedures.
Should have good amount of
data analysis experience, should know about various exploratory techniques
Advanced
proficiency with Microsoft Excel, including VBA, is required. Ability to
understand existing processes in excel based models and then maintaining the
same for clients.
Migrate
excel based processes into R or Python driven processes
Very good communication
skills; must be able to discuss the requirements effectively with a
technical team of developers
Qualifications we seek in you


Minimum qualifications

Graduate/ Post Graduate in B.tech/MBA/MCA

Preferred qualifications


A flexible, dedicated and solution orientated approach
through periods of change and disruption.

Should possess good interpersonal skills

Innovative and always looking for continuous improvement

Communicate with clients on day-to-day basis to discuss
project progress

Genpact is an Equal Opportunity Employer and considers
applicants for all positions without regard to race, color, religion or belief,
sex, age, national origin, citizenship status, marital status, military/veteran
status, genetic information, sexual orientation, gender identity, physical or
mental disability or any other characteristic protected by applicable laws. Genpact
is committed to creating a dynamic work environment that values diversity and
inclusion, respect and integrity, customer focus, and innovation. For more
information, visit www.genpact.com. Follow us on Twitter, Facebook, LinkedIn,
and YouTube.",3.6,"Genpact
3.6",Noida,"New York, NY",10000+ employees,1997,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"Accenture, IBM, Capgemini"
Data Science Manager,-1,"About Lam….
Together we move the Atoms that move the World:

Imagine working on the front lines of innovation! As one of the semiconductor industry's leading suppliers of wafer fabrication equipment and services, our technology depends on finding and hiring the best and the brightest employees. We know that our dynamic, global team of exceptional employees is essential to our continued growth.

Lam Research - where successful people want to work:

We are a company comprised of people who work hard, deliver outstanding results and maintain a sense of humor during even the most challenging times. This is truly a rare opportunity. Lam Research is a market leader where our core values are not just words on the back of your badge. Given the criticality of this role to Lam Research's success, this philosophy starts with you.
Job Responsibilities
Directs the activities of a data science team responsible for the design, development, programming methods, processes and systems to consolidate and analyze unstructured, diverse Â“big dataÂ” sources to generate actionable insights and solutions for businesses across the company. Oversees the development of software programs, algorithms and automated processes that cleanse, integrate and evaluate large data sets from multiple disparate sources. Identifies and communicates to stakeholders, meaningful, actionable insights from large data and metadata sources. Selects, develops, and evaluates personnel ensuring the efficient operation of the function.
Other Job Responsibilities
Lead Application Development and Data Science Project Teams. Hands-On Experience in BI, Advance Analytics and Application Development
Deliver Rapid Prototypes, Experiments, Hypothesis testing and Adhoc Analysis to support business with data driven decision making.
Provide technical leadership to BI team building architecture for tracking daily, weekly, monthly, quarterly reporting of metrics
Work with Global and local IT and Cross-functional business teams
Maintain KPI to support business needs of functional managers
Develop generic analytics infrastructure and master library based on MS SQL database that can be used for reporting across functions
Minimum Qualification
Years of Experience: Minimum 12 - 16 years, 4-6 years of supervisory experience.
Job Experience: Experience in developing Business Intelligence (BI), Applications, Advance Analytics and Data Science Projects
Educational: Bachelor’s or master’s Degree: Mathematics/Statistics/Computer Science/MBA (Systems & operations)
Preferred Qualification
Working Experience in BI , Data Science, AI, DL and ML Projects.
Hands on experience and must be up to date with skills in Data Warehousing, Business Objects, ETL, Business analytics & query building in MS SQL
Experience developing Business Intelligence with SAP HANA/SQL Server & Power BI/Qlik Sense/Tableau
Working knowledge in Web Application Development and at a minimum understanding of HTML 5.0, CSS 3.0, and JavaScript. Application development exposure with Java, C#, JQuery, Power BI, SAP Lumira, Appian, .NET, Cloud Computing (Azure, AWS), ASP.NET MVC, Angular JS, node.js.
Must have led a BI team building corporate level architecture for Supply Chain or Manufacturing Operations
More About Us ….
Our work is everywhere you look – even if you can’t actually see it. Lam Research goes deeper than software or chips to the heart of the process that enables chip creation. So if you want to help power the components that empower everything, join us.

All qualified applicants will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability.",4.4,"Lam Research
4.4",Bengaluru,"Fremont, CA",10000+ employees,1980,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),"Applied Materials, Tokyo Electron, ASML"
"Data Scientist, Data Engineer, Deep Learning,",-1,"Opening for Data Scientist At Bangalore (Hebbal )

Experience- Min 2 Years
Location - Bangalore (Hebbal )

Role & Responcibility -

2 - 4 years of experience applying ML / Deep Learning algorithms and techniques to real-world data sets
Expert knowledge of Core Python
Proficiency in Machine learning algorithms (SVM, Decision Trees, PCA, Clustering etc.)
Knowledge and Experience of Deep Learning Algorithms (CNN, RNN, LSTM etc.)
Major ML frameworks: TensorFlow, PyTorch, Keras, Scikit-Learn
Strong analytical thinking
Designs scalable processes to collect, manipulate, present, and analyze large datasets in a production-ready environment
Strong written and oral skills (in English)
Demonstrated participation on platforms like Kaggle is a plus
Prefer great appreciation or expertise in Security products such as End point detection, protection and response, Managed detection and response etc
Kindly revert your Opinion
00-6.00 Years",-1,TechPro HR Consultancy,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Science & Analytics Platform Engineer,-1,"Site Name: India - Karnataka - Bangalore
Posted Date: Jul 23 2020

GSK is one of the worlds foremost pharmaceutical and healthcare companies and we are proud to be leading a healthcare revolution.

By disrupting our approaches to R&D and commercial business processes, D&A is allowing us to integrate, simplify and unlock all our data to drive innovation, decision making and enable our transformation in servicing our patients, healthcare professionals and consumers.

If you are ready for an exciting career YOU would be responsible for the following.

Are you a top-flight developer, driven by continuously improving and acquiring new skills, then this position within our Data & Analytics team may be for you?

You will be working on creating microservices, frameworks on top of Data & Analytics platform which will enable faster acquisition and ingestion of datasets, data curation and creation of analytical ready datasets. You will also to be helping in new technology introduction by running POC/Pilots and finally creation of a qualified GXP ready software defined infrastructure of the selected platform.

While a hands-on development role which includes developing & delivering code from origin to production, you will also lead a team 2-5 data engineers, our 3rd party development service providers to help ensure that code is delivered on time, to quality and in line with the overall ecosystem being established.

This role will include responsibilities for:

Development
Hands on, sleeves up development and delivery expected as a matter of course.
Delivery
Ensure project goals are achieved on time in alignment with the stakeholders expectation.
Ability to work on complex projects and in a distributed environment.
Escalate when necessary and in a timely manner
Work in close collaboration with other team members in the Enterprise Data & Analytics Platform team, to ensure Development/Delivery aspects are well represented in the projects requirements and deliverables.
Methodology
Incorporate agile ways of working into the delivery process utilising DABL (Discovery, Alpha, Beta, Launch)
Individuals will work as part of product-centric delivery team(s) that will focus on delivering value independently while fully embracing integrated DevOps approaches.
Ownership
Take ownership for the delivery/development projects and help steer until completion
Governance
Maintain governance that allows projects and stakeholders to manage overall project performance and manage programme risks within the global nature of some of the programmes.
Forward looking:
Remain flexible towards technology approaches to ensure we are taking advantage of new technologies.
Keep abreast of industry developments in analytics and be able to interpret how these would impactservices and present new opportunities.
Quality, Risk & Compliance:
Ensure all risk and issues associated with owned projects are recorded and managed in the appropriate Risk & Issue logs in a timely manner.
Ensure all Risks and Issues have clear action/mitigation/contingency plans defined, with named action owners and timelines for completion.
Technical Architecture
Be conversant with technical architecture to contribute to design discussions in partnership with the Delivery/Development Lead and dedicated Analytics & Data Architect.
We are looking for professionals with these skills to achieve our goals. If YOU have these skills, we would like to speak to you.
Ideal candidate will have built an impressive hands-on development career to date in an advanced, recognized and innovative environment around Data & Analytics & coding experience in a variety of languages, e.g. Python, SQL, Scala, etc.
Deep understanding of Data Quality tooling (Ataccama/Talend DQ), Metadata Management (Collibra), semantic data store (Azure SQLDW/Snowflake, Cosmos DB), PowerBI, Azure Databricks, Data Ingestion/Acquisition/Prep (Azure ADF, StreamSets, Talend)
Fully conversant with big-data processing approaches and schema-on-read methodologies with knowledge of Talend/Azure Data Factory/DataBricks/Azure Data Lake/Azure SQL DW/Analysis Services
Strong experience with agile and DevOps development methodology and concepts. Must have worked in CI/CD ways of working using tools like Azure DevOps.
Experience of the Azure analytics components, Power BI, Power Apps is desirable. Developing visual reports, dashboards and KPI scorecards using Power BI desktop.
Manage Power BI administration, qualification and user access provisioning for the platform.
Experience in executing Data Analytics projects in an Agile manner, articulation of Value depending on the project life cycle stage, Creating MVPs, developing plans for scale up are all very important experience to be successful in this role.
Great communication skills and ability to communicate inherently complicated technical concepts to non-technical stakeholders.
Ability to work in close partnership with other IT functions such as IT security, compliance, infrastructure, etc. as well as partner closely with business stakeholders in the commercial and digital organizations.
MS/BS degree in Computer Science, Engineering, Design or equivalent experience.
Why GSK?


Our values and expectations are at the heart of everything we do and form an important part of our culture. These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance and trust.

GSKIndia_DA

*LI-GSK

Our goal is to be one of the worlds most innovative, best performing and trusted healthcare companies. We believe that we all bring something unique to GSK and when we combine our knowledge, experiences and styles together, the impact is incredible. Come join our adventure at GSK where you will be inspired to do your best work for our patients and consumers. A place where you can be you, feel good and keep growing.

Important notice to Employment businesses/ Agencies

GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.

It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.

GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKilne (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.

If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in gsk.com, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine.",3.9,"GSK
3.9",Bengaluru,"Brentford, United Kingdom",10000+ employees,1830,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Pfizer, AstraZeneca, Merck"
Machine Learning Engineer,-1,"We are looking for a Machine Learning (ML) Engineer to help us create artificial intelligence products. Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we'd like to meet you. Your ultimate goal will be to shape and build efficient self-learning applications.

Responsibilities:
Designing and developing machine learning and deep learning systems.
Running machine learning tests and experiments.
Implementing appropriate ML algorithms.
Study and transform data science prototypes.
Design machine learning systems.
Research and implement appropriate ML algorithms and tools.
Develop machine learning applications according to requirements.
Select appropriate datasets and data representation methods.
Run machine learning tests and experiments.
Perform statistical analysis and fine-tuning using test results.
Train and retrain systems when necessary.
Extend existing ML libraries and frameworks.
Keep abreast of developments in the field.
Requirements:
Proven experience as a Machine Learning Engineer or similar role.
Understanding of data structures, data modeling and software architecture.
Deep knowledge of math, probability, statistics and algorithms.
Ability to write robust code in Python, Java and R.
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn).
Excellent communication skills.
Ability to work in a team.
Outstanding analytical and problem-solving skills.
BSc in Computer Science, Mathematics or similar field; Master's degree is a plus.",3.9,"Involvio
3.9",Bengaluru,"New York, NY",1 to 50 employees,-1,Company - Private,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Associate Data Analysts (EPM),-1,"At Red Hat, we connect an innovative community of customers, partners, and contributors to deliver an open source stack of trusted, high-performing solutions. We offer cloud, Linux, middleware, storage, and virtualization technologies, together with award-winning global customer support, consulting, and implementation services. Red Hat is a rapidly growing company supporting more than 90% of Fortune 500 companies.

The Red Hat IT Enterprise Applications team is looking for an EPM Data Analyst with a background in financial planning and analysis or accounting to join us in Pune, India. In this role, you will be responsible for Hyperion and Anaplan administration, data loads, user training, system support, and enhancements of the enterprise performance management (EPM) toolsets. This position will also be a part of the implementation of OneStream EPM. You'll need to have a high attention to detail and a proven ability to understand complex financial problems. You'll also need great communication skills and a global focus, as the core set of responsibilities are global by nature.

Consolidate Excel files, perform validations on them and upload to Hyperion
Serve as a data subject matter expert for data reconciliations, data troubleshooting, budget adjustment summary
Provision users to Anaplan
Migrate code to production for Anaplan
Administer Financial Close Management templates, schedules and tasks
Administer Account Reconciliation Manager profiles, profile segments, reconciliations and assignments
Load and reconcile data monthly to Hyperion Planning, Essbase and ARM
Assist with the implementation and migration of Hyperion to OneStream EPM
Maintain other functional admin and user documentation, checklists
Proactively build working relationships with the Hyperion and Anaplan users to deliver, maintain and enhance application functionality
Ensure production environment stability and performance are up to par and meet service level agreements (SLAs)
Ensure compliance with all applicable change management processes and procedures including internal controls
Provide timely response and resolution of emergency production questions, issues and defects

Finance and accounting background, deep functional understanding of budgeting and forecasting
1+ yrs experience in Hyperion (11.1.2.4 preferred) as an administrator or power user
1+ yrs experience in Anaplan or other EPM toolset
Advanced Excel and SmartView skills
Excellent understanding of Google docs, sheets, and slides
Bachelor's degree in Computer Science or in fields related to Finance or Accounting
Curious individual with solid initiative and ability to work in a self-directed environment
Ability to multitask in a dynamic environment; organization and prioritization skills
Good analytic and debugging skills

Red Hat is proud to be an equal opportunity workplace and an affirmative action employer. We review applications for employment without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, ancestry, citizenship, age, uniformed services, genetic information, physical or mental disability, medical condition, marital status, or any other basis prohibited by law.

Red Hat does not seek or accept unsolicited resumes or CVs from recruitment agencies. We are not responsible for, and will not pay, any fees, commissions, or any other payment related to unsolicited resumes or CVs except as required in a written contract between Red Hat and the recruitment agency or party requesting payment of a fee.",4.1,"Red Hat
4.1",Pune,"Raleigh, NC",10000+ employees,1993,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),"VMware, Oracle, Microsoft"
DA&I DATA ENGINEER,-1,"Position Title
DA&I DATA ENGINEER

05-May-2020

Business Group
Control Products and Solutions

No. of Positions
1

Requisition Number
92118BR

Job Category
Software and Engineering

Position Type
Full Time

Relocation Eligible
Not Applicable

Position Summary
Role Purpose: The Data Analytics and Insights Analyst partners with internal and external stakeholders to understand and align business strategies, requirements and align them to DA&I priorities. Is knowledgeable about business processes within their specific domain and has good understanding of Data Analytics setup at Rockwell Automation. This resource serves as go to person for questions related to how the Data Analytics & Insights ecosystem works from both a business and technical perspective. The DA&I Analyst partners closely with DA&I Technical Lead to make decisions and set direction within their capability teams.

This role is expected to work with business to understand and requirements. Apply use of technology, example Power BI, Data Science, modelling tools to build working prototypes to confirm user expectations. Direct DA&I engineers on implementation tasks. Is always striving hard to improve the stability and quality of solutions, to increase Customer adoption, loyalty and reduce support

This role is also a key change management driver for successful adoption of Customer Literacy, Data & Analytics Governance practices within their assigned domain.

Company Background
Rockwell Automation, a $7B industrial with 23,000 employees in 100 countries is at the forefront of the IoT revolution and is transforming its IT organization to digitize our customer experiences. We need full stack engineering professionals with a passion for technology to drive innovative solutions.

Key Responsibilities:
Partners closely with DA&I Technical Lead to lead Program Increment sessions with Business stakeholders to identify 3-6-month priorities. Ensures that plan aligns with long term strategic goals for specific domain and DA&I areas.
Define business case to help prioritize/optimize execution based on team capacity
Coordinates the project resources to ensure that projects are delivered on time and within budget.
Helps map out team-to-team dependencies and collaborates with capability teams accordingly
Improves systems and processes by studying current practices; designing modifications in partnership with stakeholders
Partners closely with Data Governance team to update metadata and data literacy content
Works with DA&I Engineers to provide Level 2 and Level 3 support for Capability team.
Well versed in Analytics & Insights methodologies and tools – example: Power BI, Python, Data exploration & mining tools
Maintains professional and technical knowledge by attending educational workshops; reviewing professional publications; establishing personal networks; benchmarking state-of-the-art practices; participating in professional societies
Has good understanding of application of Analytics & Insights to solve business outcomes.
Provides consultation to our business or enterprise shared services teams
Is hands on, innovative and out of box thinker to help provide robust solutions in a timely manner.
Is always striving to improve the DA&I stack, methodologies, processes to drive decision intelligence within Rockwell Automation
Addendum of Focus Support:
Organizational Change Readiness
Vendor Management
Operating and Delivery Model Coaching
Measuring Portfolio Performance through data analytics
Enterprise of management of enterprise portfolio, tool, processes

Qualifications
Skills, Knowledge, Experience and Education
Different level of experience needed depending on level of scope required
Bachelor’s Degree in computer science, management information systems or related field
Must exhibit excellent interpersonal, verbal and written communication skills
Strong understanding of basic system engineering, object-oriented design, information risk and security guidelines and architecture standards
Knowledge in software design, documentation, development process and software requirements
Ability to adapt quickly to new technologies and changing business requirements
Excellent analytical and problem-solving skills
Ability to understand business functionality and translate it into application requirements
Ability to create compelling business cases with accurate cost and effort estimations
Excellent understanding of business complexity and project interdependencies
Intellectual curiosity and the ability to question thought partners across functional areas
Ability to partner with multiple stakeholders and influence project decisions
Understanding of the various software development lifecycles (e.g. Agile, Waterfall, etc.)
Legal authorization to work in the US is required

Temperament
Ability to adapt to and assist colleagues through change and support change management processes
Strong team orientation and ability to collaborate with the business and IT organizations
Strong teamwork, customer service and organizational skills
Ability to retain and convey a positive attitude in challenging circumstances
Maintain a positive demeanor during periods of uncertainty, conflict, and stress
Act courageously by sharing viewpoints openly and directly with others, providing relevant and timely information and feedback, as required.
Remain open to ideas; integrates multiple perspectives in decision-making
Ability to influence and obtains results through others within Rockwell in a respectful way
Open mindset and willingness to learn and promote new philosophies to impact culture and organizational transformation initiatives
Create an environment that encourages the open exchange of information and viewpoints
Adapt appropriately to competing demands and shifting priorities

IPC - Information Processing Capability (Factors of Complexity)
Ability to work on issues of moderate scope where analysis of situations or data requires a review of relevant factors
Exercise judgment within defined procedures and practices to determine appropriate action
Apply process improvements to facilitate improved outcomes
Implement and execute processes across business/function to achieve assigned goals
Seek out and embrace relevant perspectives when assessing a situation or making a decision; demonstrate clear understanding of multiple viewpoints
Leverage business insights in proposing solutions and facilitating change
Scope of work: Receive assignments in the form of objectives with goals and the process by which to meet the goals
Ability to manage multiple priorities and projects simultaneously, ensuring stakeholder expectations are managed appropriately
Ability to manage competing demands, accept criticism and constructive feedback, while being extremely adaptable and flexible
Strong analytical skills; ability to distill information from disparate data sources and the capability to tell the “story” behind it, as well as recommendations for next steps

Country(s)
India

Company Overview
Over centuries, the world has evolved and advanced. New innovations change how we work. How we live. How things get made.

The next industrial evolution is here — a new test of intelligence for humans and machines. Where breakthroughs are hard–won and success requires sifting through overwhelming data for insights, clarity and confidence.

Rather than fearing change, we embrace its possibilities. We know how to connect the imaginations of people with the potential of machines to make the world work better. More intelligent. More connected. More productive.

We stand with the problem solvers, the builders, the makers, the innovators because we belong to that community. And we stand ready to lead the way. At Rockwell Automation, we are expanding human possibility.

Work State/City
Noida, Pune",3.7,"Rockwell Automation
3.7",Pune,"Milwaukee, WI",10000+ employees,1903,Company - Public,Industrial Manufacturing,Manufacturing,₹500+ billion (INR),"Emerson, ABB, Siemens"
Machine Learning Engineer/Data Scientist,-1,"Company Description

Mindbowser Info solutions is a digital transformation services provider working with global brands aiding on their journey to digital transformation. Mindbowser offers a suite of products and services around user experience, automation, analytics, and mobility that in turn helps businesses become more efficient and improves profitability.

Job Description

We are looking for a Machine Learning Engineer/Data Scientist to work alongside our innovative and growing data science team.The role will be based in our HQ, located in Pune.

Website: https://www.mindbowser.com/

Job description
Our Data Analysts are expected to explore data, technologies, and the application of mathematical techniques to derive data insights.
Ability to gather the domain specific knowledge of the data.
Should have good quantitative skills and the ability to tell a story using data.
Ability to build and fine tune machine learning algorithms which are first used at a proof-of-concept stage and then at a production level.
Should be able to translate prototypes into new products, and provide guidelines for large-scale implementation.
Exp: 0-6 Months
Key Requirements
Programming skills (Python preferred).
Experience of statistical techniques.
Selecting features, building and optimizing classifiers.
Processing, cleansing, and verifying the integrity of data used for analysis.
A basic understanding of the graphs, chart libraries used for data visualization.
Qualifications

BE/Btech/BCA/MCA

Graduate in any stream

Experience Range - 0-1 year",3.7,"Mindbowser Info Solutions Pvt Ltd
3.7",Pune,"Pune, India",1 to 50 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Are you at your most vibrant when you've successfully distilled data into its simplest, most meaningful form?

ThoughtWorks is a global software consultancy with an aim to create a positive impact on the world through technology. Our community of technologists thinks disruptively to deliver pragmatic solutions for our clients' most complex challenges. We are curious minds who come together as collaborative and inclusive teams to push boundaries, free to be ourselves and make our mark in tech.

Our developers have been contributing code to major organizations and open source projects for over 25 years. They've also been writing books, speaking at conferences and helping push software development forward, changing companies and even industries along the way. We passionately believe that software quality is driven by open communication, review and collaboration. That's why we're such vehement supporters of open source and have made significant contributions to open source tools for testing, continuous delivery (GoCD), continuous integration (CruiseControl), machine learning and healthcare.

As consultants, we work onsite with our clients to ensure we're evolving their technology and empowering adaptive mindsets to meet their business goals. You could influence the digital strategy of a retail giant, build a bold new mobile application for a bank or redesign platforms using event sourcing and intelligent data pipelines. You will learn to use the latest Lean and Agile thinking, create pragmatic solutions to solve mission-critical problems and challenge yourself every day.

Data Engineers develop modern data architecture approaches to meet key business objectives and provide end-to-end data solutions. You might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems. On other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product. It could also be a software delivery project where you're equally happy coding and tech-leading the team to implement the solution.

You'll spend time on the following:
You will partner with teammates to create complex data processing pipelines in order to solve our clients' most ambitious challenges
You will collaborate with Data Scientists in order to design scalable implementations of their models
You will pair to write clean and iterative code based on TDD
Leverage various continuous delivery practices to deploy data pipelines
Advise and educate clients on how to use different distributed storage and computing technologies from the plethora of options available
Develop modern data architecture approaches to meet key business objectives and provide end-to-end data solutions
Create data models and speak to the tradeoffs of different modeling approaches
Here's what we're looking for:
Have around 6-10 yrs experience.
You have a good understanding of data modelling and experience with data engineering tools and platforms such as Kafka, Spark, and Hadoop
You have built large-scale data pipelines and data-centric applications using any of the distributed storage platforms such as HDFS, S3, NoSQL databases (Hbase, Cassandra, etc.) and any of the distributed processing platforms like Hadoop, Spark, Hive, Oozie, and Airflow in a production setting
Hands on experience in MapR, Cloudera, Hortonworks and/or cloud (AWS EMR, Azure HDInsights, Qubole etc.) based Hadoop distributions
You are comfortable taking data-driven approaches and applying data security strategy to solve business problems
Working with data excites you: you can build and operate data pipelines, and maintain data storage, all within distributed systems
Strong communication and client-facing skills with the ability to work in a consulting environment
#LI-INDIA",4.4,"ThoughtWorks
4.4",Bengaluru,"Chicago, IL",5001 to 10000 employees,1993,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Accenture, Infosys, Boston Consulting Group"
Senior Data & Applied Scientist,-1,"What if your job description were simply “make tomorrow better?” Every day at Microsoft, we bring an insatiable curiosity to the workplace, challenging ourselves to reimagine what it is and what it can be. We build on what’s come before to create what’s next. We help shape the future and we empower billions of people around the globe.

We are the computational advertising team in the AI & Research organization at Microsoft. We are looking for candidates with research and applied experience in machine learning related areas. Search advertising is a $100 billion market worldwide. Microsoft's Bing search engine supports over 30% of desktop search in the US, with similarly significant presence in many other countries.

Responsibilities


We are a team of applied scientists working on machine learning components in the whole sponsored search stack. Our team works on problems related to machine learning, deep learning, natural language processing, image understanding, optimization, information retrieval, auction theory, among others. Our work entails building large-scale machine learning systems for ad matching, filtration, ranking, and multiobjective optimization, and a number of other ML-driven business problems. You will design, implement, analyze, tune complex algorithms and ML systems and the supporting infrastructure for operating on large datasets. You will collaborate with top machine learning scientists and engineers in delivering direct business impact. We're looking for sound understanding and insight into productionizing machine learning models in large-scale systems, an ability to pick up new technical areas, as well as a commitment to developing, delivering, and supporting algorithms in production.

Qualifications
MS/BS in CS/EE, mathematical or machine learning related disciplines, with 8 or more years of experience
Solid understanding of probability, statistics, machine learning, data science
A/B testing & analysis of ML models, and optimizing models for accuracy
Experience with Hadoop, Spark, or other distributed computing systems for large-scale training & prediction with ML models.
End-to-end system design: data analysis, feature engineering, technique selection & implementation, debugging, and maintenance in production.
Experience implementing machine learning algorithms or research papers from scratch
Experience with TensorFlow/PyTorch and deep learning models is a plus
Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.",4.3,"Microsoft
4.3",Bengaluru,"Redmond, WA",10000+ employees,1975,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Google, Amazon, Apple"
Manager - Marketing Data Science,-1,"Job Title
Manager - Marketing Data Science
Job Description


Responsibilities
Analyzes, measures, and facilitates optimization of our marketing return on investments and tactics across multiple channels. Drive excellent practices and technical standards for establishing KPIs and goals for Marketing, developing information suites (Dashboards, reports, visualizations) fit for C-level consumption, and marketing campaign tracking and measurement.
Leverage machine learning models to address key growth challenges such as lifecycle marketing, predictive LTV, cross-channel spend allocation, response modelling, campaign/channel performance measurement methodologies, Program effectiveness and media attribution.
Develop and improve marketing mix and A&P models and frameworks to assign credit for traffic and conversions across a variety of Marketing channels and touchpoints.
Leverage Philips’ data to scale our ability to optimize marketing across the customer journey to optimize return on investment through analysis, modelling, experiments and pre-post analyses.
Develop and implement marketing data management practices
Ability to use data for Exploratory, descriptive, Inferential, Prescriptive, and Advanced Analytics - Mandatory
Ability to share dashboards, reports, and Analytical insights from data – Mandatory
Technical Knowledge and Skills required
Econometrics, Market mix modeling, some Operations research and affinity modeling experience is mandatory
Track record in delivering strong and impactful; competitor and market tracking insights
High affinity with applying new IT platforms / dash boarding software tools for reporting and Experience in a consumer focused, complex, matrixed, multinational environment, e.g. consumer goods, online services, e-commerce, or mobile applications
Competitor insight generation
Strong background into Database design, modeling and architecture – preferred Fluency in web analytics and deep technical understanding of how data are created from first party and third-party web beacons
Proficiency with R and/or Python libraries commonly used in data science
Soft Skills Required
Good communication and presentation skills
Highly driven, energetic, flexible, resourceful & ability to multitask
Clarity of thoughts and vision
Ability to ideate and bring solutions to the table
Adherence to timelines, without sacrificing quality of output
Hands on and detail oriented, with a strong ability to co-ordinate across different Geographies and with different stakeholders at Exec and Director levels
Straightforward, honest and succinct communicator. Can organize, clarify and communicate complex ideas quickly, succinctly and accurately.
Creative. Demonstrated ability to think innovatively—connecting the dots where others cannot when it comes to consumer/ customer and user data to create business building insights
Work Experience
Minimum 8-11 years of increasingly responsible experience in high impactful marketing analytics individual contributor roles
Can be from e-Commerce companies like Amazon, Flipkart etc.
In depth knowledge of multivariate statistical techniques including marketing mix modeling, attribution modelling, TURF, RAD, clustering, churn, customer scoring, neural networks amongst others
High affinity with AI powered insight tools and engines and application of data science to marketing problems
Rich experience in Marketing analytics with a strong understanding of the full range of online marketing channels, how they work, how they can be integrated, and how to evaluate them
Academics
Master’s degree in a quantitative discipline, e.g., Math, Statistics, Physics, Operations Research, Economics, Econometrics
MBA /BTech-BE from IIT/NITs or Tier 1 engineering schools only, , MS Analytics from Tier 1 schools; special preference to MBA from Mudra Institute of Communication, Ahmedabad or MBA schools that excel in Marketing
Strong exposure to Statistics – Predictive Analytics – Mandatory
Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Advanced Analytics - Data Architect,-1,"Business Environment

Hewlett Packard Enterprise is an industry leading Technology Company that enables customers to go further, faster. With the industrys most comprehensive portfolio, spanning the cloud to the data center to workplace applications, our technology and services help customers around the world make IT more efficient, more productive and more secure.

Learning does not only happen through training. Relationships are among the most powerful ways for people to learn and grow, and this is part of our HPE culture. In addition to working alongside talented colleagues, you will have many opportunities to learn through coaching and stretch assignment opportunities. Youll be guided by feedback and support to accelerate your learning and maximize your knowledge. We also have a reverse mentoring program which allows us to share our knowledge and strengths across our multi-generation workforce. The team has an excellent mix of experienced professionals with strong analytics, business research and consulting background.

Job Description

The candidate would join the HPE Global Operations Advanced Analytics team housed in Bangalore. The candidate will work closely with global HPE Global Operations organization to design, develop and manage Analytics solutions using various tools and technologies. Some work would also involve superior data handling skills to support various aspects of planning and executive decision making.
Understand business requirement to develop and implement solutions that address business needs and adhere to big data architectural guidelines
Develop data-driven solutions to complex business challenges while working with data scientists and business consultants
Architect and create data views from big data store to feed into analytics solutions and visualization layers
Troubleshoot, debug when data is found to be inaccurate.
Root cause analysis of data issues and coming up with stable long terms solutions.
Education & Experience
Masters degree in IT, Computer Science, Software Engineering, Business Analytics or equivalent
12-15 years experience in industry experience working on data warehousing / distributed system (e.g. Hadoop)
Expert in building and optimizing big data data pipelines, architectures, and data sets
Excellent experience in data processing using Scala/Python/Java
Proficient in Big data tools and ecosystem (e.g. HIVE, Spark)
Experience working on analytics tools and solutions using Microsoft R
Strong in user requirements gathering, maintenance, and support
Experience working on scheduling tools like Oozie
Strong technical fundamentals to quickly learn next gen tools and start working on the same.
Personal Attributes
Analytical, with ability to think strategically.
Detail oriented ability to validate, analyze and sort through data.
Good written and numerical skills
Strong interpersonal skills
Works well in cross functional environments with matrix/influence management
Customer orientation
Results oriented, high energy and drive with a winning attitude
Hewlett Packard Enterprise Values:

Partner. Innovate. Act.

We live by three core values that drive our business.

Simplified, we are good partners, great innovators and we make things happen.

Extensive social benefits, flexible working hours, a competitive salary and shared values, make Hewlett Packard Enterprise one of the world´s most attractive employers. At HPE our goal is to provide equal opportunities, work-life balance, and constantly evolving career opportunities.

If you are looking for challenges in a pleasant and international work environment, then we definitely want to hear from you. Apply now below, or directly via our Careers Portal at www.hpe.com/careers
You can also find us on:
https://www.facebook.com/HPECareers
https://twitter.com/HPE_Careers

1067693",4.1,"Hewlett Packard Enterprise
4.1",Bengaluru,"Palo Alto, CA",10000+ employees,2015,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Oracle, Accenture"
Data Analyst,-1,"Title: Data Analyst

Skills: Data Warehouse, Data Analyst, SQL Database, Power BI, no-SQL Database – Mongo DB

Location: DLF Cyber Hub, Gurugram

Company Summary:
We’re the global leader in workspace scheduling technology. We make it easy to find and book space to meet up and work together. We provide workspace scheduling software to over 1,000 of the world’s biggest brands, integrating meeting room and workspace reservation solutions that help remove friction in the workplace and free businesses and their people up to get the most out of their working day.

Responsibilities:
Identify and assess key opportunity areas where data, analytics and science can enhance our business.
Develop hypothesis-driven analysis and statistical models to identify trends and key drivers in consumer behaviours that can be used to develop compelling value-props for the company and our clients.
Drive productization of analytic capabilities in data management, modelling and insights.
Gather information, perform data analysis by using latest Date Technologies to define technology requirements, business rules and ensure the technology meets the business objectives.
Work on Data Acquisition from upstream systems performing below-
Data Analysis
Data profiling
Gap Analysis
Prepare Data spec
Do feed testing
Perform Testing (QA and Functional)
Research and design data enrichment & transformation processes.
About You:
Experience with Power BI or other BI tools such as Qlikview, Tableau, Spotfire, Cognos is required.
Hadoop, Spark, Kafka, Scala, Python, DB2, MySQL, Oracle, no-SQL databases like MongoDB, Elastic Search.
Should have worked as Business/Data Analyst for a Data Lake or Warehousing project, preferably on Big Data platform.
Strong SQL skills is necessary along with exposure to data analysis using industry standard tools, methods and techniques. Prior experience of data modelling is useful.
Strong Data Analyst or System Analyst experience.
Ability to work on complex data mapping issues involving large datasets.
Quantitative skills in mathematics, statistics, and analytics.
Ability to analyse existing tools and databases and provide software solution recommendations.
Ability to turn data into information, information into insight and insight into business decisions.
Able to analyse large data sets, preferably utilizing Excel, SQL, or R/Python.
Solid and proven background in data mining, statistical analysis, segmentation and modelling.
Benefits:
Health insurance fully paid – Spouse, children and Parents
Accident insurance fully paid
Transport allowance
Gratuity fully paid
25 days holiday
7 paid sick days
10 public holidays
Company Information:
Follow us on Twitter | LinkedIn | YouTube.
Condeco are proud to be an equal opportunity employer. We are committed to treating all individuals in a fair and equal manner by creating an inclusive and open environment for all employees.",3.8,"Condeco
3.8",Gurgaon,"London, United Kingdom",201 to 500 employees,2005,Company - Private,Computer Hardware & Software,Information Technology,₹1 to ₹5 billion (INR),"Teem, Asure Software"
"Sr. Analyst, Risk Adjustment and Data Quality Governance",-1,"It’s Time For A Change… Your Future Evolves Here

Evolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Our pursuit of this mission is the driving force that brings us to work each day. We believe in embracing new ideas, challenging ourselves and failing forward. We respect and celebrate individual talents and team wins. We have fun while working hard and Evolenteers often make a difference in everything from scrubs to jeans.

Are we growing? Absolutely about 40% in year-over-year revenue growth in 2018 . Are we recognized? Definitely. We have been named one of “Becker’s 150 Great Places to Work in Healthcare” in 2016, 2017, 2018 and 2019, and One of the “50 Great Places to Work” in 2017 by Washingtonian. We recognize employees that live our values, give back to our communities each year, and are champions for bringing our whole selves to work each day. If you’re looking for a place where your work can be personally and professionally rewarding, don’t just join a company with a mission. Join a mission with a company behind it.

Please be sure to include a cover letter with your resume detailing your interest in Evolent Health, your timeline for a new position, and what office location(s) you are interested in. Position will be located in our Pune, India office.

Who You’ll Be Working With:

Risk adjustment, STARS and Quality (RASQ) Performance metrics are essential for a health plan to maintain and improve in healthcare. The RASQ Platform team at Evolent Health provides industry-leading solutions for clients in Medicare Advantage, Next Generation ACOs, ACA Exchanges, and Medicaid. If you want a part of solving one of the most interesting quantitative challenges in healthcare today, like we do, then the RASQ Platforms team is the place for you.

What You’ll Do:

The Sr Analyst, Risk Adjustment and Quality Data Governance, will be working with a highly-motivated team of software engineers and data scientists on ingesting, transforming and organizing disparate streams of healthcare data from our partners and internal teams into data models for application and analytical insights.
Passionate about data and will collaborate with other teams including engineering, analytics, customer relations to identify and stream data files into a centralized repository
Work in both relational and non-relational databases including SQL Server, MongoDB, Flat files utilizing SAS, Python, SQL or any other programming language.
Participate and contribute to data governance, management, ingestion and transformation discussions
Work in an agile, collaborative environment to understand requirements, design, code and test innovative applications, and support those applications for our customers
Become a resource for all data needs in Risk Adjustment, Quality, Payer and Provider data services
The Experience You’ll Need (Required):
Bachelor’s degree with either a quantitative major (e.g. actuarial, statistics, economics, engineering, computer science, operations research, applied math) or healthcare major (health administration, public health)
4-7 years of total experience with 3+ years of experience in an actuarial, health analytics, data science, or quantitative analyst or software engineering / programming role
Experience with writing data Extract-Transform-Load (ETL) scripts in SQL, Python, Java, SAS or any other programming language with emphasis on loading & processing data files (CSV, Excel, Text files, JSON files or any other data sources).
Ability to understand and apply highly technical specifications to healthcare datasets
Strong verbal & written skills and excellent communication & presentation skills. Comfortable presenting complex analyses
Collaborative working style with the ability to work across different organizations and personalities as well as comfort in a highly matrixed environment
Ability to multitask, prioritize, adapt to change, work well under pressure in an entrepreneurial environment, meet deadlines, and manage a project from start to finish
Finishing Touches (Preferred):
Experience working with healthcare datasets including claims, encounters, eligibility, Risk Adjustment and Quality/HEDIS measures
Evolent Health is an equal opportunity employer and considers all qualified applicants equally without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin.",2.9,"Evolent Health
2.9",Pune,"Arlington, VA",1001 to 5000 employees,2011,Company - Public,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),-1
Senior Data Scientist,-1,"At TomTom…
You’ll move the world forward. Every day, we create the most innovative mapping and location technologies to shape tomorrow’s mobility for the better.
We are proud to be one team of more than 5,000 unique, curious, passionate problem-solvers spread across the world. We bring out the best in each other. And together, we help the automotive industry, businesses, developers, drivers, citizens and cities move towards a safe, autonomous world that is free of congestion and emissions.
TomTom is hiring an experienced data scientist in our maps engineering team. As a Senior Data Scientist, you are passionate about computer visions, statistical sampling and analytic methods, deploying machine learning models @ scale in the production, monitoring and tuning them via active feedback loops. You will be part of agile unit and will be collaborating with engineers, data engineers, map and location experts and fellow data scientists.
As an experienced data scientist, you will help to make location content best-in-class by advocating for and implementing changes to technology, process, tools, and systems. We look for people who are curious, innovative, out of box thinker, loves taking risk and work to make system better every day. In this role, the person is expected to take on critical tasks such as productionizing, deploying, testing and monitoring of machine learning models including exposing them as service.
What you’ll do
Draw insights by manipulating Satellite imagery, vertical imagery, street level imagery, GPS traces, etc. individually and by fusing several combinations of these sources
Use these sources individually or their combinations to predict various map features and attributes by training statistical models/ ML models
Applying various data science methods coupled with Computer vision like CNN, explore and experiment on new models through research papers or via various frameworks
Develop processes and tools to monitor and analyze model performance and data accuracy
Automate feedback loops for algorithms in production through standardization of process and authoring best practices
Collaborate with teams to bring synergy
Mentor/Coach/Guide team members aspire to become a Data Scientist
What you’ll need
Bachelor’s/Masters/PHD in Computer science, Mathematics, Statistics or equivalent field and must have min. 8+ years of overall experience
Minimum 4-5 Years of experience working as a Data Scientist in deploying ML at scale in production
Experience in slicing and dicing of large data sets to draw insights
Experience in various machine learning techniques (e.g. Convolutional Neural Network, Object detection, NLP, Decision tree, Regression, etc..) and frameworks (e.g. TensorFlow, PyTorch, Scikit-learn, etc.)
Experience in deploying trained models for high scalability on public cloud platforms (AWS/Azure) using Dockers/Kubernetes
Experience working with data technologies that allow effective storage and analysis of large amounts of data (e.g. Hadoop, Hive, Spark, Presto, S3, etc).
Strong level of proficiency in Python, Unix/Linux and SQL
Active participation in competitions on a platform such as Kaggle
Strong problem-solving skills
Excellent written, verbal and presentation skills
A drive to learn new technologies
Expertise in designing and testing experiments
Knowledge and experience with using GIS tools for spatial data analysis.
Excellent oral and written communication skills

Meet your team: MAPS Product Unit
Part of TomTom’s Location Technology Products technical unit, the Maps product unit is comprised of over 2,000 people in 40 countries – all driven to deliver the most up-to-date, accurate and detailed maps for the hundreds of millions of people using TomTom maps around the world. Joining this product unit, you can help continuously innovate our map-making processes, create a real-time closed loop between detected changes in the real world and the users’ map, and build maps that will enable the future of autonomous driving.
Achieve more!!!
We are self-starters who play well with others. Every day, we solve new problems with creativity, meet new people and learn rapidly at our offices around the world. We will invest in your growth and are committed to supporting you. In everything we do, we’re guided by six values: We care, putting our heart into what we do; we build trust (you can count on us); we create – it’s how we make a difference; we are confident, but don’t boast; we keep it simple because life is complex enough; and we have fun because life’s too short to be boring.
Ready to move the world forward?
After you apply

Our recruitment team will work hard to give you a meaningful experience throughout the process, no matter the outcome. Your application will be screened closely, and you can rest assured that all follow-up actions will be thorough, from assessments, conversations and interviews through your onboarding.

TomTom is an equal opportunity employer

We celebrate diversity, thrive on each other’s differences and are committed to creating an inclusive environment at our offices around the world. Naturally, we do not discriminate against any employee or job applicant because of race, religion, color, sexual orientation, gender, gender identity or expression, marital status, disability, national origin, genetics, or age.

Ready to move the world forward?",3.8,"TomTom
3.8",Pune,"Amsterdam, Netherlands",5001 to 10000 employees,1991,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹50 to ₹100 billion (INR),"Garmin, HERE Technologies, Google"
Data Science - Principal Software Engineer,-1,"We believe work is not a place, but rather a thing you do. Our technology revolves around this core philosophy. We are relentlessly committed to helping people work and play from anywhere, on any device. Innovation, creativity and a passion for ever-improving performance drive our company and our people forward. We empower the original mobile device: YOU!

What we're looking for:


You will join a crack team of experienced and talented engineers, with years of history delivering high-quality Analytics products and Solutions, in a fast-paced business environment. You will be collaborating with fellow engineering teams across the globe

Position Overview:

Citrix is expanding its Advanced (Appsec) Analytics team with professionals in the ML/AI/Data Science domains.

Roles responsibilities
Research & develop Machine Learning models for security problems, in the areas of Application Security, Networking, Application & Data.
Suggest, collect and synthesize requirements, and create effective features.
Apply research methodologies to identify the Machine Learning models for the problem at hand.
Basic Qualifications
Bachelors/Masters/PhD in CS/IT/EE/Mathematics and computing with 12+ years of experience
Experience in implementing and deploying Machine Learning solutions (using various models, such as Linear/Logistic Regression, Support Vector Machines, (Deep) Neural Networks, Hidden Markov Models, Conditional Random Fields, Topic Modeling, Game Theory, Mechanism Design, etc.)
Extensive background in statistical analysis and modeling (distributions, hypothesis testing, probability theory, etc.)
Strong hands-on experience with statistical packages and ML libraries (e.g. R, Python scikit learn, Spark MLlib, etc.)
Experience in effective data exploration and visualization (e.g. Excel, Power BI, Tableau, Qlik, etc.)
Experience in developing and debugging in one or more of the languages C/C++, Java, Scala, Python, or R
Ability to work in cross-functional teams
Excellent written and verbal communication skills in English; the ability to convey your message to team members and other stakeholders
Preferred Qualifications
Experience in Application Security Domain, AppFW, BOT, etc
Experience working with relational and NoSQL/Graph databases
Unsupervised & Deep Learning Experience
Familiar with Big Data frameworks (Hadoop or Spark) and cloud infrastructures
Experience in applying Machine Learning techniques
Ability and willingness to multi-task and learn new technologies quickly
What youre looking for:


Our technology is built on the idea that everyone should be able to work from anywhere, at any time, and on any device. Its a simple philosophy that guides everything we do including how we work. If youre an engineer, well give you plenty of ways to test your skills on cutting edge technology. We want employees to do what they do best, every day.

Be bold. Take risks. Imagine a better way to work. If this sounds like you then wed love to talk.

Functional Area:
Software Development
About us:


Citrix is a cloud company that enables mobile workstyles. We create a continuum between work and life by allowing people to work whenever, wherever, and however they choose. Flexibility and collaboration is what were all about. The Perks: We offer competitive compensation and a comprehensive benefits package. Youll enjoy our workstyle within an incredible culture. Well give you all the tools you need to succeed so you can grow and develop with us.

Citrix Systems, Inc. is firmly committed to Equal Employment Opportunity (EEO) and to compliance with all federal, state and local laws that prohibit employment discrimination on the basis of age, race, color, gender, sexual orientation, gender identity, ethnicity, national origin, citizenship, religion, genetic carrier status, disability, pregnancy, childbirth or related medical conditions, marital status, protected veteran status and other protected classifications.

Citrix uses applicant information consistent with the Citrix Recruitment Policy Notice at https://www.citrix.com/about/legal/privacy/citrix-recruitment-privacy-notice.html

Citrix welcomes and encourages applications from people with disabilities. Reasonable accommodations are available on request for candidates taking part in all aspects of the selection process. If you are an individual with a disability and require a reasonable accommodation to complete any part of the job application process, please contact us at (877) 924-8749 or email us at ASKHR@citrix.com for assistance.

If this is an evergreen requisition, by applying you are giving Citrix consent to be considered for future openings of other roles of similar qualifications.",4.0,"Citrix
4.0",Bengaluru,"Fort Lauderdale, FL",5001 to 10000 employees,1989,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),"VMware, F5 Networks, Cisco Systems"
Data Engineer,-1,"About phData

We build next-generation strategic platforms helping customers to save money and unlock real business value for our customers and the community. If you are inspired by innovation, hard work, and a passion for data, we want to hear from you.
Our Commitment – you will be working in a fast-moving environment with the brightest and most experienced minds in technology. We're committed to constant learning and innovation.
Our Work – you'll be helping companies answer questions and create products that, until now, were too big, too expensive, and too complex to accomplish.
Our Technology – we focus on building and deploying disruptive big data technologies. If you have experience in or passion for Hadoop and its supporting technologies, we want to hear from you!
In addition to the phenomenal growth and learning opportunity, we offer competitive compensation and excellent perks including base salary, annual bonus, and extensive training - in addition to generous PTO, flexible hours and comprehensive Insurance cover.

Passionate about Big Data, Data Science, and Machine Learning Algorithms? Be part of a team of industry pioneering experts that operate some of the largest analytics and data science infrastructure systems at phData. Our customers apply these technologies on terabytes of data a day on petabyte-scale infrastructure.

Job Information

Technical Responsibilities
Hands-on Engineering of Data Processing applications
Experience with Big Data technologies, assisting customers in building software solutions on-prem or cloud.
Very strong understanding of SQL alongside traditional/conventional data warehousing design patterns.
Hands-on experience in developing Big Data applications using Hadoop technologies such as Spark (Scala or PySpark), Map Reduce (Java), YARN, HDFS, Hive, Impala, Sqoop, Oozie, HBase, Kudu.
Good understanding of UNIX shell scripting.
Develop analytical functionality and complex transformation that will be finally deployed in production data platforms.
Good understanding of Big data design patterns
Hands-on experience troubleshooting, optimizing, and enhancing the big data pipeline and bring improvements.
Experience & good proficiency with at least one programming language (Java, Scala, Python)
Extensive experience with at least one major Hadoop platform (Cloudera, Hortonworks, MapR)
Worked and deployed at least one data engineering application using cloud-native data platform and services (example EMR or Redshift in AWS or Data factory in Azure or BigQuery in GCP)
Strong troubleshooting and performance tuning skills.
Very well versed with continuous integration and deployment procedure considering the bigdata stack on-prem or cloud environment.
Ability to analyze business requirement user stories and translate them into system requirement specifications.
Experience working under the agile delivery methodology.
Behavioral Requirement
Demonstrated ability to work independently
Good communication skills and documentation skills.
Good & Collaborative Team Player.
Good organizational and time management skills
An ability to work to deadlines
A good eye for detail
Must be ready to learn and adapt to new technologies.


Qualifications Requirements
BE/BTech in computer science Or MCA with sound industry experience (2-4 years)
A minimum of 2 years' experience in hands-on development
Experience in Java, Scala or Python (Production level coding)
Experience in a cloud-based environment with PaaS & IaaS
Work iteratively in a team with continuous collaboration",2.9,"phData
2.9",Bengaluru,"Minneapolis, MN",51 to 200 employees,2014,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Big Data Engineer,-1,"CAREERS

Big Data Engineer

Bengaluru, India
JOB DESCRIPTION

Develops data architectures and pipelines by;
Understanding requirements;
Understanding deadlines;
Understanding systems flow, data usage, and work processes;
Working in tandem with the Analytics team and providing inputs as and when required
Investigating problem areas;
Follow Agile and Scrum practices;
Be thought partner to the onsite counterpart in creating the data charter for the client
Should be able to lead client calls and answer design specific queries
Documents and demonstrates solutions by developing documentation in the forms of flowcharts, layouts, diagrams, charts, code comments and clear code;
Provides information by collecting, analyzing, and summarizing development and service issues;
Accomplishes engineering and organization mission by completing related results as needed and on time with high quality;
THE IDEAL CANDIDATE WILL

Thorough understanding of the entire Hadoop Ecosystem
Should have created convoluted data-pipelines
Should have expertise with more than one of the following Hive, Map Reduce, Pig, Oozy, Spark
Should have worked with clusters from different distributors namely MapR, CloudEra, Hortonworks
Should have worked extensively on data modeling and data lake creation
Should be able to estimate, design pipelines based on High data volumes and create base data assets for analytical work to commence
Proficient with Ubuntu/Linux and shell scripting
Should be aware of one Scripting language namely Python/Scala/Java
Expert in performance tuning Hive queries based on storage formats and partitioning
Strong fundamentals in SQL
Experience with Streaming data sources and NoSql databases is a plus
ELIGIBILITY CRITERIA

2 to 6 years of relevant experience
Bachelor’s and/or Master’s degree in computer science or equivalent experience
Strong communication, analytical and problem-solving skills with a high attention to detail
Send your CV to careers@tredence.com",3.5,"Tredence
3.5",Bengaluru,"San Jose, CA",501 to 1000 employees,2013,Company - Private,Consulting,Business Services,₹1 to ₹5 billion (INR),-1
Data Engineer,-1,"HP is the worlds leading personal systems and printing company, we create technology that makes life better for everyone, everywhere. Our innovation springs from a team of individuals, each collaborating and contributing their own perspectives, knowledge, and experience to advance the way the world works and lives.

We are looking for visionaries, like you, who are ready to make a purposeful impact on the way the world works.

At HP, the future is yours to create!

We are Pricing Analytics Team; our main objective is to help the business to decide optimal price for the HP products in a scientific way through statistical and predictive analysis.

If you are our Data Engineer in India, you will get an opportunity to work on below.
Designs and establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data pipelines, repositories or models for structured data.
Analyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.
Writes and executes complete pipeline plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs and creates solutions for issues with data sources and integration into data system architecture.
Collaborates and communicates with project team regarding project progress and issue resolution. Represents the data engineering team for all phases of larger and more-complex development projects. Provides guidance and mentoring to less experienced staff members.
Are you a high-performer? We are looking for an individual with.
Well versed knowledge on SQL servers and database solutions.
Python programming language to create efficient data flow
Various operating systems like Linux, windows, Unix which will enable data interconnection Data warehousing and ETL tools Good to have.
Knowledge on R and visualization tools such as Power BI / Tableau/ R Shiny Data architecture skills to create effective data flow Team player to interact and understand the data based on data scientists and analysts
#LI-Post",4.1,"HP Inc.
4.1",Bengaluru,"Palo Alto, CA",10000+ employees,1939,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Analyst II,-1,"Business Title
Data Analyst II

04-May-2020

Requisition Number
25081BR

Job Description and Requirements
At Synopsys, we’re at the heart of the innovations that change the way we work and play. Self-driving cars. Artificial Intelligence. The cloud. 5G. The Internet of Things. These breakthroughs are ushering in the Era of Smart Everything. And we’re powering it all with the world’s most advanced technologies for chip design and software security. If you share our passion for innovation, we want to meet you.

Our Software Security and Quality business is all about building secure software—faster. That starts with our static analysis, software composition analysis, and dynamic analysis. So our customers can build security and quality into the DNA of their code at any stage of the software development lifecycle and across the supply chain. All while minimizing risks and maximizing speed of application development.

Data Analyst

We’re looking for a Data Analyst to join the team.

Does this sound like a good role for you?

In this role, the Data analyst need to gather and understand the business requirements using appropriate tools and techniques. You would need to carry out data quality control and validations. The data analyst needs to prepare reports for internal and external stakeholders using business analytics and tools.

Responsibilities include but not limited to the following:
Liaise with internal and external stakeholders to understand data content and develop and support reporting processes
Identify areas to increase efficiency and automation of processes
Set up and maintain automated data processes
Design and carry out surveys and analyze survey data
Create data dashboards, graphs and visualizations
Analyze large datasets, draw valid inferences and present them successfully to management using a reporting tool.
Key Qualification
Bachelor’s degree in Mathematics / Statistics / Computer Engineering
3+ Years in data analyst role
Strong verbal and written communication skills
Preferred Experience
Excellent numerical and analytical skills
Understanding of IT services and management reporting
Experience of data analysis techniques and statistical models
Ability to produce clear graphical representations and data visualizations
Knowledge and advanced skills in Excel, VBA, XML, PPT
Familiarity with Tableau, APIs and programming skills for data and analytics
Inclusion and Diversity are important to us. Synopsys considers all applicants for employment without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, military veteran status, or disability.

Hiring Location
INDIA - Bangalore, INDIA - India

Hire Type
Employee

Job Category
Business Development

Country
India",4.1,"Synopsys
4.1",Bengaluru,"Mountain View, CA",10000+ employees,1986,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),"Cadence Design Systems, Mentor Graphics, Ansys"
Lead Data Scientist,-1,"About vPhrase

vPhrase helps make data easier to understand by explaining the insights in words, using AI. The company's patent pending platform, Phrazor, analyses data, derives insights and then communicates those insights, in words, in multiple languages.

Role Overview

As lead data scientist at vPhrase you would be responsible for developing, testing and maintaining our NLG engine as well as the analytical engine of our product Phrazor. These models would power analytical and decision modules of our product’s AI engine. The candidate is also expected to lead our independent applied research team.

Requirements
Phd./Masters/Bachelors in Statistics, Computer Science, Economics or a related field with at least 12 years of experience.
The candidate should have directly led an independent team of data scientists and NLP Engineers .
Proficiency making ML models work at scale in production environments. With comfort working with tools to manage large datasets.
Deep understanding of machine learning models, data analytics tools and deep learning frameworks.
Background in Natural Language Processing (NLP) and text analytics is preferred.
Ability to handle large and complex structured as-well-as unstructured datasets.
Ability to perform independent research across various domains of analytics.
Proficiency working with scripting languages like Python/R and Query languages SQL.
Experience working with B2B SaaS products in preferred.
Key Responsibility
The candidate is expected to lead the applied research team with focus on our core NLG engine.
Working closely with our product teams to power intelligence in our product.
Improving analytical engine, our domain agnostic decision models as well mining algorithms.
Managing and grooming a team of data scientists, NLP engineers and analysts.
Designing own experiments and developing new methodologies for analysis as per business goals.
Comfortable with finding possible problems, exploring different approaches and arriving at solutions that enhance our analytical modules.
Building data models and maintaining them in testing as well as production environments.
Impact

We are transforming the way people interpret data with our proprietary AI powered NLG(Natural Language Technology) engine that analyses, reasons and writes like a human being. We have filed several patents in this field and are leaders across the globe with only NLG product company in India.

Major BFSI, Health, Media organisations across the globe use our product Phrazor everyday to churn out millions of AI powered stories in real-time.

Benefits

Being part of a startup that’s turning out to be a game-changer, you will be blessed with:
A young and energetic workplace where new ideas are always welcome. The crazier, the better.
Freedom to try new things; failure is not censured.
Casual dress code
5 day work week. Yes, Sat-Sun off
No over-time, proper work-life balance
Take-it-when-you-need-it vacation
Above all, we as a team devote one day every month to volunteer for social causes close to our hearts.

Apply",-1,Meyrahkee,Pune,"Bengaluru, India",1 to 50 employees,2019,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Analyst/Scientist,-1,"Founded in 1987 and listed on NASDAQ, our client is headquartered in the USA and has an annual turnover of over USD 2+ Billion. They are a leading provider of technology solutions for small, medium, enterprises throughout the North America, Europe and Asia. Their comprehensive expertise and proven experience in advanced technologies and consulting & implementation services makes them the preferred partner for many global MNC customers

As a Data Analyst/ Scientist you will be responsible for reviewing, analysing and for gaining insights from the data stored in the BI data cubes as well as position BI for future uses such as machine learning and predictive analytics of sales behaviors.

Ket Responsibilities and Qualifications/Skills
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Excellent understanding of machine learning techniques and algorithms, etc.
Experience with common data science toolkits
Great communication skills
Experience with data visualization tools such as Power BI
Experience with MS SQL databases and Analytics / OLAP Cube Development (Microsoft SSAS and MDX)
Proficiency in using query languages such as SQL
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality
Location: Gurgaon, India

Employment Term: Dedicated & Full Time",5.0,"itForte
5.0",Gurgaon,"New Delhi, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist-2,-1,"Role and responsibilities

Work with business partners and stake holders to understand the business, formulate the problems, come up with the solutions and communicate them back effectively to non-technical audience.

Lead complex, multifunctional data science projects

Design, develop and implement real-time, highly complex advance machine learning models to solve credit business problems (demand generation, marketing, fraud, credit, account management and collections)

Work with large volumes of data; extract and manipulate large datasets using standard tools such as Python, R, H2O, Hadoop and SQL

Collaborate with engineers to implement models on one of the best data platforms in the industry.

Analyze data to identify trends, perform root cause analysis and test hypotheses.

Communicate complex concepts and the results of the models and analyses to technical and non-technical audience

Mentor and grow junior data scientists

Qualification

Advance degree (MS or PhD) in science or engineering field with 4+ years of relevant experience

Strong problem-solving and communication skills

Proven track record of building and implementing machine learning solutions

Experience in leading cross-functional, highly complex Data Science projects

Data Mining experience in Python, R, H2O and/or SAS. Familiar with various Machine Learning algorithms and Statistical methods

Have a passion for working on big data and professional experience in data mining, statistical analysis, predictive modeling and data manipulation.

Ability to deal with large amount of data and fluency with SQL or SQL-like tools.

Financial services or eCommerce experience a big plus",3.7,"PayPal
3.7",Chennai,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Distributed computing & Data Analytics Developer,-1,"Distributed computing & Data Analytics Developer

Job Description:

Job Experience - 12 to 16 years

Job Title - Distributed Computing/ Data Analytics developer

The Company

Interset Software uses big data and advanced behavioral analytics to detect and prevent the theft of intellectual property...simply put, WE CATCH BAD GUYS WITH MATH!!!

Part of the Micro Focus group of companies, we are a fast-paced, all-hands-on-deck kind of environment where you are respected and listened to from day one. We have a start-up feel within the stability and structure of a large global company.

We are currently looking to fill a development position focussed on extending the existing analytics platform and related capabilities to add unprecedented analytics flexibility for our customers. This will include enabling Data Scientists to manipulate and combine events and models to extend and customize the analytics in ways that provide unique value for each customer.

Were looking for a software developer whos passionate about what they do, takes a creative approach to problem solving and will be the champion for creating innovative machine learning hooks that deliver real value and perform in big data environments.

If youre passionate about true machine learning and want to be part of a company building solutions that leverage the latest in big data technology, we want to talk to you!!

What you'll do:
Implement model data flows to support running cutting-edge machine learning techniques on massive amounts of data
Work with product managers and data scientists to turn new features and algorithms into beautiful, battle-tested code
Work with the technologies we use to analyze and identify cyber-security threats for our customers (Elasticsearch, Spark, HBase, Kafka, Vertica, NiFi, using Java and Scala)
Work side by side with some of the smartest minds in the fields of machine learning and behavioural analytics
Create efficient and robust cloud-based solutions, leveraging the best in cloud technologies.
Who you are:
Undergraduate or Masters degree in Computer Science or equivalent engineering experience
Strong interest in software design, distributed computing, and databases
Experience developing in a JVM environment (Java, Scala, Clojure)
At least two years of experience developing with or using Big Data & Analytics stacks/tools such as Hadoop, HBase, Spark, Presto and Vertica.
Experience implementing and using streaming platforms such as SparkSQL, Flink, Kafka, Storm, etc.
Experience with Kubernetes, Docker, Ansible or any other infrastructure or containerization management/automation platform.
Familiarity leveraging AWS EMR, Azure, GCP cloud technologies best practices to enable the distribution and analysis of big data on the cloud would be considered an asset.
Nice to haves:
Familiarity with data science or machine learning packages (pandas, R, TensorFlow, etc...)
Familiarity with virtualization technologies (VMWare ESX, Docker)
Contributions to open source software (code, docs or mailing list posts)
Interest in understanding and analyzing diverse types of data
Job:

Engineering

Micro Focus is proud to be an Equal Opportunity Employer. Prospective employees will receive consideration without discrimination because of race, colour, religion, creed, gender, national origin, age, disability, marital or veteran status, sexual orientation, genetic information, citizenship or any other legally protected status",3.3,"Micro Focus
3.3",Bengaluru,"Newbury, United Kingdom",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),"SAP, Oracle"
Artificial Intelligence / Machine Learning Engineer,-1,"Nagpur, India Full-Time

About the Job
AI / ML is one of the most exciting technologies of the decade. This role is your opportunity to build and deploy new AI products from the ground up. You will be part of a team helping chart our AI strategy and define the problems we are solving with AI. You will help build our AI development and production infrastructure and set our technical standards. To succeed you must become an expert in building AI models and putting them into production.

Requirements
Have 1+ years of work experience with large volumes of data preferably in healthcare.

Have a formal education in relevant fields such as stats, computer science or applied mathemathics.

Love data. You need to eat, breathe and sleep data. For you, everything has to be measured and data-driven.

You should have a very good understanding of Python and Image processing, and hands-on software development skill from the development to production.

Are an expert at data visualization and presentation.

Have a strong background in statistical concepts and machine learning models.",3.6,"Healthcoco Technologies
3.6",Pune,"Pune, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"Data analysts translate numbers into simple readable statics, every business collects data, whether it's sales figures, market research, logistics, or transportation costs. A data analyst's job is to take that data and use it to help companies make better business decisions.
Analytical Skills: Data analysts work with large amounts of data: facts, figures, and number crunching. You will need to see through the data and analyse it to find conclusions.
Communication Skills: Data analysts are often called to present their findings, or translate the data into an understandable document. You will need to write and speak clearly, easily communicating complex ideas. Demonstrates good communication skills.
Critical Thinking: Data analysts must look at the numbers, trends, and data and come to new conclusions based on the findings.
Attention to Detail: Data is precise. Data analysts have to make sure they are vigilant in their analysis to come to correct conclusions.
Math Skills: Data analysts need math skills to estimate numerical data.
Programming Skills: This role requires an understanding of programming logic, although no experience with a specific programming language is required. Familiarity with SQL will be an important part of the data analyst role.
Educational Requirements: Bachelors of Science in any related fields.
Overall Knowledge/Skills/Abilities: Must have strong analytical skills and an understanding of system databases, data elements, and application software solutions to maximize data gathering and data analysis.
Have the ability to interpret their intent and application. Demonstrates the ability to handle a variety of responsibilities under pressure. Must be able to function independently.",4.1,"TBO Group
4.1",Gurgaon,"Dubai, United Arab Emirates",201 to 500 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
MNA Data Engineer 1,-1,"Nokia is a global leader in the technologies that connect people and things. With state-of-the-art software, hardware and services for any type of network, Nokia is uniquely positioned to help communication service providers, governments, and large enterprises deliver on the promise of 5G, the Cloud and the Internet of Things.

Serving customers in over 100 countries, our research scientists and engineers continue to invent and accelerate new technologies that will increasingly transform the way people and things communicate and connect.

Nokia is an equal opportunity employer that is committed to diversity and inclusion.

At Nokia, employment decisions are made regardless of race, color, national or ethnic origin, religion, gender, sexual orientation, gender identity or expression, age, marital status, disability, protected veteran status or other characteristics protected by law.

Position description:


The Advanced Analytics Practice team is looking for a proactive key member who will have a key role in its development and maintenance. It is a unique opportunity to become part of a world-class team that is developing and managing the next generation, global analytics-as-a-service practice for Nokia. This is a hands-on technical role using state-of-art Microsoft Azure Platform in a dynamic agile environment, working directly with developers, architects, test engineers, product management and internal customers.

Responsibilities:


Solution maintenance, enhancements, troubleshooting, problem investigation, solution defects fix up
Modeling in SQL DB/DW and Azure Analysis Service
Handling application service requests
Train and lead less experienced or junior engineers
Responsibility for single assignments in task level of user stories in Microsoft DevOps tool (VSTS)
Solution source coding components, such as Azure Data factory, SQL DB/DW, web app service
Unit testing for each source function and function test for each user story
Review the source code quality from peer developers
Design, implement and integrate features based on the platform and solution architecture
Assure application backups and recovery
Assure solution knowledge management
Improve the DevOps practice withing the team
Implement telemetry and monitoring on Azure platform and solutions

Required skills:


Bachelor’s degree in computer science, software/computer engineer or related relevant field
5+ years of combined experience Microsoft Azure cloud platform services, data and analytics solutions
Proficient SQL and Powershell programming skills on Azure (ADF, DWH, Runbook)
Experience with complex data modelling on Azure Analysis Services
Advanced skills on PowerBI reporting
Azure security expertise
Experience in implementing and managing Azure DevOps processes
Experience in software design/development and/or operations
Background in software development, systems architecture and operations
Experience in deliveration applications in Azure with GIT source control systems
Deploying application and services to Azure PaaS and IaaS
Excellent communication skills in written and verbal English

Desired skills:

Certifications in Microsoft Azure and Power BI is a plus
Ability to work in and with cross-functional distributed teams, including working across multiple time zones and providing remote support
Be an independent self-learner with the “let’s get this done” approach
Experience in implementing telemetry and monitoring in Azure environments
Experience in TDD/Agile development environment and unit testing tools
Experience in leading agile teams

Required Qualifications: (Education, Technical Skills/Knowledge)
Above 5 years of hands-on experience in software design/development and/or operations
Background in Development, Systems Architecture, and/or Operations.
Experience delivering applications in Azure.
Experience with configuration management tools
Experience with source control systems such as TFS and GIT.
Work experience deploying web and application services to Azure PaaS and IaaS.
Experience working with Microsoft SQL Server
Working knowledge of DNS, Monitoring, SSL Certificates, File Servers, Security, Performance, High Availability, Redundancy, and Disaster Recovery.
Working knowledge of Microsoft OMS
Experience in Automated Deployments with Continuous Integration workflows.
Excellent written and oral communication skills.
Excellent interpersonal skills.
Highly self-motivated and directed.
Proven analytical, evaluative, and problem-solving abilities.
Ability to motivate and inspire team members
Adaptable to changing environment
Ability to effectively prioritize and execute tasks in a fast-paced environment

Desired Qualifications: (Education, Technical Skills/Knowledge)
Experience on Python, PowerShell, Javascript is a plus
Experience with business intelligence application is a plus
Azure, Scrum certifications considered as a plus
Willing to learn new technology and open mind for sharing is a plus
Bachelor in computer science, Master Degree considered as a plus

Apply now.",4.2,"Nokia
4.2",Bengaluru,"Nokia, Finland",10000+ employees,1865,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Ericsson-Worldwide, Huawei Technologies, Microsoft"
Senior Research Scientist,-1,"Company Description

FireEye is the leader in intelligence-led security-as-a-service. Working as a seamless, scalable extension of customer security operations, FireEye offers a single platform that blends innovative security technologies, nation-state grade threat intelligence, and world-renowned Mandiant® consulting. With this approach, FireEye eliminates the complexity and burden of cyber security for organizations struggling to prepare for, prevent, and respond to cyber attacks. FireEye has over 7,500 customers across 67 countries, including more than 50 percent of the Forbes Global 2000.
Job Description

FireEye’s network research team focuses on finding and preventing cyber attacks to protect our customer base. Attacks comes from various vectors such as social engineering threats and various exploits, but if a customer is breached, we are there to detect malicious C2 traffic as well as lateral movement activity in our customer environments.

We’re looking for security savvy candidates who understand the current threat landscape. As a security researcher, you’ll get the satisfaction of understanding the attacker mentality and stop intrusions. Security operations is just one aspect of the job and you’ll have the opportunity to learn new areas and develop new, innovative ways to detect threats in the cloud.

What You Will Do:
Develop network detection to block threats as they come into the network
Handle customer detection issues, provide prompt and accurate feedback to customers
Understand network-based vulnerabilities and develop new content to detect potential exploits
Identify new techiques used by attackers to traverse laterally in a customer environment
Brainstorm and develop new detection modules in the cloud to identify unknown threats
Discover, track and analyze latest malware, network and email cyber threats
Qualifications
At least 3-5 years direct or equivalent experience in areas of network (IPS) detection, vulnerability analysis and other aspects of cyber-attacks discovery.
Specialist in programming with Python
Candidate should have good communication skills to respond to the support/customer queries.
Able to work independently and occasionally available during non-business hours to handle critical customer issues/malware outbreak
Knowledge in security and malware detection technologies",3.3,"FireEye, Inc.
3.3",Bengaluru,"Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium"
Data Analyst,-1,"About Us
Established in May 2015, Indus OS is a homebred system apps company, building India’s only content and commerce platform for users to discover and consume digital content & services in the language of their choice. With a vision of digitally connecting 1 Billion Indians, Indus OS is constantly striving to adapt its existing portfolio (App Store, Minus One Screen, Keyboard, Messenger, etc) by introducing new features to enrich the user experience in their native language.
Currently, Indus OS has a user base of over 60+ Million on the back of 10+ smartphone brand partnerships with leading OEMs such as Samsung, Gionee, iTel, Micromax, Intex, Karbonn, and others. The Indus platform is available in English & 23 Indian regional languages and is intended to digitally connect the next 1 billion people in the emerging markets.

Indus App Bazaar:
India’s Largest Indigenous App Store with more than 60mn users.
Indus App Bazaar is an offering from Indus OS, a home-grown technology brand-building content and commerce platform for users to discover and consume digital content & amp; services in the language of their choice. Indus App Bazaar is an alternative Android-based app store designed with innovations in localization, simplicity, user personalization, and performance optimization. The platform provides multi-lingual support for users, in English as well as 12 Indian languages –
Hindi, Gujarati, Marathi, Tamil, Telugu, Urdu, Malayalam, Kannada, Punjabi, Odia, Assamese, and Bengali.
With AI-driven user experience, Indus App Bazaar offers targeted content to its users based on their interests, location, and language. The browse-based discovery platform is easy to use and does not require an email address for users to download apps. Indus App Bazaar offers over 400,000 apps and has over 60 million users. It also has a strategic partnership with Samsung to power its Galaxy Store, across all Samsung devices in India. It is the preferred app distribution channel for top developers like TikTok, Likee, Helo, Paytm, Phonepe, Xender, Shareit, Vmate, Amazon, Meesho.

Indus OS in news
Yourstory: https://bit.ly/34ZqWGs
FirstPost: http://bit.ly/2s1GURE
The Asian Age: http://bit.ly/2OboBSW
Indian Television: https://bit.ly/2OT01q8
Inc42: https://bit.ly/2Lulkfw
Job Description
We are looking for an analyst who can join our team & can add value to the product through his/her analytical skills.

Key Responsibilities:
Design & develop methods to analyse relevant data, share insights & provide recommendations
Develop metrics and prototypes that can be used to drive business decisions
Create necessary systems to regularly monitor the performance for stakeholders
Provide feedback to Tech/ Product for new product requests/product enhancements/ bug fixes etc.

Desired Candidate’s Profile:
Experience 2+ years
Experience in analysing data to draw business-relevant conclusions and in data visualization
Solid experience in writing SQL queries
Basic knowledge in generating process documentation
Strong written and verbal communication skills including technical writing skills
Strong background in statistical concepts and calculations with 1 -2 yrs experience
Innovative and strong analytical and algorithmic problem solvers.
Proficiency with analysis tools like Excel, SQL, Python (Knowhow of AWS infra is a plus point)
Acquaintance with concepts of BI – (MicroStrategy, QlikSense, Tableau – Plus point)
Team Handling.

Additional Requirements:
Should be a fast learner and a self-starter, open to learning new tools.
Must possess excellent communication (both verbal & written), documentation skills.
Flexible and adaptable to change and ability to multitask.
Ability to work with minimal supervision. Should be able to prioritize own workload to meet personal and team objectives.
Good interpersonal skills with a clear ability to work effectively to fully understand customer requirements.
Focused on the timely delivery of accurate results.

Our Offering:
True start-up experience – no bureaucracy and a ton of tough decisions that have a real impact on the business from day one.
The camaraderie of an amazingly talented team that is working tirelessly to build a great OS for India and surrounding markets.

Perks:
Awesome benefits, social gatherings, etc.
Work with intelligent, fun, and interesting people in a dynamic start-up environment.",4.3,"Indus OS
4.3",Mumbai,"Mumbai, India",51 to 200 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Scientist (Upto 5years),-1,"Desired Candidate Profile

Experience in relevant field such as Statistics, Computer Science or Applied Math or Operational Research.
Must have Masters in (Maths/Statistics or Applied Mathematics/Machine Learning etc.)
History of successfully performing customer implementations
Strong customer facing skills, and previous consulting experience.
Experience of handling high frequency streaming data for real time analysis and reporting.
Familiarity with - Natural Language Processing, Statistical Analysis (distribution analysis, correlation, variance
Experience with open source technologies is a must.
Energy/Hunger for Growth
Excellent communication and executive presence to connect at CXO levels
Ability to lead & build strong teams
Ability to work in an ambiguous environment.
Desired Skills and Experience

Languages/Tools:Python/R,Scala,SQL,
Experience in applying Data Science methods to Business Problems. Machine Learning,
Concepts: Strong presentation and communication skills with a knack for explaining complex analytical concepts to people from other fields.
Team leadership, Mentoring and project management skills.
Education :PG - Any Postgraduate - Any Specialization, MS/M.Sc(Science) - Any Specialization, Maths, Statistics",5.0,"XLNC Technologies
5.0",Mumbai,"Mumbai, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Scientist -1,-1,"Role and Responsibilities:
Work closely with Business teams & Product Managers to identify opportunities and serve as an ambassador for data science
Translates complex functional and technical requirements into detailed architecture, design, and high performing software and applications.
Works with peer developers to make sure that all data solutions are consistent and ensures all automated processes to preserve data by managing the alignment of data availability and integration processes
Eligibility Criteria:
2 years of experience in the field of statistics, data mining and machine learning
Qualifications:
BTech/BE Premier institute like IITs/BITS/NITs
Experience in e-commerce/Online Internet companies
Skills:
Expert-level understanding of the underlying theory of Machine Learning.
You have superior knowledge of statistical analysis methods, such as input selection, logistic and standard regression, random forests, etc.
Taking end-to-end ownership of problem domains and continuously improving upon quantitative solutions
Demonstrated ability to facilitate and work with minimal direction, with the proven ability to coordinate complex activities
Analytical thought leadership and stay current on developments in data mining and the application of data science",3.0,"Acko General Insurance Limited
3.0",Bengaluru,"Bengaluru, India",201 to 500 employees,2016,Company - Private,Insurance Operators,Insurance,Unknown / Non-Applicable,-1
Associate Data Scientist,-1,"What makes Gartner a GREAT fit for you? When you join Gartner, you’ll be part of a team with a no-limits mindset that helps the world become smarter and more connected. We’re the world’s leading research and advisory company that steers clients toward the right decisions with business and technology insights they can’t find anywhere else. Our associates enjoy a collaborative work environment with exceptional training and career development. If you like working with a curious, supportive, high-performing team, Gartner is the place for you.

Interested in learning more, view and register for any of our upcoming recruiting events here!

Associate Data Scientist

The Team and Leader Statement: Gartner’s digital client products team (Digital Products & Innovation) is a fast growing Product organization. Our mission is to create effortless, customer-centric, habit-forming digital experiences that enable clients to solve their Mission Critical Priorities, by ensuring cost-effective, scalable, and secured platform for all our products. This team is responsible for Gartner.com search & recommendation.

Job description:
Leverage data science algorithms to deliver client value and ultimately improve retention of clients
Applying Natural Language Processing and predictive modeling to understand client’s search query intent so we can offer relevant content
Using machine learning to develop self-correcting algorithms to improve recommendation in homepage feed and emails
Develop models to help predict retention outcomes and identify levers to improve outcomes
Leverage internal and external big data to understand client’s company level priorities, competitive landscape and deliver targeted support.

Essential must-have skills:
Graduation in Engineering, Math’s or Statistics from University of repute.
3 - 4 years of experience in building predictive models, recommendation systems, or NLP/text mining tools. Prior experience in NLP is highly preferable
Proficiency in Statistics and Machine learning literature: Linear algebra, Matrix factorization, linear and non-linear feature transformation, Linear/Nonlinear Modeling, Un/Semi/Supervised modeling, High dimensional methods.
Familiar with the foundational approaches to the major data science disciplines, such as data preparation, advanced statistics, machine learning, simulation, and natural language processing
Experience and proficiency with various programming languages (e.g., Python), machine learning tools (e.g., scikit-learn), statistical packages (e.g., SciPy)

Benefits: We offer a highly competitive rewards and benefits package including Company benefits like medical insurance, life insurance, and accidental insurance starting day one, best in industry pay package, flexible work environment, and lucrative paid time off policy, etc. Gartner is a high growth company which will provide the right candidate with a wealth of career development opportunities. All Gartner associates strive on being high performers, problem solvers, team players with passion, integrity and effectiveness. We strive to attract exceptional people who really enjoy what they do. Are you ready to jump on board?

Equality statement: The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, caste, creed, religion, sex, sexual orientation, gender identity or expression, marital status, citizenship status, age, national origin, ancestry, disability, or any other characteristic protected by applicable law. Gartner affirmatively seeks to advance the principles of equal employment opportunity and values diversity and inclusion.

Gartner is an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified applicant with a disability and unable to or limited in your ability to use or access the Gartner’s career webpage as a result of your disability, you may request reasonable accommodations by calling Human Resources at +1203-964-0096 or by sending an email to Applicant.Assistance@gartner.com

Job Requisition ID:46851

By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.

Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.",3.6,"Gartner
3.6",Gurgaon,"Stamford, CT",10000+ employees,1979,Company - Public,Consulting,Business Services,₹100 to ₹500 billion (INR),"Salesforce, Boston Consulting Group, ZS Associates"
"Data Scientist (Only from IIT, NIT,IIIT,IIM,VIT,BIT)",-1,"About Zycus :

Zycus is a leading global provider of A.I. powered Source-to-Pay suite for procurement, finance, and AP organizations. Our comprehensive product portfolio includes eProcurement, eInvoicing, Spend Analysis, eSourcing, Contract Management, Supplier Management, Financial Savings Management, Project Management, Request Management, Supplier Network, Insight Studio, and Merlin A.I. Suite.

The Merlin A.I. Suite is a unique platform of pre-packaged intelligent BOTs to automate run-of-the-mill procurement and A.P. tasks with intelligent and predictive suggestions. It enables teams to improve productivity through optimal efforts, enhance accuracy with minimal human intervention, and focus on strategic activities. Driven by Artificial Intelligence, Zycus’ Merlin A.I. BOTs introduce cutting edge technologies in procurement operations, making it truly autonomous and cognitive.

Our spirit of innovation and passion to help organizations create a more significant business impact is reflected among the hundreds of procurement solution deployments that we have undertaken over the years.

About Us (80 words)

Zycus is a leading global provider of A.I. powered Source-to-Pay suite for procurement, finance, and AP organizations. Our comprehensive product portfolio includes eProcurement, eInvoicing, Spend Analysis, eSourcing, Contract Management, Supplier Management, Financial Savings Management, Project Management, Request Management, Supplier Network, Insight Studio, and Merlin A.I. Suite with intelligent BOTs. Our spirit of innovation and passion to help organizations create greater business impact is reflected among the hundreds of procurement solution deployments that we have undertaken over the years.

Role : Data Scientist

Location : Bangalore

Drive Timings : 9 AM to 2.00 PM

Education : Any Engineering From IIT ,NIT , IIIT ,VIT , BITS Pilani

Venue Details :

ZYCUS INFOTECH PRIVATE LIMITED

SEZ UNIT,6TH FLOOR,GARNET Building,

Bagmane Developers Pvt Ltd SEZ II,

Bagmane World Technology Centre SEZ,

Mahadevapura,Outer ring Road,

KR Puram Hobli, Bengaluru (Bangalore) Urban,

Karnataka, 560048

Contact Person : Priyanka

Contact Number : 7899408877

Please carry your original ID proof along with Hard Copy of Resume

Requirements

We are especially looking for applicants with a strong background in Analytics and Data mining (Web, Social and Big data), Machine Learning and Pattern Recognition, Natural Language Processing and Computational Linguistics, Statistical Modelling and Inferencing, Information Retrieval, Large Scale Distributed Systems and Cloud Computing, Econometrics and Quantitative Marketing, Applied Game Theory and Mechanism Design, Operations Research and Optimization, Human Computer Interaction and Information Visualization. Applicants with a background in other quantitative areas are also encouraged to apply. If you are passionate about research and developing innovative technologies of interest to Zycus and the research community at large, the BigData Experience Lab may be the right place for you.

All successful candidates are expected to dive deep into problem areas of Zycus’s interest and invent technology solutions to not only advance the current products, but also to generate new product options that can strategically advantage Zycus

Skills
Master’s or Ph.D. in statistics, mathematics, or computer science
Only from Tier 1 Colleges
Experience using statistical computer languages such as R, Python, SQL, etc.
Experience in statistical and data mining techniques, including generalized linear model/regression, random forest, boosting, trees, text mining, social network analysis
Experience working with and creating data architectures
Knowledge of machine learning techniques such as clustering, decision tree learning, and artificial neural networks
Knowledge of advanced statistical techniques and concepts, including regression, properties of distributions, and statistical tests
1- 10 years of experience manipulating data sets and building statistical models
Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
Experience visualizing/presenting data.
Data Scientist will report in to Director Engineering - Data Scentist & the roles & responsibilities are as below:
Work as the data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with the engineering team to strategize and execute the development of data products
Execute analytical experiments methodically to help solve various problems and make a true impact across various domains and industries
Identify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variables
Devise and utilize algorithms and models to mine big data stores, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracy
Analyze data for trends and patterns, and Interpret data with a clear objective in mind
Implement analytical models into production by collaborating with software developers and machine learning engineers.
Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems
Benefits

Along with a competitive compensation structure, Zycus believes in an open culture learning environment, where everyone gets a chance to share their ideas and deliver par excellence. Here's a sneak peek to our life at Zycus.",3.3,"Zycus
3.3",Bengaluru,"Princeton, NJ",501 to 1000 employees,1998,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),"SAP Ariba, GEP, Coupa Software Inc"
Analytics Consultant,-1,"CAREERS

Analytics Consultant

Bengaluru, India
JOB DESCRIPTION

As an Analytics Consultant with Tredence you will work in a challenging environment with smart peer group. In your role, you will work hands on and provide thought leadership to real life business problems using analytical thinking and by applying complex mathematical techniques.
THE IDEAL CANDIDATE WILL

Solve business problems which involves:
Brainstorming with clients/onsite and internal teams to define a problem
Translate the business problem into an analytical problem
Identify internal and external data requirements for solving the analytical problem
Solving the analytical problem using concepts from mathematics, statistics, Artificial Intelligence and Machine learning
Translate the solution to a business solution and create artefacts that can help communicate the solution to clients like dashboards, power point slides, excel sheets etc.
Understand challenges faced by our clients in the context of their business and industry
Work hands on and provide thought leadership to real life business problem
Use analytical thinking and apply complex mathematical techniques
Work in a challenging environment with smart peer group
ELIGIBILITY CRITERIA

Bachelors in Engineering or Masters in Statistics/Economics
At least 5 years of working experience in analytics
Experience in statistical techniques such as Regression, Clustering & Time Series Forecasting, etc.
Strong analytical/logical thinking and communication skills
Proficient in:
SQL, R and/or Python
Visualization tools like Tableau or SpotFire
Send your CV to careers@tredence.com",3.5,"Tredence
3.5",Bengaluru,"San Jose, CA",501 to 1000 employees,2013,Company - Private,Consulting,Business Services,₹1 to ₹5 billion (INR),-1
Applied Scientist II,-1,"Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the worlds largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages.

In this role, you will build and develop ML models to address content intelligence problems, build advanced algorithms in detecting and generating content. These models will rely on a variety of visual and textual features requiring expertise in both domains. These models need to scale to multiple languages and countries. You will collaborate with engineers and other scientists to build, train and deploy these models. You will propose hypotheses, validate these offline and run A/B tests to validate them online. As part of these activities, you will develop production level code that enables moderation of millions of ads submitted each day.


Basic Qualifications

· Masters in Computer Science, Computer Engineering or related technical discipline
· Expertise in Computer vision and familiar with text processing
· 3+ years of relevant applied sciences experience
· A deep understanding of algorithms, ML, and some exposure to big data systems
· A track record of shipping models to production on time.
· Prior experience with agile methodologies
· Experience in software engineering an added plus.

Preferred Qualifications

· Advanced Degree (MS/ME/PhD) in Computer Vision, Natural Language Processing, Machine Learning, Statistics or equivalent.
· Significant peer reviewed scientific contributions in relevant field
· Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
· Strong fundamentals in problem solving, algorithm design and complexity analysis
· Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
· Experience with defining organizational research and development practices in an industry setting.
· Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts

Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Senior Data Scientist,-1,"Business Unit:
Cubic Corporation
Company Details:
Cubic offers an opportunity to provide innovative technology for government and commercial customers around the globe, helping to solve their future problems today. We’re the leading integrator of payment and information technology and services for intelligent travel solutions worldwide, and the leading provider of realistic combat training systems, secure communications and networking and highly specialized support services for military and security forces of the U.S. and allied nations. If you have an entrepreneurial spirit and thrive in an innovative environment, we want to talk to you about your next role at Cubic! We are seeking employees inspired by technology, and motivated by the rewards of hard work, commitment, teamwork, quality, integrity, and respect. We invite you to explore opportunities with Cubic.
Job Details:


Job Summary:

Works closely with the Corporate Analytics team and business stakeholders to build information-rich decision-making tools using innovative techniques and technologies to solve enterprise performance management related challenges and problems. Understands and leverages data mining, data visualization, artificial intelligence, machine learning, data modeling, and statistical modeling techniques. Applies strong problem solving and analytic skills to data integration projects and can isolate non-obvious relationships between disparate data sources.

Essential Job Duties and Responsibilities:
Works with the corporate analytics team and stakeholders to address business challenges by harnessing structured, semi-structured, and unstructured data in a distributed processing environment.
Designs, develops and programs methods, processes, and systems to consolidate and analyze unstructured, diverse data sources to generate actionable insights and solutions that solve business problems and provide predictive insights.
Develops data integration using Alteryx, Tableau Prep, or Python. Designs algorithms and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources.
Prepares and delivers presentations that effectively describe complex quantitative methods in clear and concise communications.
Works with the business stakeholders to gather requirements and understand business needs. Documents and maintains the requirements as well as any developed code/analytical assets.
Creates Tableau Dashboards that present actionable insights. Utilizes alerts and subscriptions for automated reporting to stakeholders.
Works extensively with enterprise applications including but not limited to SAP, Workday, Salesforce, JIRA, Service Now, Oracle P6, and Aras PLM.
Keeps up to date with technical as well as industry developments, analytics software/tools, trends, and recognized best practices.
Drives business performance and is well versed with everything from Finance, Operations, Sales, HR, and Marketing.
Contributes to projects under the direction of project owners to adhere to funding, resourcing, schedule, and other constraints.
Minimum Job Requirements:

Four-year college degree in Computer Science or Computer Engineering from a highly recognized institute; plus, six to eight years of related experience using data mining, data modeling, data integration, machine learning, statistical modeling, and other data science skills and techniques from a Fortune 500 US firm. MBA from a top institute is preferred or at least someone with a solid business KPIs understanding. Previous product company experience is preferred. Ability to think about delivering analytics as a service or product is key. Understanding with Python or comparable scripting language. Expert in Javascript frameworks (e.g. Reach, Angular JS, Vue). Good understanding of front-end architecture and data-driven development. Hands on experience with Azure ecosystem – primarily Databricks. Experience and knowledge of SQL is essential. Experience with statistical and analytic programming design and technologies such as Alteryx and other simulation / data analysis tools. Knowledge of database management systems and other software tools used to manage an organization’s business activities. Requires fundamental knowledge and experience developing algorithms and analytics applications. Must have strong analytical and problem-solving skills, attention to details, critical thinking ability, and creativity. Must be able to abstract from ambiguous and sometimes conflicting information to identify opportunities for improvement and the critical business drivers and factors that influence outcomes. Must have demonstrated ability to produce high quality analytics applications that can be deployed in a repeatable and scalable fashion. Must have expertise in data visualization tools such as Tableau, PowerBI, D3 or Plotly. Requires strong knowledge of statistics, signal processing, machine learning, predictive analytics, and other related techniques. Must have excellent written and verbal communication skills used to effectively communicate and present complex information in terms appropriate to the audience.

Incumbent will have well-developed research skills and knowledge of current data management principles, procedures, and other tools of the trade. Must be able to manage and prioritize multiple projects simultaneously while balancing according to scope, budget and schedule. Prior experience working in defense, transportation or logistics industries desired.

The description provided above is not intended to be an exhaustive list of all job duties, responsibilities and requirements. Duties, responsibilities and requirements may change over time and according to business need.

Worker Type:
Employee",3.3,"Cubic
3.3",Hyderabad,"San Diego, CA",5001 to 10000 employees,1951,Company - Public,Aerospace & Defence,Aerospace & Defence,₹100 to ₹500 billion (INR),"Accenture, Northrop Grumman, Xerox"
Data Engineer,-1,"Job Requisition ID #
19WD35705

Data Engineer
Location: Bangalore- India
Job ID: 19WD35705

Position Overview
As a Data Engineer, you will be responsible for building the data foundations that enable data driven marketing at Autodesk

Responsibilities
Build ETLs and data processing workflows for various projects
Setup reliable data ingestion pipelines for new data sources and integrate them with other data sets
Provide engineering support to investigate, identify and setup new tools and processes for data warehousing, data quality, reporting, business intelligence, data governance and data cataloging
Build data quality tracking mechanisms and address inevitable disruptions in data ingestion and processing
Assist in building a comprehensive data catalog and implement data governance strategies, as required by the business
Address questions and concerns from downstream data consumers
Continue to adapt to changes based on emergence of new technologies, new competitors, artificial intelligence and alternative sources of data
Qualifications
Bachelors or masters degree in Computer Science, Engineering, Statistics, Informatics, Information Systems or in another quantitative fields
2+ years of experience in data engineering or data warehousing
Intermediate to advanced SQL skills
Excellent programming skills in Python, Java, or Scala. (Python preferred)
Experience working with relational databases, query authoring as well as working familiarity with a variety of databases
Optional Experience building products in a cloud-based environment, especially AWS and its services like EC2, Lambda, API Gateway, S3, EMR, RDS, Cloudwatch etc
Optional Experience working on or integrating a diverse set of in-house or acquired technologies
Optional Experience working on Spark or a similar distributed processing platform
Optional Experience working on orchestration tools like Airflow
Optional Working knowledge of the Agile development process
The Ideal Candidate
Strong technical aptitude and strong interest to learn best of class technologies around data warehousing, data wrangling, data quality and data governance
Excellent problem solving and analysis skills
Excellent written and verbal communication skills, empathy, initiative and ownership
Superb analytical skills, technical aptitude, influencing skills and attention to detail
Eager to learn new things and passionate about technology
Flexible and be able to embrace change effectively
Ability to work effectively in teams
Process focused
#LI-POST

At Autodesk, we're building a diverse workplace and an inclusive culture to give more people the chance to imagine, design, and make a better world. Autodesk is proud to be an equal opportunity employer and considers all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender, gender identity, national origin, disability, veteran status or any other legally protected characteristic. We also consider for employment all qualified applicants regardless of criminal histories, consistent with applicable law.

Are you an existing contractor or consultant with Autodesk? Please search for open jobs and apply internally (not on this external site). If you have any questions or require support, contact Autodesk Careers.",4.0,"Autodesk
4.0",Bengaluru,"San Rafael, CA",5001 to 10000 employees,1982,Company - Public,Computer Hardware & Software,Information Technology,₹100 to ₹500 billion (INR),-1
Senior Data Scientist,-1,"PhonePe's mission is to make it easy and secure for our customers to use and manage their
money via a purely digital, mobile experience. The data science team at PhonePe
contributes to this mission by using the power of big data and advances in machine learning
to help various stakeholders in the business. Most important of these are our users, to whom
we seek to provide the best possible experience by showing them information and insights
that are most relevant and interesting to them. Additionally, we ensure that our own business
partners also benefit from how they can best serve customers via the PhonePe platform.
Finally, we help our own teams understand and utilize data to improve their own processes
and planning efforts. The volume of data, and the variety of problems mean that data
scientists can have a visible and a real, positive impact on millions of our users.
Responsibilities
We plan to expand our data science team, and we are looking for senior data scientists who
will work on applications related to financial services. They will work in a dynamic
environment, and with cross-functional teams to assist those teams in every possible
manner to ensure that our products help our users derive most value. They will be expected
to work with product, business, and engineering teams to
help them understand what data science can do for them and set the right
expectations,
analyze large volumes of data, and implement and deploy solutions as necessary,
be able to clearly communicate results and recommendations to various stakeholders,
evaluate the effectiveness of the solutions and improve upon them in a continuous
manner. We expect them to have a mix of a strong technical background, the ability
to understand the business implications of their work, and the ability to empathize
with our users and work towards helping PhonePe give them the best experience,
and
help and mentor junior members to become better data scientists.
Qualifications
A Bachelor's or higher degree in a quantitative discipline (computer science, statistics,
engineering, applied mathematics)
6-7 years relevant work experience with a Bachelor’s degree, or 3-4 years relevant
experience with a Master's degree
Specific technical skills include
o Expertise in Java, Python, R, shell scripting languages.
o Expertise in querying relational, non-relational, graph databases.
o Ability to clearly communicate and work with people of different backgrounds.
o Experience in big data technologies (Spark, MapReduce, Pig, Hive)
o Experience using machine learning (structured, text, video data) libraries
(preferably in Python), deep learning (Tensorflow, PyTorch)
o Experience using visualization libraries
Good to have: Hands-on experience with source control and deployment tools (Git,
Jenkins, etc.).",4.0,"PhonePe
4.0",Pune,"New Delhi, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"At Spice Money, we are about fun as much as we are about work. Being part of one of India’s biggest conglomerate, Spice Group, We have always known that only happy & motivated employees create great companies.Though great attention is focused on work, we ensure that employees enjoy their fair share of fun and frolic. Cultural events, sports and adventure activities, and a host of other initiatives are a part and parcel of life here.

We celebrate all festivals with great excitement & various onsite events /training etc. are organized from time to time. Latent talents are discovered at these meets and individuals and teams are given an equal opportunity to showcase and bring out their creative side.We have a dedicated club known as the ""Fun Committee"" that conducts various activities. The club is chaired and managed by the employees themselves & they have the power to decide what activities, event, etc. suit them best.
Data Analyst (Location: Mohali)
o
Qualification required: B.Tech / MCA
o
Experience required: 3 - 4 years
o
Create and develop reports, support in ETL process for the reports.
o
Exposure to Google BigQuery, Java, R Shiny, Tableau, Google Compute, Tableau, Python/ R, machine learning, dashboarding would be required.
o
Email us at human.resource@spicemoney.com
Growth

We are growing at a phenomenal
pace, grow with
us.

Benefits

We offer the best pay practices in the industry, great benefits and a safe working environment.

Training

Everyone is encouraged to avail the training sessions, to help enhance their personal and professional growth.

Family

We treat each other as family - we nurture, listen and help each other reach our true potential.

Committed

We are committed to the growth of
our employees, agents and
customers.",4.7,"Spice Money
4.7",SAS Nagar,"Noida, India",201 to 500 employees,-1,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1
Customer Analytics â€“ Data Scientist,-1,"Must-Have:
Overall 8-14 years of working experience with preferably 5 years in single domain at senior levels.
2.Domain Expertise: The candidate should have a good hold on one or more domains as listed: Communication & Media, Retail, CPG, BFSI, Utilities, Automobiles
Ability to perform statistical modelling (predictive, regression, hypotheses testing, multivariate analysis, Time Series, Cluster, forecasting, ARIMA) using R/ Python.
Good to Have:
Knowledge of Spark, Yarn, other big data technologies

Responsibilities:
As a Data Scientists you must be able to translate Business Problem to a Statistical Problem and Statistical solutions to a viable Business solution.
Ability to manipulate unstructured data to form insights about the business.
Minimum Qualification:
15 years of full-time education;
Minimum percentile of 50% in 10th, 12th, UG & PG (if applicable)

Register yourself @ TCS Careers: https://ibegin.tcs.com/iBegin/jobs/159069J
00-14.00 Years
Bachelor Of Technology (B.Tech/B.E)",3.8,"Spice Money
4.7",SAS Nagar,"Mumbai, India",10000+ employees,1968,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Accenture, IBM, Infosys"
Data Analyst,-1,"Requirements:
Working knowledge of HTML5, CSS, Java Script, JQuery, AJAX. Must have experience in latest UI design concepts e.g. responsive, adaptive etc. and web standards.
Writing web content for websites /portals.
Designing of the user interfaces.
Experience with UI frameworks such as Bootstrap and Foundation.
Web Designing experience in Angular 2+ will be an added advantage
Responsibilities:
Candidate must have ability to work creatively and analytically in a problem-solving related to User experience.
Regular updation/content management of the website as and when received.
Creating provisions for adding new web pages / new links for displaying the required information.
Creation and regular updation of the news items and links as and when received.
Good Communication skills, verbal and writing.
Experience with agile software development methodology.
A highly motivated self-starter",3.8,"Xcaliber Infotech
3.8",Pune,"Pune, India",51 to 200 employees,2008,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Data Scientist (1-3 yrs),-1,"Role & Expectations
Data scientists who are good with knowledge of statistics & programming in R/Python, transforming the business problem to analytics framework and weaving final results into actionable items for customers. Share your resume at [email protected]

Requirements and General Skills
Leading and managing analytics engagements
Coordinate daily interaction with the client and in-house analytics team
Propose and finalize modeling techniques relevant to a business problem
Drawing managerial insights through Statistical Techniques and Predictive Modelling
Managing client satisfaction, feedback process, managing/tracking workflow
Drawing actionable recommendations from data for senior management
Build sales and marketing collateral for prospects
Qualifications & Technical Skills
2 – 4 years of experience in Advanced Analytics within consulting environment
Hands-on with R & Python with application of varied machine learning algorithms i.e. Random Forests, Decision Trees, SVM, Neural Networks, Linear/Logistic Regression, Clustering, NLP
Demonstrated experience in translating business problems into analytics frameworks and translating analytics results back to final results for client consumption. Able to decide modeling techniques that can be applied to solve business problems effectively.
Consulting Skills: Ability to impact business decisions through analytics and research
We are an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",4.0,"Valiance Solutions
4.0",Noida,"Noida, India",1 to 50 employees,2014,Company - Private,IT Services,Information Technology,₹100 to ₹500 million (INR),-1
Senior Data Scientist,-1,"At Aera, we deliver the cognitive technology that enables the Self-Driving Enterprise™: a Cognitive Operating System™ that connects you with your business and autonomously orchestrates your operations. Aera's Cognitive OS leverages the best of artificial intelligence, machine learning, natural language processing, big data, and enterprise domain expertise to deliver Cognitive Automation at scale for some of the world's largest companies.

Aera Technology is looking for an expert Senior Data Scientist based in Pune, India. You will be working on new and challenging data science problems. This is the chance to be part of Aera's growing Data Science team, led by one of Aera's longest-tenured Engineering leaders!
Responsibilities
You will be responsible for designing, implementing, monitoring and maintaining our machine learning systems that powers the Aera platform
You will be working in a highly-collaborative environment with other experts in data science and engineering
Transform business problems into data problems
Research and build statistical/machine-learning models
Perform Exploratory Data Analysis and Statistical Analysis; clearly present the results of an analysis to customers and management
Collaborate with other team members to build data-science products and services using the Aera platform
About You
Master’s Degree in Computer Science, Mathematics, Statistics or a related quantitative field with a focus on Machine Learning or Deep Learning. Ph.D. preferred
7+ years of professional experience as a Machine Learning Engineer/Data Scientist; in a product development setting
Hands-on experience with software development, including translating ML models into scalable production services
Good intuitive understanding of machine learning algorithms and practical experience building models with incremental/iterative approach
Strong in Python
Experience in Full-Cycle Data Science projects
Experience in implementing machine learning algorithms using APIs/libraries from scikit-learn, H2O, MLlib and TensorFlow
Hands-on experience with software development, including translating ML models into scalable production services
Experience in working with large data sets and pipelines, distributed systems for machine learning using frameworks such as Apache Spark
Excellent verbal and written communication skills
You take complete ownership of your work and are self-driven
At Aera, we're on a mission to solve the biggest, most intractable challenges in the world of enterprise software. We envision the rise of the Self-Driving Enterprise: a more autonomously functioning business with a central operating system that connects and orchestrates business operations. Our Cognitive Operating System is increasingly used by the world's largest companies to fundamentally transform their organizations and how work is done.

If you share our passion for building the next generation of enterprise software, and deploying it for the most sophisticated customers in the world, you’ve met your match. Headquartered in Mountain View, California, we're growing fast, with teams in Mountain View and San Francisco (California), Bucharest and Cluj-Napoca (Romania), Paris (France), Munich (Germany), London (UK), Pune and Bangalore (India), Sydney (Australia) and Singapore. So join us, and let’s build the future of work together!",3.5,"Aera Technology
3.5",Pune,"Mountain View, CA",201 to 500 employees,2017,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Elementum, Qlik"
Surveillance Scientist,-1,"Job Title: Surveillance Scientist
Location: TRIL GTC
GCL : D1

Reports to: Group Manger or Senior Manager Patient Safety Physician or Senior Manager Patient Safety Scientist , Patient Safety, Bangalore

The statements made in this job descriptor are intended to describe the general nature and level of work being performed by those persons assigned to this job. These statements are not intended to be an exhaustive list of all responsibilities, duties and skills required of people, nor will they necessarily all apply for every individual assigned to this job.

Description

Associate Patient Safety Scientist should be able to support the Global Safety Physician (GSP) and (Senior/Principal) PV Scientist with the review of safety data and related documents to identify and escalate potential safety issues. He/she has the ability to provide the first draft of safety documents and regulatory reports, and will participate in meetings, as necessary.

Accountabilities/Responsibilities
Perform all Surveillance activities including monthly signal-detection activities and SIRC activities for established products with supervision.
Able to draft the periodic regulatory documents (PBRERs, PSURs, DSURs) according to the agreed process and timelines for established products with supervision.
Support or draft production of high-quality and timely responses to safety queries with supervision.
Identifies and uses appropriate sources of information and database searches to retrieve relevant data for evaluation of signals in partnership with the GSP, for all products in area of responsibility.
Support a performance-driven culture
Raises appropriate concerns/issues to senior staff in a timely manner.
Ensure compliance with global and local procedural documents and local implementation of Patient Safety objectives, policies, processes and procedures
Compliance with relevant procedural documents
Ensure good communication and guidance to AZ products
Liaise effectively and maintain excellent relationship with external contacts
Support a performance-driven culture
Minimum Requirements Education and Experience
Qualified to degree level in biosciences or an equivalent healthcare or pharmaceutical industry background, with proven competency in patient safety/clinical development
Comprehensive understanding of applicable Patient Safety regulatory obligations
Awareness of Patient Safety policies, processes and procedures
Awareness of medico-legal aspects of patient safety
Up to 2 to 4 years Patient Safety experience (with clear evidence of delivery
Total of 6 to 8 years of experience
Skills and Capabilities

The role holder will have:
Ability to work effectively as a member of a cross-functional or global team
Ability to acquire and assimilate knowledge in different disciplines, disease and therapeutic areas
Good communication skills with ability to work across cultures
High ethical standards, including a commitment to AstraZeneca values and behaviors
Ability to appreciate diversity and work as equals with global and cross-functional teams
Good attention to detail
Good time management
Delivery focused
Customer-focused
Fluent in English
Computer literate

Internal and External Contacts/Customers
Patient Safety personnel at all levels
Regulatory Affairs and other AstraZeneca personnel
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",4.0,"AstraZeneca
4.0",Karnataka,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
Data Engineer,-1,"Noon is making education fun by social learning and collecting a lot of data points, which help to make product and customer experience better. Data comes from a variety of sources, internal and external, and in different formats. The data that we collect in a heterogeneous and distributed storage (data lake).

For our users (employee, customer) to be productive, data needs to be accessible uniformly. While understanding the nature of the data they deal with, our users should not be held responsible for its quality. The collected data might end up containing duplicates, being outdated, and generally being corrupted in several ways; one of the jobs of a data engineer is to prevent these issues and to minimize their occurrence.

We massage data, put its pieces together to provide a different perspective, elaborate it, store it, manipulate it, and optimize its access. We are also in the process of building pipelines to make the data flow from one sector of our architecture to another. We write efficient software, maintain our clusters, optimize and advise on queries, and continuously re-evaluate our process to make it faster and more accurate. To do this, we keep the discussion open, share our findings, and hold each other accountable.

We are in the middle of a substantial transformative process. We are piecing together a data science architecture that needs to sustain tons of gigabytes of data in a dependable and distributed way so that the data is at the fingertips of its users. If you haven’t scared yet? Then maybe you might consider joining forces with us.

Requirements

Excellent knowledge of SQL and Python
Experience with cloud platforms, in particular, Amazon Web Services
Preferred knowledge of Java / Scala
Good understanding of SQL and NoSQL databases, Star schema (data modeling, data warehousing)
Excellent Experience of Python, Java or Scala
Experience with big data: Hadoop, Spark, Kafka, Flink (HDFS, HBase, Hive)
Knowledge of algorithms and data structures
Deep understanding of the distributed systems
Experience with data visualization tools like Tableau or ElasticSearch will be a big plus

What can you expect

Work with a team who believes in STUDENT FIRST, you will have an opportunity to build the first (BE ORIGINAL) Open Social Learning Platform that can impact millions of students across the globe
A working environment where you can look at things differently and challenge and offer solutions; which also offers you a freedom to commit ‘n’ number of first time mistakes - NEVER DEPRIVE A LEARNER
Complete ownership and responsibility for the success of your autonomous team across all scope of works - OWN IT and BE BOLD
An opportunity to lead bunch of Young, Smart, Driven and Dynamic engineers who are committed to go BEYOND SELF to solve business challenges
Work closely with the leadership team who live by the value of BE BETTER EVERYDAY to help growing an amazing organisation",4.1,"Noon Academy
4.1",Bengaluru,"Riyadh, Saudi Arabia",51 to 200 employees,2014,Company - Private,Primary & Secondary Education,Education,Unknown / Non-Applicable,-1
Analyst Data Scientist,-1,"Build an in-depth understanding of the problem domain and available data assets
Research, design, implement, and evaluate machine learning approaches and models
Perform ad-hoc exploratory statistics /data mining tasks on diverse datasets - small scale to big data
Participate in data architecture and engineering decision-making to support analytics
Take initiative in evaluating and adapting new approaches from data science research
Investigate data visualization and summarization techniques for conveying key findings
Communicate findings and obstacles to stakeholders to help drive the delivery to market
Code your solutions (this is a hands-on position requiring strong programming skills)

Key Requirements:
Professional experience as a data scientist or a related software engineering role
Graduate degree (MS) in mathematics, computer science or other quantitative discipline
Thorough understanding of probability and statistics, Bayesian methods, time series analysis
Strong programming skills (in any language)
Great communication skills, team player, self-starter, demonstrated strong work ethic
Desire to use modern technologies as a disruptive influence within the Finance domain

Preferred:
Expertise in Statistics, Empirical Data Analysis, Machine Learning or Natural Language Processing
Experience and in-depth knowledge of Python and other modern programming languages
Experience in a specialized statistical computing environment, preferably R
Experience in practical data processing, data mining, text mining and information retrieval tasks
Experience in scalable data management tools - Relational and NoSQL databases
Knowledge of Big Data architectures a strong plus
Knowledge of Pythons data analysis and machine learning libraries a strong plus
Exp: 3 to 8 yrs

Location: Bangalore/Mumbai/Hyderabad/Chennai/Pune/NCR",4.1,"Camsdata
4.1",Mumbai,"Bengaluru, India",51 to 200 employees,2017,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),eTeam
Data Analyst Intern,-1,"Exceptional verbal and written skills. Ability to work effectively both independently and as part of a team. Experience using computers for a variety of tasks. Competency in Microsoft applications including Word, Excel, and Outlook. Knowledge file management, transcription, and other administrative procedures. Ability to work on no target.Salary- 15k/Negotiable

Job Types: Full-time, Part-time, Fresher, Walk-In

Salary: ₹9,000.00 per month

Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Location:
Cuttack, Orissa (Preferred)",-1,DATTATREYA PROJECTS PRIVATE LIMITED,Cuttack,-1,-1,-1,-1,-1,-1,-1,-1
Data Analyst 2,-1,"Scope of responsibility:
Proficiency to complete assignment with multiple steps, guided by defined processes and project requirements.
Focuses primarily on completing short-term goals of a project efficiently and effectively
Functional Skills
Solid technical / data mining skills and ability to work with large volumes of data; extract and manipulate large datasets using tools such as SQL, SAS, Hadoop or other programming/scripting languages (Perl, R, Java/C/C++, etc.) to translate data into business decisions/results
Intermediate statistical skills, proficiency in experimental design, and ability to forecast real-world performance based on samples, simulations and user behavior analytics
Solid knowledge in rule writing systems, development and implementation of complex decision frameworks by coding action rules and decision tables using BAL (Business Action Language), variables creation, RADD files design, regular expression proficiency (see examples in the last tab)
Intermediate capability to create/revamp innovative and technical solutions that require the processing of large datasets across different platforms. Collaborate with other analysts to achieve the optimal level of system automation decisions and minimize human intervention
Intermediate capability to create and own ""Standard Operation Procedures"" and clearly articulate methods and principles of account review and user facing interaction
Strong analytical skills -- ability to build quick estimates using back-of-the-envelope analysis, structure (and, if needed, execute) more complex analyses, pull together business cases and forecasts to navigate through multi-dimensional sets of tradeoffs.
Enthusiasm for data-driven problem solving within a fast-paced environment is a must. In addition, experience with Microsoft Excel or statistical software, working knowledge of SQL or other relational database languages, and hands-on experience in data analysis involving large data sets are strongly desired but not absolutely required.
communication skills risk analysts need to collaborate cross-functionally with product managers, data scientists, business owners, and customers to learn from subject-matter experts, present findings in a clear and concise manner, and reach alignment on how to execute risk strategies.
Can-do attitude, team player, energetic personality, ability to work well under pressure in a fast-paced and constantly changing environment to meet deadlines. The successful risk analyst is a self-starter who has the resilience to learn from their mistakes and reach their true potential.
An innate intellectual curiosity, and a willingness to build awareness of current payments industry and risk management best practices. PayPal is constantly innovating by introducing new products and entering new markets, so successful risk analysts on this team must quickly get up speed on new content areas.
BS/BA degree with 2+ years of experience, MS degree with 1+ year of experience",3.7,"PayPal
3.7",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Data Engineer,-1,"Position: Data Engineer
Description of Duties
The Automotive Supply Chain and Technology team at IHS Markit isin search of a Data Engineer to support its global team's ongoing research and analysis efforts. The research team produces granular forecast dataset and written analyses on the supply chain of parts supplied to automakers with technology, supplier and logistic information. The team generate forecasts on technology trends through multiple research channels and by using many connected and disconnected data sources to drive the forecast.
The position covers an array of critical data-centric activities aimed at enhancing the efficiency of our 70+ strong research team, sustaining the increasing data complexity and most importantly supporting new product development at one of IHS Markit's fastest growing product lines. The position is based in Gurgaon or Bangalore, India and reports to our U.K.-based Data and Platform operations lead.
Responsibilities and duties
Understanding business requirements to create maintainable workflows e.g. inbound/input data from analysts and external sources to feed a set of interconnected data sets and calculations
ETL process design, implementation, maintenance and documentation for large inter-connected data sets
Data cleaning and manipulation of raw data to provide to Data Science team
Creation of logical and physical data models
Utilise existing database infrastructures as well as building new DB infrastructures as required
Data acquisition exploration
Create and maintain detailed documentation of workflows
Qualifications and skills
3+ years experience as a data engineer with data science touchpoints
At minimum, a degree in computer science, computer engineering or a related quantitative field with proven work experience in the data engineering/scientist field
Proven experience with SQL and NoSQL databases like Oracle DB, SQL Server, Cassandra, MongoDB, MySQL, Hadoop, Spark, AWS (EC2 and S3)
Proven experience with one or more programming/scripting languages (e.g. Python, R) is highly desirable
Knowledge of OLAP and ETL processes
Familiarity with data science platforms such as KNIME is a bonus
Knowledge of API creation and maintenance
Familiar with techniques to manage large databases, including partitioning, compression and indexes as well as data mining
Ability to build models (e.g. Linear regression, logistic, Markov models) a plus
Established MS Office skills, O365 desirable
Good communication skills, collaborative team spirit, curiosity to constantly keep thinking of unique approaches and solutions.
Ability to work independently.
Experience committing to deadlines whilst multi-tasking

-----------------------------------------------
IHS Markit is committed to providing equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by the laws and regulations in any of our locations.

We are proud to provide reasonable accommodations to applicants with disabilities. If you are interested in applying for employment with IHS Markit and need special assistance or an accommodation to use our website or to apply for a position, please contact or call +1 212 849 0399. Determination on requests for reasonable accommodation are considered on a case-by-case basis. This contact information (email and phone) is intended for application assistance and accommodation requests only. We are unable to accept resumes or provide information about application status through the phone number or email address above. Resumes are only accepted through the online application process, and only qualified candidates will receive consideration and follow-up.

IHS Markit maintains a substance-free workplace; employees may be asked to submit to a drug test (where permitted by law). In addition, as a federal contractor in the United States, the company participates in the E-Verify Program to confirm eligibility to work.

For information please click on the following links:

IHS Markit Business Code of Conduct
Right to Work
EEO is the Law
EEO is the Law Supplement
Pay Transparency Statement

-----------------------------------------------

Current Colleagues

If you are currently employed by IHS Markit, please apply internally via the Workday internal careers site.",3.6,"IHS Markit
3.6",Noida,"London, United Kingdom",10000+ employees,2016,Company - Public,Consulting,Business Services,₹100 to ₹500 billion (INR),"Thomson Reuters, International Data Group"
Machine Learning Engineer,-1,"About DMI


DMI (Digital Management, LLC.), the world’s first end-to-end mobility company, combines all the skills and services necessary to deliver mobile enterprise solutions. Built to reinvent business through mobility, DMI has expertise in mobile strategy, UX, web, and app development, omni-channel commerce, brand and marketing, IoT and big data analytics, and secure device and app management. The company’s unique, integrated approach to mobility has resulted in dramatic growth as well as an expanding client base, which includes hundreds of Fortune 1000 commercial clients and all fifteen U.S. Federal Departments. DMI is headquartered in Bethesda, MD, with satellite offices around the world. The company was named one of the 2018 Top Workplaces in the Washington, DC area by The Washington Post and received Inc. Magazine’s Hire Power Award as one of the top 100 Private Job Creators in the US. Additional information is available at www.dminc.com and on LinkedIn, Twitter, Facebook, and Instagram.

About the Opportunity


We are looking for a passionate Machine Learning Engineer to work closely with our Data Scientists and Data Engineers to integrate and deploy models into our application’s production environment.

If you have a sense of adventure, take pride in solving complex data problems, and strive to build the best products on the planet, we want you on our Big Data Engineering team.

This role would be responsible for:
Providing solutions for the deployment, execution, validation, monitoring, and improvement of data science solutions.
Creating high performance and scalable Machine Learning systems
Building reusable production data pipelines for machine learning models
Collaborating with Data Engineers and Data Scientist to build data and model pipelines and help in running machine learning tests and experiments
Helping to manage the infrastructure and data pipelines needed to bring an ML solution to production
Troubleshoots production machine learning model issues, including recommendations for retrain, revalidate, and improvements
We are seeking people who are passionate about:
Working with data in all forms (structured, unstructured, video, audio, etc) and using it creatively to help solve problems
Collaborating with data scientists and data engineers to make a big impact
Staying in-tune with the big data community and encouraging the organization to utilize cutting edge technologies to innovate and invent solutions.
Qualifications


Technologies in our environment:

Skills - Experience and Requirements


You would be considered a great fit for this role if you have the following:
Bachelor’s degree in Computer Science Engineering, Data Science, or a related technical degree.
Experience in developing and deploying machine learning systems into production
Proven ability to learn things quickly and stay up to date on breakthroughs in Machine Learning techniques
Ability to quickly prototype new approaches and productionize solutions at scale for millions of active users
Ability to work in a Linux environment
Strong experience with Python, Scala, Golang, or Java
Experience with big data tools and processing technologies such as Apache Spark, Apache Flink, and cloud platforms like GCP or AWS
Experience in building containerized solutions using Kubernetes
You have worked with automated build systems such as Jenkins. A desire to write tools and applications to automate work
Experience implementing Continuous Integration or Continuous Delivery processes in engineering teams
These qualifications would make you stand out among other applicants:
Great communication skills - someone who is passionate about evangelizing the value of advanced data science capabilities.
Experience deploying and maintaining model Microservices
Experience building maintainable data pipelines for deep learning models
Familiarity with data-oriented workflow orchestration frameworks such as Kubeflow, Airflow",3.4,"DMI
3.4",Bengaluru,"Bethesda, MD",1001 to 5000 employees,2002,Company - Private,Consulting,Business Services,₹10 to ₹50 billion (INR),"Deloitte, IBM, Accenture"
Data Engineer,-1,"We are building a world-class language-related product that has the potential to positively transform lives worldwide. We have a passionate team of data scientists, coders, and linguists who have been working on it.

We are looking for a Data Engineer who will identify and implement the best data-driven methodologies considering the product requirements.

Work location: Goregaon (West), Mumbai

Key responsibilities:

Create, build and design data management systems across an entire organization
Work with very large data sets (both structured and unstructured).
Help data scientist to easily retrieve the needed data for their evaluations and experiments.
Design, develop and implement R&D and pre-product prototype solutions
Must have strong engineering skills that will help engineering team to productivize NLP/ML algorithms
Implement scalable, maintainable, well documented and high-quality solutions.
Stay abreast of the new developments in Artificial Intelligence (AI)/Machine Learning (ML). Contribute to the research strategy and technical culture of the team


Skills Required:

BTech/MTech/ME/MCA from reputed Engineering college.
0-2 years of industry experience
Extremely curious and relentless at figuring out solutions to problems
Knowledge of Big Data platforms like Hadoop and its eco-system
Proficiency in programming languages like Java/C/C++/Python
Experience with cloud services
Exposure to NLP and its related services.
Experience with one or more visualization tools like Tableau, etc.
Experience with Docker, Kubernetes, Kafka, Elasticsearch, Lucene
Experience with relational or NoSQL databases such as MySQL, MongoDB, Redis, Neo4j.
Experience of handling various data types and structures: structured and unstructured data, validating and cleaning data, and measuring evaluation
Excellent understanding of machine learning techniques.",2.9,"Crimson Interactive
2.9",Mumbai,"Mumbai, India",201 to 500 employees,2005,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Lead Data Scientist,-1,"Brillio is forging ahead aggressively amidst the current COVID-19 situation and continues to hire for various roles globally - with all interviewing and on-boarding done virtually. Brillio has invested in the right capabilities to adapt to the new normal and empower its employees to operate seamlessly. All the new joiners, along with the Brillio family, will temporarily work remotely until it is safe to return to our offices. Read Brillio’s Chief Operating and Delivery Officer, Aftab Ullah’s statement about Brillio's hiring plans in the leading publications - The Times of India and The Week’s latest stories about the positive hiring sentiments of tech firms.



As a Brillian what your day would look like:

o Take ownership of large-scale data science engagements and drive end-to-end solutions that have efficient and productionable algorithms, and communicate relevant insights to stakeholders through storyboards/presentations

o Engage and mentor those around you in advanced statistical analysis concepts and foster data driven thinking

o Stay abreast with current technical and industry development and constantly strive to devise innovative statistical models for data analysis

o Communicate with multi-disciplinary teams, internal and external stakeholders define problems, uncover insights hidden in large data sets that drive impactful business decisions

o Actively participate in external forums and industry conclaves



To succeed, you’d have technical experience and expertise in –

A. For you to be successful, you must:

o Build partnerships within and outside the team regardless of formal authority

o Create value by anticipating and meeting needs of customers and delivering high-quality results and be accountable for outcomes

o Disseminate personal knowledge, share own experiential learning with others and empower others by mentoring those around you

o Be open and flexible to accommodate and implement new ideas, understand business complexities, nurture innovation and challenge the status quo persistently

o Be subject matter expert in chosen area of specialty through continuous learning

o Have an eye for detail to ensure accurate conclusions in data analysis and presentations

B. For you to be successful, you must: -

o Critical Thinking in order to drive end-to-end solutions to ambiguous problem; with excellent sense of risk and resource management

o Strong analytical skills with the ability to collect, organize, review significant amounts of information

o Strong problem-solving skills with an emphasis on product development

o Experience using statistical computer languages (R, Python, SAS) to manipulate data and draw insights from large data sets

o Expertise in basic statistical concepts such as properties of distributions, statistical tests and their proper usage

o Expertise in advanced machine learning techniques such as Clustering, Regression/Classification, Time Series Analysis, Network Analysis, Popular Deep Learning architectures and theory, simulation, scenario analysis

o Experience with some optimization techniques (Linear Programming, Genetic Algorithm, Sim. Annealing, MC Simulation)

o Clear, professional written and verbal communication skills, ability to easily communicate complex ideas

o Experience with any distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, etc. or AWS/Azure

o Experience with machine learning on big data

C. It would be exceptional, if you also have this:

o Expertise in Image, Video, Speech, Sound, Text domain

o Working knowledge of concepts and application of Design of Experiments

o Depth across areas within the domain or industry",3.0,"Brillio
3.0",Bengaluru,"Santa Clara, CA",1001 to 5000 employees,2014,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),-1
Consultant – Data Analyst with Python,-1,"Consultant – Data Analyst with Python
Function: Operations

Noida, India

With
a startup spirit and 90,000 curious and courageous minds, we have the
expertise to go deep with the world’s biggest brands—and we have fun doing it.
Now, we’re calling all you rule-breakers and risk-takers who see the world
differently, and are bold enough to reinvent it. Come, transform with us.

Are
you the one whom we are seeking ?

Inviting
applications for the role of Consultant – Data Analyst with Python

In
this role, the focus is to ensure smooth delivery, client engagement and
spearhead business growth of a large account in U.S. It is imperative for this
hire to have deep Banking & Capital Markets experience, in-depth
understanding of technology and domain skills in Auto Finance, Equipment
Finance and Lending.

Responsibilities
Assisting users with Python setup and
configuration, getting access to data sources within the organization, and
responding to their questions
Performing analysis projects on behalf
of the users
Understand data requirements of the
requestor
Interact with the requestor to handle
any changes and updates to the request.
Do required analysis of the data set
as required.
Work with the team on data projects to
provide timely solutions.
Create and Visualize reports/analysis
and share it with the stakeholders.
Qualifications


Minimum
qualifications we seek in you!
BE/B.Tech/equivalent
Preferred
qualifications
Good Python development skill is a
must.
Working knowledge of R is an added
advantage.
Working knowledge of Tableau &
Spotfire is an added advantage.
Good communication skills & highly
proactive in approach.
Ability to manage & prioritize
deliverables.
Ability to be learn and apply new
processes and tools
Process orientated awareness of Lean
Six Sigma.
Genpact
is an Equal Opportunity Employer and considers applicants for all positions
without regard to race, color, religion or belief, sex, age, national origin,
citizenship status, marital status, military/veteran status, genetic
information, sexual orientation, gender identity, physical or mental disability
or any other characteristic protected by applicable laws. Genpact is committed to
creating a dynamic work environment that values diversity and inclusion,
respect and integrity, customer focus, and innovation. For more information,
visit www.genpact.com. Follow us on Twitter, Facebook, LinkedIn, and YouTube.",3.6,"Genpact
3.6",Noida,"New York, NY",10000+ employees,1997,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"Accenture, IBM, Capgemini"
Data Analyst,-1,"About DMI


DMI (Digital Management, LLC.), the world’s first end-to-end mobility company, combines all the skills and services necessary to deliver mobile enterprise solutions. Built to reinvent business through mobility, DMI has expertise in mobile strategy, UX, web, and app development, omni-channel commerce, brand and marketing, IoT and big data analytics, and secure device and app management. The company’s unique, integrated approach to mobility has resulted in dramatic growth as well as an expanding client base, which includes hundreds of Fortune 1000 commercial clients and all fifteen U.S. Federal Departments. DMI is headquartered in Bethesda, MD, with satellite offices around the world. The company was named one of the 2018 Top Workplaces in the Washington, DC area by The Washington Post and received Inc. Magazine’s Hire Power Award as one of the top 100 Private Job Creators in the US. Additional information is available at www.dminc.com and on LinkedIn, Twitter, Facebook, and Instagram.

About the Opportunity


Our environment is…

Complex

Highly elastic

Based on some of the latest and greatest cloud native technologies

Very fast paced

Your team will be…

Enabling a proper enterprise Data Lake in AWS

Engaging regularly with stakeholders to understand and implement business logic

Building models and tools to get value out of the mass amounts of data we have in our environment

Enabling the best, most personalized and resilient customer experience possible

In order to be successful in this role, you will need to be…

Highly motivated, driven & hard working

Not afraid to fail and comfortable working independently and with a team

Comfortable working with massive datasets in real time and batch processing with superior analytics skills

Comfortable talking to and working with Senior Executives

Apply data mining techniques, do statistical analysis, and build high quality prediction systems integrated with our product. Doing ad-hoc analysis and presenting results in a clear manner.

Processing, cleansing, and verifying the integrity of data used for analysis

Enhancing data collection procedures to include information that is relevant for building analytic systems

Data mining using state-of-the-art methods. Create automated anomaly detection systems and constant tracking of its performance.

A team player. We have a great group of diverse folks working together in harmony. Big egos and “super heroes” need not apply.

Qualifications


Technologies in our environment:

Here are some of the key technologies that make up our environment. While we do not expect you to have a detailed understanding of each, the more of these you are familiar with the better.

MUST HAVE Tableau or other visualization tool experience

Strong SQL experience

ELK Stack / HDFS / Hadoop / Hive

Linux

AWS Big Data Tools: S3, Kinesis, Red Shift, Athena

Java, Python, R, SQL

Predictive Analytics

Kafka / Confluent

CI / CD and Cloud Native Computing (Docker, Kubernetes, Consul, Vault)

there it is",3.4,"DMI
3.4",Bengaluru,"Bethesda, MD",1001 to 5000 employees,2002,Company - Private,Consulting,Business Services,₹10 to ₹50 billion (INR),"Deloitte, IBM, Accenture"
Machine Learning Engineer,-1,"We are looking for a Machine Learning (ML) Engineer to help us improve the current products. Your ultimate goal will be to shape and build efficient self-learning applications.

Key Responsibilities:
Identify key variables, parameters and elements defining a problem or its solution.
Research and develop innovative, scalable and dynamic solutions to hard problems
Select appropriate data sets and data representation models
Run machine learning tests and experiments
Perform statistical analysis and fine tuning using test results
Scale the machine learning infrastructure for speed and performance
Keep abreast of developments in the field

Knowledge, Skills & Experience:
4+ years of Experience with Machine Learning or similar role
Ability to come up with the best model that would solve the problem at hand and develop and tune that model
Can apply probability models and machine learning approaches to solving complex problems
Strong coding skills with ability to write high performance code in Java/Python/R
Have experience using machine learning libraries or platforms
Strong understanding of data structures, data modelling and software architecture
Experience building scalable, sound architectures and reliable, high performance back-end services that work amazingly well in the complex real world as well as stand the test of time.
Deep knowledge on mathematics, statistics and data analysis Outstanding analytical and problem solving skills",4.7,"Grid Logic Software Private Limited
4.7",Hyderabad,"Gurgaon, India",501 to 1000 employees,2010,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Sr.Data Scientist,-1,"Experience

You have a strong primary expertise as data scientist, with the ability to stretch beyond one’s core field of expertise

You have a strong research background in machine learning, deep learning, reinforcement learning

You have PhD or M Tech at least 2+ years of *relevant experience* as a strong contributor on a data science team

You have a relevant degree in Statistics, Math/Applied Math, Operations Research, Computer Science, Economics or Quantitative Finance

You have expertise in at least one analytics function: attribution, segmentation, response modelling, churn, propensity, customer LTV, supply chain / logistics, geospatial inference, recommend-er systems, causal inference, forecasting, pricing, NLP or image/speech processing.

You are proficient in R/Python, particularly to prototype mathematical models

You know SQL and are familiar working with at least one of the tools - Tableau, R-Shiny/or other data visualisation tools

You are able to scope and define data sets needed for specific use cases and identifying data gaps

You are able to translate scientific insights into product decisions and work streams

You have good communication skills

You can manage customers – ability to lead and persuade, positive energy, relentless focus on business impact

Must Have Skills

Python

Sklearn / Scikit

NLP

Jupyter

Pandas

Numpy

Matplotlib

Good to have Skills

R Language

Tensorflow / Keras

Caffe

Pytorch

OpenCV

Tableau

Location: Noida",5.0,"Lumiq
5.0",India,"Turin, Italy",51 to 200 employees,-1,Company - Private,Film Production & Distribution,Media,Unknown / Non-Applicable,-1
Data Analyst,-1,"At Rockstar Games, we create the games we would want to play ourselves.

A career at Rockstar is about being part of a team working on some of the most creatively rewarding, large-scale projects to be found in any entertainment medium. You would be welcomed to a friendly, inclusive environment where you can learn, and collaborate with some of the most talented people in the industry.

Rockstar India is on the lookout for talented Data Analyst who possess a passion for Game Analytics. This is a full-time permanent position based out of Rockstar's unique game development studio in Bangalore.

WHAT WE DO
The Rockstar Player Insights & Analytics team provides insights and actionable results to a wide variety of stakeholders across the organization in support of their decision making.
We work together with a number of departments to design and implement data and pipelines.
We collaborate as a global team to develop cutting-edge data pipelines, data products, data models, reports, analyses and machine learning applications.
RESPONSIBILITIES
Analyze, synthesize, and interpret product and player data to determine observations and trends.
Monitor and maintain the health of our dashboards, data sources, and data collection systems.
Collaborate with game and development teams to ensure that the implementation of metrics corresponds to the observed values.
Contribute to the development and enhancement of the data collection systems.
Drive requirements for data collection and for data modeling with data engineers.
Document new and modified data sources, tables, fields, reports, and dashboards.
QUALIFICATIONS
Minimum 4+ years in a similar position or a position requiring data preparation, data validation, and report building and monitoring.
Bachelor's degree in Computer Science, Engineering, Statistics, or related field.
SQL knowledge and hands-on experience is a must.
Demonstrated analytical ability, problem-solving skills, and entrepreneurial spirit in a results-oriented environment.
Expertise, aptitude, or prior background understanding complex and large data sets.
History of seeking and acting on opportunities to improve data documentation, upgrade processes and reports, or increase data quality.
Excellent written and verbal communication skills with the ability to express thoughts logically and succinctly.
Strong team spirit and dynamic team player.
PLUSES


Please note these are desired skills and not required to apply for the position.
Experience with Hadoop and/or Impala.
Advanced SQL skills, programming experience, fluency in R and/or Python.
Experience with statistical techniques and big data.
Basic understanding of data warehousing, data modeling concepts, and database documentation.
Game industry experience and passion for Rockstar Games strongly preferred.
HOW TO APPLY


Please apply with a CV and cover-letter demonstrating how you meet the skills above. If we would like to move forward with your application, a Rockstar recruiter will reach out to you to explain next steps and guide you through the process.

Rockstar is proud to be an equal opportunity employer, and we are committed to hiring, promoting, and compensating employees based on their qualifications and demonstrated ability to perform job responsibilities.

If you've got the right skills for the job, we want to hear from you. We encourage applications from all suitable candidates regardless of age, disability, gender identity, sexual orientation, religion, belief, or race.",4.0,"Rockstar Games
4.0",Bengaluru,"New York, NY",1001 to 5000 employees,1998,Subsidiary or Business Segment,Video Games,Media,₹1 to ₹5 billion (INR),-1
Data Analyst-GlobalSellingIN,-1,"Amazon is looking for a talented, driven Data Analyst It is a pivotal role that will contribute to the evolution and success of one of the fastest growing businesses in the company.

Amazon Global Trade is an important initiative to grow the Amazon Marketplace Seller Business around the world, with the India team focused on cross-border selling from sellers in India catering to customers abroad and sellers across the globe catering to customers in India. The Global Trade team is looking for a professional who relishes diving deep into data. You will have the exciting opportunity to deliver on a strategy to enable broad use of Amazon Seller Services by small/medium sellers and large enterprises in India.
Working in a dynamic environment, you will be responsible for monitoring key success metrics for sellers, identifying problem areas and business challenges and collaboratively shaping solutions with category and business teams to help sellers grow and optimize on the Amazon platform. The successful candidate has a passion for extracting actionable insights from data. He/she rolls up his/her sleeves, innovates, and quickly becomes a subject matter expert to assess business performance across sellers and market segments. He/she has significant experience working with customers, analyzing data, identifying trends, extracting conclusions, and presenting findings in a simple and clear manner. He/she enjoys problem solving and is proficient using Excel and other tools to analyze large data sets.


Key Responsibilities:
· Understand Amazon seller Services products and services and track/report business performance and problem areas using appropriate metrics.
· Work cross functionally with the account management team to fix problems with sellers
· Use Amazons tools to problem solve and validate solutions
· Partner to define goals around key operational metrics
· Recommend business actions based on analytical findings. Includes defining new metrics, techniques, and strategies to improve seller performance



Basic Qualifications

· 1+ years of experience as an analyst or engineer in the data/BI space
· Experience with data visualization using Tableau, Quicksight, or similar tools
· Demonstrated experience with SQL and working on large datasets
· Bachelors degree in a quantitative field such as Mathematics, Statistics, Engineering, Computer Science, Economics, Finance, or related field
· Excellent written and oral communication and presentation skills and the ability to express thoughts logically and succinctly.



Preferred Qualifications

· Experience in using R/Python to handle large data sets
· Knowledge of statistical modelling and ML techniques",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Scientist / Analyst,-1,"If you are someone who always argues that data tells you everything and can speak numbers in your sleep, then you are it.

Requirements
Bachelor of Engineering in Computer Science, Math, Physics, Engineering, Statistics from Tier-1 college.
Development experience in SQL and any scripting language (Shell, Python, etc.)
Basic understanding of statistic and Experience manipulating large data sets through statistical software(ex R, Matlab etc).",4.0,"Adoro
4.0",Mumbai,"Munich, Germany",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
"Associate Analytics consultant, Analytics consultant, Senior Analytics consultant (BI)",-1,"If you are interested, please email your resume to us at recruitment@quantzig.com
Job Location: Bangalore

Experience: 1+ years

Key Skills: Tableau, PowerBi, SQL, SAS, Spotfire R / Python, Master-level skills in SQL and query languages Excellent written and verbal communication skills

Roles & Responsibilities:
If you are creative, understand design ideas, are detail oriented and know to make amazing visuals, you are the person we are looking for
You should be passionate to make an impact with high degree of work ownership and are self-driven.
You should be creative and passionately curious about exploring data to deliver impactful business insights
Experience in delivery and client facing roles from major analytics service providers in the industry are preferred
You should possess customer-centric thought process and is able to understand client’s business processes with ease, identify problems with precision and develop customized, accurate analytical solutions
Understand efficient coding standards and has a knack to plan for QC checks
Added advantage if you understand Cloud hosting, customizing visualization tools using DAX, data integration with analytical data-streams

Desired Profile:
Be a consultant to our clients. Think out-of-the-box and develop visualization solutions which help clients in solving their business problems
Tremendous passion towards learning is a must. You must be able to merge the art of consulting and the science of Design in visualization
Drive and energy to work hard and achieve success in an entrepreneurial environment
Should have hands-on experience in delivering projects across multiple industries and analytics areas (e.g. Supply chain analytics, Marketing Analytics, Customer Analytics, Digital Analytics, Pricing Analytics etc.)
Deep understanding of at least one tool
Strong communication, storyboarding and presentation skills",3.3,"Quantzig
3.3",Bengaluru,"London, United Kingdom",Unknown,-1,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Data engineer,-1,"People come to work at Parallel Wireless because we are building the future of telecom. They stay, because they are challenged and driven by an incredible product and team. We take pride in our commitment to employee development, and our culture fosters an atmosphere of empowerment, trust, respect, and communication. Learn more about our mission, vision and values.

We are looking for Data Engineer with goood hands on Data engineering and Advanced Analytics experience
What you will do :
As a Data Engineer you will a part of the Data Engineering and Advanced Analytics team; building fast and reliable data pipelines to collect data from thousands of remote wireless devices in distributed cloud
Develop code in Python, Golang and Scala to perform stream analytics, log analytics, monitoring and store data in NoSQL databases for analytics model development
Deploy containers in Kubernetes clusters to collect and analyze data
Follow software engineering best practices by estimating, documenting, and developing work products
Work in a fast-paced development environment applying advanced tools and technologies solving hard data engineering problems
What you will have:
Experienced in developing distributed data processing pipelines in Pandas, Kafka, for 2-3 years
Strong skills in writing code using Golang, Python, C/C++ or Java or Scala with unit tests
Proficiency in time-series databases and/or big-data data management: Prometheus, Influxdb, TSDB, Hadoop, Cassandra, Hbase, Hive
Familiarity with DevOps environment using tools, Jira, Git, Jenkins and CICD
Knowledge of packaging code as Micro-services and containers in Docker, Kubernetes
Additional skills:
Experienced working in teams responsible for monitoring solutions using time-series analysis
Experience in developing UI with charts and graphs
Familiarity with other pieces of our technical stack (Prometheus, Grafana, HAProxy, Elasticsearch, Airflow)
Understanding of Linux and distributed computing
machine learning (AI) will be advantage
Publications or any classifcations
Education:
Bachelor or Master degree in CS or Math or Engg
Job Location India

Parallel Wireless is the leading U.S.-based company challenging the world’s legacy vendors with the industry’s only unified ALL G (5G/4G/3G/2G) software-enabled OpenRAN solutions. Its cloud-native OpenRAN and network architectures redefine network economics for global mobile operators in both coverage and capacity deployments, while also paving the way to 5G. Through open collaboration with the OpenRAN ecosystem partners, Parallel Wireless has created the world’s first and largest fully-compliant OpenRAN ecosystem that is capable of delivering next generation wireless infrastructure at a dramatically lower cost, ensuring more equal access to 5G across the globe. The company’s OpenRAN portfolio is designed to help customers modernize their networks, reduce deployment costs and complexity, increase operational efficiency, enable interoperability, find new revenue streams, and start deploying multi-vendor 5G networks today. The company’s customers include over 60 global mobile operators, as well as private and public industries and governments that use their software-defined network portfolio to reimagine their networks. Parallel Wireless's innovation and excellence in multi-technology, open virtualized RAN solutions have been recognized with 65+ industry awards. Please visit www.parallelwireless.com for more information.",3.3,"Parallel Wireless
3.3",Bengaluru,"Nashua, NH",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Science Intern,-1,"Codemonk is a young and energetic startup that empowers other startups and enterprises by building simple and elegant software solutions. Through our expertise in the domains of AI, Blockchain, IoT and enterprise applications we have helped brands such as Unilever, IndiaMART, greytHR, Fyle, Skylark Drones, etc. to craft world-class products and improve their business. We are churning out amazing software for our clients located across the globe from our headquarters at Bengaluru.

To meet our expanding business needs, we are looking out for young individuals who can join our team.

About the Internship

Selected interns day-to-day responsibilities include:
1. Mine data using modern tools and programming languages

2. Define and implement models to uncover patterns and predictions creating business value and innovation

3. Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value

4. Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems

5. Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring).

Requirements
Who can apply

Only those candidates can apply who:
1. Are available for full-time internship

2. Can start the internship immediately

3. Are available for duration of 6 months

4. Have relevant skills and interests.

Skill(s) required: Python and knowledge of any Machine Learning Library such as Tensorflow, Keras or Pytorch.

Benefits
Certificate, Letter of recommendation, Flexible work hours.",-1,Codemonk,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Science Lead,-1,"Bachelors / Masters
Experience

5-10 years

Required Skills
5-10 years of professional experience is required
Degree in applied math, statistics, machine learning or computer science. PhD/ MS is preferred
Deep understanding of statistics and experience with machine learning algorithms/techniques
Proven programming skillsin particular C++ and Python, strong experience with DL frameworks such as TensorFlow, Theano and others
Scientific expertise and real-world experience in deep learning (convolutional neural networks, restricted Boltzmann machines, and deep neural networks)
Passion for solving challenging analytical problems
Ability to quickly, qualitatively and quantitatively assess a problem
Ability to work productively with team members, identify and resolve tough issues in a collaborative manner.
Experience in applying machine learning techniques to real-world problems in a production environment
Roles & Responsibilities
Design, develop and deliver AI/machine learning enabled solutions for our industry specific data analytics platform
Build scalable, availableand supportable processes to collect, manipulate, present, and analyze large datasets in a production environment
Articulate problem definition and work on all aspects of data including acquisition, exploration/visualization, feature engineering, experimentation with machine learning algorithms and deploying models
Develop working prototypes of algorithms, evaluate and compare metrics based on the real-world data sets
Provide design input specifications, requirements and guidance to software engineers for algorithm implementation for solution/product development",4.5,"D Cube Analytics
4.5",Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Scientist - Natural Language Processing (NLP),-1,"Lynk aims to revolutionize how people and companies access knowledge. Our advanced expert knowledge platform is used by global top tier asset management firms, investment banks, hedge funds, private equity firms, management consulting firms and multinational corporates. With Lynk, our enterprise clients can access the world's greatest minds for quick conversations or projects, who help advise on strategy, due diligence, and critical business decisions.

Join us, and tackle some of the most challenging problems in natural language processing and large scale applied machine learning. You will build cutting edge natural language understanding technologies and deploy them on a global scale.

What You’ll Do
Deliver data-driven products, insights and inferences employing methodologies in the Data Science and primarily Machine Learning domains
Maintain knowledge of and concurrency with cutting-edge but commercially-viable (resilient and scalable) methodologies in the Data Science and primarily Machine Learning domains
Translate complex and embryonic ideas into tangible data-driven deliverables; iterate; test; and sensibly promote or demise solutions to our customers
Design and implement Semantic-enabled systems, enterprise data lakes and semantic search applications in the intersection of Semantic web and ontology, knowledge graph and domain model, NoSQL and graph database, NLP, Solr/Lucene, text mining and machine learning
Lead and develop ontological knowledge graphs to capture knowledge in domain models and metadata
Build semantic master/ systems to automate data analytics and services using AWS EC2, S3 (distributed data lake), Elastic Map Reduce (computation cluster), Data Pipeline (job management in Spark (Scala) on Hadoop, using Avro and Parquet) and Redshift (columnar data warehouse), and Google Big Query and CloudStorage.
Design domain-driven event models and event sourcing paradigm for a real-time Web-scale ""event"" processing platforms
What Expertise You’ll Add To The Team
Top-notch expertise in Knowledge Representation and Discovery, Semantic Web, Ontology and Knowledge Graph, NLP and text mining
Ideally PhD in a STEM subject directly leveraging the application of Machine Learning to a level where critique of algorithms’ operations/principles comes naturally to you. Extensive experience in lieu of a PhD may be considered
Advanced expertise in at least:
Python,
R,
ML tooling from Cloud providers (ideally AWS)
The ability to train elementary machine learning models such as logistic regression and random forests, to select the right tool or the right task and to judge when a model is good enough for a particular purpose
Experience with a core ML domain sub-speciality such as:
(Deep) Neural Networks,
Natural Language Processing (NLP),
Conditional Random Fields,
Mechanism Design,
Latent Dirichlet Allocation.
Proven track record of implementing a real-world Recommender or Ranking system
Strong experience with Agile delivery methods
Experience in API creation is a strong plus
Solid experience in implementing multi-core/distributed software
Experienced in solving real problems using machine learning techniques and with statistical rigor
Excellent communication skills; the ability to convey complex analysis results clearly and with conviction to all stakeholder levels
What We Commit To You
Competitive remuneration package in a rapidly-expanding growth stage global company
Comprehensive medical insurance coverage
Generous leave policy, including a ‘work remote policy’
The opportunity to travel and work around the globe with our international clients and growing number of offices (Hong Kong, Shanghai, Singapore, Mumbai, Hyderabad, Manila, Ho Chi Minh, New York City, Toronto)
Notes:

- LYNK employees are prohibited from trading Restricted Securities (defined as any security whose performance is linked to a single company) on any Personal Trading Account.

- All future new joiners are required to undergo a background check.",2.4,"The Straits Network
2.4",Hyderabad,"Hong Kong, Hong Kong",51 to 200 employees,2015,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,-1
Data Analyst,-1,"By ruby7adminOn 22 Mar, 2020 0 Comments

Data Analyst


Social and mobile gaming studio Ruby Seven Studios is looking fora talented Data Analyst to work for our office situated in Kochi, India. This is your chance to get involved with a creative gaming studio, and to add to our ever-growing roster of games across Facebook, iOS, and Android.

You will be handling these responsibilities:
Consulting with internal customers (e.g., Marketing team, Game Producers) to develop analysis and frame actionable insights that helps the management in decision making
Wrangling data from multiple sources (including but not limited to): sales, product, player events, and customer/player databases, to create integrated views that can be used to drive decision making
Working with several large and complex SQL databases
Designing and building reports and analytical dashboards
Perform statistical analysis and A/B tests in events of new feature or content releases
Routinely keep an eye on anomalies in the game data and provide reasoning for the same
Qualifications:
Educational qualification – Degree (Bachelors/ Masters) in Computer Science/ IT; Engineering; Information Systems; Math’s/Statistics
Highly analytical data junkie who enjoys business analysis by using data interpretation skills
Positive, people-oriented, and energetic attitude
Self-starter and curious person who sees information as a tool to find answers to business questions
Analytical, creative, and innovative approach to solving problems
Strong written and verbal communication

Tech Skills:
Highly proficient in SQL with ability to write efficient queries and taking data from multiple data-sets as and when required
Should have a strong working knowledge in Excel and proficiency in either R or Python for automation purposes
Exposure to any visualization tool/ library (Tableau, ggplot, matplotlib, etc)
Machine learning algorithms – Individual who has exposure to ML modelling techniques will be an added advantage
Tools -Any Big data knowledge (e.g. Hadoop, Spark) will be an added advantage
How to apply:
Send the CV to careersindia@rubyseven.com",3.8,"Ruby Seven Studios
3.8",Kochi,"Reno, NV",51 to 200 employees,2012,Company - Private,Video Games,Media,Unknown / Non-Applicable,"WMS Gaming, IGT, Caesars Entertainment"
Associate-Data Engineer(Punjabi),-1,"Why we exist:
The Indian internet has exploded. Over half a billion Indians will be online before the end of this year. Most of these Indians will prefer using their own language online. And next to nobody is building solutions for them. They are prevented from using the internet to its fullest potential because English forms a language barrier.

Whenever they visit a site or app, they are met with a wall of text in a language that they do not understand.

We at Reverie believe in language equality on the internet. It’s what drives us and gives what we do meaning. Language equality basically means that every Indian should enjoy the same range of options and experiences online in their own language that an English speaker does online.

What we do:
We take immense pride in the fact that we tackle some of the most complex and impactful problems Indian language users currently face today.

We’re working towards our mission of language equality by building a full-stack of language technologies and solutions, spanning fonts, font rendering, transliteration, translation, app & website localisation in real-time, Indian language input (check out our Swalekh keypad on the App Store), Indian language voice assistants, and Indic search, to empower the Indian language user and let them tap into the possibilities the internet offers them.

What we DON’T care about:
Your age, gender, where you went to college, or your academic scores.

What we DO care about:
Our mission resonates with you
You have an insatiable curiosity, which means you’ll figure a way out even in an unfamiliar environment.
And finally your integrity and work ethic

Experience - 0 to 3 Years (Freshers also can apply)

Location - Bangalore (Preferred location)

Type of Role - Permanent / Contractual

As a Data Engineer:
Your responsibility would be Audio Editing (Noise removal, audio splitting, Aligning transcripts with respective audio etc.)

Must have skills:
Should be familiar with audacity or wave pad audio editing tool.
(Note: If you are not familiar with these tools please check the links for audacity, wavepad, and find some tutorials on YouTube)
Basic computer knowledge.
Should be proficient with at least 1 Indian language. (Reading & Written)
Should have a good aptitude",4.3,"Reverie Language Technologies
4.3",Bengaluru,"BENGALURU, India",51 to 200 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Ai Scientist,-1,"Location: Mumbai, India
About Us
Most of the world’s digital information was created in the last few years with the vast majority of that information being unstructured in the form of text, tweets, videos, images, blogs, etc. The rate of growth of digital information vastly exceeds our biological processing abilities. The consequence for investors is that it’s becoming harder to make sense of the factors that drive financial markets. Acting upon partial understanding of vast quantities of information (i.e., heuristics) infuses investment decisions with cognitive biases. In order to beat markets and make money, humans need to augment their reasoning capacity, consider the relevance of more information, and make bias-free decisions.
At Accrete.AI, our vision is to help investors generate alpha, or excess returns, by training machines to think in the language of the markets. We leverage deep learning and Machine Augmented Collective Intelligence (MACI) to train machines to reason and learn so they can help human investors make better investment decisions.

About You:
Two to three years of experience with Artificial Intelligence, Quantitative and Qualitative Analytics, Deep Learning, Machine Learning, Natural Language processing and Unstructured data analytics
Good knowledge of machine learning techniques, feed-forward, recurrent and convolutional neural networks, entropy models, supervised and unsupervised learning
Experience with one of the following: Theano, Tensorflow, Caffe, or any other deep learning/machine learning framework
Strong willingness and aptitude for learning new concepts and analytical approaches
Ability to formulate hypotheses, draw conclusions and deliver results
Experience working with datasets, and strong interest in deep data analysis – you need to be a detective at heart.
Effective interpersonal communication skills
Must have at least a Master’s degree or PhD, preferably in Applied Mathematics, Computer Science, Statistics or Economics
Responsibilities
Work with deep learning models optimize/customize/refine them
Define and design corpus structures, ANNs, and required activation functions
Document use cases and develop component and Interaction (sequence) diagrams
Design, development and delivery of tested code in an innovative, and, evolutionary environment.
Work effectively in teams, managing and leading teams
Provide effective, constructive feedback to the delivery leader
Manage client expectations and work with an agile mindset with machine learning and AI technology",5.0,"Accrete.AI
5.0",Mumbai,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Decision Scientist,-1,"Who we are


Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 305 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom, enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.

When applying for a job you are required to create an account, if you have already created account - click Sign In.

Creating an account will allow you to follow the progress of your applications.

Note:

Provide full legal first Name/Family Name
DO: Capitalize first letter of First and Last Name. Example: John Smith
DON'T: Capitalize entire First and/or Last Name. Example: JOHN SMITH
NOTE: Use correct grammar for Names with multiple cases. Example: McDonald or O'Connell
Provide full address details

Resume is required

Multiple attachments can be uploaded including Resume and Cover Letter for each application

Job Description Summary:

We are looking for a Senior Decision Scientist to develop PayPal’s Risk strategy within the Next-Generation Platforms & Strategic Partners portfolio. This portfolio is comprised of PayPal’s newest leading-edge payments solutions, as well as customized experiences developed for the company’s highest-priority strategic partnerships.
Each Decision Scientist on this team has full ownership of a portfolio of merchants and is responsible for end-to-end management of loss and decline rates. Day-to-day duties include data analysis, monitoring and forecasting, creating the logic for and implementing risk rules and strategies, providing requirements to data scientists and technology teams on attribute, model and platform requirements, and communicating with global stakeholders to ensure we deliver the best possible customer experience while meeting loss rate targets.
If you’re interested in working with PayPal’s most interesting payments experiences, then this is the right team for to join!

Job Description:

PayPal’s Next-Generation Platforms Consumer Risk team is responsible for assessing and managing buyer-side financial risk exposures for this $8 billion portfolio (including identity theft, stolen financials, account takeover, and credit risk), as well as developing and implementing the policies, treatments, and experiences related to the management of these exposures. The team is also responsible for partnering with the corresponding Business Units to align with and influence their strategic priorities, educate business partners about Risk management principles, and collaboratively optimize the Risk treatments and experiences for these unique products and partners.

Each Decision Scientist on this team has full ownership of a portfolio of merchants and is responsible for end-to-end management of loss and decline rates. Day-to-day duties include data analysis, monitoring and forecasting, creating the logic for and implementing risk rules and strategies, providing requirements to data scientists and technology teams on attribute, model and platform requirements, and communicating with global stakeholders to ensure we deliver the best possible customer experience while meeting loss rate targets.

Scope of responsibility:
Work is generally self-directed with minimum supervision. Review is normally after the fact and may be developmental in nature.
Works on assignments that are of intermediate complexity with multiple steps in execution, and guided by generally defined processes and project requirements
Focuses primarily on completing short-term goals of a project efficiently and effectively
Job Requirements:
Strong analytical skills -- ability to build quick estimates using back-of-the-envelope analysis, structure (and, if needed, execute) more complex analyses, pull together business cases and forecasts to navigate through multi-dimensional sets of tradeoffs.
Enthusiasm for data-driven problem solving within a fast-paced environment is a must. In addition, experience with Microsoft Excel or statistical software, working knowledge of SQL or other relational database languages, and hands-on experience in data analysis involving large data sets are strongly desired.
Polished communication and influence skills – risk decision scientists need to collaborate cross-functionally with product managers, data scientists, business owners, and customers to learn from subject-matter experts, present findings in a clear and concise manner, and reach alignment on how to execute risk strategies. Demonstrated ability to influence groups and effectively resolve conflicts is required.
An innate intellectual curiosity, and a willingness to build awareness of current payments industry and risk management best practices. PayPal is constantly innovating by introducing new products and entering new markets, so successful risk analysts on this team must quickly get up speed on new content areas. You will be expected to become an expert in your specific domain
“Can-do” attitude, team player, energetic personality, ability to work well under pressure in a fast-paced and constantly changing environment to meet deadlines. The successful risk analyst is a self-starter who has the resilience to learn from their mistakes and reach their true potential.
Identify glitches in processes and tools and develop and execute solutions to overcome general issues and obstacles with little supervision.
Learning in-depth analysis of alternatives and applying specialized knowledge
Impact of decision has moderate reach
Seeks improvement within defined tasks. Understands, evaluates, and executes improvement ideas from supervisors
BS/BA degree with 5+ years of experience or master’s degree with 3+ years of experience.

Subsidiary:

PayPal

Travel Percent:

0

Primary Location:

Bangalore, Karnataka, India

Additional Locations:

We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.",3.7,"PayPal
3.7",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Data Architect,-1,"Atlassian is continuing to hire with all interviewing and on-boarding done virtually due to COVID-19. Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices.

Job Description
Atlassian is looking for a Senior Data Architect to join our GTM - Data Engineering team and build world-class data solutions and applications that powers crucial business decisions throughout the organisation. We are looking for an open minded, structured thinker who is passionate about building systems at scale. You will enable a world-class engineering practice, drive the approach with which we use data, develop backend systems and data models to serve the needs of insights, and play an active role in making Atlassian data driven. You love thinking about the ways the business can consume this data and then figuring out how to build it.

More about you
As a data architect, you will have the opportunity to apply your strong technical experience on building analytics data models, that supports a broad range of analytical requirements across the company. You will work with other teams to continually evolve solutions as business processes and the requirements change. You enjoy working in a fast paced environment and you are able to take vague requirements and transform them into solid solutions. You are motivated by solving challenging problems, where creativity is as crucial as your ability to write code.
On a typical day, you may be consulted on the
Information architecture of our data lake.
Understand the existing analytical data models, reuse and make necessary revisions as required.
Understand Integration Design patterns & anti-patterns and create designs accordingly
Understand & Design Dimensional Data Models.
Understand & Design Tables leveraging different Hadoop File Formats
Working with different stakeholders to understand the business reporting needs and architect/build the data models, ETL processes and data applications that can help answer those needs.
Experience working with large datasets and are interested in reporting platforms and data visualisation using Tableau.
Optimise the data pipelines/infrastructure with the goal of providing data with quality and trust. As the data domain expert, you will be partnering with our technology teams, analytical teams, and data scientists across various initiatives
Understand the different source systems and their data attribution to identify the source of truths for bringing the trust in data while reporting
Experience in implementing Master Data Management (MDM) solutions.
You'll own a large program end-to-end, so those skills will come in handy not just to collect, extract, and clean the data, but also to understand the systems that generated it, and automate your analyses and reporting. On an on-going basis, you'll be responsible for improving the data by adding new sources, business rules, and producing new metrics that support the business. Requirements will be vague. Iterations will be rapid. You will need to be nimble and take smart risks.
On your first day, we'll expect you to have:
At least 12-15 years professional experience with at least 5 years as a data architect or in a similar role
Strong programming skills ( Python & Java(good to have) )
Experience in requirements collection, analysis, data profiling for BI systems.
Experience in working with project managers in drafting project plans and effort estimations
Experience in data warehouse modelling, master data management solutions.
Experience building data pipelines using Spark and/or Hive
Experience working in a technical environment with the following technologies: AWS data services (Redshift, Athena, EMR) or similar, Apache projects (Spark, Flink, Hive, Kafka)
You’re well versed in modern software development practices (Agile, TDD, CICD) and how they can apply to data engineering
Experience in building frameworks to aid in quality data pipelines.
Experience on Observability
Experience writing and tuning SQL
A willingness to accept failure, learn and try again
An open mind to try solutions that may seem crazy at first
A BE in Computer Science or equivalent experience
Mentoring junior team members through review processes.
We’d be super excited if you have:
Experience working on Apache Airflow (or similar tools) for orchestrating data pipelines
Experience building MDMs and other enterprise data integration solutions
Deployed ML models and know when best to use them
Followed a Kappa architecture with any of your previous deployments
Implemented solutions on top of Kafka
Good experience on building data solutions for Subscription businesses.
Above all else, as a data Architect you will be leading the development process, driving architectural decisions, and incorporating business and technology strategy. You will be earning the trust of other developers in the team and then coaching and influencing them into the right behaviour to build the ultimate analytical data model and pipelines.
You’ll be joining a team that is crazy smart and very direct. We ask hard questions and challenge each other to constantly improve our work. We are self-driven but team oriented. We're all about enabling growth by delivering the right data and insights in the right way to partners across the company.

More about our benefits

Whether you work in an office or a distributed team, Atlassian is highly collaborative and yes, fun! To support you at work (and play) we offer some fantastic perks: ample time off to relax and recharge, flexible working options, five paid volunteer days a year for your favourite cause, an annual allowance to support your learning & growth, unique ShipIt days, a company paid trip after five years and lots more.

More about Atlassian

Creating software that empowers everyone from small startups to the who’s who of tech is why we’re here. We build tools like Jira, Confluence, Bitbucket, and Trello to help teams across the world become more nimble, creative, and aligned—collaboration is the heart of every product we dream of at Atlassian. From Amsterdam and Austin, to Sydney and San Francisco, we’re looking for people who want to write the future and who believe that we can accomplish so much more together than apart. At Atlassian, we’re committed to an environment where everyone has the autonomy and freedom to thrive, as well as the support of like-minded colleagues who are motivated by a common goal to: Unleash the potential of every team.

Additional Information

We believe that the unique contributions of all Atlassians is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.

All your information will be kept confidential according to EEO guidelines.",4.4,"Atlassian
4.4",Bengaluru,"Sydney, Australia",1001 to 5000 employees,2002,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,GitHub
Information Scientist,-1,"ThinkAnalytics is the leading provider and most widely deployed real-time personalized content recommendations engine in the market today, bringing together intelligent search with comprehensive media content recommendations.
Our Recommendations Engine broadens customers’ tastes with a unique personalized experience for live linear TV, VOD and over-the-top, delivered through multiple platforms including the set-top box, Web, IPTV, tablet, mobile, and more.
Our head office is in Glasgow-UK; other offices are in London-UK, Los Angeles-USA, Singapore and Pune, India.

Job Overview:
The ThinkAnalytics Content Recommendations Engine (CRE) analyses data from multiple content sources to provide recommendations for movies and television programmes.
To provide personalized recommendations, the CRE uses natural language processing to automatically extract features. However, this process is dependent on good quality synopses, which in some cases is not available.
When this happens, the Information Science Team carries out extensive research and categorizes any titles that are affected because of poor quality synopses.
We are currently hiring Information Scientists in the team who will work on the above stated improvements.

An Information Scientist’s responsibilities include:
• Analyzing the genre and feature information in catalogues (that include film and television content) from various countries and establish the right strategy to deliver the best recommendations
• Analyzing the customer’s metadata to identify any issues that may impact the quality of the recommendations
• Ensuring that the customer genres have maximum advantage of the ThinkAnalytics thesauri (in-house vocabulary)
• Liaise with the Project Managers, engineers and Leads to understand the work that needs to be carried out, be able to report any issues, and/or support them in any needed way
• Creating new and improving existing ThinkAnalytics thesauri
• Conducting general maintenance and documentation of any issues found in the ThinkAnalytics thesauri
• Helping with improvements in the different ThinkAnalytics products when needed

Educational Qualification:
A degree in Information Science/ Information Management/ Library and Information Science
Since this is an Associate level position, we are open to candidates from other backgrounds, but it is essential that they have prior experience in metadata curation/metadata tagging/development of taxonomies or thesauri/classification systems

Must Haves:
Must be a self-driven, fast learner and logical thinker who:
• Has an affinity for and in-depth knowledge about film and television content – both regional and international (international being key)
• Has excellent data research and analysis skills
• Has an eye for details/is detail-oriented
• Has excellent communication skills – both verbal and written English
• Is proficient in the use of MS Office (especially MS Excel) and general computer skills
• Has excellent problem-solving skills and the ability to use different tools and technologies creatively and effectively
• Shows interest in using technology to solve business problems and the willingness and ability to learn about new technology and contribute in discussions and generation of new ideas
• Is committed to delivering high quality results
• Follows in-house processes methodically
• Has the ability to work independently and/or as part of a team
• Possesses good organizational and time management skills

Added advantage:
• A background in linguistics/media studies/film studies
• Knowledge of additional regional or foreign languages (read-write-understand)
• Knowledge or experience with indexing (e.g., for books or movies)
• Experience in using relational databases and SQL
• Experience using GIT and/or other version control systems
• Knowledge/experience of any mark-up language (XML) or programming language
• Knowledge/experience with Atlassian tools (Jira, Bitbucket, Confluence, etc.)
• Knowledge of Unix/DOS",3.8,"ThinkAnalytics
3.8",Pune,"Glasgow, United Kingdom",51 to 200 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"Site Name: India - Karnataka - Bangalore
Posted Date: Jul 23 2020

GSK is one of the worlds foremost pharmaceutical and healthcare companies and we are proud to be leading a healthcare revolution.

GSK Consumer Healthcare is seeking to make a Step Change in Digital, Data & Analytics and is establishing a new-from-the-ground-up Analytics Platform and Products purpose built to help execute on that vision. As a result, we are looking for a Data Analyst to join our Data & Analytics team.

By disrupting our approaches to R&D and commercial business processes, D&A is allowing us to integrate, simplify and unlock all our data to drive innovation, decision making and enable our transformation in servicing our patients, healthcare professionals and consumers.

The ideal candidate would be highly experienced in conducting data analysis on multiple projects simultaneously in a distributed global matrix environment. The Data Analyst will join a strong technical team in a technically demanding area of Tech and so the ideal candidate should possess a strong background in technology and be familiar with Agile and DevOps processes.

This role will provide YOU the opportunity to lead key activities to progress YOUR career. These responsibilities include some of the following.
Develop high-level requirements / use cases for projects to support business justification
Be face of Product Owner and translate the requirements in form of data mapping, logical data model for engineering team
Work closely with the Data Architect to turn conceptual data models into logical and physical models using best practices to ensure high data quality and reduced redundancy
Implement and document data architectures and data models consistent with business and technical requirements
Optimize and update logical and physical data models to support new and existing projects
Develop test scenarios and test cases in collaboration with data test engineer along with acceptance criteria
Identify and drive opportunities to reuse data models in new environments
Effectively communicates with both technical and non-technical staff, stakeholders, end-users, and vendors
Understand the needs and challenges of the commercial business environment.
Manages communications with engineering team members, internal and external partners, stakeholders, program staff and users
Provide leadership & best practice guidance for requirements analysis and prioritization.
Elicit business requirements from key stakeholders by using interviews, document analysis, requirements workshops, competitive product analysis, task and workflow analysis
Monitor and document post-implementation problems and revision requests to ensure it meets end user needs
Understand when to highlight risks or issues and ability to clearly communicate them to management teams and stakeholders.
In this role you will interface significantly with senior colleagues across the company in the Commercial Business & in the digital business including product development and new product introduction. This is an excellent time to be joining a highly successful market leader in the healthcare industry and drive significant technology change across the organization.
We are looking for professionals with these skills to achieve our goals. If you have them, we would like to speak to you.
Bachelors degree; MBA or relevant technical degree preferred. Ideal candidate would have built an impressive hands-on career to date in an advanced, recognized and innovative environment.
Extensive experience as a Business And/or Data Analyst in Data focused products and proven history working on and delivering complex projects in an Analytics environment space.
Deep expertise in producing conceptual, logical and physical data models, and using industry standards artefacts (e.g. ER diagrams) to visualize data models
An understanding of relational databases, including their structure and design
Advanced knowledge of database languages (SQL and variants) including pivoting data, hierarchical queries and query optimization/performance tuning
Experience of tools like JIRA, Azure DevOps and experience working in agile environment
Prior experience with working with Commercial and/or Supply chain data is a must.
Knowledge of Analytics & self-service BI approaches and predictive analytics solutions is a strong advantage.
Excellent oral and written communication skills with ability to align stakeholders from business and IT with competing priorities
A strong background in technology, analysis and critical evaluation of information gathered from multiple sources
Experience writing epics, features, stories including creating workflow/process flow diagrams
Very high level of interpersonal skills to work effectively with others, motivate team members, and elicit work output in a team environment
Proven experience in successfully working in a team setting and ability to reconcile conflicts
Strong problem-solving skills and willingness to roll up ones sleeves to get the job done
Have a highly innovative mind-set and experience with analytics in a healthcare or CPG company is a plus.
Why GSK?


Our values and expectations are at the heart of everything we do and form an important part of our culture. These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance and trust, the successful candidate will demonstrate the following capabilities.

GSKIndia_DA

*LI-GSK

Our goal is to be one of the worlds most innovative, best performing and trusted healthcare companies. We believe that we all bring something unique to GSK and when we combine our knowledge, experiences and styles together, the impact is incredible. Come join our adventure at GSK where you will be inspired to do your best work for our patients and consumers. A place where you can be you, feel good and keep growing.

Important notice to Employment businesses/ Agencies

GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.

It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.

GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKilne (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.

If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in gsk.com, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine.",3.9,"GSK
3.9",Bengaluru,"Brentford, United Kingdom",10000+ employees,1830,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Pfizer, AstraZeneca, Merck"
Senior Data Scientist,-1,"Salary
DOE
Number of positions
1
Description
A senior data scientist will assist customers by being able to deliver a ML / DL project from beginning to end, including understanding the business need. And, use Deep Learning frameworks like MXNet, Caffe 2, Tensorflow, Theano, CNTK, and Keras to help customers build DL models.
Minimum Qualification
A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
7+ years of industry experience in predictive modelling, data science and analysis.
Technical Skills
Experience using Python and/or R and SparkML.
Experience using ML libraries, such as scikit-learn, caret, mlr, mllib
Experience working with GPUs to develop models.
SQL
Responsibilities
Experience giving data presentations.",5.0,"TCPWave
5.0",Hyderabad,"Princeton, NJ",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,₹50 to ₹100 million (INR),-1
Senior Data Analyst,-1,"We are seeking a full-time Senior Data Analyst with 5 years or more experience of doing various marketing campaigns using SAS model, strong analytical skills and keen attention to detail to develop and deliver marketing programs for retail, finance, insurance and other businesses.

Must have grounding in traditional data mining/database marketing and experience in the evolving digital data marketing landscape. Bridgetree is a virtual company and the position will require to work from Kolkata/Bangalore-India office. Must be a legal Indian resident.

Requirements:
Creates Marketing campaigns e.g. Mailing, e-mailing, Call lists etc.
Analyzes Data and builds various reports efficiently using different business intelligence and reporting tools
Responds to various data requests like building waterfall and customer profile reports, Mail/Email Campaign Response Analysis
Performs additional checks and implement diagnostic reporting to ensure that the final production is 100% accurate and quality assured
Recommends and implements better ways to make the process lean and efficient – set up and maintain automated data processes
Qualifications:
5+ years of working experience in a Statistical Analyst role using SAS, SQL. Knowledge of SSIS, R or Python will be added advantage.
Must have a master’s degree in Mathematics, Statistics or Economics with good educational background.
Personally, strives to ensure data quality, consistency, and accuracy in all work.
Desires to participate in a learning environment where sharing and collaboration with others is the culture.
Must have great communication and problem-solving skills
To apply: Please email your resume to jobs@bridgetree.com",4.0,"Bridgetree
4.0",Bengaluru,"Mooresville, NC",51 to 200 employees,1995,Company - Private,Advertising & Marketing,Business Services,₹1 to ₹5 billion (INR),-1
Principal - Software Engineering - Data Scientist,-1,"Job Description:


Job TitlePrincipal Software Engineering - Data Science (Data Scientist)

The Purpose of This Role

The Artificial Intelligence Chapter delivers both internal use cases, digital tools and customer facing applications by leveraging a diverse set of data sources. We employ a full spectrum of data science techniques - statistical models, predictive models from machine learning, and topic modeling from natural language processing are all part of the mix. You will work on data science projects at the intersection of machine learning and financial services, with data engineers, software developers, and other data scientists. You will work on all phases of projects, from initial design to the final coding updates to put into production.

The Value You Deliver
Leading & building data science applications from inception to installation for various FMR business units
Supporting existing Analytics, Research & Data interdisciplinary teams, whose members will be data scientists, software developers, and data engineers
Designing and build machine learning models in latest frameworks and algorithms
Communicating project updates & value created through work to both technical and business stakeholders
The Skills that are Key to this role

Technical / Behavioral
You are knowledgeable about machine learning and statistics
Expert in handling various data types and structures: structured, unstructured, voice, static versus streaming data. Extensive prior experience in integrating data
Possess extensive knowledge of and experience in applying data mining and machine learning, deep learning and Reinforcement learning techniques
Expertise in Natural Language Processing (NLP) and Natural Language Understanding (NLU) techniques
You are fluent in Python and SQL with an ability to design, train, and code up machine learning and statistical models (experience with big data platforms such as Snowflake, Spark, and Hive is a big plus)
You know how to work well in a team to deliver on both business and technical requirements
The Skills that are Good to Have for this role
Experience in working with any AI/NLP for building chatbots with any one of the technologies (JavaScript, Node.js or Python).
You have excellent technical communication skills, with an ability to give compelling presentations
How Your Work Impacts the Organization

Analytics, Research & Data delivers business analytics, financial research & data capabilities to various business units with Fidelity. We use data and analytics to personalize incredible customer experiences and develop solutions that help our customers live the lives they want. As part of our digital transformation, we have significant investments to create innovative big data capabilities and platforms. One of them is to build various enterprise data lakes by gathering data across Business Units.

The Expertise Were Looking For
10+ years of hands-on experience in Data Science, Machine Learning/AI use cases
Graduate / Post Graduate degree with focus on Mathematics, Statistics & Programming
5+ years of hands-on Python, SQL programming experience
Location : Bangalore - Manyata/EGL

Shift timings: 11:30 am - 7:30 pm

Certifications:
Category:
Information Technology",4.0,"Fidelity Investments
4.0",Bengaluru,"Boston, MA",10000+ employees,1946,Company - Private,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Charles Schwab, Vanguard, Citi"
Lead Data Scientist,-1,"Position Description

This position is in the data science team under the Advertising Technology organization. The mission of the Advertising Technology organization is to advance Walmart eCommerce by driving higher value for our customers and vendor partners. Walmart is investing in building a world class advertising platform and the Ads team is responsible for defining and performance advertising products that drive discovery, sales and profits.

We are a highly motivated group of Big Data Geeks, Data Scientists and Applications Engineers, working in small agile group to solve sophisticated and high impact problems. We are building smart data systems that ingest, model and analyse massive flow of data from online and offline user activity. We use cutting edge machine learning, data mining and optimization algorithms on ad relevance, ranking and campaign optimization.

The senior data scientist of ad targeting will be leading a team of data scientists and machine learning engineers to build the next generation ad targeting and scoring solution. Join us if you want to be spending your time on:

• Working with product and other business stakeholders to define our roadmap to drive advertiser value and enhance customer experience;

• Leading a team of data scientists and machine learning engineers to develop, implement, and test scalable solutions for improving ad targeting; interacting with other teams to define interfaces and resolving dependencies;

• Researching and implementing methodologies to measure the impact of the technologies;

• Initiating and proposing unique and promising modelling projects, developing new and innovative algorithms and technologies, pursuing patents where appropriate;

• Staying current on published data mining, machine learning and modelling techniques and competing technologies and sharing these findings with scientists and engineers in the organization;

• Maintaining world-class academic credentials through publications, presentations, external collaborations and service to the research community.

Minimum Qualifications

Bachelors or equivalent degree in a computational science with 10+ years OR Masters or equivalent degree in a computational science with 6+ years of experience in Machine Learning/Statistics/Data Science;

Experience with traditional as well as modern machine learning/statistical techniques, including Regression, Classification, Ensemble Methods, Deep Learning and Reinforcement Learning;

Strong implementation experience with high-level languages, such as Python, R, Scala or similar scripting language, and familiarity with Linux/Unix/Shell environments;

Strong hands-on skills in sourcing, cleaning, manipulating and analysing large volumes of data using distributed computing platform;

2+ years of experience mentoring junior data scientists;

Strong written and oral communication skills.

Preferred Qualifications

Ph.D. in a computational science with an emphasis in Machine Learning;

Experience in online advertising, recommender system, ecommerce or relevant areas;

Experience with end-to-end modelling projects emerging from research efforts;

Excellent academic or industrial track record of proposing, conducting and reporting results of original research, plus collaborative research with publications;

2+ years of experience managing a data science/modelling team.",3.3,"Walmart
3.3",Bengaluru,"Bentonville, AR",1001 to 5000 employees,1962,Company - Public,"Department, Clothing, & Shoe Shops",Retail,₹500+ billion (INR),"Target, Costco Wholesale, Amazon"
Senior Machine Learning Engineer,-1,"Ushur is transforming the way businesses communicate, with cutting-edge AI and automation technologies. Previously using outdated emails and phone calls, businesses are now automating their conversations with automated text-messaging using Ushur’s platform. We are creating breakthrough experiences for our enterprise customers by deploying the best of web, mobile and data analytics technologies. We focus on fast, iterative development with an emphasis on design-right philosophy. Currently, at Ushur, we are experiencing unprecedented & exciting growth with endless opportunities to innovate!

The Role

Ushur seeks a Senior Engineer with Machine Learning Expertise to join a high-impact team to enhance the Language Intelligence framework that is at the core of industry’s leading Micro-Engagement Platform from Ushur.

What you’ll be doing…

As one of the key members of of the Language Intelligence team, your responsibilities will include:
Design, develop and support machine learning and deep learning models involving
Ushur’s Language Intelligence that encompasses the spectrum of NLP and NLU to support information processing as well as drive the Ushur micro-engagements with users.
Responsible for designing and/or adapting various algorithms, undertaking experiments and impacting the Ushur Micro-engagement Platform.
Construct comprehensive knowledge graphs to support various applications that are delivered over the Ushur Platform.
Research and employ modern algorithms into the Ushur Platform to keep innovating with efficiency, impacting the feature-base of Ushur’s Platform.

Collaborating with engineers from AI & other teams on data analysis and feature design efforts

Qualifications

MS/PhD in Computer Science or related field
At least 3 years hands-on working experience in the AI/ML Area
Demonstrable experience with NLP/NLU techniques, language data
Strong knowledge of NLP tasks and techniques, NER, training machine learning models, neural networks
Strong programming skills in Python or Java and fluency in data manipulation (SQL/Spark/Pandas) and machine learning kits like scikit-learn, Keras/Tensorflow, XGBoost, Gensim
Excellent verbal & written communication, strong organizational skills and attention to detail

Why Join us?

We are passionate about Ushur, our product, and helping our employees grow and develop in their career in a caring, collaborative environment. We offer a very competitive compensation plan & stock options for the ideal candidates.",4.4,"Ushur
4.4",Bengaluru,"Sunnyvale, CA",1 to 50 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"No. of Positions : 1

Total Relevant Experience : Fresher - 3 Years

Education : BE (Computers / IT), MCA, M.Sc. or any equivalent degree

Job Description :
• Interpret data and analyse results using statistical techniques and algorithms.

• Understand the business requirements and provide proper solution.

• Perform basic pre-processing of data.

• Extract data and provide solution for implementing transformation and manipulation of data.

• Develop and provide support to various reporting processes.

• Create dashboards, graphs and visualizations from data.

• Should have ability to acquire knowledge on new things, especially about technological developments.",2.5,"Insigno Quipment
2.5",Ahmedabad,"Ahmedabad, India",51 to 200 employees,2002,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
Urgent requirement For Data Scientist Position,-1,"Tasks:-

Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Analyze and interpret statistical data to identify significant differences in relationships among sources of information.
Collating and analyze data from company databases to drive optimization and improvement of Employee Management, Work Environment, Employee Experience, Employee Retention, product development, marketing techniques and business strategies.
Use predictive modeling to increase and optimize Employee experience, Reduce employee crunch, customer experiences, revenue generation marketing target and other business outcomes.
Identify relationships and trends in data, as well as any factors that could affect the results of research.
Develop Machine Learning Models to accurately perform predictive analytics using python and R.
Interactive visualization using Python Scripts & R Scripts.
Determine whether statistical methods are appropriate, based on user needs or research questions of interest.
Prepare data for processing by organizing information, checking for inaccuracies, and adjusting and weighting the raw data.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Automating Microsoft excel and other Microsoft applications using VBA & Python
Work Styles
Analytical Thinking— Job requires analyzing information and using logic to address work-related issues and problems.
Attention to Detail— Job requires being careful about detail and thorough in completing work tasks.
Integrity— Job requires being honest and ethical.
Dependability— Job requires being reliable, responsible, and dependable, and fulfilling obligations.
Achievement/Effort— Job requires establishing and maintaining personally challenging achievement goals and exerting effort toward mastering tasks.

Required Candidate profile

Skills :-

Mathematics— using mathematics to solve problems.
Critical Thinking— using logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions or approaches to problems.
Reading Comprehension— Understanding written sentences and paragraphs in work related documents.
Active Listening— Full attention to what other people are saying, taking time to understand the points being made, asking questions as appropriate, and not interrupting at inappropriate times.
Complex Problem Solving— Identify complex problems and reviewing related information to develop and evaluate options and implement solutions.
Excellent written and verbal communication skills for coordinating across teams.

Technical Skills :-

Analytical or scientific software— SAS, StataCorp Stata, The MathWorks MATLAB, XLISP-STAT, SPSS, Microsoft Power BI, Tableau
Data base management system software— Apache Hadoop; Apache Pig; Teradata Database
Object or component oriented development software— Python; R; SAP PowerBuilder
Good Working Experience on JavaScript & VBA Macros
SAP Knowledge is must.

Salary: Not Disclosed by Recruiter

Industry:Industrial Products / Heavy Machinery

Functional Area:IT Software - DBA, Datawarehousing

Role Category:Programming & Design

Role:Database Architect/Designer

Keyskills
SAP
Data Analyst
Power Builder
Data scinetist
Python
Desired Candidate Profile
Please refer to the Job description above

Education-

UG:B.Sc - Statistics

PG:MS/M.Sc(Science) - Statistics

Company Profile

Walchandnagar Industries Ltd.

Walchand Industries limited (WIL)

Walchand Industries is an ISO 9001: 2015 certified global company specializing in heavy engineering and project execution, hi tech manufacturing. We not only offer an entire range of services involved in the design and construction of plants and machinery for a variety of business such as sugar, cement and railways industry but also develop critical and complex components for nuclear, defence, aerospace and missile sectors.
Apart from this, we have also diversified our portfolio and made significant headway in Oil & Gas, Mining & Bulk, Mineral Processing and Bulk Material handling, Foundry as well as Precision Instruments.
Backed by a strong foundation and a century old tradition of providing excellence in engineering, we are not just a trusted name in India but have also succeeded in expanding our footprint across South America, Africa, Asia and Middle East.
In the India Inc., we are highly regarded for our pioneering achievements and for our contribution to nation building activities.
We are strongly customer driven and firmly believe in serving our customers in a timely and cost efficient manner and in the process, adding value to ourselves. A perfect blend (amalgamation) of superior technical expertise, sound project management capabilities as well as a relentless commitment to the highest standards of quality, ethics and efficiency is the reason why customers choose us/ ( is what makes us a (preferred) vendor of choice).
Our continuous quest for quality compels us to partner with leading OEMs around the world to ensure we deliver our best to our customers.

Led by a strong focussed management team and supported by a team of a highly qualified talent base comprising of engineers and technicians, we strive to create an environment that enables individuals to achieve functional excellence, continuous improvement, teamwork and innovation in order to satisfy our stakeholders.",3.7,"Walchandnagar Industries
3.7",Pune,India,Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Principal Data Scientist,-1,"Yodlee’s Data Science team is driving innovations using Big Data at Yodlee. We have a high-caliber, focused and a mission-driven culture for our teams. The models we build and the analysis that we derive from financial data matters to crucial cutting-edge business decisions made across the global financial services firms every day and solves real world problems. We are leveraging our deep expertise in financial data to launch innovative solutions into the Financial Services Industry.

Description

You need to be a thinker. We are looking for a very curious data scientist who enjoys a deep dive into the raw data to help figure out the right set of questions and find the answers to those questions.

You also need to be a doer. You will be responsible for data cleansing, transformation and creating predictive models and classifiers.

You need to be smart and build smart products. A big part of this job is about creating actionable insights for our customers and the business using machine learning and statistical techniques. Translate analytic insights into concrete, actionable recommendations for business or product improvement.

You need to be ambitious. You must be passionate about applying mathematical modeling to solve real world problems. You must be willing to work with a team of modelers on cutting-edge prediction techniques who knows the best practices around modeling and validation. And more than anything, you must love to turn ideas into reality. If you are the happiest when you can prove the impact of statistical models/machine learning in generating business impact, let us know.

Required Skills and Experience:
8+ years of experience in the area of data science/machine learning (OR) PhD degree specializing in a relevant field such as Probability, Statistics, Machine Learning, Data Mining, Artificial intelligence/Computer Science.
Deep understanding of statistical modeling/machine learning/ data mining concepts
Strong analytical and quantitative problem solving ability
Strong interpersonal and communication skills: ability to tell a clear, concise, actionable story with data, to folks across various levels of the company.
Experience in managing high performance teams",-1,Envestnet | Yodlee,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Quantitative Analyst,-1,"Morningstar Indexes- http://indexes.morningstar.com

Position: Quantitative Analyst – New Product Development – Morningstar Indexes

The Area: Morningstar Indexes Team leverages its expertise in equity research, manager research, asset allocation, and portfolio construction to create innovative investment solutions. It uses Morningstar’s intellectual property to create indexes that empower investors to achieve their goals at every stage of the investment process - market monitoring, benchmarking, and asset allocation. The unit offers a broad suite of global equity, bond, commodity and asset allocation indexes.

The Role: As a part of the Indexes New Product Development Team, you will participate in the full development cycle including ideation, design, development, presentations to global research team and clients, leading up to implementation. The ideal candidate will have a good grasp of investment concepts, possess strong analytical skills, good communication skills and will be technically proficient with at least one programming language (Python, R or MATLAB) in addition to SQL. The position will have a special focus on Strategic Beta (Factor) and ESG Indexes, and candidates with hands-on experience with such investment strategies will have an advantage. This position is based in our Navi Mumbai office.

Responsibilities:

The successful candidate will
Collaborate effectively with Morningstar research organization including equity, quantitative, manager or sustainability research teams, and product management to develop novel thematic and smart beta indexes that leverage Morningstar IP.
Work on the entire product development lifecycle from ideation, design, development, and validation, leading up to launch.
Work closely with other index teams to operationalize index methodologies.
Develop new tools and capabilities to perform portfolio construction or analytics independently, including the use of statistical and machine learning techniques.
Publish white papers, factsheets, client presentations, and other collateral to support go-to-market plans.
Requirements:
Up to 2 years of experience.
Bachelor’s degree in a quantitative, financial discipline, or engineering.
MBA from a premier institute is preferred.
CFA charter or candidature (at least passed Level II) is preferred.
Knowledge of SASB framework or prior experience in incorporating ESG factors in portfolio construction is preferred.
Knowledge of institutional investing, modern portfolio theory, and portfolio construction processes.
Proficiency in at least one programming language (Python, Matlab, R or C#) in addition to SQL.
Excellent documentation habits, oral and written communication and presentation skills including ability to distil complex ideas into simple explanations.
Morningstar is an equal opportunity employer.

I10_MstarIndiaPvtLtd Morningstar India Private Ltd. (Delhi) Legal Entity",4.1,"Morningstar
4.1",Mumbai,"Chicago, IL",5001 to 10000 employees,1984,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),"Thomson Reuters, FactSet, Bloomberg L.P."
DATA ANALYST,-1,"The Data Analyst needs to analyze technology trends to identify markets for future scientific product development or help in increasing sales through predictive analysis. He or she creates compelling reports using database-stored procedures and triggers. In addition, the Data Analyst needs to coordinate and communicate with the internal and external stakeholders. He or she also needs to understand the complete requirement of the project and document as per the company’s requirement.

Job Description:
The roles and responsibilities of the Data Analyst include the following:
Building SQL pivots and developing/manipulating data cubes
Interacting with different stakeholders
Performing requirement analysis to strategize further action points
Analyzing information to determine, recommend, and plan installation of a new system or modification of an existing system
Adhering to compliance procedures and internal/operational risk controls in accordance with any and all applicable regulatory standards, requirements, and policies
Desired Skills and Experience:
Education—BCA/MCA/BTech/BE
Experience—2-5 years of experience in data analysis and data mining
Experience in developing stored procedures, triggers, and complex SQL queries
Exposure to VB and .Net is mandatory, as the role involves building an engine to read data from MS Excel files and create SQL queries dynamically
Exposure to data warehousing/ETL
Should be a self-starter and capable of operating on minimal management oversight
Ability to work under pressure to meet agreed deadlines
Passion, energy, and enthusiasm to drive results",3.6,"Indegene
3.6",Bengaluru,"Bengaluru, India",1001 to 5000 employees,1998,Company - Private,Healthcare Services & Hospitals,Healthcare,₹10 to ₹50 billion (INR),"Accenture, Cognizant Technology Solutions, Tata Consultancy Services"
Senior Data Analyst,-1,"Job Description:

This role requires you to own the analytics space for a given Cleartrip product. You would be responsible for all the data & analysis requirement related to this product. You would work closely with & across the business team, product managers & functional teams to make significant impact to this product by informing decisions using analytics & data intelligence. The data analyst would be an integral part of the product-engineering- design-business- marketing pod for that particular product. The data analyst would report all the key metrics for the product, and bring in an unbiased understanding of the causality for movement of the same. Additionally, you will be expected to identify, develop and deliver key projects which contribute to the business & product goals.
As a requirement, the candidate needs to be excellent in handling & integrating data from different sources/ platforms in order to meet the analytic requirements on his/her projects.

Skills and capabilities:

(i) Understanding of key aspects of a typical product line: product, marketing, operations and finance

(ii) Excellent analytical abilities: data driven and understanding of key analytical techniques

(iii) Strong background & hands-on experience on analytical tools like R, SQL, Excel, Python (plus) etc.

(iv) People skills: Ability to interact across team & drive ideas (& execution to an extent)

Education: B.Tech/B.E./M.Tech. graduate from premier institutes

Experience: 4-7 years",3.5,"Cleartrip
3.5",Bengaluru,"Mumbai, India",501 to 1000 employees,2006,Company - Private,Travel Agencies,Travel & Tourism,Unknown / Non-Applicable,-1
Business Analyst - Data Science,-1,"With a startup spirit and 90,000 curious and courageous minds, we have the expertise to go deep with the world’s biggest brands—and we have fun doing it. Now, we’re calling all you rule-breakers and risk-takers who see the world differently, and are bold enough to reinvent it. Come, transform with us.
Transformation happens here. Come, be a part of our exciting journey!
Inviting applications for the role of BA, Data Science
In this role, we are looking for a commerce graduate / Postgraduate in Finance with prior data handling experience. In this role, you will be encouraged to work on deadlines, in a fast paced business environment while being a standout colleague.
Prior Commercial Analytics in sales/orders reporting / MIS experience in the BPO Industry with Access skills experience will be preferred
Responsibilities
Technical expertise: Provide expertise in Statistics, Mathematical modeling and simulation, Numerical Analysis and Differential Equation
Curiosity: a desire to go beneath the stated client needs and discover and distill a problem down into a very clear set of hypotheses that can be tested.
Cleverness: the ability to look at a problem in different, creative ways.
Should be able to handle large data sets, Compute and Calculate Sales Incentives with multiple slice and dice of the Sales data.
Should be able to identify automation opportunities, handle customer queries and issues and process log variations, exceptions, output errors for traceability
Ensure client happiness and successful external & internal audits
Qualifications
Minimum qualifications
MBA / M.Sc. Statistics / M.Sc. Operations Research
Meaningful work experience
Preferred qualifications
Relevant work experience in Reporting and handling large data sets and databases
Flexibility to adapt to a variety of engagement types, working hours and work environments and locations
Very good written and verbal communication skills
Proficient in MS Office applications, especially in MS excel, R, Python
Good analytical and problem-solving skills and ability to handle team and client discussions
Genpact is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. Genpact is committed to creating a dynamic work environment that values diversity and inclusion, respect and integrity, customer focus, and innovation. For more information, visit www.genpact.com. Follow us on Twitter, Facebook, LinkedIn, and YouTube.",3.6,"Genpact
3.6",Noida,"New York, NY",10000+ employees,1997,Company - Public,IT Services,Information Technology,₹100 to ₹500 billion (INR),"Accenture, IBM, Capgemini"
Data Analyst,-1,"Data Analyst 1 to 5 years work experience. Determination in working in a high data volume environment. Fresh graduate will also be considered. Combination of analytical, technical savviness and business acumen.

Good understanding of experimental approaches in Degree or equivalent experience in Computer Science, Data Science, Statistics, Operations Research or any other quantitative discipline preferred. Coimbatore Gather, organize, analyze and input information from proxy reports, news and earnings press releases, corporate descriptions and other relevant stock information Use a variety of data analysis tools to explore our existing data sets to uncover The Data Analyst role is a hands on individual contributor responsible for end-to-end design, development deployment of analytics solutions for assigned projects. We are looking for an energetic Analyst with proven record of developing solutions pertinent to identification, analysis and interpretation of patterns from complex data problems.",3.0,"Sripathi Paper and Boards
3.0",Coimbatore,"Coimbatore, India",201 to 500 employees,-1,Unknown,Industrial Manufacturing,Manufacturing,₹1 to ₹5 billion (INR),-1
Data Science Intern,-1,"Role: Intern
Location: Bhubaneswar
Duration: 3-6 Months

Key Responsibilities:
Apply Data Mining/ Data Analysis methods using a variety of data tools, building and implementing models using algorithms and creating / running simulations to drive optimization and improvement across business functions.

Education qualification:
Final year engineering students from top institutes. Information Technology and Computer Science background are preferred.
Excellent written and verbal communication skills for coordinating across teams.
Should have knowledge on R, Python, SQL etc.
Reach us on careers@eta-iota.com.",-1,ETAIOTA Systems,Bhubaneswar,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"Job Location – Pune, India
Required experience – 6-10 Years

About Innoplexus
Innoplexus at its core uses AI to provide non-obvious insights to researchers by acquiring and analyzing the word’s knowledge in bioinformatics.

Our products leverage proprietary algorithms and patent pending technologies to help global Life sciences & Financial services organizations with access to relevant data, real time intelligence & intuitive insights, across the life cycle of the products.

We automate the collection, curation, aggregation, analysis & visualization, of billions of data points from thousands of data sources, using domain-specific language processing, ontologies, computer vision, machine learning, network analysis and more.

You are the right person in our team if you can:
Lead and mentor a small team of data scientists in applying existing learning algorithms and develop new ones
Develop scalable customer-facing solutions over real-world, noisy and unstructured data
Develop highly scalable deep learning algorithms to improve our platform
Develop state-of-the-art machine learning and neural network methodologies to improve our intelligence platform
Cross-functional collaboration between data science and engineering teams to support the integration of finished algorithms and prototypes into product
Support sales and business development teams to fine-tune client requirements, perform feasibility testing and proposing an approach for solutions

We need you to have:
Bachelors/Masters/PhD Degree in Computer Science, related Machine Learning field or equivalent from Tier-1 or premier institutes like IIT, IISc, BITS, NIT or globally renowned universities

Knowledge On:
Relevant Hands-on Experience in any of the below groups:
Information Extraction, Text Mining from Unstructured data

Computational Genomics, Bioinformatics

Strong in Python programming

Knowledge commonly used machine learning tools:, pytorch, scikit-learn, gensim, pandas

Experience with major NoSQL products

Experience in the domain of life sciences is a plus

Must have experience in leading teams

Innoplexus believes in the power of collaboration and teamwork. You will work and grow alongside creative thinkers to turn great ideas into reality. We will help you develop your skills with training courses and knowledge sharing.",4.1,"Innoplexus
4.1",Pune,"Frankfurt am Main, Germany",201 to 500 employees,2011,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),"Palantir Technologies, Mu Sigma, IQVIA"
Marketing Operations Data Analyst - Reporting & Visualization,-1,"The Company

Hitachi Vantara, a wholly owned subsidiary of Hitachi, Ltd., helps data-driven leaders find and use the value in their data to innovate intelligently and reach outcomes that matter for business and society. We combine technology, intellectual property and industry knowledge to deliver data-managing solutions that help enterprises improve their customers’ experiences, develop new revenue streams, and lower the costs of business. Only Hitachi Vantara elevates your innovation advantage by combining IT, operational technology (OT) and domain expertise. We work with organizations everywhere to drive data to meaningful outcomes.

The Role

The marketing operations data analyst is responsible for defining, maintaining, enriching, and reporting on marketing account, lead, and contact data records, along with quality assurance. This role is tactically focused on assuring the uniformity and quality of data records used within the marketing automation platform (MAP) and sales force automation (SFA) systems.

Responsibilities
Analyze account and contact data, including customer data
Analyze marketing program requirements for data
Conduct gap analysis to determine the status of existing data
Define and implement data acquisition and update activities to maintain database at desired coverage and quality levels
Support all data hygiene processes
Support all data enrichment processes
Document data schema
Monitor and report on database quality metrics
Help craft compelling visuals using PowerPoint, Power BI and other mediums.
Qualifications
One or more years of data analysis work
Proven experience with common tools such as Microsoft Excel, Salesforce, Marketo, Eloqua, Pardot, or Hubspot
Experience working with business owners in defining reporting and data requirements
You worked in operations activities
High degree of proficiency with creating compelling visuals with tools such as PowerPoint
You are skilled at verbal and written communications
Fluent in English
We are an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.",2.7,"Hitachi Vantara
2.7",Pune,"Santa Clara, CA",5001 to 10000 employees,1989,Subsidiary or Business Segment,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Scientist Director,-1,"Data Scientist Director-20000L3V Applicants are required to read, write, and speak the following languages: English
Preferred Qualifications


The Product Development Leader in Oracle CX Marketing will work with the data science team and the product leaders of all portfolio products to drive build out and adoption of data science initiatives across the entire portfolio of products.

We are searching for a hands-on product leader who is extremely technical, product-oriented, and business driven, with a deep knowledge of and expertise in data science, machine learning platforms, and container technologies. This person should have built and launched highly scalable data/intelligence platforms used by multiple constituents (internal and external).

This leader will work cross functionally with CX Marketing Product Management, Engineering, and Design teams and other Oracle product groups to drive a product vision and achieve strategic business objectives.

We seek an accomplished, energetic, collaborative leader who is a clear champion of our strategy and products. An understanding of our users as well as knowledge of and passion for the rapidly evolving mar-tech space is a must. The ideal candidate has extensive hands-on experience in developing machine learning platforms, algorithms and having deployed them for use by various enterprise products. The person understands flexible and open architectures and can hold his/her own in debates with senior level technical folks.

MINIMUM QUALIFICATIONS AND REQUIREMENTS:
10+ years’ experience in hiring and developing high performance teams, building large scale, multi-tenant big-data enterprise platforms, using docker containers and open architectures.
Direct experience leading and managing Data Scientists or Applied ML engineers, building AI/ML features in enterprise products.
Experience working and communicating with a variety of global stakeholders (engineering, design, sales, product marketing, customers)
Experience building large scale software development projects, docker containers, git, JIRA, Confluence, and other tools
Candidate should have demonstrated ability to build and launch highly scalable platforms
PRINCIPAL DUTIES AND RESPONSIBILITIES:
Candidate should be able to articulate vision, have clarity of thought, be able to execute tactically rolling up sleeves, be good with internal (executive) and external (customer) presentations, and have solid speaking/communication skills.
Build and lead teams of Engineers and Applied Data Scientists to build, deploy and operate Data Science platform, delivering ML features across a variety of CX Marketing products.
Roll up sleeves and participate in detailed roadmap, sprint planning, monitoring of projects, doing detailed product reviews, guiding team with vision and in execution.
Strong hands-on knowledge of Java, Python, SQL, and other programming languages.
Hands-on knowledge of open source ML libraries, including scikit-learn, Tensorflow, Keras and others.
Strong hands-on ability to troubleshoot and resolve production and customer escalations. Knowledge of operational monitoring tools (Prometheus, others).
Excellent software design skills, building large enterprise systems. Experience building loosely coupled, scalable backend systems.
Experience building big data systems. Knowledge of Apache Spark, Kafka, MQ, and other technologies.
Strong knowledge of Kubernetes, Docker, and containerization. Experience building applications on cloud platforms (ex: OCI, AWS, Azure, etc.).
Drive overall software platform architecture, working closely with product specific architects and driving towards consensus across organizational boundaries.
Works independently to drive product development from conceptualization through launch - creating actionable plans, development epics, and establishing a process to bring features to market.
Patience to work with a variety of stakeholders and drive platform adoption through influence.
Leverage data, analytics, and competitive analysis to make strategic product decisions about which features to develop when.
Ability to recognize and drive development of features that will disrupt the market.
Deep understanding of the customer- works always to identify new opportunities to improve their experience.

Detailed Description and Job Requirements
Leads a team of people who design, develop and program methods, processes, and systems to consolidate and analyze unstructured, diverse “big data” sources to generate actionable insights and solutions for client services and product enhancement.

Plans, manages, and controls the activities of a team that interacts with product and service teams to identify questions and issues for data analysis and experiments. Brings expertise or identifies subject matter experts in an effort to integrate and evaluate large datasets from multiple disparate sources. Advises business groups by providing strategic direction to initiative prioritization, integration and resource application. Ensures that policies and procedures align with corporate vision. Selects, develops, and evaluates personnel ensuring efficient operation of the function.

Assists in the development of short, medium, and long term plans to achieve strategic objectives. Regularly interacts across functional areas with senior management or executives to ensure unit objectives are met. Ability to influence thinking or gain acceptance of others in sensitive situations is important. Strong written and verbal communication skills. Attention to detail and ability to multitask. Ability to travel as needed. Demonstrated leaderships skills. BA/BS degree or equivalent. Advanced degree desirable.
Job
: Business Operations
Location
: IN-IN,India-Hyderabad
Job Type
: Regular Employee Hire
Organization
: Oracle",3.7,"Oracle
3.7",Hyderabad,"Redwood City, CA",10000+ employees,1977,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹500+ billion (INR),"SAP, Salesforce, Microsoft"
Senior Data Scientist,-1,"We are looking for a strong Senior Analyst/Senior Data Scientist, who will guide model development. The person will be part of data science team that continuously interacts with underwriting analysts and developers that drive solutions to the complex business problems, in credit and risk domains.

Roles and Responsibilities:
In addition to the responsibility of analyst/Data Scientist, additional responsibilities:

Good understanding of the underlying business and workings of cross functional teams for successful execution.
Good written and oral communication, and ability to convey technical details to teams working across multiple time zones.
Mentor a small team of analysts.

Qualification & Experience:
4+ years of experience in the field of credit rist analytics, marketing analytics backgrounds
Proven experience working in teams with end to end real time implementation
Strong with programming languages like Python and data processing using SQL or equivalent and ability to experiment with newer open source tools
Strong with analytical and statistical packages like R, Python Scikit-Learn
Familiarity with deep learning, xgboost, scikit, apache spark, GPU based machine learning
Good communication skills and ability to articulate complex scientific and technical matters to the business group
Ability to successfully interact with business and software teams for execution
Experience in newer machine learning algorithms
Experience with NoSQL and distributed data processing technologies such as Hadoop is also desirable
Experience in risk and credit score domains are a big plus
Bachelor or Master in Operations Research, Computer Engineering or in closely related Quantitative Disciplines from a premier institution.
Interested? Please send your resume to careersindia@applieddatafinance.com.",4.5,"Applied Data Finance
4.5",Chennai,"San Diego, CA",51 to 200 employees,2014,Company - Private,Lending,Finance,Unknown / Non-Applicable,Avant
Data Analyst-Internship,-1,"Job Title
Data Analyst-Internship

Location(s)
Hyderabad

This role supports Reviewing and standardizing the new Inventory data of GSK Site

Creation of new Contract Materials in Lotus Notes and get it approved in SAP

Assigning Contract Materials to Equipment Records

Standardizing the MFG, Model, Device Type, PL , Type Description etc of all Equipment records

Reviewing the Go-Live data in SAP and work in its Standardizing

Support BA team in Filling the Blanks in Equipment records

Any Ad-hoc support as needed by Business Analytics team.",3.2,"Perkinelmer
3.2",Hyderabad,"Waltham, MA",10000+ employees,1937,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹100 to ₹500 billion (INR),-1
Data Analytics Specialist - Product Insights,-1,"You will ensure the tribe and its squads are making decisions based on sound qualitative and quantitative evidence by collecting and making use of a wide variety of data – usage statistics, web analytics, surveys, support tickets, financials, and more – which are spread across different systems at various levels of maturity.
In this role, you will tap in and derive novel insight using a wide variety of quantitative methods, including advanced analytics. As needed, you will draw on the talents of your data scientist and qualitative research colleagues.
You will synthesize your findings into actionable insights and communicate them to teams, stakeholders, and functional leaders in a compelling, digestible way. You’ll pose and answer questions like “Why is this application stickier with junior consultants but not senior ones?” “Should we take on new features from the backlog or fix accumulating technical debt?” Your overarching goal is to enable data-informed decision making at all levels of the organization.
The work you do will inform how your squad or tribe prioritizes and orchestrates their work, refines their mission and scope, and collaborates with other teams across the organization. Efforts in this space will vary in scale from informing adjacent, ongoing improvements to conducting discovery for new products or services. In addition to evaluating product and service value and success, you will apply analysis and reporting to help identify and prioritize opportunities for incremental and transformational innovation.
As a member of the Design & Innovation team, you will contribute to our growing set of best practices, tools, and assets intended to help product and service teams gain better access to and insights from their data. You will work to instill these best practices at the product squad and tribe level.",4.4,"McKinsey & Company
4.4",Gurgaon,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&"
Data Analyst,-1,"Experience
1 to 3 years

No.Of.Positions
4

Location
Chennai

(willing to relocate to Hyderabad down the line )

Notice Period
Immediate – 15 days

Job Description:
Passion for problem solving by gathering descriptive insights through data extraction, slicing and dicing the data
Experienced in writing complex SQL select queries
Strong in querying logic and data interpretation
Individual contributor
Responsibilities

Understand the real-time business problem, create insightful reports and build story via insights
Look at the data from different databases in different dimensions and think out of the box to find solutions
Connect different datasets to find new information, that presents implementable tactics and actions

Skills:
SQL, one of the Visualisation toolset like PowerBI, Tableau, Qlikview
Database concepts
Business understanding
Good Communication skills, should be able to hold a conversation with client on a solution for 30 minutes",4.0,"Indium Software
4.0",Chennai,"Cupertino, CA",501 to 1000 employees,1999,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Analytic Consultant 2,-1,"About Wells Fargo India Wells Fargo India enable s global talent capabilities for Wells Fargo Bank NA., by supporting business lines and staff functions across Technology, Operations, Risk, Audit, Process Excellence, Automation and Product, Analytics and Modeling. We are operating in Hyderabad, Bengaluru and Chennai locations. Department Overview: The Financial Institutions Group is part of the Corporate and Investment Banking division of Wells Fargo Banks Wholesale business. The FIG Portfolio Management and Underwriting Unit supports Wells Fargo Bank in taking the right exposure on other banks/Financial institutions, by underwriting the credit of Financial Institutions across the Globe . About the Role: FIG Credit Analyst evaluates banks and other financial institutions in different regions like Asia and the Indian sub-continent, Europe, Latin America and the Middle East based upon standard and documented underwriting criteria as per Corporate and FIG Credit Policies. The end-product of the underwriting activity is a timely and thorough review of the financial institution, with appropriate internal risk ratings assigned to the counterparty and acceptable justification of those ratings. Responsibilities: Individual at this level are expected to follow established guidelines in performing credit analysis work and use some independence of thought but to refer to more complex problems to supervisors or other experts. Primary duties include: Timely and accurate credit reports of banks and other financial institutions including Non-Bank Financial Institutions (NBFI) in assigned geographic markets. This includes extensive financial statement analysis of individual institutions and comparison to other peer institutions within the same country In addition to the financial review, the analysis should incorporate current news on relevant topics or/and events related to the counterparty, its industry and country. As part of the analysis, an accurate risk rating (including any changes from current rating) must be assigned to the institution, with adequate justification contained within the analysis to support the assigned rating. Maintain credit files for assigned accounts. May assist in internal and external exams by preparing the necessary credit folders for the exam. This will be done under direct supervision of the Portfolio Manager 52075",3.6,"Wells Fargo
3.6",Bengaluru,"San Francisco, CA",10000+ employees,1852,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),-1
Lead Data Scientist,-1,"Hello, we’re Tide (www.tide.co)!

We believe SMEs have been vastly underserviced and overlooked by traditional banks. Something as simple as opening an account can take weeks, mountains of paperwork and too much time. Through a mobile-first platform, we provide modern business banking services to small-business owners, saving them time so they can get back to doing what they love.

Based in central London, Tide is backed by some of Europe’s most notable founders and investors, including Robin and Saul Klein (LocalGlobe) and Alex Chesterman (Zoopla Property Group), as well as top VCs in London and Stockholm (Anthemis, Creandum and Passion Capital).

We’re offering the right person, the opportunity to join our dynamic team to help unlock the next stage of our growth. We’re a rocket ship that's going places – this looks a little like world domination!

Your day will look a little like this:

As Lead Data Scientist at Tide (fondly referred to as a Tidean, a god like challenger of the banking world) you will split your time between translating business requirements into data solutions, building data-pipelines, building ML-models, helping our engineers to deploy these models as well as leading a team of data-scientists to do the same. You will be working closely with the business as well as the engineering teams in order to deliver business value within an agile framework. Projects under your supervision will likely include transaction classification and receipt matching.

You will join our data science community of practices and your input on how to improve processes and maintain a high quality will be very welcomed. Career progression is as important to us as it is for you! With our expanding teams and business we will encourage you to outgrow your initial responsibilities, if you so desire. This role offers an exceptional opportunity to make a real difference with responsibilities across engineering practices in a rapidly expanding company!

Requirements

Who are we looking for?
Excellent leadership skills - you have managed a team of data scientists before and coached them to become better versions of themselves
Excellent business acumen, you manage to translate business problems into data products
Excellent communication skills including the ability to explain statistical concepts and technical tradeoffs to business users
Experience in training, optimizing and deploying a variety of ML-algorithms, such as logistic regressions, boosted trees and neural networks
Experience solving natural language processing task
You’re a self-starter - you take initiative in spotting opportunities and finding ways to solve challenges with data
Ability to deal with ambiguity and competing objectives in a fast paced environment
Extensive experience with Machine Learning tools - TensorFlow, Keras or PyTorch
5+ years of experience in Software development or Machine Learning. Strong in Python and bash.
Experience with big-data technologies such as Spark, SparkML, Hadoop etc. Strong knowledge of Cloud (AWS or other).
Experience with automating deployment processes and containerisation (eg. docker, kubernetes)
Familiarity with basic data table operations (SQL etc.), data transform in warehouse (dbt etc.) and business intelligence softwares (eg. Looker).
Though not required, it would be nice if you also had:
Experience working for a Fintech
Experience working in a Scale-Up
Experience in Integration components - Integration, SOAP Service, RESTful web service implementations, XML/XSD, JSON. MQ Integration.
What are we like to work for?
We’re not corporate, we’re a start-up. You will have an unparalleled exposure to many areas of the business – improve and impact how we work
We will give you the freedom to be inquisitive and proactive – pursue your interests and develop career with us as we scale
We’re open and progressive – input is encouraged at all levels
We’re a social bunch. We celebrate the milestones, big and small and genuinely enjoy each other’s company!
Diversity is what makes our world interesting. Different people bring fresh new ideas, thinking and approaches, which make the way work is undertaken more effective and efficient. If you’re not into diversity, Tide may not be in the right place for you! Tide holds itself accountable against measurable diversity objectives.",3.6,"Tide
3.6",Hyderabad,"London, United Kingdom",201 to 500 employees,2015,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"Business Unit:
Cubic Corporation
Company Details:
Cubic offers an opportunity to provide innovative technology for government and commercial customers around the globe, helping to solve their future problems today. We’re the leading integrator of payment and information technology and services for intelligent travel solutions worldwide, and the leading provider of realistic combat training systems, secure communications and networking and highly specialized support services for military and security forces of the U.S. and allied nations. If you have an entrepreneurial spirit and thrive in an innovative environment, we want to talk to you about your next role at Cubic! We are seeking employees inspired by technology, and motivated by the rewards of hard work, commitment, teamwork, quality, integrity, and respect. We invite you to explore opportunities with Cubic.
Job Details:


Job Summary:

Solves complex problems using data analysis techniques throughout the entire data life cycle. Works with public and proprietary data to find new methods of data integration where relationships are often obscured. Designs repeatable and optimized workflows using SQL, python, and other scripting and programming languages to clean, transform, and prepare data for reporting. Uses visualization tools to assist with data validation, mining, pattern identification, and report building. Prepare and deliver oral or written presentations on findings from analyses. This position typically works under general supervision and direction. Incumbents of this position will regularly exercise discretionary and substantial decision-making authority.

Essential Job Duties and Responsibilities:
Filter, clean, and prepare large data sets for more advanced transformations
Perform statistical analyses, develop new performance metrics, benchmarks, and indices
Develop and document new data models, ERDs, schemas, and data workflows
Validation and quality control of produced data sets
Research, interpret and perform quantitative and qualitative analysis against HR Data
Participate on project teams to develop new reporting and analysis tools and workflows
Analyze client information needs and business challenges to determine how they may be addressed through the delivery of customized decision support tools and services
May involve external customer/supplier interaction
Apply understanding of global and/or local trends and events (e.g., economics, social issues) to assist with the formulation of hypotheses and interpretation of data
Stay current with technical and industry developments, analytics software/tools, and recognized best practices
Minimum Job Requirements:
Four-year college degree in computer science, statistics, economics, mathematics, operations research, informatics, or related field plus a minimum of two years of experience.
Master’s degree in a related discipline is a plus.
Experience in developing data warehouses, performing data analysis, database management, data integration, ETL, or similar roles required.
Experience with Advance excel is must
Exposure to Workday Studio is preferred
Experience with SQL and using Access, MySQL, Oracle, and other RDMS required.
Experience with Python, R, Hadoop, HQL, Pig, Oozie, Tableau, Qlikview/Qliksense preferred.
Strong analytical and problem-solving skills, attention to detail, critical thinking ability, and creativity required.
Must have excellent written and verbal communication skills used to effectively communicate and clearly present complex information in a manner appropriate to the audience.
Prior experience working with HR data is a plus.
The description provided above is not intended to be an exhaustive list of all job duties, responsibilities and requirements. Duties, responsibilities and requirements may change over time and according to business need.

Worker Type:
Employee",3.3,"Cubic
3.3",Hyderabad,"San Diego, CA",5001 to 10000 employees,1951,Company - Public,Aerospace & Defence,Aerospace & Defence,₹100 to ₹500 billion (INR),"Accenture, Northrop Grumman, Xerox"
Python for Data Science-Lead,-1,"Job Description

Key skills required for the job are:
Python for Data Science-L3 (Mandatory)
Teradata-L2
Good Knowledge of Database ( Preferably Teradata )
Good Experience in python application development, real time working experience.
Knowledge of enhanced machine learning frameworks.
Elementary knowledge of Using and developing APIs
Experience in deploying Machine learning model.
Experience in Text Analysis and unstructured data.
Minimum work experience: 5 - 8 Years
Roles & Responibilities
""As a Lead, you are responsible for managing a small team of analysts, developers, testers or engineers and drive delivery of a small module within a project (Delivery/Maintenence/Testing) You may serve as entry level specialist with expertise in particular technology/industry domain/a process / application / product. You are responsible for functionalechnical track of a project.""

We are an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law.
Wipro does not charge any fee at any stage of the recruitment process and has not authorised agencies/partners to collect any fee for recruitment. If you encounter any suspicious mail, advertisements or persons who offer jobs at Wipro, please do let us know by contacting us on helpdesk.recruitment@wipro.com
Mandatory Skills
Python for Data Science-L3
Desirable Skills
Teradata-L2",3.6,"Wipro Limited
3.6",Bengaluru,"Bengaluru, India",10000+ employees,1945,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Cognizant Technology Solutions, Tata Consultancy Services, Accenture"
Machine Learning Engineer,-1,"Position: Machine Learning Engineer
Location: Chennai
Experience Required: 3 to 6 years

Skillsets:
Our team is seeking experienced engineers who can help us design and build both infrastructure and algorithms in the areas of machine learning, and computer vision.

Responsibilities:
Drive the end-to-end problem solving for a people tracking ML product. Design novel and breakthrough ML technology to fully solve ambiguous problems for real-world environment. Work with data acquisition, ML infrastructure and data serving team to propose solutions for new problems and design system in a way that can be successfully deployed at customer premises. Fast iteration on experiment which can develop state-of-the-art deep neural net models, while also aiming to build a common multi-modal neural net that can tackle a broad spectrum of similar problems. Understand the limitations of ML applications performance on embedded platforms. Work closely with development and QA teams in transitioning prototypes to commercial products.

Minimum Qualifications:
B.E/M.E/PhD in Computer Science, or equivalent field.
3-6 years core experience in ML research & infrastructure.

Must have skills:
Computer Vision - Experience with object detection, tracking, classification, recognition (Face, Iris, Finger, Gesture,), scene understanding, facial expression analysis.
Delivered at-least two products in the customer environment.
Thorough understanding of full ML pipeline, starting from data collection to model building to experimental framework to data analytics.
Deep understanding of at-least two popular frameworks (Tensorflow, Keras, MxNet, Caffe. CNTK, Theano / Pytorch), their strength and applicable AI use-cases.
Experience implementing ML algorithms - Regression, Naive Bayes, Bayesian Network, Decision Tree, Neural Network, SVM, Boosting, K-Means, Ensembler Classifiers, Random Forest, convex optimization, transfer learning.
Experience in frameworks such as Spark, Lucene to implement real-time ML systems
Strong mathematical understanding.
Should have deep expertise in Computer Vision at at-least one vision framework such as OpenCV.
Image Processing - hands-on expertise
Programming in C / C++ Usage of Mat lab, Open CV tool kits.
Experience on embedded/mobile platforms and real-time implementation of complex algorithms.
Able to execute quickly with ever-changing problem set and environment.
Ability to work in small team / rapid prototyping environment.

Good to Have:
Knowledge and experience in building image/video data-sets to evaluate the solution.
Working with machine learning in embedded applications: model quantisation, fixed point neural networks.
Experience with Multi-Threading and C++/Python/Java/Boost/R/SQL desirable.
Advanced degree in Machine Learning, Computer Vision, Applied Mathematics, and Statistics or related fields.",3.2,"e-con Systems
3.2",Chennai,"Chennai, India",201 to 500 employees,2003,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Sr Data Analyst,-1,"We collect peta-bytes of retail data and are looking for data analysts who can derive meaningful insights from this data for our clients. Apart from building dashboards and reports, data analyst are also responsible for forensic data analysis, troubleshooting data issues and ensuring data integrity.

Primary Responsibilites
Distill our technology's performance down to consumable and familiar key performance indicators and visualizations
Build/utilize tools and processes that will scale the reporting function
Perform diagnostic and forensic analysis of product performance
Develop new ways to view and describe our business and product lines
Collaborate with the Engineering and Product Management groups
Mentor Junior Analysts
Technical Skills
SQL expert and basic Python
Proficient in basic statistics (sample sizing, Bayesian vs frequentist)
Exposure to web analytics tools and/or BI tools
Exposure to a statistical package (R, SAS, Matlab) is a plus
Experience with Hadoop (Hive/Pig/Hbase) is a plus
Scrappiness with UNIX is a plus
We are looking for passionate and curious engineers, who are tinkerers at heart and love to build. At CodeHall, we have a strong focus on the right tools, frameworks and libraries which helps engineers build solutions to real world problems in a fast and efficient manner. If you write code using modern toolsets, frameworks and platforms and are interested in any of the job opportunities below, send your resume to careers@codehall.in",3.5,"CodeHall
3.5",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Consultant - ModellingOps Data Engineer,-1,"Job Title: Senior Consultant - ModellingOps Data Engineer
Location: TRIL GTC
GCL: D1

JOB DESCRIPTION:

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for AI Ops consultant who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

ROLES & RESPONSIBILITIES:

7-10 years of experience in IT Operations involving Data Science, Artificial Intelligence-Machine Learning and Predictive Analytics. Experience in architecting and implementation of end-to-end AIOPs solutions through ELK stack, Splunk. Experience in applying statistical methods, analysis, pattern recognition and modeling on IT Operational data using ELK machine learning. Experience in extracting meaning full data from incoming data streams from different sources through RegEx, Grok etc. Hands-on experience in applying machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc in the IT Operation domain. Experience with machine learning and statistical programming languages - Python, R etc. Experience in assessing the existing IT environment and providing recommendations to reduce the critical applications impacting incidents. Experience in exploring and identifying areas where manual tasks can be automated in IT environment. Experience with various Enterprise IT monitoring solutions including Infrastructure monitoring, Application Performance Monitoring, Network Monitoring, Cloud monitoring etc. Experience in IT Service Management including Service Desk, Incident Management, Change Management, CMDB etc. Excellent knowledge on various IT infrastructure components that includes Server Infrastructure, middle ware, database and application architectures and Cloud Components. Experience/knowledge on Infra monitoring tools - NOI, Zabbix, AppDynamics, Datadog, SCOM, SolarWinds etc. and Service Management tools -IBM Control Desk, BMC Remedy, ServiceNow etc. Experience/Knowledge on BI tools Knowledge on distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Knowledge on other programming languages/scripting: Python, Java, JavaScript, etc. ( Added Advantage ) Good analytical skills, strong communication skills are must. Client facing experience is an added advantage. Excellent experience in understanding the problem statement, architect and designing the solution

MANDATORY SKILLS:
Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential.
Experience provisioning computational resources in a variety of Cloud environments using Infrastructure as Code.
Experience with best practice of data transport and storage within cloud system.
Experience building large scale data processing pipelines. e. g. Spark and SQL.
Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
Excellent working knowledge in DevOps, using continuous integration and continuous development.
Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
Good written and verbal skills, fluent English
DESIERED SKILLS:
Agile practices, especially being a SCRUM Master
EDUCATIONAL BACKGROUND: B.E/B.Tech/MCA

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",4.0,"AstraZeneca
4.0",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
Principal Data Scientist,-1,"Job Overview
The successful candidate will be responsible for developing solutions using state-of-the-art machine-learning & computer vision techniques. They will work in a team to research, develop and deliver software/algorithms to make our products AI capable.

Job Responsibilities
Research, develop and prototype algorithms to solve problems in video content analysis.
Document and demonstrate working prototype on benchmark datasets and real world scenarios.
Interface with other teams within the business to ensure timely delivery of high quality products.
Innovate to come up with new solutions and improve existing solutions.
Be an enthusiastic and motivated member of the team.
Maintain knowledge of new technologies in the field of Computer Vision and Machine Learning.

Essential Competencies & Skills
Integrity, Excellence, Accountability, Communication, Innovation, Problem Solving & Analysis, Teamwork
Knowledge of state-of-the-art techniques in Computer Vision and Machine Learning.
Hands on experience with designing, training and fine tuning deep learning algorithms.
Comfortable using multiple deep learning frameworks like Caffe, PyTorch, TensorFlow etc.
Experience in software development using C/C++/Python in a Unix/Linux Environment.
Excellent diagnostic and troubleshooting skills.
Ability to work in an agile software development environment.
Excellent written and verbal communications, and interpersonal skills.

Desirable Competencies & Skills
Experience with working on object detection/recognition/tracking using machine learning.
Experience with scripting languages (e.g. Matlab, Bash, Perl).
Experience with HTML/JavaScript.
Experience of video streaming technologies (e.g. gstreamer, ffmpeg).

Education and Experience:
At least 7 years of experience in Computer Vision and Machine Learning.
PhD in Computer Science or equivalent with a focus on machine learning is a must.
Demonstrated record of research and development in Computer Vison and Machine Learning.",3.4,"Johnson Controls
3.4",Bengaluru,"Cork, Ireland",10000+ employees,1885,Company - Public,Industrial Manufacturing,Manufacturing,₹500+ billion (INR),"Honeywell, Trane Technologies, Siemens"
Data Engineer,-1,"Develop maintain and enhance Bluejeans's Big data warehouse using state of the art ETL frameworks and technologies

Description
Develop and extend ETL pipeline for a number data systems used by Engineering, Operations, Sales, Marketing and Finance and product.
Build and integrate reporting system for ad-hoc queries and business dashboards
Help architect our Big Data system, using as much as practical third-party solutions
Work with outside vendors and other staff on integration projects
Define Data Quality and Data Governance processes to help the system scale
Help resolve data issues, troubleshoot system problems and assesses priorities
As needed, assist other staff with reporting, debugging data accuracy issues and other related functions.


Qualifications :
3-6 years of strong experience in developing reporting/ETL solutions using any standard third party tools such as Informatica, Abnitio, Tableau
Experience with distributed data processing technologies such as Spark/Hadoop/EMR
Programming experience in of python or relatedto implement ETL pipelines
Strong SQL, database and SQL performance tuning skills
Strong experience in understanding business requirements and dimensional modelling
Exposure in developing real time pipelines using Kafka/Kinesis or related
Exposure to any third party Reporting tools such as Tableau/Cognos/Business objects preferable
Exposure to machine learning a plus
Verizon recently acquired BlueJeans and plans to integrate BlueJeans employees into Verizon, including its compensation and benefits programs, in due course. This position will be part of that planned integration.",3.0,"BlueJeans
3.0",Bengaluru,"San Jose, CA",201 to 500 employees,2009,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"Job Location
Hyderabad (SAL) ININD, Bangalore, KA
Job Posting Title
Data Analyst
The Challenge
Summary:

Systems Analyst is responsible for designing, developing and implementing enterprise-wide reporting and analytics solutions across the business processes such as manufacturing, supply chain and distribution, sales, and financials. The primary reporting platforms are Oracle Business Intelligence Applications (OBIA), Oracle Endeca Information discovery and Advanced planning command center, with OBIEE as the presentation layer and Oracle data integrator as the ETL tool. Functional knowledge of one of the enterprise processes Supply Chain, Order ship bill or Finance is desired.
What you will Do


Role Responsibilities:
System Analyst interacts with business users to understand the requirement and partner with various ERP+ teams. They are responsible for design, extend, customize ETL modules and develop technical solution components including interactive dashboards, Scorecards, adhoc queries, KPIs and reports independently. They are the point of contacts for their solutions and ensure that requirements are clear/executable, that solutions are built to technical standards and meet customer needs, and that solutions get built and launched per project schedules. Additionally, Systems Analyst is responsible for migrating solutions to support the project schedules and documenting the solutions after production launches. Systems Analyst participates in design discussions, generate design alternatives, provide development time estimates, and build solutions that match the given solution specifications. Systems analyst develops solutions independently or in collaboration with other team members for larger projects, and in both cases should ensure that solutions are built efficiently and with very high quality.
Key Role Responsibilities:
~ Interact directly with business users to understand the reporting requirements
~ Translate the business requirements to OBIA or Endeca reporting solutions
~ Document the design in the form of High level and low level designs
~ Understand ETL concepts and develop interfaces/mappings within ODI
~ Conduct performance analysis and optimize OBIEE reports and repository
~ Code, unit test, implement and support enterprise reporting solutions.
~ Provide accurate build estimates and timely development status updates.
~ Ensure solutions meet standards, get built on time
~ Follow OBIA development methodology, unit testing, documentation migration standards.
~ Obtain required sign-offs at each phase and own assigned solutions from start to finish.
~ Facilitate successful production launches

What you need to Succeed


Experience:
3+ IT experience, preferably in Business Intelligence area along with Bachelors in computer science or relevant field

Attributes:
• Strong verbal and written communication skills
• Collaborate with cross functional teams
• Independently interact with global business users
• Owns customer's experience and takes stake in customer's success
• Committed to helping customer win
• Listens to understand and challenges assumptions
• Thinks outside the box. Takes risks

GE Appliances is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.",3.9,"GE Appliances
3.9",Hyderabad,"Louisville, KY",10000+ employees,2016,Subsidiary or Business Segment,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),"Whirlpool Corporation, Electrolux, LG Electronics"
Data Engineer,-1,"Site Name: India - Karnataka - Bangalore
Posted Date: Jul 15 2020

GSK is one of the worlds foremost pharmaceutical and healthcare companies and we are proud to be leading a healthcare revolution. By disrupting our approaches to R&D and commercial business processes, D&A is allowing us to integrate, simplify and unlock all our data to drive innovation, decision making and enable our transformation in servicing our patients, healthcare professionals and consumers.

If you are ready for an exciting career YOU would be responsible for the following.
You will be working on fully up to date technologies in the Data & Analytics environment and in a team, which is fully committed to remain at the leading edge of this skillset. Therefore, the impetus to keep improving skills and acquiring skillsets in new technologies will be very strong. If you are a top-flight developer who wants to continue to keep learning and remain at the cutting edge of the very fast-moving Data Analytics technology environment, then this role is for you.
As part of this role you will be working on creating microservices, frameworks on top of Data & Analytics platform which will enable faster acquisition and ingestion of datasets, data curation and creation of analytical ready datasets. A part of this role will also to be helping in new technology introduction by running POC/Pilots and finally creation of a qualified GXP ready software defined infrastructure of the selected platform.
This is very hands-on development role which includes developing & delivering code through from origin to production, plus working in partnership with 3rd party development service providers to help ensure that code comes in on time, to quality and in line with the overall ecosystem being established.
The Data Engineer will directly contribute to the extensive and varied build and deployment activities involved in establishing the new platform then continue to work on the already significant and growing pipeline of future build-outs of platform services on the Enterprise Data & Analytics platform.
Development: Hands on, sleeves up development and delivery expected as a matter of course.
Delivery: Ensure project goals are achieved on time in alignment with the stakeholders expectation. Ability to work on complex projects and in a distributed environment. Escalate to other Data & Analytics leadership team when needing support. Work in close collaboration with other team members in the Enterprise Data & Analytics Platform team, to ensure Development/Delivery aspects are well represented in the projects requirements and deliverables.
Methodology: Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show value periodically. Individuals will work as part of product-centric delivery team(s) that will focus on delivering value independently while fully embracing integrated DevOps approaches.
Ownership: Take ownership for the delivery/development projects and help steer until completion.
Governance: Follow governance that allows projects and stakeholders to manage overall project performance and manage programme risks within the global nature of some of the programmes.
Forward looking: Remain flexible towards technology approaches to ensure that the best advantage is being taken of new technologies. Keep abreast of industry developments in analytics and be able to interpret how these would impact services and present new opportunities.
Quality, Risk & Compliance: Ensure all risk and issues associated with owned projects are recorded and managed in the appropriate Risk & Issue logs in a timely manner. Ensure all Risks and Issues have clear action/mitigation/contingency plans defined, with named action owners and timelines for completion.
Technical Architecture: Be conversant with technical architecture to contribute to design discussions in partnership with the Delivery/Development Lead and dedicated Analytics & Data Architect.
We are looking for professionals with these skills to achieve our goals. If YOU have these skills, we would like to speak to you.
Extensive experience as a Developer in the Data & Analytics arena with demonstrated expertise in emerging technologies and data technology platforms and management.
MS/BS degree in Computer Science, Engineering, Design or equivalent experience.
Ideal candidate would have built an impressive hands-on career to date in an advanced, recognized and innovative environment around Data & Analytics.
Fully conversant with agile and DevOps development methodology and concepts. Must have worked in CI/CD ways of working using tools like Azure DevOps.
Methodologies is a must and knowledge of Azure Data Factory/DataBricks/Azure Data Lake/Azure DW/Analysis Services is a must.
Experience of the Azure analytics components, Power BI, Power Apps & Microsoft Visual Studio is desirable.
Good to have an excellent development skills & extensive hand-on development & coding experience in a variety of languages, e.g. Python, SQL, Scala, etc.
Ability to work in close partnership with other IT functions such as IT security, compliance, infrastructure, etc. as well as partner closely with business stakeholders in the commercial and digital organizations.
Experience in executing Data Analytics projects in an Agile manner, articulation of Value depending on the project life cycle stage, Creating MVPs, developing plans for scale up are all very important experience to be successful in this role.
Great communication skills and ability to communicate inherently complicated technical concepts to non-technical stakeholders.
Why GSK?


Our values and expectations are at the heart of everything we do and form an important part of our culture. These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance and trust, the successful candidate will demonstrate the following capabilities.

GSKIndia_DA

*LI-GSK

Our goal is to be one of the worlds most innovative, best performing and trusted healthcare companies. We believe that we all bring something unique to GSK and when we combine our knowledge, experiences and styles together, the impact is incredible. Come join our adventure at GSK where you will be inspired to do your best work for our patients and consumers. A place where you can be you, feel good and keep growing.

Important notice to Employment businesses/ Agencies

GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.

It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.

GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKilne (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.

If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in gsk.com, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine.",3.9,"GSK
3.9",Bengaluru,"Brentford, United Kingdom",10000+ employees,1830,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Pfizer, AstraZeneca, Merck"
GS Accelerate - Louisa - Data Analyst,-1,"About the Team
Louisa is a GS Accelerate business focused on connecting the minds of our 36000 people to deliver one Goldman Sachs to clients.

HOW YOU WILL FULFILL YOUR POTENTIAL
• You will be part of Louisa, focusing on building data sourcing, controls and distribution that enables the business to operate efficiently with data
• You will help design data architecture to enhance existing pipelines as well as build feeds for new data sources.
• You will participate in data architecture decisions and partner with engineering teams to implement data products in production systems.
• This is a wide open opportunity for a motivated individual to use their skills to drive change in a high-visibility, challenging environment.

SKILLS AND EXPERIENCE WE ARE LOOKING FOR
• Bachelor’s degree or higher in Finance, Engineering or related disciplines
• 2+ years of financial industry experience with strong analytical and problem solving skills
• Good understanding and experience in using data structures and algorithms
• Basic understanding in working with SQL/NoSQL
• Good communication and interpersonal skills

Preferred Qualifications
• Basic understanding of data analysis methodologies
• At least 1 years’ experience dealing with data modeling
• Experience in working with SQL/NoSQL data stores
• Ability to work with the Louisa team to transform business requirements into data solutions
• Experience working in a start-up business or a new business line within a larger organization is preferred
• Proactive and self-directed with the ability to chase down and follow up on requests to a variety of businesses within the firm
• Ability to present findings in a concise manner

ABOUT GOLDMAN SACHS

At Goldman Sachs, we commit our people, capital and ideas to help our clients, shareholders and the communities we serve to grow. Founded in 1869, we are a leading global investment banking, securities and investment management firm. Headquartered in New York, we maintain offices around the world.

We believe who you are makes you better at what you do. We're committed to fostering and advancing diversity and inclusion in our own workplace and beyond by ensuring every individual within our firm has a number of opportunities to grow professionally and personally, from our training and development opportunities and firmwide networks to benefits, wellness and personal finance offerings and mindfulness programs. Learn more about our culture, benefits, and people at GS.com/careers.

We’re committed to finding reasonable accommodations for candidates with special needs or disabilities during our recruiting process. Learn more: https://www.goldmansachs.com/careers/footer/disability-statement.html


© The Goldman Sachs Group, Inc., 2020. All rights reserved.
Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Veteran/Sexual Orientation/Gender Identity",4.0,"Goldman Sachs
4.0",Bengaluru,"New York, NY",10000+ employees,1869,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"J.P. Morgan, Merrill Lynch, Morgan Stanley"
Data Science Engineer,-1,"Experience : 2 to 4 years
Location : Mumbai

Role Requirement :
Building advanced ML models for statement processing and transaction data processing on top of existing technology stack for understanding Customers better and development of Advanced Credit decisioning tool
Working experience in Consumer businesses or fintech is crucial
Should have built production-level models using NLP (Must), machine learning, deep learning, and other newer statistical techniques, should have worked on Python
Don’t disappoint yourself by not finding your type of job requirement. If you feel you have the talent and you can contribute to our growth, mail your resume and write to us the areas where you can contribute at careers@mystro.in",-1,Mystro,Mumbai,"San Francisco, CA",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Breeding Design Scientist,-1,"Job Description

PURPOSE:
Leads the design, development, implementation and execution of new innovative genomic and data science approaches for future product design strategy in alignment with product concept and portfolio need to deliver genetic gain in short and long term for multiple APAC pipeline across corn, Rice, Cotton, Pearl Millet and Mustard, valued at ~ $300M annual sales

Build a strong linkage with Pipeline Breeding, Discovery Breeding, Product Systems, Field Testing, APD, APC and Biotech functions to develop product concept driven future product design and robust analytics driven product advancement plan

WHAT YOU DO:
Exploration of haplotype data and germplasm to map haplotypes for key traits for different APAC markets
Working on haplotype explorer tools and identification of key haplotypes. Report preparation and sharing with pipeline breeders and discovery teams for use in breeding programs
Supporting pipeline breeding and discovery team to formulate plan to introgress key haplotypes in XDs and develop breeding populations
Understanding the global germplasm mining and GWAS strategy and develop a similar plan for Asia germplasm and allele mining
Working with discovery scientists to build a hap catalogue for Asia and tropical germplasm
GWS model accuracy review and action item planning with breeding and APD. Implementing plans to improve accuracy for all APAC pipelines
Data quality check
Periodic GWS model retraining plan implementation coordination with breeding and APD. Incorporation of negative selections for better model performance
Working with plant health, discovery and breeding teams to explore plant health native traits and plan to incorporate them in GWS model
Model performance review and execution to enhance selection efficiency
GWS fate analysis using historical selections and support pipeline breeders for decision making
Making GWS implementation plan and timeline mapping for rice in coordination with pipeline breeders, discovery and APD. Phenotypic data review, quality check. Model performance review and improvement planning
Planning and implementation APAC origin prediction model for different APAC pipelines
Coordination with pipeline breeders and APD to use appropriate data for origin prediction, review and quality check
Model performance review and performance analysis of SC2 and stage less models. Working with breeding and APD teams to improve model accuracy
Fate analysis and model performance review
Action item preparation for in time model retraining
Execution of long term predictive analytics strategy for Rice (cotton)

Required Candidate profile

PhD in quantitative/statistical genetics or plant breeding or animal breeding with expertise in the field of data science, analytics.
Working expertise in R programming language is desirable
3+ years of experience in data science, discovery breeding or related field
Handling of genetic marker data, large phenotypic data, haplotype database will be added advantage
Ability to deliver innovative and creative solutions to complex problems. Ability to think and develop innovative information systems.
Independent, self-motivated and assertive with a results orientation.

Salary: Not Disclosed by Recruiter

Industry:Agriculture / Dairy

Functional Area:Other

Keyskills
discovery breeding
haplotype
GWAS
germplasm
Genome - wide Association Study
haplotype database
Pipeline Breeding
statistical genetics
plant breeding
rice
data quality
breeding data science
data science
genomics
predictive analysis
R programming
Desired Candidate Profile
Please refer to the Job description above

Education-

UG:B.Sc - Other Specialization, Agriculture, Maths, Statistics

PG:MS/M.Sc(Science) - Statistics, Other, Agriculture, Biotechnology, Data Informatics

Company Profile

Bayer Group

Bayer CropScience Ltd.",3.5,"Bayer Group
3.5",Bengaluru,"Las Vegas, NV",201 to 500 employees,-1,Company - Public,Vehicle Dealers,Retail,₹5 to ₹10 billion (INR),-1
AP - Data Science Consulting LT00,-1,"Introduction
As a Strategy Consultant at IBM, you will help reinvent businesses and industries by developing and utilizing specialized knowledge of industry-specific and cross-industry competitive strategies. You'll manage complex components of an engagement, working closely with clients and their customers to understand their pain points. Your strategic recommendations will drive change in a digitally-enabled era and give you the opportunity to collaborate with highly talented IBMers. Are you ready?

Your Role and Responsibilities
Deep data science skills, including the knowledge of statistical and machine learning based predictive model development.
Prior experience of framing and running a comprehensive data science program for a large enterprise.
Driving last mile consumption of models and insights with a variety of stakeholders, including the program sponsor, various Lines of Businesses. Branches/Channels, Field Staff,
Should have led feedback loop from the field back to into program to improve the accuracy, relevance, effectiveness and adoption of models and insights based decision making.
Developing C-Suite relationship and consistently winning client confidence on a range of program objectives.
Ability to collaborate with disparate partes and be able to drive alignment on business objectives, deliverables and has a closure mindset.
kwd1xyabc

Required Technical and Professional Expertise
15+ Years of relevant experience.
Post Graduate in one of the the following quantitative and/or business degrees, mathematics, statistics, computer science, engineering, economics/econometrics, business management with under graduate in quant.
Preferred Technical and Professional Expertise
Should have led a large and diverse skill set team consisting of data scientists, data engineers, business insight generator, AI geeks.
Ability to travel extensively
Extensive experience in third party services and consulting
About Business Unit
IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",New Delhi,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Engineer,-1,"Posted on: 2019-04-22

Job Function Role : IT

Industry : IT - Software

Job Registration No : LCS2681254

Job Location : Mumbai

Selection Process : Face to Face Interview,

Do you Need Back Log Allowed : NO

Do you Need Travell Required : No

Do you Need Bond : No

Do you Need InnRotation Shift : Yes

Job Responsibilities:
Good understanding of RDBMS NoSQL databases (Key/Value, Document, Column family, Graph databases), Apache SOLR, MongoDB, Cassandra, practical experience in SQL, Java, Python, Scala, And good to have experience in ETL using tools/languages like Informatica, Python, Perl, Bash, Autosys and Tableau, Qlikview.",-1,Ladder Consultancy Services,Mumbai,"Chennai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Locations: Bangalore, New York

Alphonso data platform processes hundreds of millions of data-points about tv and adviewership data from the entire country. We plan to continue to invest in drawing deep insights from this vast pool of tv data. You will be responsible for developing scalable data models, machine learning algorithms to unlock new insights from TV data, innovate on targeting algorithms and data graphs to drive the business value further.

Requirements:
PhD in Computer Science or equivalent.
8+ years in handling high volume (hundreds of millions of records) data sets
Proficiency in one or more of Python, Java or JavaScript
Experience with machine learning algorithms and/or statistical modeling
Familiarity with Big data technologies like Hadoop, Map/Reduce, Spark, Hive etc. is a plus",4.1,"Alphonso
4.1",Bengaluru,"Mountain View, CA",51 to 200 employees,2012,Company - Private,TV Broadcasting & Cable Networks,Media,Unknown / Non-Applicable,-1
Lead Data Scientist,-1,"About Wells Fargo India Wells Fargo India enables global talent capabilities for Wells Fargo Bank NA., by supporting business lines and staff functions across Technology, Operations, Risk, Audit, Process Excellence, Automation and Product, Analytics and Modeling. We are operating in Hyderabad, Bengaluru and Chennai locations. Department Overview Product, Analytics and Modeling (PAM) brings a team member-based approach to the international talent pool focusing on analytical requirements. PAM encompasses roles that deliver meaningful insights, analysis and reporting based on skills, experience and judgment to support the Enterprise Analytics and Data Science (EADS) organization operate successfully today, and continue on the right trajectory to operate successfully in the future. About the Role Advanced Analytic Consultant 4 is a partner-facing role and is responsible for delivering high impact analytic and data science projects by using analytics, in support of operational risk initiatives across consumer lending. This role supports analytics requirements for Credit Bureau Oversight and Quality reporting along with reporting for Issues Management. EADS is the central analytics group tasked with solving high-impact business challenges and standing up cutting-edge analytical capabilities to be shared across Wells Fargos analytic community. We are looking for a high performer to join our team and help us solve challenging and interesting business problems through rigorous data analysis and predictive modeling. In this highly consultative and visible role, you will support development analytic projects from multiple business lines using various technology and techniques ranging from but not limited to supervised, unsupervised and semi-supervised machine learning, deep-learning, NLP, optimization algorithms in both edge nodes and in big data environments (like hortonworks, MapR, Aster etc.) Responsibilities : Person would be required to work individually or as part of a team on data science projects and work closely with business partners across the organization. He/she would be developing statistical/machine learning models using various techniques (supervised, unsupervised, semi-supervised) and technologies including but not limited to R, Python, Spark, H2O, Aster etc. Work closely with data engineers, BI and UI specialists and deliver top notch analytical solution for the bank. Define business problem and translate it into analytical problem 49161",3.6,"Wells Fargo
3.6",Bengaluru,"San Francisco, CA",10000+ employees,1852,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),-1
Data Analyst,-1,"If you meet our position requirements and can see yourself at Course5, we invite you to apply by e-mailing your resume and cover letter to careers@course5i.com. Please include the job title in your subject line. Sorry, no telephone calls please.
1

Company Course5 Intelligence Pvt. Ltd.

Position Title Sr. Data Scientist

Location Mumbai

OVERVIEW

COURSE5 INTELLIGENCE

We enable organizations to make the most effective strategic and tactical moves relating to their customers,
markets, and competition at the rapid pace that the digital business world demands. Founded in 2000, our business
areas include Market Intelligence, Big Data Analytics, Digital Transformation, Artificial Intelligence, and Analytics.
Rapid advances in Artificial Intelligence and Machine Learning technology have enabled us to create disruptive
technologies and accelerators under our Course5 Intelligence suites that combine analytics, digital, and research
solutions to provide significant and long-term value to our clients.

More information is available at www.course5i.com

GLOBAL OFFICES

United States | India | United Kingdom | Singapore | United Arab of Emirates

SPECIFIC RESPONSIBILITIES

At Course5, we drive Digital Transformation for businesses through Analytics, Insights, and Artificial Intelligence.

We build for organizations the capabilities and intelligence to make the most effective strategic and tactical

moves related to customers, markets, and competition. Over these years, we have built various solutions and

products catering to the Marketing, Merchandising, CX, Sales, Supply Chain, Research and Operations teams of

the fortune 500 enterprises, and we are proud to serve the top 4 companies in the world in-terms of their

market cap.

We are using best of breed technologies in all our solutions and products, such as Hadoop, Spark, Cassandra,

MongoDB, Kafka, Storm, AWS S3, AWS EMR, Redshift, Azure DW, Azure Data Factory and Azure Data Bricks. The

successful candidate will be working in a fast paced, dynamic team environment, building brand new commercial

products which are at the heart of our business.

The candidate will work along with other data scientists, developers, architects and analysts to develop products

that generate key actionable insights for our clients using different mediums such as Chatbot, Voicebot,

Collaboration Portal, Visualization platforms like PowerBI and Tableau by applying various machine learning and

data science techniques on proprietary as well as open data sources. The person will need to coordinate with

Product Managers, Industry Analysts and Technology experts to develop and deliver the product in accordance

with customer requirements and agreed timeline.
Drive complex analytical projects by leading and participating in tasks that use advanced statistical
modeling and machine learning techniques
Apply knowledge of various machine learning techniques and best practices in data science to improve
existing analytics products or develop new products
Research new or adapt existing machine learning approaches to novel practical problems
Employ efficient algorithms for data mining and visualization
Work with business stakeholders and product managers to deliver outstanding products that exceed
customer expectations

2
Handle project management and stakeholder management activities and take full ownership of quality
and timeliness of product deliverables.
Train and mentor junior team members on use of correct statistical techniques and logical frameworks
for problem solving

REQUIRED KNOWLEDGE, SKILLS AND ABILITIES
4-5 years of progressive experience in Advanced Analytics / Data Science
Good understanding of fundamental concepts in statistics, predictive modeling and forecasting,
statistical learning, machine learning and experience applying them in real world projects
Ability to perform complex data analysis and statistical modelling in one or more: Python, R, Java, Scala
Knowledge of RDBMS concepts and experience working with SQL
Understanding of data visualization principles and experience with data visualization tools
Master’s degree in a quantitative discipline (Computer Science, Data Science, Mathematics, Statistics) or
data science certification from premier institute.
Experience in leading complex analytical projects, leading data scientists and managing stakeholders
Experience working with unstructured/semi-structured data
Experience using big data tools for data manipulation and modeling (Spark, BigQuery, Hive, MongoDB,
Cassandra etc.)",3.4,"Course5
3.4",Mumbai,"Mumbai, India",1001 to 5000 employees,2000,Company - Private,Consulting,Business Services,₹10 to ₹50 billion (INR),-1
Business Data Analyst,-1,"At 1CloudHub we are looking for Data Analyst(BA-PM), with 8-12 years of experience who could front end our Data Analytics, AI/ML projects. We are looking for leaders with a sharp focus and willingness to learn and adapt to new technologies.

Position

Business Data Analyst

Experience

We are looking for someone who has:
Excellent written and verbal communication skills, able to tell the data story
Experience in managing projects of medium size with 5- 10 members
Project delivery experience using both waterfall and iterative delivery methodologies
Previous experience working in data centric projects in either a data or business analyst or data architect role
Previous experience doing data analysis using both structured and unstructured data sets
Understands data policy and data protection legislation to ensure security and apply to data requirements
Experience of conducting analysis with large unstructured data sets
Experience of prototype-enabled delivery, allowing for discovery/innovation based delivery approaches as part of overall delivery lifecycles
Experience of conducting data analyses with cloud based technologies (AWS)
Experience of using a variety of tools such as SQL, Hadoop, Hive, Pig, Impala, Python and R
Experience of using visualisation tools such as Power BI and Tableau
Job description

As an Business Data Analyst at 1CloudHub, you will:
Identify data availability and define sourcing strategies to address data gaps for existing and new Enterprise solutions
Define multiple data sourcing approaches and strategies for the given scenarios
Provide insight into the quality and usefulness of data through data profiling and data analysis techniques
Plan, manage and control the project to deliver the defined scope within the schedule and cost
Collaborate with source system owners to build an inventory of data sources
Define the end-to-end data quality management lifecycle articulating how data quality needs to be managed from source to its target
Support and drive data quality assessments
Expected time to onboard

Immediate or < 30 days.",-1,1CloudHub,Tamil Nadu,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist_ Fraud,-1,"Job Description

1. What we are looking for

1.
Must-Have: Should have hands on
experience with Machine learning models like Logistics regression, Survival
analysis model, Gradient Boost, Collaborative filtering, Bayesian, SVM, Random
Forest, NLP techniques etc.

2.
Prior experience in
predictive model building using Python/ pyspark

3.
Excellent knowledge
of R &-or Python (must) and other stati stical tools

4.
Masters Statistics,
Mathematics, Computer Science or another quantitative field

5.
Minimum 2-3 years’
experience in programing in Python/ pyspark. Excellent programming skills must

6.
Minimum 1-2 years
documentation skills using GitHub based data science solution development

·

7.
Good to Have: Experience
in time series concepts like stationarity, auto correlation, cross correlation,
trend analysis, ARIMA/ ARMA and statistical modelling like regression and
classification

8.
Past experience in
statistical concepts like Normal, Poisson and Weibull Distribution, hypothesis
testing, maximum likelihood estimation

9.

Minimum
1-2 years’ experience in distributed agile

·

Job Function

TECHNOLOGY

Role

Scientist

Job Id

159055

Desired Skills

Machine Learning | Python | R Programming | Fraud Management and Forensics

Desired Candidate Profile

Qualifications :
BACHELOR OF TECHNOLOGY",3.8,"Tata Consultancy Services
3.8",Mumbai,"Mumbai, India",10000+ employees,1968,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Accenture, IBM, Infosys"
Lead Data Scientist,-1,"<
Lead Data Scientist - Computer Vision

About the job :
Experience: 5-10 Years.
Job Type: Full-time.
Location: Chennai or Mumbai.

Duties & Responsibilities:
Responsibilities include Identify, develop and implement the appropriate Computer Vision algorithms and Deep learning / ML Models to create new, scalable solutions that address business challenges across industry domains , as well as provide actionable insights with a clear impact on ROI. Define and develop, maintain and evolve data models, tools and capabilities. Communicate your findings to the appropriate teams through visualisations. Collaborate and communicate findings to diverse stakeholders. Ability to build, train and lead a team of data scientists.

Preferred Qualification:
Bachelors/ Masters/ PhD degree in Math, Computer Science, Information Systems, Machine Learning, Statistics or related technical degree with ability to break complex business problems.
5-10 years total experience with minimum of 2 years of experience in a related position, as a
data scientist building computer vision solutions for various types of business problems.
Advanced knowledge of statistical techniques, machine learning algorithms and deep
learning frameworks like Tensorflow, Keras, Pytorch.
Minimum 3 years of Programming background and expertise in building models using at
least one of the following languages: Python, R ,Java, C,C++.
Implementation of deep learning based models for image classification, Document
classification models, object detection, logo detection, Object tracking.
Strong individual planning and project management skills, able to juggle multiple tasks and
priorities Self-motivated and driven to deliver agreed results on-time.
Strong storytelling & articulation skills - ability to convert analytical output into clear,
concise, and persuasive insights & recommendations for technical & non-technical audience.
Strong influence and relationship management skills; comfortable interacting with all
management levels; Prior experience in providing strategic analysis and consulting.
Track record of delivering strong business results.

If you think you fit in with the above requirements we'd love to talk to you about working in our organization.

To apply for this job please send your resume to connect@blackstraw.ai

Location :
Blackstraw.ai , Chennai, 4th floor, Tower C, Ratha Tek Meadows Rd, Elcot Sez, Sholinganallur, Chennai, Tamil Nadu 600119, India",4.6,"Blackstraw
4.6",Chennai,"Tampa, FL",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Computer Vision/Deep Learning Research Scientist,-1,"Job Title : Computer Vision/Deep Learning Research Scientist
Job Location : Bangalore, India
Job Description :

- A world-class research lab that excels at novel product development through fundamental architecture research. -
Looking for highly qualified, dynamic researchers for path breaking research in Architectures for Computer Vision and Deep Learning.
Next generation image processing and associated real-time, low-power programmable/accelerator hardware architectures for Computer Vision and Deep Learning is the focus of this research thrust.
Optimized implementations of geometric methods in Computer Vision Multi view Geometry, SLAM, SfM etc, Inertial visual sensor fusion, real-time image-based rendering techniques, 3D reconstruction, Deep Learning based recognition methods in Computer Vision will all be explored. - This will be done in collaboration with teams across the globe evaluating, researching and co-developing new algorithms and hardware architectures for emerging new world applications like Augmented Reality AR, Virtual Reality VR and drones.
All Research Scientists will advance the state-of-the-art in deep collaboration with product architecture/design teams while also contributing to scientific literature/conferences and developing Intellectual Property.
Main responsibilities
Hardware-oriented Computer-Vision/Deep-Learning Research Scientists will be responsible for power/area/performance driven architecture, microarchitecture development and optimization.
Activities include Logic design, RTL-to-GDS synthesis, layout optimizations and FPGA emulation.
Algorithm/software-oriented Computer-Vision/Deep-Learning Research Scientists be responsible for research and development of new algorithms and their optimization for high performance and quality, and highly efficient mapping and implementation to hardware.
Qualification :

Candidate Should hold -
PhD or advanced MS in EE/CS
Research background
Job Posted : 2017-09-13",-1,Approgence,Bengaluru,"Irvine, CA",1 to 50 employees,2006,Company - Private,IT Services,Information Technology,₹500 million to ₹1 billion (INR),-1
Data Engineer,-1,"When everything's connected, how we connect is everything… and we'd like to connect with you too! We are looking for you to help us deliver exceptional customer experiences as a Data Engineer.

As a technologist, we know you’re in high demand. And we know it’s important you find the right fit for your future. Have ideas you want to contribute? We’re listening. Looking for exposure to different clients, different technologies? It’s what we do. Want to make an impact on the future? We’re innovating every day. Teamwork key? You'll have the opportunity to work on global projects with a knowledge-thirsty, international team. Join our inclusive Corporate IT team and you’ll help create meaningful employee experiences that drive memorable customer experiences.

What you’ll be doing
The data engineer will be responsible for all aspects of execution and delivery for new and ongoing client implementations of the analytic platform. This will require working with clients and coordinating with internal business consulting, analyst, data science, and technology teams.
Technical and functional analysis of customer implementation and integration requirements
Documentation of implementation requirements and expected effort
Configuration and setup of the analytics platform
Configuration of data loaders and development and configuration of workflow processes and customizations to the platform
Participate in testing
Proactive identification of internal and external dependencies, highlighting issues, scope changes, and progress against project plan
Communication of project status/issues to clients and internal management
Partner with various internal teams
Provide technical support to assist clients and partners during and post implementation.

What you'll bring to the role
Bachelor’s Degree in Computer Science, Information Systems or related with 2-3 years of relevant experience
In-depth familiarity with Big data technology and its application.
Proficiency with the Azure or AWS ecosystem
Experience with Big Data ETL
Understanding of complex data flows, identification of data processing bottlenecks and designing and implementing solutions.
Proficiency in .NET, C#, Python, Linux bash, Power Shell.
Experienced in consuming third-party REST APIs (JSON) and SDKs
A broad set of technical skills and knowledge across hardware, software, systems and solutions development and across more than one technical domain.
Experienced in U SQL, PostgreSQ, TSQL
Experience in professional services or technical consulting with enterprise software solutions, specifically enterprise software installation, configuration, customization, and testing.
Proven ability to balance and manage multiple, competing priorities.
Collaborative interpersonal skills and ability to work within cross-functional teams.
Self-starter who relies on experience and judgment to plan and accomplish goals in complex fast-paced environment to ensure quality of all data integration points.
Excellent customer service skills.
Creative problem-solving and analysis skills.
Ability to handle problem situations quickly, inventively, and resourcefully.
Project management skills including:
Ability to prioritize and manage tasks
Ability to plan, commit, and deliver to schedules
Ability to identify, escalate, and manage project issues
Willingness to work extended hours on an as-needed basic

#LI-IG1",3.4,"TTEC
3.4",Hyderabad,"Englewood, CO",10000+ employees,1982,Company - Public,Staffing & Outsourcing,Business Services,₹100 to ₹500 billion (INR),"Teleperformance, TaskUs, Convergys"
Consultant Data Scientist-(H/F),-1,"Et si c’était vous ?

Bac +5 en école d’ingénieur, master Data Science

Bon niveau d’anglais

Compétences métier :

- Expertise en statistiques et mathématiques appliquées : Connaissance machine Learning, analyse prédictive à partir de différentes bases de données

- Programmation informatique : Python, R, C++

- Algorithmie et gestion des bases de données : SQL, noSQL, MapReduce, Hadoop

- Forte curiosité intellectuelle : intérêt pour le secteur bancaire, vision sur les enjeux stratégiques

- Sens du résultat, pragmatisme

- Capacité à communiquer ses analyses notamment en utilisant des outils de visualisation de manière claire avec une orientation décision

- Autonomie / esprit d’initiative

- Esprit d’équipe / capacité d’écoute / sens des responsabilités

Plus qu’un poste, un tremplin

“We are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status”.

Pourquoi nous choisir ?

Societe Generale Global Solution Centre (SG GSC), a 100% owned subsidiary of European banking major Societe Generale (SG), Our role and purpose is to enable the strategic vision of Societe Generale Group. We are doing this by pioneering cutting edge innovation from Design Thinking to Smart Automation & Artificial Intelligence, and applying it to banking.

SG Global Solution Centre provides services in the areas of Application Development and Maintenance, Infrastructure Management, Business Process Management, and Knowledge Process Management, to Societe Generale's business lines around the world.

“We are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status”.",3.5,"Société Générale
3.5",Bengaluru,"Paris, France",10000+ employees,1864,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"BNP Paribas, Natixis, Calyon Securities USA"
Data Analyst,-1,"Work Location: Chennai

Required Experience: 3 - 5

Job Description:
Knowledge on R Programming, VBA, Macros
Proficient in Microsoft excel with exposure on Pivot tables, Vlookup, logic formulas
Presenting various analysis and reports to the management as and when required
understanding of Marketing and the importance of clean/ accurate lists.
Understanding of data privacy & compliance (ie: GDPR)
Demonstrated experience in design, develop and maintain BI reports, optimizing efficiency in manipulating data and writing complex queries
Build an understanding of business and operational strategies and identify critical metrics required to support those strategies
Experience in working with large datasets,derive insights and present information through visualization and reports",4.7,"iKomet Technology Solutions
4.7",Chennai,"Chennai, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst Intern,-1,"Role requires the ability to interpret data from different sources, analyze data and communicate how to apply findings to the business models and needs for the company. Your interpretation of the data will require a large amount of interaction with other teams to understand what the sources of data are, how this data might affect the business and its processes, and what problems are being solved by drawing conclusions from the data that has been collected.
*
Qualifications:
BE/ B.Tech/ ME/ M.Tech/ MCA/ MSc - CSE, ECE, EEE, Statistics, Math, Economics

BSc Statistics, Math, Economics , BCA, BSc IT etc
A passion for helping organizations understand how to solve problems through analytics.
Ability to manage simultaneous tasks in a fast-paced, technology-oriented environment.
Job Types: Full-time, Part-time, Internship, Fresher

Salary: ₹25,000.00 - ₹30,000.00 per month

Education:
Bachelor's (Required)
Work Remotely:
Temporarily due to COVID-19",-1,iBAX,Chennai,"Chennai, TN",Unknown,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"Description:

We are looking for a passionate experienced & Certified Data Analyst. The Successful candidate will turn data into information, information into insight and insight into business decisions.

Data analyst responsibilities include conducting full life cycle analysis to include requirements, activities and design. Data analysts will develop analysis and reporting capabilities. They will also monitor performance and quality control plans to identify improvements.

Responsibilities:
Interpret data, analyze results using statistical techniques and provide ongoing reports.
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.
Acquire data from primary or secondary data sources and maintain databases/data systems.
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and ""clean"" data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities
Be able to develop a clear under stand of user behavior and interpret patterns that can help improve experience
Requirements
Proven working experience as a data analyst or business data analyst.
Should have worked on tracking and analyzing data for web and/or mobile apps.
Experience with Google Data Studio, Mix panel would be highly beneficial.
Technical expertise regarding data models, data base design development, data mining and segmentation techniques.
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Java script, or ETL frameworks).
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc).
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
Adept at queries, report writing and presenting findings.
BS in Mathematics, Economics, Computer Science, Information Management or Statistics.
Powered by JazzHR",3.8,"BuzzBoard
3.8",Hyderabad,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Sr Data Engineer-Master Data Management,-1,"Data Engineer

The data engineering role is team member that will help source, cleanse, load, curate, and automate master data processes for IE 2.0. In addition to these processes, this role will work with external and internal business partners and leaders to capture business requirements and help develop queries, datasets, and processes to support the business.

This individual will apply developed subject matter knowledge to solve common and complex business issues and recommend appropriate alternatives. The daily work will consist of solving problems that are of diverse complexity and scope, while exercising independent judgment within generally defined policies and practices. This role will require handling unique or unclear requirements and seek advice from team members and leaders in order to make decisions on complex business issues.

Responsibilities
Works with other data engineers and architects to establish secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data platform, repositories or models for structured/unstructured data.
Analyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.
Writes and executes complete testing plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs, and creates solutions for issues with code and integration into data system architecture.
Collaborates and communicates with project team regarding project progress and issue resolution.
Works with the data engineering team for all phases of larger and more-complex development projects and engages with external users on business and technical requirements.
Collaborates with peers, engineers, data scientists and project team.
Typically interacts with high-level Individual Contributors, Managers and Program Teams on a daily/weekly basis.
Helps define and lead portions of project requirements for data exchanges and business requirements with externals and internal teams
Creates plans, data collection and analysis procedures and works with data insight visualization teams for assigned projects.
Collaborates with internal and external partners to perform experiments and validations in accordance with overall plan.
Collaborates with SMEs to develop procedures for collecting, recording, analyzing, and communicating data for review and feedback.
Knowledge and Skills
Using data engineering tools, languages, frameworks to mine, cleanse and explore data.
Fluent in relational based systems and writing complex SQL.
Fluent in complex, distributed and massively parallel systems.
Strong analytical and problem-solving skills with ability to represent complex algorithms in software.
Designing data systems/solutions to manage complex data.
Strong understanding of database technologies and management systems.
Strong understanding of cloud-based systems/services, including the AWS environment.
Database architecture testing methodology, including execution of test plans, debugging, and testing scripts and tools.
Excellent written and verbal communication skills; mastery in English and local language.
Ability to effectively communicate product architectures, design proposals and negotiate options at management levels.
Using scientific design and data collection methodologies, tools and analysis packages to collect, validate, and analyze research data.
Strong analytical and problem-solving skills.
Application and implementation of experimental design, scientific procedures and processes, and data analysis.
Excellent written and verbal communication skills; mastery in English and local language.
Ability to effectively communicate research plans, proposals, and results, and negotiate options at management levels.
Collaborates with peers, junior data scientists and engineers, SMEs and external and internal research and product development partners.
Typically interacts with high-level Individual Contributors, Managers and Program Core Teams.
Experience
Bachelor's or Master's degree in Computer Science, Information Systems, Engineering or equivalent.
More than 8 years experience in a data engineering / data analyst role.
#Elitepost",4.1,"HP Inc.
4.1",Bengaluru,"Palo Alto, CA",10000+ employees,1939,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Scientist- NLP/Deep Learning- Mumbai (5+ years).,-1,"An exciting techno-functional job opportunity for a professional holding at least 3 years as Data Scientist. Our distinguished client is looking for smart, pliable developer who is keen to develop their career into Data Science, Deep Learning and Analytics. You will lead end to end implementation and development of our client product from scratch and work on cutting edge technology such as Deep Learning and NLP.

Location: Mumbai

Your Future Employer: A Leading provider of investment research serving different market regions across the globe.

Responsibilities:
Designing and developing flexible enterprise solutions.
Improving complex data flow, data structures to move to next platform.
Building solutions incorporating numerical techniques such as ML, statistics and optimization
Developing areas of continuous and automated development.
Interacting with both upstream and downstream stakeholders.
End-to-end responsibility for model development, including data exploration, training data, feature extraction and model development, validation and scoring.

Requirements:
Minimum of 3 years of experience in data science
Expertise in either Python or Java.
Basic knowledge of ML/Ai/statistical algorithms.
Experience n back end XML ,relational and file based databases.
Experience in developing solutions using services in AWS ecosystem.

What is in store for you?

A meritocratic culture with great career progression.
Fast track career growth.
Work in a dynamic environment for an established research and analytics brand and their Fortune 500 clients.

Reach Us:
If you think this role is aligned with your career, kindly write me an email along with your updated CV on riddhi.sharma@crescendogroup.in for a confidential discussion on the role.
Reference Number: 833
Contact Details: Riddhi Sharma
Profession: Analytics > All
Company: Client of Crescendo Global
Date Posted: 25/07/2020",4.6,"Crescendo Global Services
4.6",Maharashtra,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Staffing & Outsourcing,Business Services,₹100 to ₹500 million (INR),"PageGroup, Hays, Russell Reynolds"
Data Analyst,-1,"Team Lead - CDM/PV

Qualification:

Graduate/Post Graduate/ Doctorate degree in life sciences/Pharmacy/Medical sciences/Registered Nurse

Responsibility:

Business/ Customer:
Minimal Customer interaction under guidance.
Understands Domain Process/sub process, functions, terminologies (such as SOP, QC checklists).
For PV/Complaints Management :
Individuals in this role perform data entry of data received from Source documents into the respective Clinical/Safety database While peroforming this activity the associate is responsible for meeting turnaround times and accuracy.
These associates are usually used to handle more critical/senitive transactions.
These associates also act as Subject Matter Expert.
CODING:

Perform coding activities on the assigned project with timelines and efficiency
• Import uncoded terms in database and export coded medical terms from coding platform.
• Query Management.
• Create “New Term Request” and prioritize.
• Perform Dictionary upversioning activity.
• Send Coding (Consistency) Reports.
• Participate in study related meetings as needed.
• Provide feedback on quality related issues to other medical coders in timely manner.
• Serve as an SME to Medical Reviewers regarding coding activities & guidelines.
• Perform UAT for coding related applications.
• Perform Operational QC.
• Mentor Team Member.
• Coordinate with CDM working on the same study.
• Coordinate to resolve Rave specific issues.
CDM:
1 Execute Data Management Activities ie Data Cleaning, Executing Manual and System checks, Update relevant trackers, Discrepancy and query management, Issue resolution, Database lock activities.
2 Participate in innovation and process improvement initiatives.
3 Identify and develop action plan in coordination with the TL for activities not meeting the client SLAs.
4 Archive all necessary information for audit purposes according to quality and security requirements, to ensure reliable and timely retrieval of documentation and information.
5 Support multiple clinical trials, across diverse therapeutic areas, to successful conclusion and provide technical oversight when required.
Project / Process:
Attempts Complex problems (procedures/processes) and refers to Supervisor/Line Manager in rare cases.
Handle first level processing of transactions.
Adhere to quality requirements, achieve targets/volumes in given TAT(Turn around time).
Proactively identify issues.
Contribute to process improvement initiatives.
Identify and report process changes.
Adhere to the mandatory industry regulation and compliance requirements for the given process.
Knowledge Management:
Update Process documentation as appropriate for the process under guidance.
Participate in knowledge transfer.
People/Team Management:
Adhere to org hygiene and compliance needs in terms of.
a Personal Utilization & Time sheet submission.
b Personal and new hire Assimilation.
c Attendance.
d Team Initiatives.
Collate team performance metrics.
Manage break schedule/transport logistics for the team in the absence of his/her supervisor.

Must Have Skills
Customer Service
COTS Products(LS Mfg&SC)
Employee Status : Full Time Employee

Shift : Day Job

Travel : No

Job Posting : Apr 14 2020

About Cognizant

Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 193 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant.",3.7,"Cognizant Technology Solutions
3.7",Mumbai,"Teaneck, NJ",10000+ employees,1994,Company - Public,-1,-1,₹500+ billion (INR),"Tata Consultancy Services, Accenture, Capgemini"
Data Engineer,-1,"About Us :
Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. The Firm's employees serve clients worldwide including corporations, governments and individuals from more than 1,200 offices in 43 countries. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow. A philosophy that balances personal lifestyles, perspectives and needs is an important part of our culture.
Technology/Role/Department at Morgan Stanley:
Technology is the key differentiator that ensures that we manage our global businesses and serve clients on a market-leading platform that is resilient, safe, efficient, smart, fast and flexible. Technology redefines how we do business in global, complex and dynamic financial markets. We have a large number of award-winning technology platforms that help to propel our Firm’s businesses to be the top in the market. Our India technology teams are based in Mumbai and Bengaluru. We have built strong techno-functional teams which partner with our offices globally taking global ownership of systems and products. We have a vibrant and diverse mix of technologists working on different technologies and functional domains. There is a large focus on innovation, inclusion, giving back to the community and sharing knowledge.
Morgan Stanley is seeking an experienced and ambitious candidate to join their Enterprise Computing (EC) Site Reliability Engineering group as an automation development lead. The group is responsible for managing all the Linux-based infrastructure and middleware for the firm. This includes the virtualisation, OS, storage and web platforms, plus databases, messaging buses and other foundational services upon which developers build their applications. The group aims to provide fully automated management solutions to maximise the availability and stability of the infrastructure it manages.
Job Responsibilities
● The primary focus of this role is to lead a team of developers in building automation tools in python which control and manage the Morgan Stanley private cloud infrastructure platform.
o Oversee the quality of the technical deliveries, and the day-to-day supervision of the developers in his or her team or squad.
o Liaise with the infrastructure SMEs to agree on quantitative quality and delivery goals, and be accountable for those metrics.
o Act as scrum master for the squad when there is no dedicated scrum master available.
● The successful candidate will be responsible for mentoring and developing junior team members.
● The candidates should be comfortable reviewing code written by others and giving constructive feedback.
● They must demonstrate initiative, good judgement, be confident working independently and be comfortable handling sensitive, confidential information.

Primary Skills:
● 7 years of overall IT experience
● 3 years of experience of developing in Python, including the use of RESTful APIs, and how to write comprehensive unit tests;.
● Knowledge of software engineering concepts such as common data structures, object-oriented programming, and regular expressions.
● Comfortable working in a Linux CLI environment, using modern development and troubleshooting tools such as git, CI/CD pipelines, and tcpdump.
● Experience with Agile methodologies, GIT and CICD.
Desired Skills:
● Experience with using Ansible for large scale infrastructure automation.
Morgan Stanley is an equal opportunities employer. We work to provide a supportive and inclusive environment where all individuals can maximize their full potential.",3.8,"Morgan Stanley
3.8",Bengaluru,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
A++ Data Scientists @ Pune High Impact!,-1,"You will join a world famous Profitable Product Startup!

You Will :
Retrieve, prepare, and process a rich data variety of data sources such as social media, news, internal/external documents, emails, financial data, and operational data
Analyze and model structured data and implement algorithms to support analysis using advanced statistical and mathematical methods from statistics, machine learning, data mining, econometrics, and operations research
Perform Statistical Natural Language Processing to mine unstructured data, using methods such as document clustering, topic analysis, named entity recognition, document classification, and sentiment analysis
Utilize a diverse array of technologies and tools as needed, to deliver insights, such as R, SAS, Python, Spark, Hadoop, Qlikview, and Tableau
Translate advanced business analytics problems into technical approaches that yield actionable recommendations
Perform exploratory data analysis, generate and test working hypotheses, and uncover interesting trends and relationships.
Experience
2 to 4 years

Qualification

Master’s degree from an accredited college/university in Computer Science, Statistics, Mathematics, Engineering, Econometrics, or related fields, with five years of relevant experience and strong knowledge in at least one of the following fields: statistics, data mining, machine learning, statistics, operations research, econometrics, natural language processing, and/or information retrieval; PhD preferred.
Deep experience in extracting, cleaning, preparing, and modelling data; command-line scripting, data structures, and algorithms; and working in a Linux environment
Proficiency in analysis packages (e.g. R, SAS, Matlab) and programming languages (e.g. Python, Ruby, Java, Scala).
Write to Deepa.m@careerxperts.com to get connected!

Job Location
Pune",-1,CareerXperts,Pune,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"OakNorth is the next-generation credit and monitoring platform that provides banks and lending institutions with the insight and foresight needed to create a better borrowing experience for the Missing Middle – the growth business who are the backbones of communities and economies globally but who have been in banking’s blind spot for decades.

The business was founded in 2015 by Rishi Khosla and Joel Perlman, who previously co-founded Copal Amba and grew it to 3,000 employees over 12 years, before selling it to Moody’s (NYSE: MCO) in 2014, returning 125 times capital to seed investors.

Since its inception, OakNorth has secured over $1bn from several investors, including: Clermont Group, Coltrane, EDBI of Singapore, GIC, Indiabulls, NIBC, Toscafund, and SoftBank’s Vision Fund.

The Platform has been deployed at various banks across North America, Europe, and Asia, and in the UK where OakNorth lends off of its own balance sheet via OakNorth Bank. The platform has helped OakNorth Bank become the fastest-growing business in Europe according to the Financial Times FT 1000 (2020), profitably lending over £4bn to date. In terms of the impact this has had on the economy, OakNorth Bank’s loans have directly helped with the creation of 13,000 new homes and 17,000 new jobs in the UK, as well as adding several billion pounds to the economy.

With offices in London, New York, Manchester, Singapore, Hong Kong, Shanghai, Istanbul, Gurgaon and Bangalore, the global team across the OakNorth Holdings group is over 800 people.

Job Responsibilities:
Review raw financial data received in various formats and standardize its processing
Analyse and interpret acquired data from internal/external data sources and develop validations and a quality control process
Use internal proprietary tools to manipulate and migrate data into the Platform
Collaborate daily with other areas of the firm on execution of tasks
Design scalable data management and entry process solutions that can be readily implemented across the team
Model financial data to fit data templates
Perform due diligence on new sources quickly and identify data questions and concerns
Construct and maintain data dictionaries
Desired Skills:
3-6 years professional experience in a data-intensive role
Strong analytical skills
Excellent organizational skills, including attention to precise details
Have a solid working knowledge of MS Excel
Knowledge of VBA, SQL, Python, or other programing languages is a plus
Financial industry experience is a plus
Ability to handle multiple tasks, meet reporting deadlines, and demonstrate flexibility with delivery of assignments
Thank you very much for your interest in OakNorth. We are happy to consider you for roles within our group of companies. If we can identify a match between your skill set and our immediate recruiting needs, please expect to hear from us very soon. If we are unable to identify a fit in the near term, please note that we intend to retain the data you send to us so we may contact you in the future.",4.1,"OakNorth Bank
4.1",Bengaluru,"London, United Kingdom",51 to 200 employees,2015,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
Data Analyst,-1,"We are looking for a passionate Data Analyst. The successful candidate will turn data into information, information into insight and insight into business decisions.

Job Description:

Freshers with excellent communication and excel skills can apply
Proven working experience as a data analyst or business data analyst between 1 to 2 years will be a added advantage.
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
Understanding of utility value chain
Energy domain experience
Billing/Invoicing Background Preferably knowledge of energy market
Good Communication skills
Good with the numbers
Good Email writing skills
Immediate Joiners preferred
Job Type: Full-time

Pay: ₹15,000.00 - ₹18,000.00 per month

Experience:
Data Analyst: 1 year (Preferred)
Education:
Bachelor's (Required)
Industry:
IT Operations & Helpdesk
Work Remotely:
Temporarily due to COVID-19",4.8,"Proziod Analytics Pvt Ltd
4.8",Karnataka,"Bengaluru, India",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
AI/NLP Scientist (P.hd / MS must),-1,"Expert in developing code in Python
Strong programming skills with proven experience crafting, prototyping, and delivering advanced algorithmic solutions
A passion for making ML methods robust and scalable
Experience in extraction from structured/unstructured text (knowledge or statistics based)
Experience in one or more of the following areas: entity/relation extraction, normalization, text summarization, semantic search, word/paragraph/document embedding, ranking etc.
NLP algorithm implementation experience as well as the ability to modify standard algorithms (e.g. change objectives, work-out the math and implement)
Experience in deep learning approaches to NLP: word/paragraph embedding, representation learning, text/sentiment classification, ambiguity disambiguation
Experience with neural networks and deep learning frameworks (such as Keras, tensorflow, torch)
Familiarity with database queries and data analysis processes (SQL, Python, Java)
Background /Education
PhD/MS in Computer Science with focus on Natural Language Processing
Self starter who can be productive from the first day",5.0,"Sequoia Applied Technologies Inc.
5.0",Thiruvananthapuram,"Sunnyvale, CA",1 to 50 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,Altran Americas
Analytics Consultant,-1,"Analytical consultants will have the opportunity to leverage a wide variety of skills:
Lead overall project execution from India - starting from project design to analysis design and synthesis to final recommendations
Lead teams of analysts working on large-scale healthcare datasets using various database manipulation tools (SAS, SPS, Alteryx, etc.)
Synthesize and document/communicate results using PowerPoint slides and online visualization techniques
Work closely with onshore team to understand the business context and work with India team members to provide client ready deliverables
Mentor junior associates and help shape their growth
Help advance product offerings (existing or new) that help meet a unique need in the market
Responsibilities:

The position is expected to work at least 40 hours per week, and distribute work as per the tasks assigned. Here's an approximate breakout of time spent on different tasks:
Designing, analyzing and documenting high impact business solutions - 50%
Mentoring Junior associates and associate consultants-20%
Internal initiatives - includes contribution to scaling India operations and building capabilities- 20%
Enhance own and team's understanding of client's business - 10%
Consulting is a fast-paced environment, and the candidate will be open to learning new skills quickly and deliver work under tight timelines. Consultant needs to be flexible working with multiple clients and managing analysis to deliver high quality work.

Qualifications:

159 solutions seeks candidates with strong analytical, communication and project management skills. We welcome candidates with at least a bachelors in engineering/science and an MBA (preferred):
At least 4-6+ years of experience pre-MBA
Prior work in dealing with and comfort in quantitative problem solving
Ability to quickly learn the basics of healthcare and become an expert in proprietary data sets
High motivation, strong work-ethic and positive attitude while working under tight timelines
Strong attention to detail, and focus on quality
Good communication skills to effectively interact with 159 US team and clients through email, and phone
Willingness to mentor associates and dedication to continuous learning

Powered by JazzHR",3.6,"159 Solutions, Inc.
3.6",Pune,"Durham, NC",10000+ employees,2017,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹100 to ₹500 billion (INR),"PPD, INC Research, PRA Health Sciences"
Data Scientist -Phd,-1,"SkillData Scientist -Phd
Experience2-6yrs
Job Location:Bangalore.

Job Description:
Phd with atleast 1 year of relevant experience
Expertise in machine / deep learning, and used various complex algorithms related to NLP, Recommendation Systems, Scoring, etc.
Good knowledge on different Neural Networks (RNN, CNN), Tensor Flow, NeuMF, Google Cloud API, etc.
00-6.00 Years",3.1,"Indecomm Global Services India Private Limited
3.1",Bengaluru,"Edison, NJ",1001 to 5000 employees,2003,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),-1
Senior Data Engineer,-1,"Position Summary:

Quaeros Customer Data Platform (CDP) is the leading data management and analytics platform-as-a-service for marketers. This offering originated as an internal capability to drive Quaeros consulting practice and has evolved into an externally facing product offering. Your role is to continue driving this evolution, and to support further market penetration, through the rapid delivery of new features that delight our end users- data engineers, data scientists and marketing strategists.

In this role, you will contribute individually to both design and development. Well look to you to employ, instill and enforce best practices in product development and deployment as part of mentoring and further growing a high-performance development team.

Responsibilities:
Employ, instill and enforce best practices in product development and deployment
Provide leadership, in collaboration with peers, on overall system architecture
Commit and review code regularly. Demonstrate flexibility to overcome hurdles and drive velocity wherever you are most needed
Participate in cross-functional work planning- contributing your particular perspective on all facets of development life-cycle ranging from requirements, design, work planning, testing, delivery and support
Mentor and provide technical leadership to team members
Skills and Qualifications:
5-7 years of cumulative experience, in a principal engineer or senior engineer role, dealing with data intensive platforms.
Fluency in Java (Mandatory) and Scala(Preferred)
An engineer-at-heart that has demonstrated success at both individual contributor and leadership roles, in early stage and growth environments.
Ability to reference design patterns that solve a given problem the right way, addressing performance, robustness and scalability criteria
Drive efficient, high quality development operations through automation, systems thinking and unusually strong problem-solving skills.
High proficiency with end to end distributed applications using Spark, apache storm, (or similar technology).
Prior experience with streaming systems that used RabbitMQ, Kafka, Kinesis, EventHub or DataFlow at the core( preferred)
Experience utilizing JVM performance measurement tools and tuning approaches.
Understanding of containerization, Kubernetes, Swarms, ECS or similar deployment stack would be a plus
Delivering enterprise software for B2B customers, with digital and/or direct marketing exposure
Experience with both traditional(MYSQL/SQL Server) and distributed data base(Hive/ Hbase)
Experience with Oozie/Airflow(Preferred)
Demonstrated success as part of team employing agile product development and product management.
Powered by JazzHR",4.4,"Quaero
4.4",Bengaluru,"Charlotte, NC",51 to 200 employees,1999,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),-1
Data Science AI Ops Lead,-1,"Job Title: Data Science AI Ops Lead
Career Level: E1

Company
AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. But we're more than one of the world's leading pharmaceutical companies. At AstraZeneca, we're proud to have a unique workplace culture that inspires innovation and collaboration. Here, employees are empowered to express diverse perspectives and are made to feel valued, energized and rewarded for their ideas and creativity.

Role

We are looking for an AI Ops Lead to join our Data Science & AI team in Chennai. The ideal candidate will have industry experience working in a range of different cloud environments where they devised and deployed large-scale production infrastructure and platforms for data science. The position will involve taking these skills and applying them to some of the most exciting data & prediction problems in drug discovery.

The successful candidate will be part of building a new, close-knit team of deeply technical experts and together have the chance to create tools that will advance the standard of healthcare, improving the lives of millions of patients across the globe. This platform will support major AI initiatives such as clinical trial data analysis, knowledge graphs, imaging & omics for our therapy areas. You will also have responsibility to help provide the frameworks for data scientists to develop scalable machine learning and predictive models with our growing data science community, in a safe and robust manner.

As a strong software leader and an expert in building complex systems, you will be responsible for inventing how we use technology, machine learning, and data to enable the productivity of AstraZeneca. You will help envision, build, deploy and develop our next generation of data engines and tools at scale. You will be bridging the gap between science and engineering and functioning with deep expertise in both worlds.

Key Accountabilities
• Own the development roadmap to build and operationalise our data science environment, platforms and tooling.
• Support any external opportunities, through close partnership and engagement such as Benevolent.AI collaboration.
• Deployment of systems, applications and tooling for data science on cloud environments.
• Understanding of the necessary guardrails required for different use cases and data sensitivities.
• Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU).
• Provide the necessary infrastructure and platform to support the deployment and monitoring of ML solutions in production Optimizing solutions for performance and scalability.
• Liaise with the Data Engineering team to ensure that the platform and the solutions deployment therein benefit from an optimised and scalable data flow between source systems and analytical models
• Implementing custom machine learning code and developing benchmarking capabilities to monitor drift of any analyses over time.
• Understanding of the latest AI webservices and data science tools, from DataBricks to citizen data science tools like Dataiku, C3.AI and Domino. Experience working on regulatory data would be helpful but not essential.
• Liaise with other teams to enhance our technological stack, to enable the adoption of the latest advances in Data Processing and AI
• Being an active member of the Data Science team, you will benefit from, and contribute to, our expanding bank of Data Science algorithms and work efficiently with our data science infrastructure.
• Appreciation of how to optimise predictive models, run in production and monitor. Experience running a service team will be beneficial.
• Testing and assessing the quality of new tools.
• Line management responsibilities as well as team recruitment, training provision and coaching

Candidate Knowledge, Skills and Experience

• BSc in Computer Science or related quantitative field or MSc/Ph.D degree in Computer Science or related quantitative field.
• More than 2 years of experience and demonstrable deep technical skills in one or more of the following areas: machine learning, recommendation systems, pattern recognition, natural language processing or computer vision.
• Experience managing an enterprise platform and service, handling new customer demand and feature requests.
• Strong software coding skills, with proficiency in Python and Scala preferred.
• Significant experience with AWS cloud environments, working knowledge of Google and Azure platforms. Knowledge of Kubernetes, S3, EC2, Sagemaker, Athena, RDS and Glue is essential. Certification in appropriate areas will be viewed favourably.
• Experience with best practice of data transport and storage within cloud system.
• Experience building large scale data processing pipelines. e. g. Hadoop/Spark and SQL.
• Experience provisioning computational resources in a variety of environments.
• Experience with containers and microservice architectures e.g. Kubernetes, Docker and serverless approaches.
• Experience with automation strategies e.g. CI/CD, gitops.
• Use of Data Science modelling tools e.g. R, Python, SAS and Data Science notebooks (e.g. Jupyter).
• Creative, collaborative, & product focused.
• Ability to just get things done.

Other

The role will have line reports and task management responsibilities within project or services may occur.

Department – Data & Analytics, S&EUIT
Science and Enabling Units IT is a global IT capability supporting Drug Research, Drug Development, Product & Portfolio Strategy, Medical Affairs, Finance, HR, Compliance, Legal and Global Business Services. We are organized around 7 key capability areas: Business Partnering, Solution Delivery, Architecture, Application Support, Data & Analytics, Change & Operations, operating out of sites across the US, UK, Sweden, India and Mexico.

Data & Analytics provides analytics and data insight services and solutions critical to the Data & AI/ML emerging strategy and mission of S&EUIT and AZ. D&A is organized into teams specializing in Information Architecture, Data Engineering, Data Visualisation, Knowledge Management, Data Science, Data Analysis and Information Governance.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Date Posted

12-Feb-2020

Closing Date

AstraZeneca embraces diversity and equality of opportunity. We are committed to building an inclusive and diverse team representing all backgrounds, with as wide a range of perspectives as possible, and harnessing industry-leading skills. We believe that the more inclusive we are, the better our work will be. We welcome and consider applications to join our team from all qualified candidates, regardless of their characteristics. We comply with all applicable laws and regulations on non-discrimination in employment (and recruitment), as well as work authorization and employment eligibility verification requirements.",4.0,"AstraZeneca
4.0",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
Data Analyst,-1,"Part of Paytm wallet web/app/customer analytics team
Responsible to Analyze raw data, Manipulate, Cleanse and Process data using Hive/Sql/R/Python and throw insights on effectiveness of campaigns running on Paytm marketplace.
Responsible for performing data driven growth analytics for building topline and optimizing marketing spends
Key technical skills (not all are mandatory)
Expertise in Excel, SQL, R/Python
Experience with Big Data technologies preferably Hive, Spark
Familiarity with visualization tools like Tableau, Grafana
Familiarity with basic statistical techniques for prediction and optimization
Desired experience:
1-3 years in analytics firm or analytics divisions of e-commerce firms
Ability to work under high pressure
Structured problem solving",3.4,"Paytm
3.4",Noida,"Noida, India",1001 to 5000 employees,2010,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Technical Specialist - Data Scientist,-1,"Data Scientist

Location: Pune

Work Experience of 3-7 years

• Selecting features, building
and optimizing classifiers using machine learning techniques

• Experience in Python, R

• Develop custom data models and
algorithms to apply to data sets

• Experience in advanced
statistical techniques and concepts (GLM/Regression, Random Forest, Boosting,
Trees, text mining) and experience with applications.

• Experience in NLP and NLG

• Excellent written and verbal
communication skills for coordinating across teams

• Coordinate with different
functional teams to implement models and monitor outcomes

• Strong problem-solving skills
with an emphasis on data transformation

·

Knowledge and
experience in statistical and data mining techniques: GLM/Regression, Random
Forest, Boosting, Trees, text mining, etc.

·

Experience creating
and using advanced machine learning algorithms and statistics: regression,
simulation, scenario analysis, modeling, clustering, decision trees, etc.

• Experience working with and
creating data architectures

• Knowledge in Cloud Analytic
Services",3.4,"Birlasoft
3.4",Bengaluru,"Pune, India",5001 to 10000 employees,1990,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹10 to ₹50 billion (INR),"HCL Infosystems, Infosys, Accenture"
"Senior Data Scientist (Data Analysis, Machine Learning)",-1,"What's the role?


At HERE Technologies in Automotive Product Engineering organization, we are looking for highly skilled, self-motivated, Sr/Lead Data Scientist who is passionate about innovating and developing machine learning and data analytics solutions to build our industry-leading map. We provide the opportunity to collaborate with an energetic and dedicated team that works on cutting-edge technology to create tools and services. The candidate will work with researchers, developers, architects, IT to develop, deploy, and maintain applications in multiple environments.

What You’ll Get:
Challenging problems to solve
Opportunities to learn cool new things
Work that makes a difference in the world
Freedom to decide how to perform your work
Variety in the types of projects
Feedback so you will know how well you are doing
Collaborative, Supportive Colleagues
Responsibilities:
Help design and build the next iteration of process automation in HERE Content Engineering employing a highly scalable Big Data infrastructure and machine learning as applied to global-scale digital map-making.
Build and test analytic and statistical models to improve a wide variety of both internal data-driven processes for map-making data decisions and system control needs.
Act as an expert and evangelist in areas of data analysis, machine learning, statistics, and predictive analysis and modeling.
Function as a predictive modeling or application team lead.
Who are you?


• MS or PhD in a discipline such as Statistics, Applied Mathematics, Computer Science, Data Science, or others with an emphasis or thesis work on one or more of the following areas: statistics/science/engineering, data analysis, machine learning, computational geometry, and image processing.• 5+ years related, professional experience.• Knowledge of data mining and analytic methods such as regression, classification, clustering, association rules, decision trees, Bayesian network analysis, etc. expert-level knowledge in one or more of these areas.• Proficiency with a statistical analysis package and associated scripting language such as Python, C++, R, Matlab, SAS, etc. • Programming experience with SQL, shell script, Python, etc. • Knowledge of and ideally some experience with Cloud platform such as AWS, and the tools such as Pig, Hive, etc., for working with big data in Hadoop and/or Spark for data extraction and data prep for analysis.• Experience with and demonstrated capability to effectively interact with both internal and external customer executives, technical and non-technical to explain uses and value of predictive systems and techniques. • Demonstrated proficiency with understanding, specifying and explaining predictive modeling solutions and organizing teams of other data scientists and engineers to execute projects delivering those solutions.Preferred Qualifications: • Development experience with C++/Python/Shell Script• Development experience with Docker• Development experience with GIS data• Development experience with Relational Database/ NoSQL Database""

What we Offer

We will support you in delivering your day to day tasks and achieving your personal goals and develop your skills. Personal development is highly encouraged at HERE. You can take different courses and trainings at our online University and join cross-functional team projects within our Talent Platform. Our office is located with easy access by public transportation options. So, what are you waiting for? Apply now and make HERE your destination. We are just getting started...!

HERE is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, age, gender identity, sexual orientation, marital status, parental status, religion, sex, national origin, disability, veteran status, and other legally protected characteristics.

Make HERE your destination, we are just getting started! Apply now!

Who are we?


Ever checked in somewhere on social media? Ever tracked your online orders? You might be using HERE Technologies every single day without even realizing it. You can find us everywhere: in vehicles, smartphones, drones or third-party apps. We believe that with the right people, we will continue to be a game-changer in the technology industry and improve the daily lives of people around the world. Find out more by clicking the video below or going HERE.",3.7,"HERE Technologies
3.7",Mumbai,"Amsterdam, Netherlands",5001 to 10000 employees,1984,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Google, TomTom, Apple"
Customer Scientist,-1,"Customer Scientist

Who are we?

A young, fast-growing AI and big data company, with an ambitious vision to simplify the world’s choices. Our clients are top-tier enterprises in the banking, e-commerce and travel spaces. They use our core AI-based choice engine maya.ai, to deliver personal digital experiences centered around taste. The maya.ai platform now touches over 125M customers globally. You’ll find Crayon Boxes in Chennai and Singapore. But you’ll find Crayons in every corner of the world. Especially where our client projects are – UAE, India, SE Asia and pretty soon the US.

Life in the Crayon Box is a little chaotic, largely dynamic and keeps us on our toes! Crayons are a diverse and passionate bunch. Challenges excite us. Our mission drives us. And good food, caffeine (for the most part) and youthful energy fuel us. Over the last year alone, Crayon has seen a growth rate of 3x, and we believe this is just the start.

We’re looking for young and young-at-heart professionals with a relentless drive to help Crayon double its growth. Leaders, doers, innovators, dreamers, implementers and eccentric visionaries, we have a place for you all.

Can you say “Yes, I have!” to the below?
5+ years of experience
Knowledge of advanced analytics techniques, including Predictive Modelling (Logistic regression), segmentation, forecasting, data mining, and optimizations
Knowledge of software packages such as SAS, R, Rapidminer for analytical modelling and data management.
Experience in using Business Intelligence tools such as SAS, Microsoft, Tableau for business applications
Can you say “Yes, I will!” to the below?
Design algorithms for product development and build analytics-based product
Coordinate individual teams to fulfil client requirements and manage deliverables
Lead analytical projects and deliver value to customers
Communicate and present complex concepts to business audiences
Manage and strategize business from an analytics point of view
Travel to client locations when necessary
Requirements

You’ll get brownie points for:
An aptitude for analytical problem solving
The capability of working effectively in a global team",4.4,"Crayon Data
4.4",Chennai,"Singapore, Singapore",51 to 200 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Responsibilities:

As a ML Engineer at Noodle.ai, you will ensure that data science code is maintainable, scalable and debuggable. Automating and abstracting away different repeatable routines that are present in most machine learning tasks. You will be responsible to bring the best software development practices to the data science team and helps them speed up their work. Test machine learning libraries to their extremes, often adding new functionalities. Enabling production deployment of code, testability and accuracy metric tracking. You may have to look constantly for performance improvement and decide which ML technologies will be used in production environment.

Qualifications:

Must have
Bachelors/Masters in Engineering with 3+ years of industry experience
Solid engineering and coding skills. Ability to write high performance production quality code in Python.
Good understanding of Design Patterns
Experience in building containers using Docker
Experience with Numpy, Pandas, Keras, Pytorch, Tensorflow, scikit-learn libraries
Knowledge of Parquet, Apache Arrow, PySpark
Working experience on any one of the orchestration engines - Airflow / Kubeflow / MLFlow
Understanding of ML engineering lifecycle - modelling techniques, feature engineering, feature selection, model training, hyper parameter tuning, model evaluation, model serving
Nice to have
Experience in deploying applications to Kubernetes
Understanding of GPU architecture, Cudas, Rapids
Experience in distributed computing using any of Spark, Open MPI, MapReduce, Celery, Akka or equivalent frameworks
Knowledge of SQL databases - Postgresql, Mysql, MSSql
Exposure to No SQL data stores such as MongoDB/ Redis/ ElasticSearch/ Cassandra
Demonstrated energy and passion that extends beyond your field of study – Are you a computer scientist who writes poetry? A mathematician who loves psychology? An engineer passionate about public policy? We want to build something with you.",4.5,"Noodle.ai
4.5",Bengaluru,"San Francisco, CA",201 to 500 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1
Data Scientist Intern,-1,"Basic Qualifications
BS in computer science, or related technical, math, or scientific field
Working knowledge of deep learning, machine learning and statistics
User interface experience with Javascript, HTML
Knowledge of ETL tools and databases (both SQL-based, NoSQL)
Experience in using Python, R or Matlab or other statistical/machine learning software
Strong communication and data presentation skills
Amazon Internet Services Private Limited (AISPL), is seeking a talented, self-directed Intern Data Scientist to help use massive amounts of data to develop Machine Learning (ML) and Deep Learning (DL). The role will focus on public sector and healthcare, to derive business value through the adoption of Artificial Intelligence (AI). If you have experience with AI/ML-Data Science, including building ML or DL models, we’d like to have you join our team. You will get to work with an innovative company, with great teammates, and have a lot of fun helping our customers.

At Amazon Web Services (AWS), we are helping public sector healthcare build ML and DL models on the AWS Cloud. We are applying predictive technology to large volumes of data and against a wide spectrum of problems. Our AI/ML and Analytics team works together with our AWS customers to address their business needs using AI.

This role will support the public sector AI/ML & Analytics team of AISPL and contribute to creation of healthcare data models for programs categorized as high impact by AISPL.

We are looking for a talented individual who is capable of using ML and other techniques to design, evangelize, and implement state-of-the-art solutions for never-before-solved problems.

Roles & Responsibilities:
Design data architectures and data lakes
Provide expertise in the development of ETL solutions on AWS
Use ML tools, such as Amazon SageMaker Ground Truth (GT) to annotate data. Work with the team on designing workflow and user interface for GT annotation.
Collaborate with our data scientists to create scalable ML solutions for business problems
Interact with customer directly to understand the business problem, help and aid them in implementation of their ML ecosystem
Analyze and extract relevant information from large amounts of historical data - provide hands-on data wrangling expertise
Work closely with account team, research scientist teams and product engineering teams to drive model implementations and new algorithms
Basic Qualifications
BS in computer science, or related technical, math, or scientific field
Working knowledge of deep learning, machine learning and statistics
User interface experience with Javascript, HTML
Knowledge of ETL tools and databases (both SQL-based, NoSQL)
Experience in using Python, R or Matlab or other statistical/machine learning software
Strong communication and data presentation skills
Preferred Qualifications
The motivation to achieve results in a fast-paced environment
Comfortable working in a fast paced, highly collaborative, dynamic work environment
Professional oral and written communication skills in English
Publications or presentation in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Experience with AWS technologies like Redshift, S3, EC2, Data Pipeline, & EMR
Preferred Qualifications
The motivation to achieve results in a fast-paced environment
Comfortable working in a fast paced, highly collaborative, dynamic work environment
Professional oral and written communication skills in English
Publications or presentation in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Experience with AWS technologies like Redshift, S3, EC2, Data Pipeline, & EMR",-1,AISPL - Delhi,Gurgaon,-1,-1,-1,-1,-1,-1,-1,-1
Digital Intelligence Data Architect,-1,"Nokia is a global leader in the technologies that connect people and things. With state-of-the-art software, hardware and services for any type of network, Nokia is uniquely positioned to help communication service providers, governments, and large enterprises deliver on the promise of 5G, the Cloud and the Internet of Things.

Serving customers in over 100 countries, our research scientists and engineers continue to invent and accelerate new technologies that will increasingly transform the way people and things communicate and connect.

Nokia is an equal opportunity employer that is commited to diversity and inclusion.

At Nokia, employment decisions are made regardless of race, color, national or ethnic origin, religion, gender, sexual orientation, gender identity or expression, age, marital status, disability, protected veteran status or other characteristics protected by law.
Analytics Data Architecture & Quality (ADA) comprises the design, architecture, and development of scalable data models.
It also incldes testing and maintaitenance of systems to processes (collect, transform and store) data and the enablement of the analysis of structured and unstructured data.
it is required to take into into account considerations related to privacy, security, reliability, and scalability.
Contains curation of data and data quality and integrity assurance.
It includes the creation and maintenance of a data dictionary of all key sources and tables.
Comprises documentation of key stakeholders and dependencies as well as the gathering, clarification, and translation of business and data requirements into documentation and the conceptual design from which technical solutions are developed.
Contains advising of clients on appropriate data governance capabilities.

'- Leads and executes technical activities and programmes within own responsibility area including reviews and relevant technical studies.
Plans, designs, and executes data analyses.
Writes requirements, specifications and other guiding documentation for R&D from product / program / system point of view.
Design and defines re-use principles.
Participates in definition of technology and other roadmaps.
Works mainly inside own process area in technical issues
Develops tools, methods and processes linked to the job.
Is responsible for sharing knowledge and training in his / her expertise area.
Seeks and communicates cost efficient solutions.
supports problem isolation and resolution.
Can develop software, understands testing and quality assurance concepts.

Apply now.",4.2,"Nokia
4.2",India,"Nokia, Finland",10000+ employees,1865,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Ericsson-Worldwide, Huawei Technologies, Microsoft"
Data Science Trainee,-1,"The training will be for a period of 6 months
Candidates currently undergoing graduation need NOT apply (This program is only for candidates who have degrees)
Only candidates with Masters or above degree should apply
Details
Training will be in projects in Artificial Intelligence (AI)
Training will be conducted in our Bangalore office
Please share your CV to careers@3d-ipsemi.com

Qualification required
M.Tech/PhD in Computer Science or Electronics degree
Knowledge of Python programming skills is required
Candidates with prior data science experience or course will be given preference",4.0,"3D-IP Semiconductors
4.0",Bengaluru,"Bangalore, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Director of Data Science,-1,"Enter Description

Description

The Director of Data Science will help TaskUs develop a point of view for both existing and prospective clients on how we see customer experience evolving. This role will utilize various technologies and internal systems to gather customer and associated business data to determine key drivers of customer success and overall experience, and then translate that data into actionable insights and recommendations

Your achievements are gauged not on hours worked, but on your ability to identify and qualify key drivers for our business, investigating areas of opportunity, evaluating effectiveness and making recommendations.

Responsibilities
You will spend your day applying business knowledge to analytics projects and providing value-added insights to directly impact TaskUs business outcomes. You will be responsible for the statistical analysis and interpretation of customer-related data with the goal of finding root causes and communicating them in compelling data driven stories. Your role is to provide insights, analysis and reports.
Partnering with people is what you love the most and you are extremely data focused. You care deeply about the overall business and look for ways to add value. You like being part of a team that delivers excellence.
You thrive in collaborative cross-functional and high speed environments. You like being held accountable for your own results. You pride yourself on providing world-class service and satisfaction.
You will translate complex research results into a cohesive and meaningful story for the business. You will stay current on trends and changes in customer experience. You will
conduct key analysis utilizing sources of customer quantitative and qualitative data.
You will develop and automate queries and reports based on internal needs and analyze data to develop top-line insights that include financial linkage of customer satisfaction and loyalty data.
You will identify urgent issues or discrepancies within the data and effectively communicate issues and recommendations
You will analyze key metrics and other business indicators to recognize areas of focus for process and procedural improvement recommendations.
You will use data science techniques to develop predictive models. You will act as a key contributor to identifying metrics that matter and establishing mechanisms to track changes in customer experience across journeys and episodes.
You will independently implement and execute various analytical requests simultaneously, including thoroughly owning all aspects of analytical execution as assigned. You will contribute to proposal development and assist with presenting recommendations to leadership. You will proactively consider how data/analytical processing can be made more efficient and improved, and make relevant recommendations for improvement.
You will develop deep customer understanding, employ a range of quantitative and qualitative research approaches. You will support departmental needs for ad hoc reporting.
Lastly, you will build and leverage internal relationships to drive results.
Qualifications
8+ years of experience in data science or related fields; with demonstrated experience building/training models in modern statistical tools
Bachelor’s degree in Data Science, Mathematics, Engineering, Statistics, Computer Science or other related courses
Experience in statistical analysis, segmentation, predictive modeling, and forecasting is required
knowledge and understanding of data manipulation concepts and languages is required
Familiarity with business intelligence and data visualization tools and software
Strong communication skills (verbal and written) with an ability to communicate complex information to non-technical audiences
strong technical skills and must be expert level in MS Excel and analytics tools
passion for Customer Experience and ability to act as an advocate for our customers",4.5,"TaskUs
4.5",Indore,"Santa Monica, CA",10000+ employees,2008,Company - Private,Staffing & Outsourcing,Business Services,₹10 to ₹50 billion (INR),-1
Machine Learning Engineer,-1,"Job Description :
We are looking for outstanding engineers to implement the novel machine learning models for various complex problems and use cases for our clients and products.

Our work might involve efficiently implementing an idea from a new research paper, building new tooling to help optimise a large scale workflow or working out how the latest open source machine learning technologies can be applied to our problem space.

We work very closely with our technology researchers and adapt the direction of our work as exciting new ideas emerge. You will be a part of a team that handles all the processes from data collection, cleaning, and preprocessing, to training models and deploying them to production.

The ideal candidate will be passionate about artificial intelligence and stay up-to-date with the latest developments in the field.

Who are we looking for?

The candidate should have knowledge in some of these areas, should have interest and desire to learn the others:

Knowledge of numerical programming, in Python using libraries such as Pandas, NumPy and tools such as Anaconda, Plotly, etc.
Analyzing the ML algorithms that could be used to solve a given problem and ranking them by their success probability
Implemented deep learning solutions either commercially or as a personal project.
Finding available datasets online that could be used for training
Defining validation strategies
Defining the preprocessing or feature engineering to be done on a given dataset
Defining data augmentation pipelines
Training models and tuning their hyperparameters
Experience working with deep learning frameworks such as TensorFlow, Keras or PyTorch.
Experience working closely with data scientists or quantitative researchers in a research directed environment.
Experience with distributed compute platforms including areas such as package management, security implementation and containerisation (Docker).
Demonstrable ability to engineer high-quality maintainable software and experience with automated testing and continuous delivery (CI-CD).
The confidence to experiment with new ideas and technologies.
Ability to engineer and own solutions that will be relied upon by many users and deployed to machines in large compute clusters.
Knowledge of version control with branching and merging in GitHub or BitBucket.
Experience in working with cloud computing. (AWS, Google or Azure).
Implementing microservices in Python for serving ML models using Flask or equivalent framework.
Knowledge of Test Driven Development (TDD) using Pytest or Unit test in Python.
Technical writing is a nice to have skill for writing technical documents, process notes, technical blogs, development stories, etc.

For any candidate, this is a challenging role requiring you to combine technical knowledge and engineering skills with the ability to understand the hard data science challenges facing our researchers.

Qualification :
Engineering Graduate - B.E. / B. Tech. (Computer Science or IT)

Application Procedure :
To apply for this job, fill this application form here. The selection process consists of the following steps:

Shortlisting of Profiles (Resume) - Shortlisted based on information provided by you in your resume.
Coding Round [1 Hour] - You will be provided with one or more use cases and data with access to a cloud instance. You need to write and execute the program to resolve the problem.
Technical Interview - This will happen immediately after you clear your Coding Round, you may be asked general technological questions, best practices, approaches and solutions you used to solve the problem given to you in the coding round.
Social Discussion - This is a more general cultural discussion round to understand your capabilities as a team player and assess your passion and appetite for technology and growth.

Interested candidates can send their resume to hr@quantrium-tech.com and can reach me at 9176663397",4.0,"Quantrium Tech
4.0",Chennai,"Chennai, India",1 to 50 employees,2019,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Analytics Consultant,-1,"We are actively looking for a talented Analytics Consultant to join our growing CPM & BI practice. This is a full-time salaried position.

The ideal candidate has worked on Analytics Consultant before and can anticipate what needs to be done rather than be instructed. These positions need leaders who can adapt, work in a very fast-pace, enriching environment and is looking for a career rather than just a job.

What Youll Do:
Work in Analytics role Oracle, Microsoft Power BI/Azure, Tableau, ThoughtSpot.
Working on Big Data/Data Lake/Snowflake/AWS Redshift experience a huge plus.
What You'll Bring:
3-5 Years of Analytics experience (not as end user) in any of these: Oracle, Microsoft Power BI/Azure, Tableau, ThoughtSpot.
Strong SQL knowledge.
DW/ETL expertise a plus.
Big Data/Data Lake/Snowflake/AWS Redshift experience a huge plus.
What We Bring:
Entrepreneurship at work
Highly competitive pay and outstanding benefits and bonus structure
Opportunity to participate in National/International Events
Work with high-caliber Oracle professional.
Up to 28 days off during your first year (includes PTO, holidays)
A fun and collaborative environment
Why Join Us?

AST is a global technology brand with a long history of creating innovative solutions as a systems integrator. Our team has the outstanding ability to motivate, inspire, and collaborate, delivering award-winning results to our clients. At AST, were lifelong learners, who tackle challenges together and win together. If you are a smart, driven person, who thrives on taking technology to the next level, youve come to the right place.

AST LLC is an Equal Opportunity Employer.

Powered by JazzHR",4.3,"Applications Software Technology LLC
4.3",Pune,"Lisle, IL",501 to 1000 employees,1995,Company - Private,IT Services,Information Technology,₹5 to ₹10 billion (INR),"CherryRoad Technologies, Huron Consulting Group, Hitachi Consulting"
Associate Machine Learning Engineer,-1,"Codemonk is a young and energetic startup that empowers other startups and enterprises by building simple and elegant software solutions. Through our expertise in the domains of AI, Blockchain, IoT and Enterprise Applications we have helped brands such as IndiaMART, greytHR, Fyle, Skylark Drones etc to craft world-class products and improve their business. We are churning out amazing software for our clients located across the globe from our headquarters at Bengaluru.
To meet our expanding business needs, we are looking out for professionals who can join our team as an Associate Machine Learning Engineer and work on problems of diverse complexity and scope.

Responsibilities
Mine data using modern tools and programming languages
Define and implement models to uncover patterns and predictions creating business value and innovation
Effectively tells stories with the data using visualisation tools/methods to demonstrate insight impact and business value
Implement data-driven solutions based on advanced machine learning (ML) and optimisation algorithms to address business problems
Partner with engineering teams to build scalable, efficient, automated ML-based pipelines (training/evaluation/monitoring)
Deploy, maintain, and debug ML/decision models in production environment
Maintains proficiency within the data science domain by keeping up with technology and trend shifts.
Requirements
Bachelor's or Master's degree in Computer Science, Statistics or similar quantitative field. However, if you feel that you do not have the necessary degree to apply, do not worry! We value skill set more than the qualification, do apply if you feel you have the right skill set.

Skills
Fluent coding skills in Python
Good understanding of the foundations of machine learning methods
Familiarity with data visualisation tools
Strong analytical and problem-solving skills
Ability to create models to pull valuable insights from data
Familiarity with machine learning frameworks (like TensorFlow or PyTorch) and libraries (like scikit-learn).

Nice to have
Experience with applying statistical modelling, machine learning, and data mining algorithms to business problems
Experience in working with large scale production data sets.


Benefits
By joining us, you can expect newness and challenges every day. As an early member of the team, you will be part of shaping the company future, fuelling the growth and defining the culture. You will be surrounded by people who carry around infectious enthusiasm; people who dream, chase and of course have fun along the way!",-1,Codemonk,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Analyst,-1,"Experience2 Years EducationB.E/B.Tech, M.E/M.Tech, M.Sc, MBA/PGDM, MCA/PGDCA (Essential requirement) Number of Openings10 SkillsData Analyst Job DescriptionMinimum 3 yrs of experience on DW projects in analysis & design
Knowledge of banking products in this space would be useful
good communication skills.
experience in banking environment will be a plus",-1,Novacom Technologies,Mumbai,"Thāne, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Digital – Data Lakes – Data Mining Lead,-1,"About The Role:

Factset is looking for leader who leads Data Mining Team to increase company ability to automate with wide variety of sources of data. He/She has to collaborate with Data Lake team and contribute in building the pipeline by enhancing or enriching the data using machine learning techniques.

Manage a science agenda that balances short term deliverable's with measurable business impact with long term projects. Proficient with Statistical analysis, standard machine learning techniques and ML model deployment engineering best practices.
Work with data scientists, engineers, and cross functional teams to produce end-to-end production-ready solutions
Drive a culture of quality, performance, scalability, and reliability
Total Experience: 7 to 9 years

.

Must have
Computer skills
Practice of programming in Python
Comfortable working in Linux and windows environment
Practice of source control, code review, testing frameworks
Practice of Big Data frameworks, like Hadoop, Spark
Knowledge of both Sql and noSql databases (Columns, Documents, Key-Value)
Cloud
Basic knowledge of cloud environment, constraints and opportunities
Statistics
Basic statistics knowledge, probability, correlation, regression, linear algebra, stochastic process
Practice of data analysis, data cleanup, data investigation, how to detect and handle unbalance, bias and noise
Proficient in data structures and algorithms, in particular: lists, queues, trees, graphs, and sorting, searching, traversing, dynamic programming, and map-reduce pattern
Knowledge and practice of ML and NN algorithms and frameworks
Knowledge and practice of Natural Language Processing
Others
Practice of data mining and data science projects, from understanding the problem to presenting results and deploying in production
Communication skills, project presentation, capacity to popularize technics and results
Knowledge of Data Mining / Data Science projects and publications
Nice to have
Computer skills
Practice of programming in other languages like R, java, Julia, Matlab
Practice working on Jupyter notebook/lab or VS Code
Practice working on Git/Github
Cloud
Practice on AWS cloud / SageMaker",3.7,"FactSet
3.7",Hyderabad,"Norwalk, CT",5001 to 10000 employees,1978,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),"S&P Global Market Intelligence, Bloomberg L.P., Thomson Reuters"
Data Engineer,-1,"Employment Type
Permanent
Closing Date
11 Aug 2020 11:59pm
Job Title
Data Engineer
Job Description


Telstra is Australia’s leading telecommunications and technology company, with operations in more than 20 countries, including in India where we’ve launched our new Innovation and Capability Centre (ICC) in Bangalore.

We’re combining innovation, automation and technology to solve the world’s biggest technological challenges in areas such as Internet of Things (IoT), 5G, Artificial Intelligence (AI), Machine Learning, and more. Join us on this exciting journey, and together, we’ll reimagine the future.

Our Software Engineering teams are building a new platform to support Microservice APIs, developed by our teams of developers spread across the globe. We're using industry leading technologies and design principles to encourage best practice application design / development and operation, such as automation and CI/CD.

As a Data Engineer, you will develop, maintain, test and evaluate big data solutions within organisations and would also be involved in the design of big data solutions. You will plan, coordinate, and execute all activities related to the requirements interpretation, design and implementation of data analytics applications.

In this role, your key responsibilities are…
Design and develop data analytics applications.
Review vendor designs and recommend solutions based on industry best practices.
Provide technical governance across data analytics solutions at Telstra.
Assess and improve the efficiency and effectiveness of the data analytics application solutions to ensure user requirements and business objectives are met in a timely and cost-effective manner.
Understand overall business landscape and develops innovative solutions to help improve productivity
Coordinate with technical resource within and outside of Feature team.
Monitor process of software configuration/development/testing to assure quality deliverable.
Ensure standards of QA are being met.
Review deliverables to verify that they meet client and contract expectations; Implement and enforce high standards for quality deliverables.
Analyses performance and capacity issues of the highest complexity.
Assists leadership with development and management of new application capabilities to improve productivity.
Provide training and educate other team members around core capabilities and helps them deliver high quality solutions and deliverables/documentation.
Design/develop user requirements, test and deploy the changes into production.
To be successful in the role, you must have…
Degree level IT qualifications in Software or Systems Engineering.
Minimum 3 years of experience in IT of building and supporting Data Engineering pipeline using Big Data Platform.
Extensive experience using Hortonworks Data Platform.
Experience in Apache Hive, Spark, Zeppelin and Ambari.
Proven expertise of working on Azure Cloud using Databricks, Azure Event hub Flume/Kafka/Spark streaming, Azure Data Factory.
Experience of using Informatica for ETL use cases.
Experience of working in Azure DevOps and ARM.
Experience of using Control-m to schedule data engineering workflows.
Experience in designing solutions for multiple large data warehouses with a good understanding of cluster and parallel architecture as well as high-scale or distributed RDBMS and/or knowledge on NoSQL platforms.
Experience in translating, loading and presenting disparate datasets in multiple formats/sources including JSON, XML etc.
Good knowledge of NoSQL Databases/ HBase/ MongoDB.
Experience in Programming: Java Spring Boot/ Scala/ Python / SQL and Multi-tenant databases.
Strong problem solving and analytical skills.
Demonstrated high level of written and oral communication skills.
Proven high level of initiative, drive and enthusiasm with excellent time management and an ability to work under pressure.
Desirable to have experience on:
Automation using PowerShell
Rabbit MQ
Jenkins
Power BI
REST API
Salesforce
Our people in India will be at the forefront of technological change as they work collaboratively with, and learn from, world-class experts and have access to the latest training programs and insights for their field.

Alongside your work on leading edge projects, working with us means you'll have access to company perks and benefits that'll reward you for the great work you do. We’re growing, fast, and for you that means many exciting opportunities to develop your career with us at Telstra.

Interested?

If you're excited about the opportunity to be part of a team, committed to delivering amazing experiences for our customers – your next step is to apply!

We’re committed to building a diverse and inclusive workforce. To enable everyone to participate, we’ve developed an ‘All Roles Flex’ policy to consider flexible ways of working for every role. To learn more, visit our Telstra Careers Website: tel.st/allrolesflex

We’re committed to building a diverse and inclusive workforce. To enable everyone to participate, we’ve developed an ‘All Roles Flex’ policy to consider flexible ways of working for every role. To learn more, visit http://tel.st/allrolesflex. We welcome applications from Indigenous Australians, people from diverse cultural and linguistic backgrounds and people living with a disability. We encourage you to talk to us about how we can support you through the recruitment process.",3.6,"Telstra
3.6",Bengaluru,"Melbourne, Australia",10000+ employees,1901,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Optus, Vodafone, Macquarie Telecom Group"
Data Analyst,-1,"Good Typing Skills

Good Communication Skills

Job Detail
Offerd Salary₹10,000- ₹15,000
ExperienceLess than 1 Year
GenderMale
QualificationB.Sc",5.0,"Inspire Global Solutions
5.0",Mysore,"Mysore, India",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Data Scientist (Risk Analytics & Modeling),-1,"Data Scientist (Risk Analytics & Modeling)


Nov. 2, 2017

Experience:
Minimum 2 years of experience in implementing statistical/machine learning algorithms (regression, decision trees, SVM) and statistical programming tools (R/Matlab/Octave/Weka)
Proficiency in programming: R/Python/VBA
Strong background in statistics and probability
Experience in handling large structured and unstructured dataset
Knowledge and experience in structured finance products (securitization structures) would be a plus
Excellent writing, oral communication and presentation skills
Qualification: PGDM/Masters degree in Maths/Statistics/Econometrics/Economics/Finance/Engineering /other quantitative disciplines. Also Actuaries/FRM/CFA/CQF/PRM certification would be a plus.

Job Description: Lead the Business Analytics for Credit portfolio Analysis of Loan Pools of NBFC & Micro Finance Companies

Primary Responsibilities:
Develop and implement new (maintain and use existing) statistical/machine learning models to identify performance and risk drivers in the credit portfolio
Develop and implement new (maintain and use existing) risk and performance assessment models to measure risk and performance in the portfolio
Manage large loan level and borrower level data used for risk and learning models
Measure the risk and performance indicators for debt and structured finance products using existing and new models
Perform qualitative and quantitative analysis of various performance metrics for structured transactions
Document the analysis methodology and findings in report and present the analysis to the internal and external stakeholders/platforms (model notes, white papers, working papers, etc.)
Contribute towards other risk management work done by the risk management function
Travel not more than 20% of the time to meet partners and understand the lending models",-1,LoanXpress,Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer: Enterprise Content Management,-1,"Introduction
At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities
As Enterprise Content Management, you will be providing application maintenance and support of ECM systems. You are responsible to work proactively with clients to refine their current business strategy or develop a new strategy in line with competitive and market forces.

Role and Responsibilities
Support and delivery of assigned project work.
Pro-active detection and timely escalation of any issues.
Driving root cause analysis and resolution to closure.
Identification and driving of related service quality improvements and engineering deliverables.
Escalation as necessary to secure assistance and technical guidance from other Technology teams to resolve support issues.
Management and progression of Action items.
Automation and process improvement.
Required Technical and Professional Expertise
Minimum 5+ years of experience in OpenText Documentum
Proven technical acumen with experience implementing enterprise content management systems,
Experience in implementing in Documentum D2
Proficient in managing the execution of the Electronic Document Management System (eDMS) Projects
Ability to manage Agile delivery of small and medium Documentum projects
Expertise in upgradations of OpenText Documentum products like D2, content server etc.
Working knowledge of day-to-day project schedule, ensuring timely delivery of committed deliverables
Preferred Technical and Professional Expertise
You love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologies
Ambitious individual who can work under their own direction towards agreed targets/goals and with creative approach to work
Intuitive individual with an ability to manage change and proven time management
Proven interpersonal skills while contributing to team effort by accomplishing related results as needed
Up-to-date technical knowledge by attending educational workshops, reviewing publications
Willingness to work all 5 days from Gurgaon office
About Business Unit
IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Gurgaon,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"Job Purpose:

We are looking for a Data Analyst whose job duties include data research, data analysis.

Roles and Responsibilities:
Perform business analysis using various techniques such as statistical analysis, explanatory and predictive modeling, data mining.
Determine the best analytical model and approaches to present and explain solutions and options to business users.
Determine best practices and develop actionable insights and recommendations for the current business operations.
Provide support for a range of data cleansing and data modeling activities, as required by the business, using internal and external data sources.
Sense-check large lists of data.
Work with strategic market teams to ensure data is accurately aligned.
Work directly with internal and external clients to identify analytical requirements.
Produce ad-hoc data queries and reports to support and guide business decisions.
Assist in the evaluation, implementation and developmental of systems to capture business operation information and documentation of the system once delivered. Provide end-user training and vendor management for related systems, as necessary.
Provide backup support for Reporting and Data Warehouse solution, OBIEE, or other reporting systems.
Guide less experienced Business Data Analysts and end users on the Data and Decisions Support teams processes and objectives.
Desired Skills:
Bachelors Degree in Maths, Statistic and computer related
0 to 2 years related experience in IT data or business process related role
Languages: R, Python, HTML, Javascript, C/C++, SQL, Matlab, SAS
Experience with Database/Data Systems preferred: MS SQL, OBIEE, Oracle, ODI, MS Access, MS Power BI NO SQL, Data Lakes.
Machine Learning, Statistical Analysis, AI Tools, CRM system experience preferred
Strong math background
Strong Excel skills with the ability to manipulate large data spreadsheets
Excellent attention to detail and accuracy of work is essential
Ability to confidently interact and engage with stakeholders at all levels in the organization from graduates through to board level
IT savvy with a problem-solving nature
Ability to effectively prioritize and execute tasks in a high-pressure environment
Ability to conduct research into a wide range of data or systems issues as required.",4.3,"AMBC
4.3",Hyderabad,"Naperville, IL",1 to 50 employees,2001,Private Practice / Firm,IT Services,Information Technology,₹500 million to ₹1 billion (INR),-1
Senior Software Engineer - Data Science and Machine Learning,-1,"Apply only if you have a minimum of 3 years of experience.


Front-End:


Web fundamentals like HTML5, JavaScript, and CSS3
Knowledge of BEM/OCSS, CSS Grid and flex
Hands on experience of JavaScript framework React, Redux, Redux-Saga/Redux-thunk, Storybook, Jest
AJAX
Strong communication skills in English, written and verbal , Strong analytic skills and work ethic.
HTML, CSS, SCSS
Proficient in CSS3 and responsive web coding
Experience developing cross-browser and cross-platform compatible solutions
Experience in creative, visually stunning, front end for web-based application
A Bachelor’s degree in Computer Science (CS), Software Engineering (SE) or related technical field is preferred for the position is Must.
Back-End:


API design and development
CRUD (Create, Read, Update, Delete)
RESTful Services
Web fundamentals like HTML, JavaScript, and CSS
Hands on experience of Server-side technology stack Node.js and Express.js
Database experience of PostgreSQL
Knowledge of Amazon AWS is plus.
Advanced Level Skills:


CSS/SCSS using BEM class naming
Front end build experience with Gulp and Webpack
Version control with Git (as well as SVN preferred)
Location: Pune, India

To apply for this job, please write to us at jobs@vshsolutions.com",4.4,"VSH Solutions
4.4",Pune,"Pune, India",1 to 50 employees,2011,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Sr Data Scientist,-1,"Location- Noida

Exp-11-14 Yrs

.Strong verbal and written communication skills.Work Experience of 6-10 years (wide range will be based on the caliber of the candidate)
Demonstrated/proven track record as an excellent learner and take up NEW areas quickly
Engineering background / automotive domain project experience preferred
3-4 years of solid ML Projects POC experience
Coordinate with different functional teams to implement models and monitor outcomes
Draft business cases and project charters based on discussion with client staff
R and Python Pandas Numpy sklearn mlr caret etc.
Must have experience with model deployment and models running in production
Statistical and data mining techniques: GLM/Regression Random Forest Boosting Trees text mining etc.
Experience with platforms such as Amazon AWS
Experience with serving Machine Learning as an API (microservice layer)
Some experience with BI and visualization tools like Tableau PowerBI - to explain the findings in the data
SQL would also help in order to perform data acquisition from SQL DBs Snowflake and other Data Related tools
Preferred but not mandatory: Computer Vision and NLP experience and pre-trained models in these areas",3.4,"Birlasoft
3.4",Noida,"Pune, India",5001 to 10000 employees,1990,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹10 to ₹50 billion (INR),"HCL Infosystems, Infosys, Accenture"
Data Analyst,-1,"Essential qualification & experience :
Qualification: Any undergraduate / postgraduate degree or equivalent

Experience: Minimum 5 years of experience

Responsibilities:
Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities

Requirements:
Proven working experience as a data analyst or business data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings",3.4,"Alliance University
3.4",Bengaluru,"Bangalore, India",501 to 1000 employees,-1,Company - Private,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Sr. Data Scientist,-1,"EXPERIENCE:
2+years
JOB DESCRIPTION:
Experience in analyzing massive and complex structured and unstructured data sets.
Ability to extract, and clean data, visualize it, communicate it and utilize it.
Around 4+ years’ relevant experience with data mining/business intelligence/statistics/data analysis.
Practical experience with building Analytical/statistical/mathematical algorithms such as predictive modeling, Optimization, Simulation, multiple regression.
Strong ability and experience in crisp and powerful data visualizations methods and tools.
Excellent analytical, logical reasoning and problem solving skills.
TECHNOLOGY STACK:
Below skills are preferred not mandatory

Exposure in using SAS E-Miner/R/both with proficiency in SAS preferably

Hands-on experience and solid working knowledge of SAS (Macros, Base and EG), SQL, PL SQL, VB, VBA for MS-Excel.

Knowledge of Hadoop (and other big data technologies), SQL and Java/C/C++ is desirable.

Excellent understanding of technical architecture requirements for big data systems.",-1,Copiousminds,Mumbai,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"The person would be responsible for data collection and input in the varioustools and dashboards
The person would be responsible for working with various teams and collate thedata from all the teams.
The data would include sales, inventory, advertising, product details. All thedata points would be linked with each other that would help the person togenerate insights and formulate strategy.
Theperson would then prepare the strategy documents and reports and share with themanagement.
RequiredExperience, Skills and Qualifications

Theperson should have a good knowledge of Microsoft excel, Tableu or MicrosoftAzure Platform.
Understandingof a few data analytics, data visualization tools would be helpful
Theperson should be willing to work in a team and as a part of fast growingcompany where processes would be very dynamic in nature.",-1,Service industry for Pharmaceuticals company,Vadodara,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist (10 to 15 years),-1,"They are looking for Senior Applied Scientist to be based at Bangalore with the following skills: Â

â€¢Total 10 to 15 years of industry experience in predictive modeling and analysis Good skills with programming languages, such as Java or C/C++
â€¢Must have experience using Python and/or R, able to write production level code, which is well-written and explainable.
â€¢A successful candidate will be a person who enjoys diving deep into data, doing analysis, discovering root causes, and designing long-term solutions.
â€¢Must have experience in helping to build production systems that take inputs from multiple models and make decisions in real time.
â€¢Must have experience in delivering ML / DL projects from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models to deliver business impact to the organization.
â€¢Masters/ PhD in a highly quantitative field (Computer Science, Machine Learning, AI, Operational Research, Statistics, Mathematics, etc.)

Kindly send your profile to tulsiarora(at)mysearch.in.net or call on 90361 39000
00-16.00 Years",-1,MY Search,Bengaluru,"New Delhi, India",1 to 50 employees,-1,Other Organisation,-1,-1,Unknown / Non-Applicable,-1
Quantum Data Scientist,-1,"Experience Required:
2-5 Years

Job Description:
Work with team on active exploratory research engagements to prepare for future use case commercialization within specific industry using Machine Learning algorithms.
Implement quantum approaches, which includes data pre-/post-processing, running numeric and visualizing data.
Define best practices related to information architecture, including collection, integration, organization, analysis, and visualization of data for quantum-enabled impact.
Collaborate with industry and solutioning experts to design and shape experiments to demonstrate quantum-enabled advantage.
PhD/Masters in STEM-related fields with knowledge in Quantum Computing.
2+ years of data engineering and data science experience
Proficiency with classical approaches to machine learning and linear algebra, including Support Vector Machine (SVM) for linear categorization and Singular Value Decomposition (SVD) to reduce dimensionality of data.
Familiar with Qiskit software, including Qiskit Aqua for domain applications and Qiskit Terra for quantum circuit design and optimization.
Excellent ideation, facilitation and communications skills.
Detail-oriented team player with strong interpersonal skills and ability to take a leadership role when necessary.
2+ years of experience in at least one of the industries, with knowledge of industry trends, R&D areas, and computationally intensive processes (e.g. optimization).

Industry:
IT-Software / Software Services

Functional Area:
IT Software - Application Programming Maintenance

Role Category:
Functional & Design

No of Position: 1

Start Date: Immediate

If Interested Mail your CV to info@kiratitsolutions.com",-1,Kirat IT Solutions,Kolkata,"Kolkata, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Machine Learning Engineer,-1,"We are looking for a machine learning engineer with experience in machine learning and time-series forecasting algorithms. If you want to work on classification, regression and time-series algorithms, Mate Labs welcomes you.

Mate Labs has built ""Mateverse"" for Data Analysts so that they can build customized machine learning and data science models for a quick prediction like sales forecasting without writing even a single line of code. At Mate Labs, we are solving a unique problem of Algorithm & Hyperparameter selection in the field of Artificial Intelligence.

Machine Learning has transformed industries and is ready to revolutionize the way you live, work and commute. It has created millions of new job opportunities and will continue to do so. This industry is going through a very exciting phase and at Mate Labs, we want to be at the forefront of this revolution. If it sounds exciting and you want to be a part of this revolution, join Mate Labs. Apply Now.

Roles and responsibilities:

* Will work on a wide range of machine learning algorithms in classification, regression and time-series forecasting areas
Will work on algorithm selection, hyperparameter optimization, and various model search methods
Will work on research paper implementations and writing our own algorithms from scratch
Will work with libraries like Scikit-learn, Pandas, Dask, PyTables, Numpy, Statsmodels, Prophet, XGBoost, LightGBM, CatBoost, and other machine learning libraries
Will work on time-series algorithms like ARIMA, SARIMAX, Prophet, Holtwinters, Exponential Smoothing, and other popular algorithms
Will work on client projects and handling the deliverables.

Skills required:

* 5 to 7 years of experience
Machine Learning Algorithms (Classification, Regression, Time-series, and Clustering)
Experience with time-series algorithms like ARIMA, Prophet, Holtwinters and Exponential Smoothing
Hyperparameter optimization algorithms for time-series algorithms
Frameworks - Scikit-learn, Pandas, Dask, PyTables, Numpy, statsmodels, XGBoost, LightGBM, CatBoost, FBProphet
Time-series - Multivariate time-series forecasting
Good communication skills

Benefits:

*Startup culture(immense scope to learn and grow).
Amazing team to work with.
Health Insurance for the employees.",4.7,"Matelabs Innovations Pvt. Ltd.
4.7",Bengaluru,"Bengaluru, India",1 to 50 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,₹10 to ₹50 million (INR),-1
Data Engineer,-1,"Who are we?

A young, fast-growing AI and big data company, with an ambitious vision to simplify the world’s choices. Our clients are top-tier enterprises in the banking, e-commerce and travel spaces. They use our core AI-based choice engine maya.ai, to deliver personal digital experiences centered around taste. The maya.ai platform now touches over 125M customers globally. You’ll find Crayon Boxes in Chennai and Singapore. But you’ll find Crayons in every corner of the world. Especially where our client projects are – UAE, India, SE Asia and pretty soon the US.

Life in the Crayon Box is a little chaotic, largely dynamic and keeps us on our toes! Crayons are a diverse and passionate bunch. Challenges excite us. Our mission drives us. And good food, caffeine (for the most part) and youthful energy fuel us. Over the last year alone, Crayon has seen a growth rate of 3x, and we believe this is just the start.

We’re looking for young and young-at-heart professionals with a relentless drive to help Crayon double its growth. Leaders, doers, innovators, dreamers, implementers and eccentric visionaries, we have a place for you all.

Can you say “Yes, I have!” to the below?
Expertise in data warehousing, relational database architectures (Oracle, SQL, DB2, Teradata), and big data storage and processing platforms required. (Hadoop, HBASE, Hive, Spark)
Working knowledge of cloud-based deployments in AWS, Azure or GCP
Technical know-how of at least one programming stack - ideally Java
Can you say “Yes, I will!” to the below?
Design algorithms for product development and build analytics-based products
Lead analytical projects and deliver value to customers
Coordinate individual teams to fulfill client requirements and manage deliverables
Communicate and present complex concepts to business audiences
Manage and strategize business from an analytics point of view
Travel to client locations when necessary
Requirements

You’ll get brownie points for:
An aptitude for analytical problem solving
Comfortable working with Linux and Shell
The ability to work effectively in a global team and thrive in a fast-paced, evolving tech startup environment",4.4,"Crayon Data
4.4",Chennai,"Singapore, Singapore",51 to 200 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Position Summary:

4 to 7 years of hands on experience as a data lake, data warehouse, /analytics developer
Experience with Data Modeling and data mapping methodologies
Good technical abilities in AWS (S3, lambda, kinesis), Python and SQL : problem solving, coding and debugging skills
Hands on experience with Database (such as Oracle, MS SQL Server, MySQL, PostgreSQL), NoSQL (such as HBase, MongoDB, Cassandra, Cosmos, Arango, Orient) and Data Warehousing (such as Microsoft Azure DW, Redshift, Teradata, Vertica) and data migration, ETL (AWS Glue, Azure Data Factory, Informatica, SSIS, etc.) and integration
Building highly scalable, robust & fault-tolerant systems and capabilities
Experienced in creating large data pipelines (via tools and code level- Python R | Spark)
Creating a complete solution by integrating a variety of programming languages & tools together.
Ability to think understand complex business requirements and render them as prototype systems with quick turnaround time.
Strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external partners/virtual teams.

Qualifications:

Experience with Big Data, Basic Data Science, Statistics, Machine Learning & Modeling is a plus
Working knowledge of modern software development practices and technologies such as agile methodologies and DevOps 3.

About Huron:

At Huron, we’re redefining what a consulting organization can be. We go beyond advice to deliver results that last. We inherit our client’s challenges as if they were our own. We help them transform for the future. We advocate. We make a difference. And we intelligently, passionately, relentlessly do great work…together.

Are you the kind of person who stands ready to jump in, roll up your sleeves and transform ideas into action? Then come discover Huron.

Whether you have years of experience or come right out of college, we invite you to explore our many opportunities. Find out how you can use your talents and develop your skills to make an impact immediately. Learn about how our culture and values provide you with the kind of environment that invites new ideas and innovation. Come see how we collaborate with each other in a culture of learning, coaching, diversity and inclusion. And hear about our unwavering commitment to make a difference in partnership with our clients, shareholders, communities and colleagues.

We offer a competitive compensation/benefits package. Huron is an equal opportunity employer. We recruit, employ, compensate, transfer, promote and train without regard to race, color, creed, religion, national origin, sex, marital status, pregnancy, disability, sexual orientation, veteran status, age, FMLA status or any other basis protected by law.
LI:",3.8,"Huron Consulting Group
3.8",Bengaluru,"Chicago, IL",1001 to 5000 employees,2002,Company - Public,Consulting,Business Services,₹50 to ₹100 billion (INR),-1
Data Analyst,-1,"ABOUT THE ROLE

Toppr is looking for a Data Analyst (DA) in its Product Marketing team. You’ll be a part of a core team that drives strategic decisions for product marketing. Your primary responsibility will be to derive insights that improve business performance. You’ll conduct exploratory analyses of large data sets, metrics identification and report creation, and development and maintenance of analytical systems. You’ll broadly influence Toppr’s product, marketing effectiveness and elevate the role of data as an asset to the business.

If you are technically adept with excellent ability to write optimised queries and possess a keen eye for business with a real passion for making an impact, then we’d love to talk to you!

HOW YOU’LL RAMP

In First Week…

● Understand Toppr’s journey, its values and mission.

● Spend time with the Business Intelligence, Marketing, Product, and Sales teams to get up-to-speed on Toppr’s offering, its competition, and future outlook.

By Day 30…

● Answer questions by querying our databases and systems of record while increasing the adoption of data across the company.

● Start to identify and pursue projects that directly drive retention, engagement and revenue.

● Implement a single source of truth by updating existing models and generating new data resources from customer interaction logs, and sales and marketing data.

By Day 90…

● Make recommendations that directly influence business outcomes. Identify areas of opportunity, spin up collaborative teams, and report on successes.

● Coach and mentor your new team members.

● Dig deeper and pick a project that matters to Toppr and its success. By doing so, you’ll be solving problems on a pan-India level.

Requirements

KEY QUALIFICATIONS

● B.Tech/BE from recognized (Tier 1) institutes.

● 1+ years of experience in data analytics, or BA/BS in Statistics, Mathematics, Economics, Computer Science or related field.

Benefits

WHY SHOULD YOU JOIN TOPPR

● Full exposure to all parts of the business: You will partner with and be exposed to every team: an unparalleled opportunity to learn about all the nuts and bolts of a business.

● As the business grows, you grow: We want Toppr to be built from within. We look at you as a business leader with the potential to make Toppr a $10B company.

● Work with the best: Learn from leaders who have built Toppr from the ground up. Work with down-to-earth, highly experienced, and insanely ambitious colleagues.

● High-growth industry: India’s online education industry is an ever-expanding pie and is poised to grow to $2 billion in by 2020.

● High-growth startup: Toppr has grown over 50x in the last 3 years, and we aim to grab a big chunk of this ever-expanding pie.",3.2,"Toppr
3.2",Hiranandani Gardens,"Mumbai, India",51 to 200 employees,2013,Company - Private,Primary & Secondary Education,Education,Unknown / Non-Applicable,-1
Lead Data Scientist,-1,"Overall 8 years of experience with at least 5+ years in Machine Learning (Random Forest, Decision Trees, SVM, NLP, Gradient Boosting, Supervised/Unsupervised Learning, Clustering, classification and regression modelling). Experience in Python or R.
Candidates should have hands-on experience in Machine Learning Algorithms with relevant experience.
Technical skills: Machine Learning, Deep Learning, AI, Python, Optimization Algorithms etc
Experience with Deep learning algorithms like RNN, CNN etc.
Experience with text processing algorithms and analytics.
Experience with Open source NLP libraries.
Hands on Experience in:
Machine learning
Natural Language processing
Artificial Neural Network
Convolution Neural Networks
Deep Learning
Semantic Technologies
Data quality management and data services
Logic and Reasoning
NOTE: Please share CV to extsmitha.gundaiah@arisglobal.com",3.3,"ArisGlobal
3.3",Karnataka,"Coral Gables, FL",1001 to 5000 employees,1987,Company - Private,Computer Hardware & Software,Information Technology,₹5 to ₹10 billion (INR),-1
Senior Analytics and Data Engineer,-1,"Site Name: India - Karnataka - Bangalore
Posted Date: Jul 23 2020

Minimum Experience:

At least 6 years of experience working on data-driven and data-informed application development, preferably covering structured / ERP data

At least 1 year of hands-on development experience in cloud technologies (Azure, AWS, Google Cloud)

Job Purpose:
Recognised as the go-to data engineering SME, to work collaboratively and adapt to constantly meet the needs of their customers and deliver value to GSK
Identifies appropriate cloud service offerings based on use cases
Configures and uses cloud components (e.g. on Azure), including data storage, transformation/modelling, database/warehousing and reporting tools
Builds flexible and streamlined data environments and automated pipelines for data provisioning from multiple source systems including SAP
Develop sustainable data-driven and analytic solutions as part of an agile team, collaborate with a diverse group of individuals with a common goal
Creates reusable enterprise data sets
Fulfils day-to-day data needs of data scientists and other data users across the organisation
Ensure compliance with GSK Procedures and Policies and assist with audit and validation requirements
To ensure the groups compliance with GSK policies and procedures and that all aspects of the groups conduct are aligned with GSKs integrity principles
Provide reliable and effective support to the Director of Operations where necessary to deal with escalations from the Operational support team for A&BI solutions
Exhibits mastery over multiple domains - model and build of ETL, near real-time, data streaming solutions
Has an intrinsic knowledge of standards and coding languages
Provides technical guidance to team members
Able to work with frameworks of a significant complexity
Key Responsibilities:
Translate business requirements into conceptual, logical, and physical data models
Build sustainable data driven solutions with new data technologies to meet the needs of our organisation and business customers
Help to streamline an appropriate quality data supply chain for analytics that goes from experimentation into production.
Look to leverage reusable code modules to solve problems across the team and organisation
Look to leverage and establish data standards across the team and organisation
Understand complex multi-tier, multi-platform, data distribution systems
Help data scientists to prepare data and assist with initial data exploration steps
Catalogue existing data sources
Enable access to resident and external data sources
To work closely with BI & Analytic Product Experts, Visualisation Engineers, Data Scientists to develop, test and enhance database architectures; to recommend and implement ways to improve data reliability, efficiency, and quality.
Demonstrate communication and influencing skills with key internal experts/stakeholders and strategic partners.
Relevant Skills or Licenses:
Hands-on development experience on Microsoft Azure cloud services ie. Databricks, Data Factory.
The ability to build reusable data pipelines using big data technologies (Spark, Databricks, or similar)
Detailed knowledge of development as part of a Continuous Integration / Continuous Deployment (CI/CD) pipeline (e.g. using Jenkins)
Expertise with developing data solutions, programming languages (e.g. Python, Perl, Javascript, Shell) or Relational Database Systems (e.g. SQL, ETL)
Familiarity with data science tools and concepts (e.g. data lifecycles, data cleaning)
Expertise coding in data management, data warehousing
Some expertise with Data Modelling preferred
Familiarity with BI reporting solutions (e.g. PowerBI)
Some expertise with agile ways of working preferred
Our goal is to be one of the worlds most innovative, best performing and trusted healthcare companies. We believe that we all bring something unique to GSK and when we combine our knowledge, experiences and styles together, the impact is incredible. Come join our adventure at GSK where you will be inspired to do your best work for our patients and consumers. A place where you can be you, feel good and keep growing.

Important notice to Employment businesses/ Agencies

GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.

It has come to our attention that the names of GlaxoSmithKline or GSK or our group companies are being used in connection with bogus job advertisements or through unsolicited emails asking candidates to make some payments for recruitment opportunities and interview. Please be advised that such advertisements and emails are not connected with the GlaxoSmithKline group in any way.

GlaxoSmithKline does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection with recruitment with any GlaxoSmithKilne (or GSK) group company at any worldwide location. Even if they claim that the money is refundable.

If you come across unsolicited email from email addresses not ending in gsk.com or job advertisements which state that you should contact an email address that does not end in gsk.com, you should disregard the same and inform us by emailing askus@gsk.com, so that we can confirm to you if the job is genuine.",3.9,"GSK
3.9",Bengaluru,"Brentford, United Kingdom",10000+ employees,1830,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Pfizer, AstraZeneca, Merck"
Python and DAta SCIENCE Developer,-1,"A2IT is a leading software development company in Mohali Chandigarh with expertise in both Cloud-based Applications and Web applications. Coding experience in Python, should be able to produce high quality code. worked on requests, pillow, scrapy, nump",5.0,"A2IT
5.0",SAS Nagar,"Mohali, India",1 to 50 employees,-1,Other Organisation,-1,-1,Unknown / Non-Applicable,-1
Lead Machine Learning Engineer/ Data Scientist,-1,"Company Description

WhizAI is the first and only purpose-built cognitive insights platform for life sciences, empowering users to get answers to their business questions by simply asking via voice or text on web and mobile. WhizAI is pre-trained on life sciences data and business terminologies, enabling it to answer even the most complex questions from billions of records in seconds. Fast, easy, and scalable, WhizAI is the trusted partner of choice at the top global life sciences companies. Asked. Answered. Instantly.

We are on a mission to make enterprise analytics as easy and delightful as using your favorite app. The days of tedious dashboards, long training hours, and complex analytics software are over. Our platform is disrupting the $190B+ analytics market industry by making it 100X faster and easier for all business users to simply talk to their data and get insights, based on the innovations in NLP, AI, ML and enterprise software. We are the future of business intelligence and if you too want to put innovation and user experience for business users above all else, this role is for you.

Job Description

Out of the box, thinker to build innovating ML models and Lead the Data Science/Machine Learning team for an AI based startup who will:
Understand and analyze requirements requiring Machine Learning Models from product owners, customers, and other stakeholders
Analyze and verify data quality and features
Design solutions by choosing the right algorithms, features, and hyper parameters
Manage the full life cycle of ML Models: Data Acquisition, Feature Engineering, Model Development, Training, Verification, Optimization, Deployment, Versioning
Augment Enterprise data with publicly available datasets to enrich models & features
Create strategies for integrating the whiz.ai platform with external enterprise data sources like Databases,Data Warehouses, Analytical Stores, External ML Systems/Algorithms, Hadoop and ERP/CRM systems
Qualifications

Technical
10+ years of software development experience, with 5+ years of experience in implementing machine learning models
Machine Learning-based models: ANN, SVM, Logistic Regression, Gradient Boosting
Statistical Modeling with ARIMA, STL, Exponential smoothing
Time Series Anomaly Detections Methods, Hierarchical or Grouped Time Series Forecasting
Understanding of ML & Data processing frameworks like TensorFlow or PyTorch, XGBoost, SciPy, Scikit-Learn, Apache Spark
SQL and handling Big Data, databases
Excellent knowledge of Python Programming, NumPy, Pandas, and processing JSON, XML, CSV files
Non-Technical
Good communication & analytical skills
Self-driven with a strong sense of ownership & urgency
Preferred Qualifications
Knowledge of Analytical/OLAP/Columnar, Hadoop ecosystem and NoSQL databases
Deep Learning, GANs, Reinforcement Learning
R programming, Matlab
Knowledge of life sciences or pharmaceutical industry datasets
Additional Information

Compensation:
Competitive and commensurate with experience. WhizAI offers a base salary, a bonus plan, and equity.

Benefits:
Health care and paid time off.",-1,whiz.ai,Pune,-1,-1,-1,-1,-1,-1,-1,-1
SENIOR DATA SCIENTIST,-1,"Location: Chennai / Bangalore

The Data Team is a boutique consulting firm with strong expertise in big data and data science. The Senior Data Scientist is a key role in the organization, and will be leading project delivery on data science projects or data products. The Senior Data Scientist is an important role within the organization responsible for providing expertise, thought leadership, mentorship and leadership in the area of statistical analysis, data analysis and data science. Accordingly senior data scientists are expected to a hands-on practitioners in business analysis, hypothesis generation, data preparation, relational modelling, statistical modelling, algorithm design and scalable machine learning and deep learning. They’ll be expected to provide deep expertise in these areas. In addition, Senior Data Scientists are expected to mentor data analysts and data scientists on project deliverables, and ensure quality and timeliness in the output. The Data Team offers high-impact work with diverse opportunities in the areas of data science for Senior Data Scientists to grow into roles such as business consulting. Prior experience in doing data science and managing data science teams is required for this role. Experience in working on large scale Hadoop databases is required for this role. Past experience in bots and API development, test driven development, continuous delivery are preferred. Client facing skills are considered a plus.

Required Skills
True depth of knowledge in statistics, machine learning, cloud platforms and databases
Critical thinking skills in business with the ability to confidently face clients and mentor data scientists
A highly imaginative mind set and the ability to formulate new and relevant hypotheses from the data
Ability to perform advanced statistical analysis on diverse data sets in Python, R, Scala and Java
Ability to implement scalable machine learning and statistical analysis algorithms with frameworks such as Spark, Tensorflow or Torch
Current knowledge of cloud technologies and architectures such as on Azure, and hands on skills in implementing machine learning algorithms at scale
Expertise validating and critically evaluating machine learning algorithms and their performance
Ability to work in a Linux environment, on cloud-based virtual machines and containers
Should have managed a team in past roles in a managerial setting, or directly faced clients
Excellent interpersonal, presentation and written communication skills
Education and Work Experience Requirements
Bachelor’s degree in computer science or applied mathematics (Master’s degree or PhD preferred)
Higher degree in business, statistics, machine learning or computer science is a plus
Between 8 and 10 years of demonstrated experience in the industry including significant prior experience in data analysis and data science
Relevant certifications in data science will be considered favorably",4.2,"The Data Team
4.2",Chennai,"Singapore, Singapore",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr NLP & Text Mining Data Scientist,-1,"Job title

Sr NLP & Text Mining Data Scientist
Department

Analytics & Data Science
Report To

Deepthi Devarakonda / Simhan Ramakrishnan
No of yrs. of exp

7+ years
Work Location

Pune, MH, India
No of Positions

1
Assigned Recruiter
Talent Partner

Version Control
Version No.

Date

Remark

Updated by
1.0

5/4/2020

Initial Version

SR

It’s Time For A Change…

Your Future Evolves Here

Evolent Health has a bold mission to change the health of the nation by changing the way health care is delivered. Our pursuit of this mission is the driving force that brings us to work each day. We believe in embracing new ideas, challenging ourselves and failing forward. We respect and celebrate individual talents and team wins. We have fun while working hard and Evolenteers often make a difference in everything from scrubs to jeans.

Are we growing? Absolutely—56.7% in year-over-year revenue growth in 2016. Are we recognized? Definitely. We have been named one of “Becker’s 150 Great Places to Work in Healthcare” in 2016 and 2017, and one of the “50 Great Places to Work” in 2017 by Washingtonian, and our CEO was number one on Glassdoor’s 2015 Highest-Rated CEOs for Small and Medium Companies. If you’re looking for a place where your work can be personally and professionally rewarding, don’t just join a company with a mission. Join a mission with a company behind it.

Position summary

The Sr. NLP and Text Mining scientist will support building of AI products in Agile fashion that empower healthcare payers, providers and members to quickly process medical data to making informed decisions and overall reduce health care costs. As a research scientist/engineer part of Data Science and Artificial Intelligence team you will be working primarily on unstructured text data to build machine learning models for information retrieval applications. These applications include but are not limited to optical character recognition, understanding the contents of the medical documents using natural language processing, and integrating processes into the overall AI pipeline to mine healthcare and medical information with high recall and other relevant metrics. We ingest claims, medical charts, etc. from providers containing unstructured data which will be transformed into structured data to support automated entry into our storage layers for downstream applications. The results will be used dually for real-time operational processes with both automated and human-based decision making as well as contribute to reducing healthcare administrative costs. We work with all major cloud and big data vendors offerings including but not limited to (Azure, AWS, Google, IBM, etc.) to achieve AI goals in healthcare and support Evolent business.

Essential functions

The Sr. NLP Text Mining Scientist / Engineer will have the opportunity to lead a team, shape team culture and operating norms as a result of the fast-paced nature of a new, high-growth organization.
7+ years of Industry experience primarily related to Unstructured Text Data and NLP (PhD work and internships will be considered if they are related to unstructured text in lieu of industry experience but not more than 2 years will be accounted towards industry experience)
Develop Natural Language Medical/Healthcare documents comprehension related products to support Evolent Health business objectives, products and improve processing efficiency, reducing overall healthcare costs
Gather external data sets; build synthetic data and label data sets as per the needs for NLP/NLR/NLU
Apply expert software engineering skills to build Natural Language products to improve automation and improve user experiences leveraging unstructured data storage, Entity Recognition, POS Tagging, ontologies, taxonomies, data mining, information retrieval techniques, machine learning approach, distributed and cloud computing platforms
Own the Natural Language and Text Mining products — from platforms to systems for model training, versioning, deploying, storage and testing models with creating real time feedback loops to fully automated services
Work closely and collaborate with Data Scientists, Machine Learning engineers, IT teams and Business stakeholders spread out across various locations in US and India to achieve business goals
Provide mentoring to other Data Scientist and Machine Learning Engineers
Strong understanding of mathematical concepts including but not limited to linear algebra, Advanced calculus, partial differential equations and statistics including Bayesian approaches
Strong programming experience including understanding of concepts in data structures, algorithms, compression techniques, high performance computing, distributed computing, and various computer architecture
Good understanding and experience with traditional data science approaches like sampling techniques, feature engineering, classification and regressions, SVM, trees, model evaluations
Additional course work, projects, research participation and/or publications in Natural Language processing, reasoning and understanding, information retrieval, text mining, search, computational linguistics, ontologies, semantics
Experience with developing and deploying products in production with experience in two or more of the following languages (Python, C++, Java, Scala)
Strong Unix/Linux background and experience with at least one of the following cloud vendors like AWS, Azure, and Google for 2+ years
Hands on experience with one or more of high-performance computing and distributed computing like Spark, Dask, Hadoop, CUDA distributed GPU (2+ years)
Thorough understanding of deep learning architectures and hands on experience with one or more frameworks like tensorflow, pytorch, keras (2+ years)
Hands on experience with libraries and tools like Spacy, NLTK, Stanford core NLP, Genism, johnsnowlabs for 5+ years
Understanding business use cases and be able to translate them to team with a vision on how to implement
Identify enhancements and build best practices that can help to improve the productivity of the team.


Nice to Have
Medical concepts with codes from standard ontologies (SNOMED CT, LOINC, RxNorm, ICD, etc.)
Lucene, Solr, Elastic Search experience
Experience with Kubernetes and dockers
Experience building REST API’s for AI work and knowledge of microservices architecture
Participation in open source community projects
Academic Qualification:
Master’s degree or above in Computer Science, Computational linguistics, Mathematics, Physics or electrical engineering with research experience from a strong academic program along with thesis (No Post Graduate diplomas and undergraduate degrees)
Completion of thesis/research is required as part of graduation in computer science, artificial intelligence, Mathematics, Physics, Electrical Engineering or statistics
A PhD degree in Computer Science, Artificial Intelligence, Computational Linguistics, Machine Learning, or related technical field is preferred from a strong academic program
Publication record in top NLP conferences (NIPS, ICLR, ACL, NAACL, EMNLP, SIGIR, WWW etc) is preferred",2.9,"Evolent Health
2.9",Pune,"Arlington, VA",1001 to 5000 employees,2011,Company - Public,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),-1
Data Analyst,-1,"• Provide sustaining support for existing dashboards and semantic.

• Design, develop, and support dashboards and reports.

• Monitor FogBugz Ticketing system to address bugs, enhancements and adhoc data requests

for Operations stake holders.

• Drive deep data profiling and analysis for insights.

• Create and deploy robust, scalable audit framework for monitoring data quality and latency

for our semantic and dashboards.

• Drive automation wherever applicable for scale and efficiency.

Key Qualifications:

• Expertise with Tableau and data visualisation is a must

• Expertise in UI/UX is a must

• Experience presenting and sharing insights with various business functions

• Relational Database design and data architecture fundamentals;

• Experience with ETL tools used to automate manual processes

• Experience with Python a plus.

Individual must demonstrate:

• Sound critical thinking, work ethics and passion to go beyond what is expected ongoing.

• Possess a very high degree of natural curiosity to drive the next levels of business questions

and insights.

• Ability to manage and deliver assigned projects from start to finish within timelines, scope

and quality.

• Advanced knowledge of SQL is a plus

• Strong verbal and written communications.",4.8,"Thoucentric
4.8",Hyderabad,"Bengaluru, India",51 to 200 employees,2015,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
AVP Quantitative Analyst - Cash Equities - Algo Development,-1,"About Citi Markets: Citis equities business is one of the largest and most established, both regionally and globally. Our clients include the worlds leading institutional investors and high net worth individuals and we provide these clients with value-added, independent, insightful and actionable investment advice. The successful candidate will join Citis Global Markets Center in Mumbai and will work closely with New York, London and Hong Kong based sales traders, quantitative analysts and technologists. Job Description: Position Title: Assistant Vice President Cash Equities Quant Business Group: Institutional Clients Group Grade/Level: Assistant Vice President Function/Group: Citi Markets Location: Mumbai Percentage of Travel: Yes, 10% of the Time Individual Contributor (IC)/Managerial: IC Role and Responsibilities: Day-to-Day Responsibilities: Citi is looking to expand its team of highly talented individuals who are working on the research and development of analytics, signals and trading tools used in the context of Citis cash equities trading businesses. The work covers a number of product lines including pre-trade, intra-trade, post-trade products, electronic execution and central risk platforms across all major global markets. A successful candidate will have a demonstrated ability in building quantitative analytics tools with preference given to those with direct experience in algo execution development and a working knowledge of equites market microstructure (or other asset class). They will use their strong programming capability to collect, manipulate and aggregate large data sets and develop production ready components. They will develop, enhance and maintain the Citi execution algorithms and participate in full algo development lifecycle from discussing requirements with desk, design, implementation, testing, and supporting the strategies used by our clients. Qualifications: Education: Bachelors or Masters degree in Computer Science/Electrical Engineering/Mathematics/Statistics from a premier academic institution Experience: 2-8 years of industry experience Skills Required: Strong object oriented programming and software design skills in Java Experience in the development and maintenance of algo execution algorithms and analytical/algo trading tools. Experience of quantitative data analysis, production and automation of regular reports. Good analytical and quantitative background, with knowledge in one or more of the following disciplines probability, quantitative finance, computer science, and statistics. Desired experience: Q/KDB+ , Git, TeamCity, and LaTeX Good communication skills, both verbal and written. Ability to work under pressure, with minimal supervision, and in a team environment Detail-oriented and with strong organizational skills ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN ------------------------------------------------------ Time Type : ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.7,"Citi
3.7",Mumbai,"New York, NY",10000+ employees,1812,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Analytic Consultant 3,-1,"About Wells Fargo India Wells Fargo India enables global talent capabilities for Wells Fargo Bank NA., by supporting business lines and staff functions across Technology, Operations, Risk, Audit, Process Excellence, Automation and Product, Analytics and Modeling. We are operating in Hyderabad, Bengaluru and Chennai locations. Department Overview The Insights & Analytics (I&A) team has a unique and exciting opportunity for an Analytics Consultant to support the Digital Customer Experience (DCE) function within the Marketing Analytics team. The primary expectation of this role is to work along stateside analytic consultants and convert our business partners questions into data-driven insights that both monitor and inform the business. About the Role The position will communicate regularly with onshore team members at all levels of the organization primarily across the Digital Customer Experience and marketing teams. An ideal candidate must be able to communicate effectively and efficiently, and be proactive in the development and partnership related to the respective data and platforms involved. Responsibilities Responsibilities include: •Understand business objectives and translate those into technical requirements. •Ability to access, explore, and perform data discovery. •Know how to perform data hygiene on complex data sets (i.e. data cleansing). •Know how to enrich datasets through data manipulation and joining. •Experience building data visualizations using BI tools or other software packages. •Basic advanced analytics knowledge, ideally in predictive or machine learning. •Ability to learn or already have hands-on web analytics experience, ideally leveraging enterprise platforms e.g. Google Analytics, Adobe Analytics, or like capability. •Understand the fundamentals of Digital Marketing and Digital Analytics, ideally with hands on experience monitoring and measuring customer journeys and sojourns. •Understand the fundamentals of site optimization, digital customer experience best practices, and how to apply complex data to online customer behaviors and interactions. Team members support our focus on building strong customer relationships balanced with a strong risk mitigating and compliance-driven culture which firmly establishes those disciplines as critical to the success of our customers and company. They are accountable for execution of all applicable risk programs (Credit, Market, Financial Crimes, Operational, Regulatory Compliance), which includes effectively following and adhering to applicable Wells Fargo policies and procedures, appropriately fulfilling risk and compliance obligations, timely and effective escalation and remediation of issues, and making sound risk decisions. There is emphasis on proactive monitoring, governance, risk identification and escalation, as well as making sound risk decisions commensurate with the business units risk appetite and all risk and compliance program requirements 51420",3.6,"Wells Fargo
3.6",Bengaluru,"San Francisco, CA",10000+ employees,1852,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),-1
Data Analyst,-1,"Website
AstegicInc Astegic


Full Time
Jaipur
Posted on January 21, 2020

Description:


We are looking for a Data Analyst to join our data team. This is a hands-on technical role. Experience with Shell Script and SQL (T-SQL/PostgreSQL/OracleSQL) is essential. The data analyst will follow an agile iterative development methodology with a focus on innovation, data quality, user value, and robust data analysis.

Job Responsibilities:


Build and test metrics using SQL data-stores.
Build, test and deploy reports and interactive dashboard, leveraging the same metrics.
Focus on visualization for effective report generation, revealing a clear data story.
Process, cleanse, and verify data-integrity for analysis.
Work closely with the USA team to collect and process data on the web crawler software.
Build analysis reports for various tests and production runs on the web crawler software.
Interpret data and analyze results using statistical techniques, and provide ongoing reports.
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.
Acquire data from primary or secondary data sources and maintain databases/data systems.
Identify, analyze, and interpret trends or patterns in complex data sets.
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems.
Work with management to prioritize business and information needs.
Locate and define new process improvement opportunities.
Job Requirements:


Strong T-SQL OR PostgreSQL OR Oracle SQL Skills.
Strong Microsoft Office Skills especially Word and Excel
Experience with scripting Language: Shell
Skilled at queries, report writing and presenting findings.
Strong analytical skills with the ability to collect, organize, analyze, and disseminate a significant amount of information with attention to detail and accuracy.
Ability to write comprehensive reports.
Processing confidential data and information according to guidelines.
Supporting the data warehouse in identifying and revising reporting requirements.
Supporting initiatives for data integrity and normalization.
Providing technical expertise in data storage structures, data mining, and data cleansing.
Identify areas to increase the efficiency and automation of processes.
Monitor and audit data quality.
Ability to deal with high-volume data under tight deadlines.
Create data dashboards, graphs, and visualizations.
Strong verbal and written communication skills.
Ability to work with little or no supervision.
Ability to work calmly under pressure.
Ability to work as a strong team player
Education & Experience:


Bachelor’s Degree in Computer Science or related field.
Minimum 3-5 years of work experience as a Data Analyst.
Other Attributes:


Knowledge of data processing, database programming, and data analytics.
Robust data analysis domain knowledge.
Ability to understand various data structures and common methods in data transformation.
Knowledge of scripting languages such as Python, Shell/Sed/Awk.
Exceptional problem solving and data analysis skills.
A high degree of reliability, flexibility, and adaptability while working under pressure.
Strong verbal and written communication skills.
Detail-oriented with excellent follow-up skills.
Job Location: Jaipur

About Astegic:


Astegic, founded in 2003, is a woman-owned SBA certified 8a firm that has successfully achieved both SEO CMMI ML2 and ISO-9001-2008 certifications. Astegic provides enterprise-level technology solutions and integrations, meeting enterprise business challenges with cutting-edge technology, for both government and commercial sectors. Our knowledgeable staff of over 150 software engineers, management consultants, IT specialists, and analysts is armed with the technology and expertise to improve and extend your existing enterprise solutions.

Full Name * (optional)
Email Address * (optional)
Phone Number * (optional)
Upload CV * (optional)
Upload your CV/resume. Max. file size: 5 MB.

Cover Letter (optional)


Services

Mobile Solutions
Mobile Strategy
Mobile Application Development
Mobile Web Development
Mobile Architecture
Mobile Security
Mobile Design & UX
Mobile Quality Assurance & Control
Mobile Device Management
Enterprise Integration

Enterprise IT Solutions
Software Development
Program Management Offering (PMO)
System Integration
Quality Assurance
IT Automation & Infrastructure Virtualization
Cloud Migration & Optimization/Scalability
Database Management
Enterprise Resource Planning (ERP)
Network & Server Management
Server Administration

UX & Design
User Research
Information Architecture
Interaction Design
Visual Design
Usability

Products
m-Conference
m-Custodial
m-Inspector
mforms

About
Portfolio & Clients
GSA 8(A) STARS II
Careers


Contact

Services
Products
Portfolio
About
Contact

© 2020 Astegic Inc. All rights reserved.

Terms of Use
Privacy Policy",4.1,"Astegic
4.1",Jaipur,"Falls Church, VA",51 to 200 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Principal Data Scientist - AI For Software Engineering,-1,"Date: Jul 22, 2020

As the tech firm that created the mobile world, and with more than 54,000 patents to our name, we’ve made it our business to make a mark. When joining our team at Ericsson you are empowered to learn, lead and perform at your best, shaping the future of technology. This is a place where you're welcomed as your own perfectly unique self, and celebrated for the skills, talent, and perspective you bring to the team. Are you in?

Come, and be where it begins.

Our Exciting Opportunity :

As a Principal Data Scientist - AI for SW Engineering, you will develop and deploy AI models/systems that will transform how software/products are engineered – this includes the full development cycle spanning requirements assembling, design, development, testing and deployment!
We believe in trust – we trust each other to do the right things.
We believe in taking decisions as close to the product and technical expertise as possible.
We believe in creativity – trying new things and learning from our mistakes.
We believe in sharing our insights and helping one another to build an even better user plane.

You will :
Balance multiple projects with a focus on AI for Software Engineering
Transform end to end SW Engineering practices using AI: Requirements collecting/traceability, software development, testing & deployment
Manage communication, planning, collaboration with business partners.
Develop new and apply/extend existing, concepts, methodologies, techniques for multi-functional initiatives
Engage with external ecosystem (academia, technology leaders, open source etc.) to develop the skills and technology portfolio for AI needs
Present and be prominent in AI related forums and conferences, e.g., publishing patents, presenting papers, organizing sessions etc.

To be successful in the role you must have :
Experience applying AI in assessment of complex dynamical systems – critical path, narrow down & prioritize a minimal set of test cases to be exercised based on code changes
Experience in mining code repositories – identifying key patterns
Experience or solid grasp in code analysis tools, compiler design, etc.
Experience in Open source management solutions like Black Duck
Demonstrated proficiencies of implementing a variety of Machine Learning techniques
Experience in natural language processing applied to large scale projects
Programming skills (R/Python) with proficiency in at least one.

Key Qualification:
Education: Bachelors/Masters/Ph. D. in Computer Science/ Data Science
Experience: 15 years

What´s in it for you?
Here at Ericsson, our culture is built on over a century of daring decisions. With us, you will no longer be dreaming of what the future holds – you will be redefining it. You won’t develop for the status quo, but will build what replaces it. Joining us is a way to move your career in any direction you want; with hundreds of career opportunities in locations all over the world, in a place where co-creation and collaboration are embedded into the walls. You will find yourself in a speak-up environment where empathy and humanness serve as cornerstones for how we work, and where work-life balance is a priority. Welcome to an inclusive, global company where your opportunity to make an impact is endless.

What happens once you apply?
To prepare yourself for next steps, please explore here: https://www.ericsson.com/en/careers/job-opportunities/hiring-process

Do you believe that an organization fostering an environment of cooperation and collaboration to execute with speed creates better business value? Do you value a culture of humanness, where fact based decisions are important and our people are encouraged to speak up? Do you believe that diverse, inclusive teams drive performance and innovation? At Ericsson, we do.
We provide equal employment opportunities without regard to race, color, gender, sexual orientation, transgender status, gender identity and/or expression, marital status, pregnancy, parental status, religion, political opinion, nationality, ethnic background, social origin, social status, indigenous status, disability, age, union membership or employee representation and any other characteristic protected by local law or Ericsson’s Code of Business Ethics.",3.9,"Ericsson-Worldwide
3.9",Bengaluru,"Stockholm, Sweden",10000+ employees,1876,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Huawei Technologies, IBM, Cisco Systems"
Sr.Business Research Scientist,-1,"About Amazon.com:
Amazon.com strives to be Earth's most customer-centric company where people can find and discover virtually anything they want to buy online. By giving customers more of what they want - low prices, vast selection, and convenience - Amazon.com continues to grow and evolve as a world-class e-commerce platform. Amazon's evolution from Web site to e-commerce partner to development platform is driven by the spirit of innovation that is part of the company's DNA. The world's brightest technology minds come to Amazon.com to research and develop technology that improves the lives of shoppers and sellers around the world.


About Team
The RBS is an integral part of Amazon online product lifecycle and buying operations. The team is designed to ensure Amazon remains competitive in the online retail space with the best price, wide selection and good product information. The teams primary role is to create and enhance retail selection on the worldwide Amazon online catalog. The tasks handled by this group have a direct impact on customer buying decisions and online user experience.

Overview of the role
This is a Senior leadership role in RBS with primary responsibility to build an ecosystem that will enable Research Analysts at RBS to leverage Data Sciences, ML and DL to solve business problems at scale. The leader will play a significant part in helping RBS meet its Top line and bottom line goals. You will collaborate with global Business and Tech teams on several of these goals. You will constantly stretch the boundaries of Data analytics to derive the business insights and entitlement for business problems. If you are customer obsessed, self-driven, tenacious and analytical, you will have fun solving our business problems of unprecedented scale. As an experienced research analyst, you will help/mentor other research analyst and develop new algorithms leveraging both classical and deep learning techniques.

Key Responsibilities for this Role:-
· Take ownership of a complex problem statement and define solution strategy to holistically solve that problem for RBS. Scoping, driving and delivering complex projects across multiple teams.
· Big data analysis to identify the defects patterns/process gaps and come up with long term solutions to eliminate the defects/issues.
· Build ecosystem for research analyst and scalable platform for RBS along with cross functional team
· Should be able to communicate effectively with business teams, tech teams as well as scientists from different groups
· Reviews and Makes recommendations that impact development schedules and the success for a product or project.
· Coordinates design effort between internal team and External team to develop optimal solutions for their part of project for Amazons network.
· Supports identification of down-stream problems (i.e. system incompatibility, resource unavailability) and escalate them to the appropriate level before they become project-threatening.
· Performs supporting research, conduct analysis of the bigger part of the projects and effectively interpret reports to identify opportunities, optimize processes, and implement changes within their part of project.
· Influence all level either to gather data and information or to execute and implement according to the plan.
· Ability to deal with ambiguity and problem solver
· Communicate ideas effectively and with influence (both verbally and in writing), within and outside the team.

Key Performance Areas:
· Solve large and complex business problems by aligning multiple teams together.
· Data analytics and Data Sciences
· Machine learning (Deep Learning)

Basic Qualifications

· Masters degree or higher in Engineering or Business.
· Thorough knowledge of Statistics, Data Sciences and Machine Learning.
· 5+ years of experience in using machine learning to solve business problems and building ML services
· Expert level competency in Python and its packages.

Preferred Qualifications

· Master degree / MBA
· Experience on product development
· Expertise in Python and Data Analytics
· Expertise in Text mining
· Expertise in Deep learning models",4.3,"Amazon
4.3",Chennai,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Analyst,-1,"Who we are:

We are reinventing personal communication for the digital era.

TouchNote is a creative platform that lets people send custom-made cards, straight from their phone to those they love anywhere in the world. Our easy to use app has helped people nurture their most meaningful relationships over 15 million times and was awarded the Good Web Guide’s App of the Year 2018.

We are a team of passionate and creative individuals trying to make a difference. We’re proud to offer a highly collaborative, solution-focused environment that celebrates diversity and has been listed in Deloitte’s Technology Fast 50 and The Financial Times Future 100 UK.

The mission:

To empower effective data-driven decision-making through surfacing the most relevant insights from data; through reporting, analysis, and optimisation with a focus on establishing best-practice processes and partnering with teams to understand their needs and challenges.

What you’ll do:
Reporting into the Data Lead, you will partner with teams on a day-to-day basis to track market trends, app user behaviour and business performance to support effective operations alongside identifying new opportunities
Develop ad-hoc/bespoke pieces of work independently to answer key performance questions
Formulate hypotheses, help design multivariate experiments and track outcomes to constantly iterate on our customer-facing proposition
Synthesise data into insights to drive actions, presenting to and engaging the wider team where necessary to ensure a focus on outcomes
Design datasets and models to operationalise insights and initiatives
Build dashboards using Looker to display KPIs and important trends
Support the development of our data environment to ensure we are set up to answer questions efficiently and effectively
Engage and train the wider team on best utilising available data sources, empowering them to self-serve over time
Design and launch qualitative user survey/tests, interpreting results to support business decisions
Synthesise both quantitative and qualitative data into insights that deepen our understanding of our product performance and user behaviour
Form part of our data community, sharing best practices and helping to create a world-class team
Requirements

Must-haves:
2+ years experience in hands-on data analysis from a role as Data / Growth Analyst, Data Scientist, Management Consultant or similar
Experience with utilising data visualisation platforms, particularly Looker and LookML
Experience in structured analysis and query optimization in SQL
Knowledge of E2E data pipelines, ideally including the use of tools like DBT
Ideally some kind of experience across subscription-based / mobile app-first / B2C / e-commerce businesses
Demonstrable experience in turning data analytics into actionable insights and communicating these across multiple stakeholders
Advanced Google Sheets/Slides and Excel/Powerpoint user
Can-do attitude, high energy and ability to work autonomously
Benefits
Company laptop (Mac or PC - you choose!)
Choice of wellbeing benefits which include Private Medical Insurance and/or a gym membership
20 days holiday plus bank holidays
Friday drinks
Team lunches
Team socials every month
Free TouchNote credits to use our product!
Reporting to Data Lead

Salary competitive and dependent on experience",5.0,"TouchNote
5.0",Hyderabad,"London, United Kingdom",1 to 50 employees,2008,Company - Private,Internet,Information Technology,₹1 to ₹5 billion (INR),"Minted, Moonpig, Shutterfly"
Data Engineer,-1,"About SpringML

At SpringML, we are all about empowering the ‘doers’ in companies to make smarter decisions with their data. Our predictive analytics products and solutions apply machine learning to today’s most pressing business problems so customers get insights they can trust to drive business growth.

We are a tight-knit, friendly team of passionate and driven people who are dedicated to learning, get excited to solve tough problems and like seeing results, fast. Our core values include putting our customers first, empathy and transparency, and innovation. We are a team with a focus on individual responsibility, rapid personal growth, and execution. If you share similar traits, we want you on our team.

What’s the opportunity?

SpringML is looking to hire a topnotch Data Engineer who is passionate about working with data and using the latest distributed framework to process large datasets.

As a Data Engineer, your primary role will be to design and build data pipelines. You will be focused on helping client projects on data integration, data prep and implementing machine learning on datasets. In this role, you will work on some of the latest technologies, collaborate with partners on early win, consultative approach with clients, interact daily with executive leadership, and help build a great company.

Required Skills:
4-7 years Python or Java programming
4+ years of hands-on experience of Java / J2EE or REST Services / Spring-boot / Application servers
3+ years of Unix/Linux experience
Qualification Required
· Bachelors in Computer Science (or equivalent)
· Google Cloud Data Engineer Certification is preferred.
Responsibilities
· Ability to work on any product on the Google cloud platform.
· Must be hands-on and be able to write code as required
· Flexibility to work on newer product areas.
· Ability to lead junior engineers.
· Ability to interact directly with end customers.
· Architect and design solutions.
· Conduct code reviews.",4.5,"springML
4.5",Hyderabad,"Pleasanton, CA",1 to 50 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Sr.Business Research Scientist,-1,"About Amazon.com:
Amazon.com strives to be Earth's most customer-centric company where people can find and discover virtually anything they want to buy online. By giving customers more of what they want - low prices, vast selection, and convenience - Amazon.com continues to grow and evolve as a world-class e-commerce platform. Amazon's evolution from Web site to e-commerce partner to development platform is driven by the spirit of innovation that is part of the company's DNA. The world's brightest technology minds come to Amazon.com to research and develop technology that improves the lives of shoppers and sellers around the world.


About Team
The RBS is an integral part of Amazon online product lifecycle and buying operations. The team is designed to ensure Amazon remains competitive in the online retail space with the best price, wide selection and good product information. The teams primary role is to create and enhance retail selection on the worldwide Amazon online catalog. The tasks handled by this group have a direct impact on customer buying decisions and online user experience.

Overview of the role
This is a Senior leadership role in RBS with primary responsibility to build an ecosystem that will enable Research Analysts at RBS to leverage Data Sciences, ML and DL to solve business problems at scale. The leader will play a significant part in helping RBS meet its Top line and bottom line goals. You will collaborate with global Business and Tech teams on several of these goals. You will constantly stretch the boundaries of Data analytics to derive the business insights and entitlement for business problems. If you are customer obsessed, self-driven, tenacious and analytical, you will have fun solving our business problems of unprecedented scale. As an experienced research analyst, you will help/mentor other research analyst and develop new algorithms leveraging both classical and deep learning techniques.

Key Responsibilities for this Role:-
· Take ownership of a complex problem statement and define solution strategy to holistically solve that problem for RBS. Scoping, driving and delivering complex projects across multiple teams.
· Big data analysis to identify the defects patterns/process gaps and come up with long term solutions to eliminate the defects/issues.
· Build ecosystem for research analyst and scalable platform for RBS along with cross functional team
· Should be able to communicate effectively with business teams, tech teams as well as scientists from different groups
· Reviews and Makes recommendations that impact development schedules and the success for a product or project.
· Coordinates design effort between internal team and External team to develop optimal solutions for their part of project for Amazons network.
· Supports identification of down-stream problems (i.e. system incompatibility, resource unavailability) and escalate them to the appropriate level before they become project-threatening.
· Performs supporting research, conduct analysis of the bigger part of the projects and effectively interpret reports to identify opportunities, optimize processes, and implement changes within their part of project.
· Influence all level either to gather data and information or to execute and implement according to the plan.
· Ability to deal with ambiguity and problem solver
· Communicate ideas effectively and with influence (both verbally and in writing), within and outside the team.

Key Performance Areas:
· Solve large and complex business problems by aligning multiple teams together.
· Data analytics and Data Sciences
· Machine learning (Deep Learning)

Basic Qualifications

· Masters degree or higher in Engineering or Business.
· Thorough knowledge of Statistics, Data Sciences and Machine Learning.
· 5+ years of experience in using machine learning to solve business problems and building ML services
· Expert level competency in Python and its packages.

Preferred Qualifications

· Master degree / MBA
· Experience on product development
· Expertise in Python and Data Analytics
· Expertise in Text mining
· Expertise in Deep learning models",4.3,"Amazon
4.3",Chennai,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Engineer,-1,"Job Responsibilities :
Responsible for gathering & processing raw data at scale (including
writing scripts,web scraping,calling APIs,write SQL queries, etc.)

Education Requirement :
B.E/B.Tech/MCA

Experience Requirement :
Minimum 6 Years - Maximum 9 Years

Skills & Competencies :
Statistical analysis and modeling
Exposure to Hadoop based technologies
Location Map : Next Gen Ops,Mumbai RCP,Maharashtra",3.6,"Reliance Jio Infocomm Limited
3.6",Mumbai,"Mumbai, India",5001 to 10000 employees,2010,Company - Private,"Cable, Internet & Telephone Providers",Telecommunications,Unknown / Non-Applicable,-1
Principal Data Scientist - AI for Security,-1,"Date: Jul 22, 2020

Ericsson is one of the leading providers of Information and Communication Technology (ICT) to service providers. We enable the full value of connectivity by creating game-changing technology and services that are easy to use, adopt, and scale, making our customers successful in a fully connected world. Headquartered in Stockholm, Sweden, Ericsson is proud of its global presence across 100+ countries and market areas. With a strong focus on innovation, we possess 49 thousand registered patents and a global strength of over 95 thousand competent professionals. We also take pride in supporting networks that cater to a capacity of 40 percent of the world’s mobile traffic, thereby connecting more than 2.5 billion subscribers and counting. We are a world leader in the rapidly changing environment of communications technology – by providing hardware, software, and services to enable the full value of connectivity.

Exciting Opportunity:

The complexity of emerging 5G networks makes manual management and operations of these networks impossible. AI technologies, including Machine Learning, are increasingly being used to drive intelligent automation and autonomous operation of 5G networks that will drive economic and social transformation. Towards this, we have setup a Global AI Accelerator (GAIA) in the US, Sweden and India, with 300 experts, to fast-track our strategy execution.

We use a combination of Machine Learning and other Artificial Intelligence technologies to drive thought leadership to automate and transform Ericsson offerings and operations, including new and emerging business. This includes development of models, frameworks and infrastructure where we not only drive AI based product innovation, but also push the AI technology frontiers. We engage in both academic and industry collaborations and drive the digitalization of Ericsson and the industry by developing state of the art solutions that simplify and automate processes in our products and services and build new value through data driven insights.

For mission critical telecom systems, security is a key concern. The scope of security spans the full range from infrastructure, platform, middleware and finally the network/third party applications. With the emerging distributed cloud based telecom systems, the resulting threat surface has to be evaluated from the ground up and it is here that AI technologies will play a key role towards identifying potential vulnerabilities, detecting system anomalies and automatically taking actions to address potential security issues.

Ericsson is now looking for Principal Data Scientists with a strong background in applying AI for Security for our GAIA team in Bangalore.

Role Summary:

As a Principal Data Scientist, you will build and deploy AI models into production with focus on scaling, monitoring and performance. You will work with business stakeholders to define and formulate the right business problems.

Your knowledge and experience in Data Science methodologies will be applied to solve challenging real-world problems as part of a highly dynamic and global team. You will work in a highly collaborative environment where you communicate and plan tasks and ideas. You will be working on high impact initiatives with other data scientists to drive growth and economic profitability for Ericsson and its customers by accelerating Ericsson’s AI offerings. Your contribution will also help to create new offerings in the areas of AI driven 4G and 5G network, distributed cloud, IoT and other emerging businesses.

Key Responsibilities:
Lead multiple AI/ML projects for a certain product/business
Manage communication, planning and collaboration with business stakeholders.
Work with huge datasets including petabytes of 4G/5G-networks, IoT and exogenous data
Identify the model monitoring strategy in production and retraining plan.
Define data sourcing, access and pipeline design. Identify and plan for sourcing external data.
Model the business problem statement into an AI/ML problem.
Define the Data sourcing strategy and work with stakeholders to procure data.
Contribute to the intellectual property creation for Ericsson in AI/ML
Define/Design data storage and retrieval strategies from various kind of data sources such as NOSQL Databases. Design data pipelines and flow strategies.
Design APIs for AI/ML models with focus on business, modularity and versioning; and build standard/canonical data models by combining multiple data sources.
Lead functional and technical analysis within Ericsson businesses and for strategic customers to understand MI-driven business needs and opportunities
Contribute to rapid and iterative development of validated minimum viable solutions addressing these needs. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical models, deep learning, reinforcement learning and other machine learning systems
Lead studies and creative usage of new and/or existing data sources. Work with Data Architects to leverage existing data models and build new ones as needed.
Collaborate with product development teams and partners in Ericsson Businesses to industrialize machine learning models and solutions as part of Ericsson offerings including providing source code, workflows and documents
Work with new technologies and be the ambassador for them in AI Communities within Ericsson, nurturing the communities and mentoring junior data scientists.
Provide AI Competence build-up in Ericsson Businesses and Customer Serving Units
Develop new and apply/extend existing, concepts, methodologies, techniques for cross functional initiatives
Engage with external ecosystem (academia, technology leaders, open source etc.) to develop the skills and technology portfolio for AI needs
Present and be prominent in AI related forums and conferences, e.g., publishing patents, presenting papers, organizing sessions etc.
Key Qualifications:
Bachelors/Masters/Ph.D. in Computer Science, Data Science, Artificial Intelligence, Machine Learning, Electrical Engineering or related disciplines from any of the reputed institutes.
Applied experience: 8+ years of ML and/or AI production level experience; and an overall industry experience of about 15+ years.
Strong knowledge and 5+ years of hands-on experience in the following areas:
Vulnerability detection in networks and systems
Threat detection - Attacks and Compromised systems
Automated remediation using AI
Understanding of security issues in Cloud Native deployments (ranging from on-prem, private clouds, public clouds)
Deep experience with application of AI technologies to develop full stack security solutions (low footprint devices to high end data centres, low level hardware infrastructure to end user/application security)
Privacy & fairness
Understanding of 5G security challenges a big plus
Understanding of security implications of AI components/technologies (model/data security etc) is a big plus
Solid understanding of Machine learning and Deep learning
Proven skills of implementing a variety of Machine Learning techniques
Strong grounding in mathematics, probability, statistics needed for data analysis and experiments
Proven skills in building AI/ML based solutions using a variety of frameworks such as Python, R, H2O, Keras, TensorFlow, Spark ML etc.
Extensive experience in model development and life-cycle-management in one or more industry/application domain
Able to build and deploy AI models into production with focus on scaling, monitoring and performance
Knowledge of building explainable models (XAI) and prescriptive analytics
Knowledge of designing data pipelines and flow strategies
Familiarity with data pipelining frameworks such as Air Flow, AWS Sagemaker, etc. would be a plus
Able to design APIs for AI/ML models with focus on business, modularity and versioning
Experience in writing and presenting white papers, journal articles and technical blogs on the results
Soft Skills:
Good communication skills in written and spoken English
Great Team worker and collaborator
Creativity and ability to formulate problems and solve them independently
Self-driven and ability to work through abstraction
Ability to build and nurture internal and external communities
Additional Requirements:
Security certifications is a plus
Applications/Domain-knowledge in Telecommunication and/or IoT, a plus.
Experience with data visualization and dashboard creation is a plus
Knowledge of Cognitive models is a plus
Ability to work independently with high energy, enthusiasm and persistence
Experience in partnering and collaborative co-creation, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence
What’s in it for you?

With over 90,000 employees across 180+ countries, we have a culture that respects and supports your ambitions, in alignment with our values of Respect, Professionalism and Perseverance. Ericsson is extremely focused on learning and development, supports mobility and flexible working hours. We are also committed to diversity and inclusion and to be a responsible and relevant driver of positive change. We also offer some awesome benefits, amazing career development and training programs to provide an empowered career in a connected world.

Next Steps:

What happens next once you apply? Read about the next steps here

For your prep and reference, here is our overall Brand video and some insights about our innovations in 5G

Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development. Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information.",3.9,"Ericsson-Worldwide
3.9",Bengaluru,"Stockholm, Sweden",10000+ employees,1876,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Huawei Technologies, IBM, Cisco Systems"
"Data Scientist II, Consumer Payments",-1,"Bachelor's degree in a quantitative field (i.e. math, engineering, statistics, finance, or similar)
4+ years of relevant work experience in data science, business analytics, business intelligence, or comparable experience
Strong proficiency in MS Excel and relational databases - e.g. Redshift, SQL, ETL, Data Warehouse, etc.
Deep understanding of common business metrics and the ability to generate new ones as needed
Strong verbal/written communication & data presentation skills, including an ability to effectively communicate with both business and technical teams
An ability to thrive in a highly ambiguous, fast-paced and rapidly-changing environment
Ability to lead large projects and drive through completion
The Amazon Payments Team manages all Amazon branded payment offerings, globally. These offerings are growing rapidly and we are continuously adding new market-leading features and launching new products. Our payments products (Amazon Co-Branded Credit Cards, Gift Cards, Points, Shop with Points and Installments ) provide the most innovative payment experience on and off Amazon. We manage a financial services ad serving platform (billions of impressions per year) through Amazon’s purchase path where we offer Amazon branded and non-branded payment products and services. Our team of high caliber software developers, statisticians, analysts and product managers use rigorous quantitative approaches to ensure that we target the right product to the right customer at the right moment, managing tradeoffs between click through rate, approval rates and lifetime value. We leverage the wealth of Amazon’s information to build a wide range of probabilistic models, set up experiments that ensure that we are thriving to reach global optimums and leverage Amazon’s technological infrastructure to display the right offerings in real time. We work closely with product managers to understand their business, collect requirements and deliver high value analytics and insights for the Amazon Payments team that drive acquisition, usage and loyalty. Our petabytes of data has the ability to improve the shopping experience for hundreds of millions of consumers worldwide. Our goal is to delight our customers with their purchasing experience. Those of us who love to work with data see this as the pinnacle of opportunities that you cannot find anywhere else in the world.

We are looking for an outstanding Data Scientist that is able to comprehend the details behind the Amazon Payments Products business, understand/clarify business requirements, transform volumes of data into actionable insights, serve as the technical/statistics SME, help us improve our targeting methods/models by initiating innovative/creative projects, lead analytical discussions and road map, work across teams and influence the analytical direction of external teams, combine expert statistical/modeling knowledge with programming skills to manage and deliver on complex/critical analysis projects, independently identify and resolve business/technical issues, develop best practices and support our product managers across the world. Amazon.com has a culture of data-driven decision-making, and demands business intelligence that is timely, accurate, innovative and actionable.
Master’s degree in an analytical field (or equivalent experience)
2+ years of relevant work experience in data science, business analytics, business intelligence (BI), or comparable experience
Practical experience in programing or scripting languages like Python, VBA, etc.
Familiarity with AWS solutions such as EC2, DynamoDB, and S3
Financial service experience is a plus",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist - GAIA,-1,"Date: Jul 22, 2020

As the tech firm that created the mobile world, and with more than 54,000 patents to our name, we’ve made it our business to make a mark. When joining our team at Ericsson you are empowered to learn, lead and perform at your best, shaping the future of technology. This is a place where you're welcomed as your own perfectly unique self, and celebrated for the skills, talent, and perspective you bring to the team. Are you in?

Come, and be where it begins.

Our Exciting Opportunity

In the fifth-generation mobile networks 5G, AI technologies are an integral part of making the networks meet the new challenges and deliver performance that far exceeds networks of today. 5G networks with distributed edge compute, will drive economic and social transformation for all aspects of society!

Machine Learning (ML) and other Artificial Intelligence (AI) technologies will be vital for us to handle this opportunity. We are setting up a Global AI Accelerator (GAIA) in the US, Sweden and India, with 300 specialists, to fast-track our strategy execution!

You will
Contribute to rapid and iterative development of high quality ML/AI applications. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical model, deep learning, reinforcement learning and other machine learning systems.
Work with new technologies and champion them in MI Communities within Ericsson.
Present and be prominent in MI related forums and conferences, e.g., presenting papers, organizing sessions and be a panelist
To be successful in the role you must have
Solid skills in Machine Learning especially techniques such as Linear/Logistic Regression, Bagging, Bayesian model, Neural Networks, Random forest, Gradient boosting, Hyperparameter optimization techniques etc.
Demonstrable skills and track record (Github, open source etc.) in the use of current state of the art machine learning frameworks such as Keras, TensorFlow, Scikit-Learn, H2o, Spark etc. in developing ML/AI applications
Programming skills in various languages (C++, Scala, Java, R) with proficiency in Python and/or C++
What´s in it for you?

Here at Ericsson, our culture is built on over a century of courageous decisions. With us, you will no longer be dreaming of what the future holds – you will be redefining it. You won’t develop for the status quo, but will build what replaces it. Joining us is a way to move your career in any direction you want; with hundreds of career opportunities in locations all over the world, in a place where co-creation and collaboration are embedded into the walls. You will find yourself in a speak-up environment where empathy and humanness serve as cornerstones for how we work, and where work-life balance is a priority. Welcome to an inclusive, global company where your opportunity to make an impact is endless.

What happens once you apply?

To prepare yourself for next steps, please explore here: https://www.ericsson.com/en/careers/job-opportunities/hiring-process

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

Do you believe that an organization fostering an environment of cooperation and collaboration to execute with speed creates better business value? Do you value a culture of humanness, where fact based decisions are important and our people are encouraged to speak up? Do you believe that diverse, inclusive teams drive performance and innovation? At Ericsson, we do.

We provide equal employment opportunities without regard to race, color, gender, sexual orientation, transgender status, gender identity and/or expression, marital status, pregnancy, parental status, religion, political opinion, nationality, ethnic background, social origin, social status, indigenous status, disability, age, union membership or employee representation and any other characteristic protected by local law or Ericsson’s Code of Business Ethics.",3.9,"Ericsson-Worldwide
3.9",Bengaluru,"Stockholm, Sweden",10000+ employees,1876,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Huawei Technologies, IBM, Cisco Systems"
Data Engineer,-1,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Data Engineer,-1,"requirements
You have at least 1 year of experience working and scaling with data pipelines and warehouses.
You have good understanding of at least 1 programming language.
You have worked on problem statements including batch-processing.
You know the basics and internal workings of at least one database/data warehouse/data lake and understood the workings in depth.
You have a knack to deep-dive into the use-cases of data, not just the technical aspects.

Bonus Requirements

Knowledge about AWS Redshift data warehouse
Understanding of AWS resources and serverless computing
Knowledge on Kubernetes (preferable Amazon EKS)
Exposure to any orchestration tool (preferably Airflow)
description

Postman leads the way in the API-first universe. Postmanâ€™s API Development Environment is used by 10+ million developers and more than 500,000 companies to access 250+ million APIs every month.

We are looking for a Data Engineer in data team to help us scale the existing infrastructure and in parallel work on next generation data tools including data scrapping, machine learning infrastructure and data validation systems.

Data team at Postman acts as a central function, catering to the needs of the overall organisation. More than half of the organisation is currently active on our data tools, hence data engineers and data analysts work together to cater to these forever increasing needs. We are a lean team which works autonomously by delegating and trusting every member to take things to completion.

Responsibilities

Be an amazing learner on a day-to-day basis.
Communicate effectively with data consumers to fine-tune data platform systems (existing or new).
Contribute to existing EL (extract & load) data pipelines while building new systems in parallel.
Own and deliver high performing systems (not just pipelines) and help the team scale them up, to endure ever increasing traffic.
Become a product owner (not just a system owner) over-time by understanding the end results of building systems.
benefits

We offer a competitive salary and excellent benefits. What you will also get to experience is a company that believes in autonomous small teams for maximum impact; that strives for organizational growth to align with that of the individual; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves and where ideas are encouraged from anyone and everyone. We seek people who naturally demonstrate our values, who not only understand the challenge but can also solve this for the rest of the world. Be a part of something big.",4.9,"Postdot Technologies
4.9",Bengaluru,"San Francisco, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"You will be working closely with the Product Team to share data driven insights on user experience, user journey and strategic issues in the game.

RESPONSIBILITIES
Create models for dynamic data analysis
Execute quantitative data analysis to draw actionable insights
Provide data driven decision making support on product features
Understanding data to decode patterns and develop user behaviour insights
Monitoring and performance analysis of product features
Opportunities to learn new things as we move along in our journey
REQUIREMENTS
Experience in analyzing data and creating meaningful insights
Hands on knowledge of SQL, R/Python is a big plus
Passion for gaming and development
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Preference for working without a handbook, with a love for doing what’s never been done before
To Apply, please submit your Resume along with your LinkedIn profile to: joinus@hitwicket.com",4.1,"Hitwicket
4.1",Hyderabad,"Hyderābād, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Company Background:

Pluto7 is a Google Premier Partner for services and solutions company focused on building ML, Ai, Analytics, solutions to accelerate business transformation. We are a Premier Google Cloud Partner, servicing Retail, Manufacturing, Healthcare, and Hi-Tech industries. Were seeking passionate people to work with us to change the way data is captured, accessed and processed, to make data-driven insightful decisions.

Role: Data Engineer

Experience: 2-5 years

Work location : India (Remote)

Must have skills :
Hands-on experience in database systems (Structured and Unstructured).
Programming in Python, R, SAS.
Overall knowledge and exposure on how to architect solutions in cloud platforms like GCP, AWS, Microsoft Azure.
Develop and maintain scalable data pipelines, with a focus on writing clean, fault-tolerant code.
Hands-on experience in data model design, developing Big Query/SQL (any variant) stored.
Optimize data structures for efficient querying of those systems.
Collaborate with internal and external data sources to ensure integrations are accurate, scalable and maintainable.
Collaborate with business intelligence/analytics teams on data mart optimizations, query tuning and database design.
Execute proof of concepts to assess strategic opportunities and future data extraction and integration capabilities..
Data extraction, Data cleansing and transformation.
Strong knowledge on REST APIs, Http Server, MVC architecture.
Knowledge on continuous integration/continuous deployment.
Preferred but not required:
Machine learning and Deep learning experience
Certification on any cloud platform is preferred.
Experience of data migration from On-Prem to Cloud environment.
Exceptional analytical, quantitative, problem-solving, and critical thinking skills
Excellent verbal and written communication skills",3.9,"Pluto7
3.9",Bengaluru,"Milpitas, CA",51 to 200 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"About the Company

We are a Cochin based ISO certified Software Development company, incorporated in January 2003. We are specialised in providing real-time solutions in the field of Application Software, System Software, Web Development, Mobile/PDA/Wireless Applications, and Embedded Systems with a clientele spread across United States, Europe and the Middle East.

Leveraging the valuable experience obtained over the years, Quest formed its IT Training division intended to deliver modern day training programs on domains like Embedded Systems, DSP, .NET, JAVA, PYTHON and Android.

Designation: Senior Software Engineer

Responsibilities:

As a Senior Software Engineer at Quest Innovative Solutions (P) Ltd, you will be expected to provide technical and management leadership for the training team. You should be capable of leading a team of trainers handling a variety of technologies. Direct responsibility for all the training activities conducted under each area (Regular training program, Corporate/Campus training programs and Live/Academic projects.

Activities:

Technical counselling, conducting classes, supervising and evaluations of trainees and trainers, mentoring trainees and junior trainers etc.

Experience:

Project Development/Academic project development

a) Good knowledge in .PYTHON / Machine Learning

b) Experience: 1 to 3 Years

c) Strong Interpersonal and Communications Skills

Academic Qualification: B.Tech / MCA / M.Sc Computer Science

Python:

Skills required: Deep knowledge in Core Python, Django, Flask, GUI, MySQL/SQL/PostgreSQL
Domains: Web applications/ Machine Learning/ Deep Learning/ AI

Job Type: Full-time

Salary: ₹15,000.00 - ₹28,000.00 per month",3.4,"QUEST INNOVATIVE SOLUTIONS PVT LTD
3.4",Thiruvananthapuram,"Cochin, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer: Big Data,-1,"Introduction
At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities
As Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the design of data solutions using Hadoop based technologies along with Java & Spark programming.
Responsibilities:

Responsible to Ingest data from files, streams and databases. Process the data with Hive, Hadoop, Spark.
Develop programs in Scala, Java and Python as part of data cleaning and processing
Responsible to design and develop distributed, high volume, high velocity multi-threaded event processing systems using Core Java technology stack
Develop efficient software code for multiple use cases leveraging Core Java and Big Data technologies for various use cases built on the platform
Provide high operational excellence guaranteeing high availability and platform stability
Implement scalable solutions to meet the ever-increasing data volumes, using big data/cloud technologies Apache Spark, Hadoop, any Cloud computing etc.
If you thrive in a dynamic, collaborative workplace, IBM provides an environment where you will be challenged and inspired every single day. And if you relish the freedom to bring creative, thoughtful solutions to the table, there's no limit to what you can accomplish here.
Required Technical and Professional Expertise
Minimum 4+ years of experience in Big Data technologies
Minimum 4+ years of experience in Java and multi-threading programming
Expertise in Python, Spark and Hadoop technologies
Proficient in development using SQL, Hive, Scala,
Ability to demonstrate micro / macro designing and familiar with Unix Commands and basic work experience in Unix Shell Scripting
Demonstrated ability in solutioning covering data ingestion, data cleansing, ETL, data mart creation and exposing data for consumers
Preferred Technical and Professional Expertise
Expertise in Python or Scala programming
You love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologies
Ambitious individual who can work under their own direction towards agreed targets/goals and with creative approach to work
Intuitive individual with an ability to manage change and proven time management
Proven interpersonal skills while contributing to team effort by accomplishing related results as needed
Up-to-date technical knowledge by attending educational workshops, reviewing publications
About Business Unit
IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world. What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Lead Sr Data Scientist,-1,"Lead Sr Data Scientist-20000IAH Applicants are required to read, write, and speak the following languages: English
Preferred Qualifications


Oracle Cloud Infrastructure (OCI) is a strategic growth area for Oracle. It is a comprehensive cloud service offering in the enterprise software industry, spanning Infrastructure as a Service (IaaS), Platform as a Service (PaaS) and Software as a Service (SaaS). OCI is currently building a future-ready Gen2 cloud Data Science service platform. At the core of this platform, lies Cloud Cognitive Service.

What OCI AI Cloud Services are: A set of services on public cloud, that are powered by ML and AI to meet the Enterprise modernization needs, and that work out of the box. These services and models can be easily specialized for specific customer/domain by leveraging existing OCI services.

Key Points: Enables customers to add AI capabilities to their Apps and Workflows easily via APIs or Containers, Useable without needing to build AI expertise in-house and Covers key gaps – NLP, Computer Vision, for Public Clouds and Enterprise in NLU, NLP, Vision and Conversational AI.

You’re Opportunity: As we blaze the trail to provide a single collaborative ML environment for data-science professionals, we will be extremely happy to have you join us and share the very future of our Machine Learning platform - by building a Cognitive Cloud service.

We are addressing exciting challenges at the intersection of artificial intelligence and cutting-edge cloud infrastructure. We are building cloud services in natural language processing (NLP) and, computer vision that works out of the box for enterprises. Our product vision includes the ability for enterprises to be able to customize the services for their business and train them to specialize in their data by creating micro models that enhance the global AI models.

What You’ll Do
Build cloud service on top of the modern Infrastructure as Service (IaaS) building blocks at OCI
Design and build distributed, scalable, fault-tolerant software systems
Participate in the entire software lifecycle – development, testing, CI and production operations
The balance between product feature development and production operational concerns like writing run books, ops automation, structured logging, instrumentation for metrics and events
Leverage a plethora of internal tooling at OCI to develop, build, deploy and troubleshoot software
Participate in on-call for the service with the team
Qualifications
Have successfully designed a very large system on Cloud with proven complexity
Have been an architect of distributed systems in the Cloud world.
You are ideally proficient in Java. Proficiency in Go would be a bonus
You have experience with Cloud Computing, System Design, and Object-Oriented Design
Deep understanding of data structures, algorithms, and excellent problem-solving skills
Experience building microservices and RESTful services and deep understanding of building cloud-based services (MT architecture, Autoscaling, Autonomous driven system, monitoring on the fly, run long-running high compute process)
Experienced at building highly available services, possessing knowledge of common service-oriented design patterns and service-to-service communication protocols
You are familiar with components of modern infrastructure like service discovery, secret storage, software-defined networking, etc.
Strong knowledge of Docker/Kubernetes to build and deploy using Terraform, Ansible
Build and Delivery of a high-quality cloud service with the capabilities, scalability, and performance needed to match the needs of enterprise teams
You have experience with production operations and good practices for putting quality code in production and troubleshoot issues when they arise
Preferably, production experience with Cloud and ML technologies
Take the initiative and be responsible for delivering complex software by working effectively with the team and other stakeholders
You feel at home communicating technical ideas verbally and in writing (technical proposals, design specs, architecture diagrams, and presentations)
Data science and machine learning knowledge would be helpful but not required
Our vision is to provide an immersive AI experience on Oracle Cloud. Aggressive as it might sound, our growth journey is fueled by highly energetic, technology savvy engineers like YOU who are looking to grow with us to meet the demands of building a powerful next-generation platform. Are you ready to do something big?
Detailed Description and Job Requirements
Design, develop, troubleshoot and debug software programs for databases, applications, tools, networks etc.

As a member of the software engineering division, you will take an active role in the definition and evolution of standard practices and procedures. Define specifications for significant new projects and specify, design and develop software according to those specifications. You will perform professional software development tasks associated with the developing, designing and debugging of software applications or operating systems.

Provide leadership and expertise in the development of new products/services/processes, frequently operating at the leading edge of technology. Recommends and justifies major changes to existing products/services/processes. BS or MS degree or equivalent experience relevant to functional area. 8 or more years of software engineering or related experience.
Job
: Product Development
Location
: IN-IN,India-Bengaluru
Job Type
: Regular Employee Hire
Organization
: Oracle",3.7,"Oracle
3.7",Bengaluru,"Redwood City, CA",10000+ employees,1977,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹500+ billion (INR),"SAP, Salesforce, Microsoft"
Data Science Engineer,-1,"• BTech / BS / BE / MTech / MS / ME in CSE, ECE OR EEE
• 5+ years experieince in web-app development, with minimum 2+ years of NLP experieince
• Proficiency in Data Structures & Algorithms
• Hands on experience with MySQL, Mongo-DB & Neo4j
• Experience with open-source NLP libraries such as spacy, NLTK
• Experience with Word2Vec, Glove, RNN, LSTM
• Experience with Data Pipeline Frameworks such as AWS Data Pipeline

Requirements
Key Responsibilities:

• Design and build highly scalable nlp pipelines
• Design and write custom algorithms to solve domain specific problems
• Build POCs using open-source libraries for independent modules
• Create AI solution for automated dialogue (chat bots); natural texting for knowledge &
expertise recommendations.
• Build & train NLP platform from user generated textual data (email, IM, search logs) on daily
basis
• Code ML models primarily using python, No-Sql & AWS
• Collaborate with other team members and stakeholders.",-1,Eminence Core Solutions LLP,Pune,-1,-1,-1,-1,-1,-1,-1,-1
DATA SCIENTIST /,-1,"Exposure to ML concepts - Probabilistic Models, Supervised and Unsupervised Learning, Neural Networks & Deep learning, Ensembling. Understanding of concepts behind Machine Learning algorithms such as Probability, Statistics, Linear Algebra. Exposure to libraries such as theano, tensorflow, keras, torch, caffe etc.",5.0,"HelloLeads
5.0",Tiruchchirappalli,"Tiruchirappalli, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Tech Lead Data Scientist,-1,"Position: Data Scientist

Location: Pune, India

NICE Actimize is comprised of talented, creative and dedicated individuals with a passion for delivering innovative solutions to the market. At NICE Actimize, we recognize that every employee’s contributions are integral to our company’s growth and success. To find and acquire the best and brightest talent around the globe, we offer a challenging work environment, competitive compensation and benefits, and rewarding career opportunities. Come share, grow and learn with us – you’ll be challenged, you’ll have fun and you’ll be part of a fast growing, highly respected organization.

NICE Actimize is currently seeking an experienced Data Scientist to join our dynamic and growing Fraud & AML Analytics Services team.

Responsibilities
Perform analysis to support the deployment of fraud prevention analytical models
Analyze fraud cases obtained from clients
Research data patterns in order to find patterns predictive of fraud
Improve the quality and actual implementation of computational algorithms and tools
Optimize the detection performance of NICE Actimize Fraud products and improve customers’ experience with our Fraud solutions
Define product requirements for analytics and provide feedback to the product team on ways in which product may be improved
Develop and enhance our solution-specific risk scores
Measure the quality of the analytical performance of Fraud Products
Develop tools to support model tuning, performance tracking and automation
Develop custom detection logic for specific clients
Help maintain and improve model development methodologies/practices.
Experience: 3 to 6 Years

Qualifications:
Advanced degree in a quantitative area (statistics, mathematics, physics, computer science, engineering)
Strong general analytical skills, Experience with statistical model development. Deep and diverse experience with multiple statistical procedures and data mining algorithms.
Strong experience with using SQL and EXCEL.
Strong programming skills in Python and ability to rapidly learn new programming tools.
Exposure to other programming languages: R, SAS, Scala, Java, Python, Matlab, SPSS, VBA, including procedures, macros, and scripting.
Experience of building and deploying classification and regression machine learning models at an enterprise level.
Good oral and written communications skills, and ability to interact with engineers, software developers, project managers, business analysts, product managers and with clients.
Ability to work in multi-disciplinary agile teams.
Strong commitment to quality
Customer facing experience – a plus
Innovative aptitude.
Additional Desired Qualifications:
Experience in development of risk management models, particularly in the fraud, AML, or financial trade compliance areas.
Knowledge of national and international financial systems and data standards.
Experience with Business Intelligence platforms, methodologies (e.g. OLAP), and tools.",4.0,"NICE Actimize
4.0",Pune,"Hoboken, NJ",501 to 1000 employees,1999,Subsidiary or Business Segment,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"SAS, Feedzai"
Machine Learning-Engineer,-1,"Job Description
t10+ years of experience as network or security engineer/architect in telecom sector %E2%80%93 must have worked with NEP, ISV/Hitech product companies as part of engineering organization OR via service provider in similar capacity. n tExpert knowledge of 3GPP NR CT/SA and ETSI ISG NFV specifications n tIn-Depth knowledge and experience in SDN, SD-WAN, NFV , IP-RAN and network orchestration n n tExtensive experience in no tCrypto & PKI technology %E2%80%93 Hash, Symmetric / Asymmetric encryption OAEP, PSS RSA-X509, ECC OCSP, CRL, EST, SCEP, TLS/DTLS, PKCS, PKIX-CMP, CP/CPS n tIn-Depth knowledge of security technologies: no tdesign and implement solution using - LDAP, OAuth, OpenID, SAML, Kerberos, SCIM WebAuthN, FIDO, U2F, TOTP, HOTP no tzero trust security model %E2%80%93 Cloud security (Azure/AWS/GCP), API security, multi-factor authentication, container security, etc. no tdata and system security %E2%80%93 application whitelisting, run-time system integrity check, anomaly detection, message signing and encryptuion, dynamic access control no tKnowledge of IP Networking including Virtual Private Cloud, VPN, SDN, DNS, Load-balancing, and Firewalls. n n tExperience developing solutions with Infrastructure as a Service and Configuration Management tools like Ansible, OpenStack, Chef, Puppet n tExperience building container-based solutions using Kubernetes, and/or Docker Data Center/swarm. n tHands-on scripting/development platform e.g. Java, Python. n n tStrong understanding of customer needs, competitive products and vendors, relevant technologies and trends, and industry standards. n tDemonstrated experience in gathering and transforming business requirements into a comprehensive technology solution definition. n tStrong team player %E2%80%93 work with internal and external stakeholder to solve problems and actively incorporate input from various sources. n tExcellent communication skills and collaborative working style. n tWilling to travel n tBachelor s degree in Engineering or related field n
Roles & Responibilities
""As a Senior Engineer, you are responsible for areas around Engineering, Global Infrastructure Services etc. You are expected to have good practical understanding of technology, its application and be involved in implementation, integrated testing, debugging and documentation. You are expected to be a Technical SME, and also handle Project Effort Estimation Related Activities, process compliance.""

We are an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law.
Wipro does not charge any fee at any stage of the recruitment process and has not authorised agencies/partners to collect any fee for recruitment. If you encounter any suspicious mail, advertisements or persons who offer jobs at Wipro, please do let us know by contacting us on helpdesk.recruitment@wipro.com
Mandatory Skills
Machine Learning-L1
Desirable Skills
Telecommunication-L1",3.6,"Wipro Limited
3.6",Bengaluru,"Bengaluru, India",10000+ employees,1945,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Cognizant Technology Solutions, Tata Consultancy Services, Accenture"
Data Analyst,-1,"Frost & Sullivan is looking for a Data Analyst/Sr Data Analyst to join our analytics team in Chennai to support our core research team in various research projects through contributions in statistical analysis and database management.

Gathering, extracting and analyzing data from various resources relating to focus markets.
Using business intelligence and statistical software to help build predictive models and perform analysis and deliver forecasts using appropriate techniques.
Identifying and analyzing trends or patterns in complex data sets.
Preferred candidate should possess:
2+ years of work experience in handling projects in advanced statistics and analytics.
A Bachelor’s degree in Statistics, Computer Science, Management or related field with an emphasis on analytics.
Business acumen and ability to translate data insights into meaningful business recommendations.
Strong analytical skills with the ability to collect, manage, aggregate, and analyze data from multiple sources with attention to detail and accuracy into a structured database and produce forecasts using statistical techniques, including segmentation, clustering, regression, time series analysis, etc.
Proficiency in advanced Excel and hands on experience in R.
Excellent written and oral communication skills, and interpersonal skills, and the ability to synthesize action items from abstract discussions.
Quick learner and highly motivated.
Ability to work in a cross cultural environment.

If you are passionate to work on complex business problems that can be solved using data, statistical modeling, we would like to talk to you.",3.1,"Frost & Sullivan, Inc
3.1",Tamil Nadu,"San Antonio, TX",1001 to 5000 employees,1962,Company - Private,Film Production & Distribution,Media,₹10 to ₹50 billion (INR),-1
Senior Data Scientist - CTS,-1,"The Applications Development Technology Lead Analyst is a senior level position responsible for establishing and implementing new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to lead applications systems analysis and programming activities. Responsibilities: Partner with multiple management teams to ensure appropriate integration of functions to meet goals as well as identify and define necessary system enhancements to deploy new products and process improvements Resolve variety of high impact problems/projects through in-depth evaluation of complex business processes, system processes, and industry standards Provide expertise in area and advanced knowledge of applications programming and ensure application design adheres to the overall architecture blueprint Utilize advanced knowledge of system flow and develop standards for coding, testing, debugging, and implementation Develop comprehensive knowledge of how areas of business, such as architecture and infrastructure, integrate to accomplish business goals Provide in-depth analysis with interpretive thinking to define issues and develop innovative solutions Serve as advisor or coach to mid-level developers and analysts, allocating work as necessary Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. Qualifications: 6-10 years of relevant experience in Apps Development or systems analysis role Extensive experience system analysis and in programming of software applications Experience in managing and implementing successful projects Subject Matter Expert (SME) in at least one area of Applications Development Ability to adjust priorities quickly as circumstances dictate Demonstrated leadership and project management skills Consistently demonstrates clear and concise written and verbal communication Education: Bachelors degree/University degree or equivalent experience Masters degree preferred This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN ------------------------------------------------------ Time Type : ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.7,"Frost & Sullivan, Inc
3.1",Tamil Nadu,"New York, NY",10000+ employees,1812,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Data Scientist,-1,"We are looking for a senior Data Scientist with 7+ years of progressive experience in mining large complex data sets, using a variety of advanced quantitative/modelling techniques. Candidate should have a knack to manage and deliver end to end projects with a proficiency to handle and deliver strategic insights to support crucial business decisions.
Candidate should have great analytical skills with an acumen for analysis, math and statistics and should be well versed with the concepts of machine learning. A rich experience in delivering analytics projects including social media analytics and big data is required.

RESPOSIBILITIES
Understanding business objectives and developing models based on structured and unstructured data to derive relevant metrics
Make the most effective use of the available Big Data infrastructure and Data Science techniques to address the business issues
Build effective presentations to communicate complex analysis and findings suitable for a wide array of audiences
Proactively plan and prioritize work according to criticality and shifting priorities/ strategies, while balancing need to drive longer-term initiatives
Mentor and coach junior team members
SKILLS
Proven experience as a Data Scientist or Data Analyst
Preparing and maintaining project, stage and exception plans as required
Identifying and obtaining support and advice required for the management, planning and control of the project
Experience in Predictive modelling, ensemble modelling, sentiment analysis, NLP, Time-Series Analysis, Deep Learning, Reinforcement learning, Recommender Systems
Presentation of insights using data visualization techniques
Problem-solving aptitude
Excellent communication and presentation skills
TOOLS & TECHNOLOGY
Familiar with statistical modelling tools such as Python, R, SAS etc. with proficiency in Python
Knowledge and experience of working with SQL and NoSQL databases
Experience in story telling with tools like Tableau, Power BI etc.
Experience with unstructured data using Hadoop
Proficiency in statistical analysis, quantitative analysis, predictive analytics, and optimization algorithms
Proficiency in statistical analysis, quantitative analysis, predictive analytics, and optimization algorithms
Benefits and Perks
Working with smart, young, mission-driven people
Approachable management team
Mobile allowance
Travel allowance
Regular team outings
Flexible Schedules",1.0,"Emerging India Group
1.0",India,"Noida, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Lead Machine Learning Engineer/ Data Scientist (India),-1,"Company Description

WhizAI is the first and only purpose-built cognitive insights platform for life sciences, empowering users to get answers to their business questions by simply asking via voice or text on web and mobile. WhizAI is pre-trained on life sciences data and business terminologies, enabling it to answer even the most complex questions from billions of records in seconds. Fast, easy, and scalable, WhizAI is the trusted partner of choice at the top global life sciences companies. Asked. Answered. Instantly.

We are on a mission to make enterprise analytics as easy and delightful as using your favorite app. The days of tedious dashboards, long training hours, and complex analytics software are over. Our platform is disrupting the $190B+ analytics market industry by making it 100X faster and easier for all business users to simply talk to their data and get insights, based on the innovations in NLP, AI, ML and enterprise software. We are the future of business intelligence and if you too want to put innovation and user experience for business users above all else, this role is for you.

Job Description

Out of the box, thinker to build innovating ML models and Lead the Data Science/Machine Learning team for an AI based startup who will:

Understand and analyze requirements requiring Machine Learning Models from product owners, customers, and other stakeholders
Analyze and verify data quality and features
Design solutions by choosing the right algorithms, features, and hyper parameters
Manage the full life cycle of ML Models: Data Acquisition, Feature Engineering, Model Development, Training, Verification, Optimization, Deployment, Versioning
Augment Enterprise data with publicly available datasets to enrich models & features
Create strategies for integrating the whiz.ai platform with external enterprise data sources like Databases,Data Warehouses, Analytical Stores, External ML Systems/Algorithms, Hadoop and ERP/CRM systems

Qualifications

Technical

10+ years of software development experience, with 5+ years of experience in implementing machine learning models
Machine Learning-based models: ANN, SVM, Logistic Regression, Gradient Boosting
Statistical Modeling with ARIMA, STL, Exponential smoothing
Time Series Anomaly Detections Methods, Hierarchical or Grouped Time Series Forecasting
Understanding of ML & Data processing frameworks like TensorFlow or PyTorch, XGBoost, SciPy, Scikit-Learn, Apache Spark
SQL and handling Big Data, databases
Excellent knowledge of Python Programming, NumPy, Pandas, and processing JSON, XML, CSV files

Non-Technical

Good communication & analytical skills
Self-driven with a strong sense of ownership & urgency

Preferred Qualifications

Knowledge of Analytical/OLAP/Columnar, Hadoop ecosystem and NoSQL databases
Deep Learning, GANs, Reinforcement Learning
R programming, Matlab
Knowledge of life sciences or pharmaceutical industry datasets

Additional Information

Compensation:
Competitive and commensurate with experience. WhizAI offers a base salary, a bonus plan, and equity.

Benefits:
Health care and paid time off.",-1,whiz.ai,Pune,-1,-1,-1,-1,-1,-1,-1,-1
Chief Data Scientist.,-1,"Job Purpose:
Provides deep technical Big Data and Machine Learning expertise to business vertical across the organization, governing the technical and methodology approach to solving Business Problems using Machine Learning.

Key Result Areas/Accountabilities:
This roll will be influencing and driving best practices to all the functions via vertical lead data scientists.
The person in the roll is expected to look at state of the art research available in the ML domain, and conduct pilots, before they are adopted by the verticals.
Will be the guardian of best practices, and help design interventions or process, that enable the teams to build robust scalable models for solving business problems.
Establish governance mechanisms, to ensure repeatable performance, and constantly oversee the quality of ML solutions built by the teams.
The person is expected to work on the difficult / challenging problems that has very high impact on business.
Develop workflows to process data and develop models for a problem, and ensure thatsuch workflows and learnt models are transferrable to other problems that are similar innature
Excellent credentials in working as a team or self-motivated individual contributorwilling to collaborate with colleagues locally and globally.
Core Competencies, Knowledge, Experience:
Working in Big Data analytics & deployment of models and algorithms from large volumes of structured and unstructured data in a commercial /consumer environment.
Turning complex (structured / unstructured /image / Voice) datasets into strategic insights for the business and communicate simply to non-technical audiences, visualizing results.
Developing Machine Learning solutions to solve real business problems, taking account of user needs, technology and operational landscape
Recognized as an expert in the community, mentoring and advising others on statistical techniques, algorithms and data sources
Hands On in Application of Big Data modeling and visualization tools (e.g. Hadoop, Spark, Python, D3.js, CartoDB, SciPy, GIS, NLTK, MLlib)
Experience on Machine Learning on Public Cloud platforms ( AWS / Microsoft, Google)
Experience in Deep Learning Frameworks Tensor flow, open-source libraries, e.g., Keras, and open-source distributed computing frameworks
Deep Expertise in Recommendation Engines, using data at petabyte scale.
Ability to test hypotheses from raw data sets, draw meaningful conclusions, and clearly communicate results
Expert in deep and broad statistical modelling
Familiarity with applications of deep learning, computer vision, and generalized artificial intelligence (e.g., convolutional neural networks, adversarial neural networks), to solving business problems
Ability to work cross functionally to translate business issues into potential analytics solutions
Strong communication skills with prior experience communicating analytics results to senior management
Ability to think critically, question assumptions and devise solutions to challenging technical problems.
Experience with very large datasets
Knowledge of applicable data privacy practices and laws
Experience in end-to-end development of the data science processes experimentation, segmentation and documentation.
Strong verbal and written communication skills.
Strong decision-making skills
Ability to accurately and effectively tell the story told by the data
Attention to detail, excellent organizational, planning and analytical skills.
Extensive knowledge attribution tracking technology or platforms
Highly analytical mindset, with the ability to interpret performance data
A drive to be updated as well as master new technologies and techniques, apply it for solving business problems.",-1,MAESTRO PLACEMENT CONSULTANCY SERVICES,Mumbai,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Machine Learning Engineer - Bangalore/Mumbai/Pune,-1,"Wissen Technology is now hiring for ML Engineers with 4 - 6 years of relevant experience.
We are solving complex technical problems in the financial industry and need talented software engineers to join our mission and be a part of a global software development team.
A brilliant opportunity to become a part of highly motivated and expert team which has made a mark as a high-end technical consulting.


We are looking for a senior engineer with 4-6 years of experience in Machine Learning or NLP. You will be working in our Wissen ML team on a multitude of projects in CV and NLP domain.

Responsibilities
Perform research on enhancing the capabilities of our existing solutions.
Work closely with the team to formulate the industry problems into the right computer science problem.
Participate in designing and implementing the solutions using cutting edge technology.
Requirements
Passion for problem solving
Problem solving ability not limited to Machine Learning.
Knows the difference between good code and better code.
Knows about different components and end-to-end understanding of a software system
Deep Learning (Tensorflow / Keras / PyTorch)
Python, OOPS, SQL/NoSQL
Preferred
Natural Language Processing, Stanford CoreNLP/ Spacy
Data Extraction from Images",4.3,"Wissen Technology
4.3",Bengaluru,"Hyderabad, India",501 to 1000 employees,2000,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
SENIOR DATA SCIENTIST,-1,"MiQ is the leading marketing intelligence company with technology and people that help businesses win. We are experts at ingesting large amounts of data, modelling data to convert into insights and then actioning these insights through a variety of products and services.

Our People have an endearing and unique quality that sets them apart from the rest and that is why our product inspires. Our People make the difference and our values make the people.

In short, MiQ make data valuable, insightful, and intelligent, which helps clients engage customers, grow sales and generate revenue. MiQ offers its clients products and services across Media (which is their programmatic managed media offering), Analytics (custom engineering and data science solutions for business challenges in digital marketing space) and Technology (technology and analytics capabilities geared for their customers use). We enjoy a 97% client retention rate globally across brands such as Walmart, Barclaycard and Ford.

MiQ was built 9 years ago by Gurman Hundal and Lee Puri, with its original base in London, UK. Remaining a self-funded business, the company has now grown to over 700 employees, with 15 global offices covering 4 continents.

Our business vision is to empower the marketing divisions with the relevant insights so that they can shape the overall business strategy. It is for this reason MiQ has very exciting and realistic growth expectations over the coming years. It’s a great opportunity to work across a global business while becoming a key contributor within a growing, winning organization.

QUICK FACTS

Represent over 450 Client’s Globally
97% Retention Rate of Client’s since Launch
700 Global Employee’s, with a 100% Staff Retention Rate in the first 3 years of the business, currently 93%
Offices in London, Manchester, Hamburg, 10 cities in the US, Toronto, Australia and Bangalore
Award Winning Infrastructure – Recently voted for the ‘Best Use of Data’ as well as ‘Best Trading Team’ in UK and ‘Most Innovative Brand in Mobile’ in North America

Product/DS Focus-

Able to understand the product requirement and able to execute end to end data product pipeline and suggest technical architectural framework
Implementing Code and Logic review of Data Scientists and providing logic documents for their own code to TL
Taking full ownership of multiple features and modules within the product

Org-Wide Collaboration

End to End Collaboration with multiple engineering teams/functions and also collaborating with traders/solutions
Excellent team player and good at collaboration and role model for Data Scientists

Innovation

Active participation in discovery/identification of ML features and research areas coupled with business impact formulating into product features
Assessing Risk and far farsightedness on Product Quality and performance whilst suggesting changes for feature change or improvement

Stakeholder Management

Proactive in Communicating with PM/Stakeholders and solving technical blockers
Working with TL/PA to offer training and presentations to analysts/CS stakeholders and be a key participant in stakeholder meetings

Cost Optimization

Assisting TL and suggesting recommendations on how to optimize at code level and feature level further optimizing processing and storage cost
Far farsightedness of compute and storage cost while reviewing code of Data Scientists

Qualifications & Experience-Bachelors or master’s degree in computer science or Mathematics/Statistics.

Skills -Must Have

Experience in working in Data Science projects for a minimum of 4 years
Strong Experience in applying machine learning, statistical pattern recognition, and data mining algorithms to prediction problems.
Strong Experience with at-least one programming language - e.g. Python,Java,R
Strong experience with advanced SQL and good experience in big data ecosystem especially Pyspark
Strong Experience in delivering data science projects leveraging cloud infrastructure either in AWS or Google Cloud
Extreme attention to detail, ability to meet deadlines and prioritise workload.
Extreme attention to create solutions which are cost efficient with respect to compute and storage
Good track record in mentoring junior data scientists on technical competencies

At MiQ, we don’t just accept the differences of our people, it is what builds us as a community. MiQ is very proud to be an equal opportunity workplace.",3.5,"MiQ Digital
3.5",Bengaluru,"London, United Kingdom",501 to 1000 employees,2010,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer 3,-1,"In this role, the individual will be part of the engineering team in Enterprise data lake group and will be responsible for.
Participating and collaborating with cross functional teams in the organization to understand the business requirements and to deliver solutions that can scale.
Planning the execution of the project in an effective and efficient manner.
Proactively anticipating problems and appropriately communicating to the team and management in a timely manner.
Being flexible and being able to support all functions of product life cycle when required.
Ability to work in a fast-paced environment
Ability to deliver from coarse grained requirements
Be a Mentor for the junior members in the organization.
Job Requirements

Required Skills:
8+ years of experience in the IT industry, experience in Data Technology space is preferred.
Advanced Shell or Perl scripting experience or proficiency in any programming language like C, C++ or CORE Java
Working experience in any MPP systems, should have strong SQL programming skills
Knowledge of data warehousing concepts
Working knowledge on any ETL tool (ie. Informatica/ Ab Initio) is preferable.
Knowledge of Scheduling Tools is a plus
Excellent written and oral communication skills
Strong analytical skills including the ability to define problems, collect data, establish facts, and draw valid conclusions
Expertise in database programming and performance tuning techniques
Familiar with data movement techniques and best practices to handle large volumes of data
Experience with data warehousing architecture and data modeling best practices
Experience with File Systems, server architectures, and distributed systems
Strong communication skills and willingness to take initiative to contribute beyond basic responsibilities
Working experience in an Agile methodology is highly preferred
Knowledge of Hadoop, HBase and Hive is highly preferred",3.7,"PayPal
3.7",Chennai,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Lead Data Scientist,-1,"LocationIndia / US / EuropeExperience10+ YearsAcademic Qualification:B.E., B.Tech/MBA from top-tier Engineering /B-School (IITs, IIM, NITs BITS) ORMasters in Statistics/Economics from leading UniversityOverviewContinuous, growth opportunities for career progression and personal developmentProfessional, stimulating, continuous learning, work environment based on camaraderie, individual mentorship, on-the-job and corporate trainingCompetitive and performance-oriented compensation and employee benefits packageIndustry benchmarked HR policies and practices, particularly in areas such as Performance Management, Learning and Professional Development, Career Planning and Compensation and Rewards.Roles and responsibilitiesLeading a team of analytics professionals to manage practice delivering analytics consulting projectsSectoral experience in Lifesciences, Financial Services, Airlines, Retail & ConsumerClear, articulate and confident written and verbal communication skills.Working experience in Advanced Analytics Techniques Predictive modelling Time series forecasting Machine Learning etc.Work directly with multinational clients, using advanced analytics to solve real-world business problems.The role will require a sound understanding of business functions, statistical concepts and algorithm design/implementation skills.Establishing and implementing Actionable Business Outcomes (ABOs) for predictive and prescriptive analytics use cases.Experience of handling high frequency streaming data for real time analysis and reporting.Be a brand ambassador for the company and represent the company in seminars and other public events related to data scienceExperience in relevant field such as Statistics, Computer Science or Applied Math or Operational Research.SPOCBuddhadeb BhattacharjeeMail toBuddhadeb.bhattacharjee@tcg-digital.com",3.0,"TCG Digital
3.0",India,"Somerset, NJ",201 to 500 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Analytics Manager /Consultant,-1,"Domain knowledge:
Predictive Analytics
Hands-on project experience in at least one of the above analytics products
Should understand how in-memory analytics works and how to leverage in-memory analytics
Should understand analytics concepts such as big data, data lake, predictive analytics, embedded analytics, machine learning and conversations AI
Should be comfortable with a platform-/cloud-based approach for analytics and should have a point of view on analytics as a service
Skills Required
Experience in managing teams and has leadership skills
Should demonstrate a team-oriented and collaborative approach,
Excellent communication skills, including strong oral and written communication capabilities
Excellent client-facing skills along with prior demonstrated experience of leading teams at various stages
Project management skills including the ability to work and plan effectively with minimal direction in ambiguous situations, and manage the implementation of the plan
Must be able to work with limited direction and self-driven
Education: MBA / M. Tech ONLY

Candidate should be in Client Facing role & Excellent communication skills

Candidates MUST be handling India Business Projects ONLY (Domestics Clients).

For Manager role: Candidate should have strong domain exp in CPG/FMCG, Automobile, Life Sciences (Mandatory)

Positions:
Analyst – Exp: 2 – 4 yrs

Consultant – Exp 4- 7 yrs

Manager – Exp 7 – 13 yrs

Job Location: Mumbai
Experience (Years): 2-12 Years",-1,freshermart,Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Decision Scientist 1,-1,"PayPal Credit is the simple, flexible credit line built into your PayPal account. PayPal Credit Risk Organization is responsible for managing the risk throughout the lifecycle of PayPals global Credit products. This is an exciting, fast paced organization where the contribution by team members can significantly impact PayPals bottom line as well as our customers experience.

Fraud Strategy & Analytics team owns fraud losses from PayPals installments, lines and partner-credit offerings for PayPals global consumers, proposing solutions and measuring effectiveness of solutions post-implementation.

In order to capture all the events critical to detect fraud loss pressure and fraud-driven friction, the analyst must be comfortable with multiple data platforms, be able to combine data at the account, transaction and critical event levels.

The Fraud Strategy & Analytics team has end to end ownership of fraud losses from PayPals installments, lines and partner-credit offerings for PayPals global consumers, proposing solutions and measuring effectiveness of solutions post-implementation. Day to day responsibilities include:
Identifying opportunities and gaps within current portfolio of PayPals Fraud Risk controls, including continuously evolving fraud trends
Based on analysis, formulating a solution to ensure optimal balance between user experience, business enablement, operational expense and loss exposure related to proposed solution
Working closely with partners in Risk Platform, Global Risk and Data Sciences, Operations, Credit Product Management, Legal & Compliance and other teams to formulate and execute fraud risk solutions
Collaborating with external partners, including external Credit/Banking partners and Data vendors
Advocating with Risk and various Business Unit leaders to gain agreement and secure resources for proposed solutions
On-going optimization of existing risk solutions
Closely monitoring performance of existing and new solutions to ensure expectations are met
This individuals key performance KPIs will include Loss Performance, Fraud Decline rates, Revenue/Margin enabled, and Customer Experience.

Job Qualifications

Required Skills:
Proficiency in SQL and Excel
Proficiency in at least one statistical analysis tool: SAS / R / Python
Strong analytical skills: ability to build quick estimates using back-of-the-envelope analysis, structure (and, if needed, execute) more complex analyses, pull together business cases, navigate multi-dimensional sets of tradeoffs. Above all, the job calls for comfort with data ability to manipulate it, question its validity, interpret it, and develop recommendations based on it
Ability to manage a large, diverse set of to-dos prioritize, stay on top of multiple work streams, monitor progress
Ability to work with leadership & stakeholders to define project scope and direction, driving large pieces of the work independently
Strong communication skills a sense of appropriate communication mechanism/approach to use given context/circumstances.
Experience working with cross-functional, geographically distributed teams, managing by influence is a plus.
Ability to contribute to strategic discussions and represent Risk in cross-functional meetings
Ability to mentor junior team members
Dedicated, proactive, curious and eager to learn new approaches / methodologies a must
Desired Skills:
Must be an intuitive, organized, analytical thinker, with the ability to perform detailed analysis
Strong written, oral, and interpersonal skills a must, including the ability to explain and/or present analysis
Must have good business judgment with demonstrated ability to think creatively and strategically
Aptitude and willingness to roll up the sleeves and get involved in the details
Risk management / big data manipulation experience is a plus
Education

Bachelors degree in Mathematics, Statistics, Operations Research, Finance, Economics or related quantitative discipline

Experience

3.5 - 5 years related experience

1+ years supervisory experience helpful, but not required

MS/MBA or PhD degree can qualify for some years of experience",3.7,"PayPal
3.7",Chennai,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Lead Quantitative Analyst,-1,"No Of Position : 1

Position: Lead Quantitative Analyst (Fixed Income), Morningstar Indexes

The Area: Morningstar Indexes Team leverages its expertise in equity research, manager research, asset allocation, and portfolio construction to create investor-focused solutions. It uses Morningstar`s intellectual property to create indexes that empower investors to achieve their goals at every stage of the investment process - market monitoring, benchmarking and asset allocation. The unit offers a broad suite of global equity, bond, commodity and asset allocation indexes.

The Role: As a fixed income specialist, you will be responsible for the fixed income index research, including developing fixed income index methodologies, creating portfolio construction and analytics, and promoting thought leadership. The candidate will have an excellent grasp of investment concepts, possess strong analytical and data munging skills, and partner effectively with senior management, other teams, and clients. Additionally, the successful candidate must possess sound verbal communication skills and be able to discuss research with both experts and non-experts alike. This position is based in our Navi Mumbai office.

Responsibilities:
Develop and implement portfolio construction and analytics tools.
Research and develop innovative fixed income indexes in areas such as ESG.
Develop cutting-edge thought leadership designed to help Morningstar’s mission of “empowering investor success”.
Partner with research teams across Morningstar to develop global fixed income research agenda and transform Morningstar’s intellectual property into investor-centric Indexes.
Support sales & marketing efforts, client roadshows and seminars.
Requirements:
At least 6 years of fixed income quantitative experience at an index provider, asset manager company or investment bank.
Bachelor’s degree in a quantitative, financial discipline, or engineering; a CFA, MBA or a Master’s degree in a quantitative or financial discipline is preferred.
Knowledge of institutional investing, modern portfolio theory and portfolio construction processes.
Hands-on analytical and quantitative skills (e.g., econometrics) and practical experience with programming and database packages.
Strong interpersonal skills and team orientation.
Excellent oral and written communication and presentation skills including ability to distill complex ideas into simple explanations.
Morningstar is an equal opportunity employer.

I10_MstarIndiaPvtLtd Morningstar India Private Ltd. (Delhi) Legal Entity",4.1,"Morningstar
4.1",Mumbai,"Chicago, IL",5001 to 10000 employees,1984,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),"Thomson Reuters, FactSet, Bloomberg L.P."
Lead Data Scientist,-1,"To be a key member of the Analytics team, working closely with data scientist, data engineers as well as business users to develop, maintain and automate delivery of model pipelines in our infrastructure. In this role, the person is expected to take on critical tasks such as productionizing, deploying and testing of machine learning & analytics models. The person will work closely and report to the lead data scientist in the team.

In this role, you will:
Spend > 75% of your time coding and implementing re-usable Machine Learning frameworks
Work with data engineers to source, analyse and engineer features
Work with data scientists to develop, test and deploy Machine Learning models
Keep up to speed with the latest industry and technology developments on Machine Learning

Basic Qualifications:
A degree in Statistics, Machine Learning, Computer Science, Data Science or related field
Familiarity with at least one major Machine Learning frameworks: Tensorflow, Pytorch, Keras, Scikit-Learn, Spark ML, etc.
Familiarity with Python, SQL and Unix/Linux Commands
Familiarity with Dockers, Kubernetes, REST APIs, AWS or similar cloud services
Familiarity with Distributed/Cluster computing environment like Spark

Preferred Qualifications:
Overall, 14+ yrs experience in IT Industry
Proficiency in the mathematics underlying Machine Learning
Ability to present complex technical information in a clear and concise manner to a variety of audiences
Minimum of 3-5 years working on Machine Learning models deployment",3.6,"DBS Bank
3.6",India,"Singapore, Singapore",10000+ employees,1968,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),"OCBC Bank, Citi, Standard Chartered Bank"
Decision Scientist,-1,"PayPal Credit is the simple, flexible credit line built into your PayPal account. PayPal Credit Risk Organization is responsible for managing the risk throughout the lifecycle of PayPals global Credit products. This is an exciting, fast paced organization where the contribution by team members can significantly impact PayPals bottom line as well as our customers experience.

Fraud Strategy & Analytics team owns fraud losses from PayPals installments, lines and partner-credit offerings for PayPals global consumers, proposing solutions and measuring effectiveness of solutions post-implementation.

In order to capture all the events critical to detect fraud loss pressure and fraud-driven friction, the analyst must be comfortable with multiple data platforms, be able to combine data at the account, transaction and critical event levels.

The Fraud Strategy & Analytics team has end to end ownership of fraud losses from PayPals installments, lines and partner-credit offerings for PayPals global consumers, proposing solutions and measuring effectiveness of solutions post-implementation.

Day to day responsibilities include:
Identifying opportunities and gaps within current portfolio of PayPals Fraud Risk controls, including continuously evolving fraud trends
Working with the product team and establish a feedback loop to provide continuous improvements related input for the Tools and capabilities at various Fraud checkpoints.
Working closely with partners in Risk Platform, Global Risk and Data Sciences, Operations, Credit Product Management, Legal & Compliance and other teams to align technical solutions with business strategies and/or support several complex business processes
Provide operational reporting and analysis (Routine and ad hoc) related to SLA and KPI compliance tracking for existing solutions and overall Fraud controls.
Own data governance by proactively performing regular audits to identify errors or opportunities and closely monitoring performance of existing and new solutions to ensure expectations are met
Based on analysis: Identifying trends and formulating a solution to ensure optimal balance between user experience, business enablement, operational expense and loss exposure related to proposed solution.
Explore on-going optimization opportunities of existing risk solutions
Closely monitoring performance of existing and new solutions to ensure expectations are met
Job Qualifications

Required Skills:
Proficiency in SQL and Excel
Proficiency in at least one statistical analysis tool: SAS / R / Python
Strong analytical skills: ability to build quick estimates using back-of-the-envelope analysis, structure (and, if needed, execute) more complex analyses, pull together business cases.. Above all, the job calls for comfort with data ability to manipulate it, question its validity, interpret it, and develop recommendations based on it
Ability to manage a large, diverse set of to-dos prioritize, stay on top of multiple work streams, monitor progress
Ability to work with leadership & stakeholders to define project scope and direction, driving large pieces of the work independently
Strong communication skills a sense of appropriate communication mechanism/approach to use given context/circumstances.
Experience working with cross-functional, geographically distributed teams, managing by influence is a plus.
Ability to contribute to strategic discussions and represent Risk in cross-functional meetings
Dedicated, proactive, curious and eager to learn new approaches / methodologies a must
Desired Skills:
Must be an intuitive, organized, analytical thinker, with the ability to perform detailed analysis
Strong written, oral, and interpersonal skills a must, including the ability to explain and/or present analysis
Must have good business judgment with demonstrated ability to think creatively and strategically
Aptitude and willingness to roll up the sleeves and get involved in the details
Risk management / big data manipulation experience is a plus
Education

Bachelors degree in Mathematics, Statistics, Operations Research, Finance, Economics or related quantitative discipline

Experience

3.5 - 5 years related experience

1+ years supervisory experience helpful, but not required

MS/MBA or PhD degree can qualify for some years of experience

Subsidiary:

PayPal

Travel Percent:

0",3.7,"PayPal
3.7",Chennai,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Data Analyst,-1,"Job Description • Min 4-8 year of experience as Business Analyst – Data Analyst. • Should have Strong Domain knowledge in Retail and Corporate Banking Domain • Good experience in Regulatory reporting and more specifically RBI ADF Reporting • Strong Analytical Skills. o Excellent documentation skills BRD, FRD and Use Cases o Fundamental analytical and conceptual thinking skills. o Experience creating detailed reports and giving presentations o Excellent planning, organizational, and time management skills o Excellent hands on experience in SQL & doing data mapping • Should be well versed with BA role and responsibilities, like understanding BRD, FRD writing and Managing E2E implementation.
Strong Communication and excellent Stakeholder management Skills. • BA / DA certification would be an added advantage",3.5,"Larsen & Toubro Infotech Limited
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
Data Scientist - Job Code(NLP-18),-1,"Job Description :
Responsibilities:
Sound experience in AI, Natural language processing, Machine Learning
Experience in Language Modelling, POS tagging, PCFG, Named Entity Recognition, Co-reference Resolution, Question Answering etc
Good understanding of various classification techniques such as Clustering, Logistic Regression, CRFs, MEMM, Neural Networks, SVMs, Decision Trees etc
Coding experience with Python and SQL/NoSQL databases, familiarity with Linux
Candidates with Publications in reputed conferences or journals are preferred
00-4.00 Years",4.1,"UVJ Technologies Private Limited
4.1",India,"Cochin, India",201 to 500 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Rockstar Games, we create the games we would want to play ourselves.

A career at Rockstar is about being part of a team working on some of the most creatively rewarding, large-scale projects to be found in any entertainment medium. You would be welcomed to a friendly, inclusive environment where you can learn, and collaborate with some of the most talented people in the industry.

Rockstar India is on the lookout for talented Data Engineers who possess a passion for Game Analytics. This is a full-time permanent position based out of Rockstar's unique game development studio in Bangalore, India.

WHAT WE DO
The Rockstar Analytics team provides insights and actionable results to a wide variety of stakeholders across the organization in support of their decision making.
We work together with a number of departments to design and implement data and pipelines.
We collaborate as a global team to develop cutting-edge data pipelines, data products, data models, reports, analyses and machine learning applications.
RESPONSIBILITIES
Resolve operational issues as they occur to maintain the team's SLAs.
Implement and support big data tools and frameworks such as HDFS, Hive, and Impala.
Implement and support data models using Spark and Spark-ML.
Assist in the development of deployment automation and operational support strategies on Hadoop and Snowflake.
Deliver near-real time and non-near-real-time data and applications to a team of analysts and data scientists who create insights and analytics applications for our stakeholders.
Maintain and extend our CI/CD processes and documentation.
QUALIFICATIONS
5+ years of work experience with ETL, Data Modeling, and Business Intelligence Big Data Architectures.
5+ years of experience with the Hadoop ecosystem (Map Reduce, Spark, Spark-ML, Oozie, Hive, Impala, etc.) and big data ecosystems (Kafka, Cassandra, etc.).
Experience developing and managing data warehouses on a terabyte or petabyte scale.
Experience developing Machine Learning pipelines and data models.
Strong experience in massively parallel processing & columnar databases.
Experience with Python and shell scripting.
Experience working in a Linux environment.
Deep understanding of advanced data warehousing concepts and track record of applying these concepts on the job.
SKILLS
Expert in at least one SQL language such as T-SQL or PL/SQL.
Good communication skills.
Dynamic team player.
A passion for technology - we are looking for someone who is keen to leverage their existing skills and seek out new skills and solutions.
PLUSES


Please note that these are desirable skills and are not required to apply for the position.
Experience in real-time analytics applications.
Experience in Lambda architecture and On-Premise Clusters.
Experience with Java or Scala programming languages.
Experience with CI/CD.
Knowledge of RestAPI and Artifactories.
Knowledge of the video game industry.
HOW TO APPLY


Please apply with a CV and cover-letter demonstrating how you meet the skills above. If we would like to move forward with your application, a Rockstar recruiter will reach out to you to explain next steps and guide you through the process.

Rockstar is proud to be an equal opportunity employer, and we are committed to hiring, promoting, and compensating employees based on their qualifications and demonstrated ability to perform job responsibilities.

If you've got the right skills for the job, we want to hear from you. We encourage applications from all suitable candidates regardless of age, disability, gender identity, sexual orientation, religion, belief, or race.",4.0,"Rockstar Games
4.0",Bengaluru,"New York, NY",1001 to 5000 employees,1998,Subsidiary or Business Segment,Video Games,Media,₹1 to ₹5 billion (INR),-1
Data Engineer,-1,"JOB DESCRIPTION

Skill: Data Engineer

Role: T2

Ready to dive in and provide technical leadership, vision and direction for a fast-paced team solving business problems with analytics/visualization? If you are passionate about helping clients do great things with their data, we at Virtusa have the right role for you!

You will lead that team whose work designing and creating data models provides the link between the client business mission and strategy and valuable insights available though their data.

The ideal professional for this Data Engineer role will:
Have a passion for design, technology, analysis, collaboration, agility and planning; along with a drive for continuous improvement and innovation.
Exhibit expertise in managing high volume data projects which leverage Cloud Platforms, Data Warehouse reporting and BI Tools, and development of relational databases.
Research, identify and internally market enabling data management technologies based on business and end-user requirements.
Seek ways to apply new technology to business processes with a focus on modernizing the approach to data management.
Consult with technical subject matter experts and develop alternative technical solutions. Advise on options, risks, costs versus benefits, and impact on other business processes and system priorities.
Demonstrate strong technical leadership skills and ability to mentor others with related technologies.

Qualifications
Bachelor's degree in a computer related field or equivalent professional experience is required.
Preferred Master’s degree in computer science, information systems or related discipline, or equivalent and extensive related project experience.
Experience on GCP skills.
5 years of experience of similar hands on software development building Data platforms with the following tools and technologies: Hadoop, Spark, Kafka, Relational SQL and NoSQL databases, Data pipeline/workflow management tools.
MUST have experience with Java Expert in Big Data querying tools, e.g. Hive and Impala.
Experience working with and extracting value from large, disconnected and/or unstructured datasets.
Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
The candidate is expected to be dynamic, flexible with a high energy level as this is a demanding and rapidly changing environment.
Thoroughness and organization is expected, as well as sound judgment
Strong interpersonal skills and ability to project manage and work with cross-functional teams.
Experience in Equities Trading Flows will be a plus.

About Virtusa

Teamwork, quality of life, professional and personal development: values that Virtusa is proud to embody. When you join us, you join a team of 21,000 people globally that cares about your growth — one that seeks to provide you with exciting projects, opportunities and work with state of the art technologies throughout your career with us.

Great minds, great potential: it all comes together at Virtusa. We value collaboration and the team environment of our company, and seek to provide great minds with a dynamic place to nurture new ideas and foster excellence.

Virtusa was founded on principles of equal opportunity for all, and so does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law. All employment is decided on the basis of qualifications, merit, and business need.

Learn more at www.virtusa.com.",3.1,"Virtusa
3.1",Hyderabad,"Westborough, MA",10000+ employees,1996,Company - Public,IT Services,Information Technology,₹50 to ₹100 billion (INR),Capgemini Invent
Data Analyst/ Senior Data Analyst,-1,"Analyst:
Engineers with 0-3 years of experience from IITs, NITs, BITS, PSG College of Technology, VIT, CBIT, ICFAI and similar good schools.

Responsibilities:
Understanding and synthesize the client requirements and information
Decide approach while thinking through possible deadlocks in advance
Get actionable insights from data with analytical tools like Project R, SQL, R, Python etc. which can be used in real time in all decision making
Create new statistical models/ improve existing models
Creating dashboards, reports and charts in Excel
Developing macros in VBA (Visual Basic Applications)

Qualifications:
Proficiency in SQL, R, Python, Advance Excel and VBA or other analysis/ programming language. (Intermediate level)
Expertise and strong experience in data gathering and analysis
Good analytical and communication skills
Candidates with strong business knowledge
Hands on expertise in Data modelling, Data migration & Data consolidation tools through working on online analytical projects / internships / Job.

Important:
Please write good cover letter as we give high importance to the same while evaluating a candidate. We recommend you to spend sufficient time and effort in writing a good cover letter. Applications without a cover letter will be ignored by the Talent Acquisition Team.

Please create your Cover Letter around the following points:
Reason to join Perceptive Analytics
Mention the snapshot of Data Analytics Project pursued during the Academics or Internship/Job, if any
Information on skills acquired and technical know-how
Achievements, if any
Note: Please ensure that you write about the following statement in your cover letter, in a separate paragraph. This will help us to gauge your understanding about the position and your overall thought process for this role. Overlooking this will lead to rejection of your resume.

“In god we trust. Everyone else must bring data.”

About Perceptive Analytics

Perceptive Analytics is a Data Analytics company, offering specialized services in Data Analytics, Web Marketing Analytics, and Spreadsheet solutions. We serve large to medium sized companies USA and India.

We have the reputation of being known as a trusted partner/advisor with a penchant to deliver compelling value. Perceptive Analytics provides solutions to problems in industries across multiple sectors such as Banking, Finance services and Insurance and e-commerce.

Perceptive is known for its employee friendly approach. You will have continuous training, sports facilities, medical insurance, access to world class journals and above all, a fun environment to work in. Bright candidates will also be eligible for stock options.

Every employee here is an owner of his/her project. Direct connect with the clients gives a complete freedom to an employee to handle their projects. Different industry projects lead to exposure to an employee. There is no space for monotony - every day is a new challenge.",4.1,"Perceptive Analytics
4.1",Hyderabad,"Hyderabad, India",1 to 50 employees,2013,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Data Science Platform Administrator,-1,"About our group:
We are a proactive, highly solutions oriented and collaborative team that works with all the various business groups and data scientists across the organization to provide data engineering and Data Science platform services. Our purpose of capturing massive amounts of data is to transform this vital information into concrete and valuable insights that will allow Seagate to make better and more strategic business decisions.

About the role-you will:
Design , build and manage high available systems for data science platforms like R , Python , KNIME , Tensor flow , H2O etc
Provide platform security management, application and underlying infrastructure support (OS, Storage, Applications, Web and Database) and ensuring processes are aligned with tactical and strategic information management initiatives
Deploying solutions in AWS cloud and onPrem environments
Supporting system application requests with updates to existing installations that require integration with the highly available platform
Evaluate, integrate and implement emerging technologies
Develop integration solutions with Python workflow scripting
Partner with internal business, engineering and data science teams worldwide for delivering incremental improvements to the advanced analysis platform.
Create and maintain architecture blueprints to integrate both vendor and open source technology analysis tools and systems into the platform.
Develop early prototypes for iterative review with customers to arrive at optimal and robust data-driven solutions.

About you:
Experience with various data science platforms R , Python , Anaconda , Tensor flow , H2O etc
Strong Linux Scripting and Administration experience
Experience with deploying solutions using containerization ( Docker / Kubernetes)
Firm understanding of GPU and relationship to Deep Learning/Neural Nets
Demonstrated experience developing and managing complex technical projects involving parallel or distributed computing, including Hadoop, the Apache Stack and related technologies
Understands importance of statistical analysis and machine learning
Solid understanding of program execution in open source R and Python environments
Ability to communicate complex technical solutions in a clear, precise and actionable manner with both technical and non-technical customers
Work flexible hours to accommodate meeting with global teams
Solid understanding of Agile software development methodologies
Good understanding of service-oriented architecture concepts (SOA and REST)
Requires innately curious person with creative ability to solve complex problems

Your experience includes:
Installing, configuring, maintaining and upgrading applications and packages in a linux environment, including application uptime monitoring tools
Linux scripting and administration
Advanced SQL techniques, stored procedures and data warehousing solutions
Python or javascript or similar development language
Expertise related to DevOps engineering including version control systems (Git, SVN), and automated build and testing (Jenkins, vagrant)
Configuration management (e.g. Puppet, SALT, Ansible)
Bachelor's degree and/or relevant experience

You might also have :
Containerization, including Docker and Kubernetes

Job Family: Engineering Professional",3.4,"Seagate Technology
3.4",Pune,"Cupertino, CA",10000+ employees,1979,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Western Digital, Fujitsu"
Data Science Specialist,-1,"Gurgaon & Bangalore
Key Responsibilities
Owning new initiatives for learning content and experience for our flagship program BABI (Business Analytics & Business Intelligence)
Ensuring ongoing review of the learning content and identifying opportunities to improve quality in terms of appropriateness, accuracy, richness.
Ensuring the efforts towards updating the content as well as creating additional content - videos, reading material, exercises and assignments.
Deliver a great learner support experience by ensuring timely response and feedback on all academic queries from learners
Leading initiatives to deliver solutions to key business problems in Operations and customer experience
Project Management for delivery excellence
Drive cross-pollination of ideas and knowledge with in-house data science team to deliver in-house solutions and translate them into learning material & case studies for learners
Use insights derived from ad-hoc data analysis to answer ad-hoc questions as well as drive processes improvements so that Great Learning’s business requirements are met
Collaborate with internal stakeholders to consistently align data interpretation with evolving business processes
Refine existing solutions & products as well as handcraft new features in the Learning Management System for superior end user experience
Create unique learning experiences that enable Great Learning customers to have a delightful learning experience and meaningful outcomes
Conceptualize, plan and execute hackathons & ad-hoc competitions,
Fostering and leveraging relationships with industry leaders in Analytics to organize conferences, panel discussions, Analytics industry sessions

Qualification:
Solid understanding and working knowledge of advanced techniques like supervised &unsupervised learning, including but not limited to, hypothesis testing, regression, clustering,decision trees, prediction techniques, model tuning and model performance measures etc.
Good aptitude, ability to think logically and problem-solve
Ability to work under pressure and tight deadlines
Ability to learn quick - ability to learn business, processes, techniques and technologies on the go
Prior experience of deploying analytics solutions
Ability to lead teams
Good understanding of what analytics is - from data to decisions
Good ability to work with complex, unstructured data from multiple sources - consolidate, analyze, interpret, clean and transform to get it ready for analysis
Ability to design approaches to solve a problem using data analysis techniques
Ability to interpret data, present/visualize metrics and extract meaningful insights to answer business problems
Good proficiency with Microsoft Office Suite
Strong working knowledge of SQL, R/Python, Excel
Excellent oral and written communication skills
Sounds like ""the"" job for you? Send in your CV @ careers@greatlearning.in & we will reach out to you accordingly.",4.1,"Great Learning
4.1",Bengaluru,"Gurgaon, India",501 to 1000 employees,2013,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),-1
Data Analyst,-1,"SL

Parameter

Description / Requirements
1

Position

Data Analyst
2

Posting

India
3

Experience

Min3 years
4

Age

Max 30
5

Computer Skills Reqd

Microsoft Power
BI Should be able to
design and extract reports from database table

Create Dashboards
for MIS

Advanced Excel

MS-Office Word/Excel/Power point / G-Suite
Mail and G-Drive

Optional

Maritime Software
Skills

- Netpas

- IMOS

JAVA
6

Qualifications

Bachelor in Computer
Science / Statistics
7

Industry Experience

Information
Technology / Maritime
8
9

Roles and
Responsibility

- Will be
responsible for working with Data repository in the companys database system
such as IMOS and other software and design Dashboard and Management
Information System Reports.

- Create
Database capture forms to minimize errors.
10

Language

Fluent in English
(Spoken and Written) essential for the role.
11

UAE Drivers License

NA
12

Other Skills

Statistics

Mathematics

Analytical mind

Aptitude to expand
software skills and use methods to simplify and present data as per
requirement.

Time Management

Presentation Skills

Capable of
Multitasking",-1,AEGIS RESOURCES DMCC,Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist - CTS,-1,"The Applications Development Technology Lead Analyst is a senior level position responsible for establishing and implementing new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to lead applications systems analysis and programming activities. Responsibilities: Partner with multiple management teams to ensure appropriate integration of functions to meet goals as well as identify and define necessary system enhancements to deploy new products and process improvements Resolve variety of high impact problems/projects through in-depth evaluation of complex business processes, system processes, and industry standards Provide expertise in area and advanced knowledge of applications programming and ensure application design adheres to the overall architecture blueprint Utilize advanced knowledge of system flow and develop standards for coding, testing, debugging, and implementation Develop comprehensive knowledge of how areas of business, such as architecture and infrastructure, integrate to accomplish business goals Provide in-depth analysis with interpretive thinking to define issues and develop innovative solutions Serve as advisor or coach to mid-level developers and analysts, allocating work as necessary Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. Qualifications: 6-10 years of relevant experience in Apps Development or systems analysis role Extensive experience system analysis and in programming of software applications Experience in managing and implementing successful projects Subject Matter Expert (SME) in at least one area of Applications Development Ability to adjust priorities quickly as circumstances dictate Demonstrated leadership and project management skills Consistently demonstrates clear and concise written and verbal communication Education: Bachelors degree/University degree or equivalent experience Masters degree preferred This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN ------------------------------------------------------ Time Type : ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.8,"Citibank
3.8",Pune,"Irving, TX",1001 to 5000 employees,-1,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
Data Science Analyst,-1,"DESCRIPTION

Should be a Senior Data Scientist with 8+ years in Solutioning, advanced statistical modeling expertise in various scenario
Masters, or equivalent experience in a quantitative field (Computer Science, Mathematics, Engineering, Artificial Intelligence, etc.)
7+ years’ experience leading and scaling teams of data scientists
Expertise in Advanced Analytics (Predictive modelling, ML, DL and AI)
Certified Data Analytics professional with certification in Machine Learning
Expertise on delivering Machine learning models for various clients in BFSI
Solution Architect for AI Implementations
Experience in at least the following 2 programming languages: Python and R
Job Type - Permanant
Location - India, Hyderabad
Experience - 7 Years
Qualification - Bachelors
Salary - Negotiable",-1,Talent Arabia,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Because you belong at Twilio.

The Who, What, Why and Where

Twilio is growing rapidly and seeking Data Engineers at multiple levels to be a key member of the Consumer Trust Team in Bangalore, India. You will be joining one of the first teams of engineers in our new Bangalore office, with an opportunity to help define our technical and team culture in India. You will also help us build solutions that prevent fraud and abuse, ensuring that Twilio is the leader in trusted communications. A successful candidate will be a self-starter, embody a growth mindset, collaborate effectively, can mentor junior engineers and operate highly resilient services.

Who?

Twilio is looking for a strong data engineer who lives the Twilio Magic and has a demonstrated track record of working with data, specifically; sourcing and integrating data from multiple disparate backend data sources, developing reporting infrastructures and applying a deep analytics background to assess business performance and deliver actionable insights to improve efficiency and increase productivity. You should also have::
BA/BS in Computer Science, Engineering or related field
Relevant work experience in a role requiring application of analytic skills to integrate data into operational planning/business planning
Knowledge and expertise with database modeling and data warehousing principles
Fluent in writing and optimizing SQL, data mining using SQL with demonstrated strength in writing complex, high-optimized queries across large data sets,
Familiar with AWS services, especially S3, Redshift, big data services and DevOps tools
Hands on experience with Lucene / SOLR / ElasticSearch, Kafka, Google Big Query
Proficiency in at least one scripting language, Python, R, or similar.
Advanced ability to draw insights from data and clearly communicate them (verbal/written) to the stakeholders and senior management as required
Demonstrated ability to manage and prioritize workload and roadmaps
Excellent problem solving, critical thinking, and communication skills.
Strong belief in automation over toil.
Nice to have:
Hands-on experience with Big Data technologies (e.g Hadoop, Hive, Spark) is a big plus
Extensive knowledge of BI and Visualization platforms i.e. Tableau and AWS Quicksight
Strong expertise in troubleshooting complex production issues.
What?

As a Data Engineer you will:
Design, develop, and maintain data pipelines, warehouses, and reporting systems to support Twilio's products, including fraud and abuse detection systems/ tools.
Design, develop, and maintain data pipelines, warehouses, and reporting systems to support Twilio's product engineering operational data: incidents, deployments, performance, utilization, defects, change failure rate, test data, infrastructure costs.
Build the data products that technical users will depend on for business intelligence and ad-hoc access.
Build scalable solutions and self-serve platforms that will provide data and KPIs to inform business decision making.
Identify, develop, manage, and execute analyses to uncover areas of opportunity and present written business recommendations that will help improve the controllership and help achieve the goals of the team.
Develop and maintain documentation relating to all assigned systems and projects
Develop high-trust relationships and processes with partner teams and stakeholders to identify and address insight requirements
Participate in workstreams planning process including inception, technical design, development, testing and delivery of BI solutions.
Be able to adapt to prioritizing multiple issues in a high-pressure environment.
Be able to understand complex architectures and be comfortable working with multiple teams.
Why?

Twilio has democratized communications channels like voice, text, chat, and video by virtualizing the world's telecommunications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world's most demanding applications.

The Consumer Trust Team is central to Twilio's continued growth. Our mission is to prevent consumer harm by offering products and services that protect our customers and help them authenticate their users. We also ensure that every call, email and message that is made using our service is wanted, safe and legal. To do this we need to continue to develop and evolve our products and services and ensure they are able to scale; driving Twilio to new heights of scale.

Twilio is a company that is empowering the world's developers with modern communication in order to build better applications. Twilio is truly unique; we are a company committed to your growth, your learning, your development, and your entire employee experience. We only win when our employees succeed and we're dedicated to helping you develop your strengths. We have a cultural foundation built on diversity, inclusion, and innovation and we want you and your ideas to thrive at Twilio.

Where?

This position will be located in our office in Bangalore, India. You will enjoy our office perks: catered meals, snacks, game room, ergonomic desks, massages, bi-weekly All Hands and more. What you will also get to experience is a company that believes in small teams for maximum impact; seeks well-rounded talent to ensure a full perspective on our customers' experience, understands that this is a marathon, not a sprint; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves.

About Us

Millions of developers around the world have used Twilio to unlock the magic of communications to improve any human experience. Twilio has democratized communications channels like voice, text, chat, video and email by virtualizing the world's communications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world's most demanding applications. By making communications a part of every software developer's toolkit, Twilio is enabling innovators across every industry — from emerging leaders to the world's largest organizations — to reinvent how companies engage with their customers.",4.0,"Twilio
4.0",Bengaluru,"San Francisco, CA",1001 to 5000 employees,2008,Company - Public,Internet,Information Technology,₹100 to ₹500 billion (INR),-1
Data Scientist Embedded Systems Innovation,-1,"We are looking for self-motivated scientists & engineers to join our supercharged workplace and build a first generation analytical product. If you are a geek about anything – algorithms, math, machine learning, data wrangling/visualizing, high performance computing, scientific computing & tools, or anything else you can convince us about – we want to meet you!

You will :
Individual technical contributor with self-drive to understand problem statements and make design decisions – ‘own’ what you do, make your calls, and defend them
Build a first generation analytical software product – design, code, test (unit & functional) and maintain the software, while proving that your implementations ‘work’
Implement software engineering processes and discipline for fast and reliable development of high-quality software product – make the software ‘elegant’
Work as a team player in a high performance environment that rewards ownership – make your opinion count withing the team and the organization

You Have :
Bachelors or Masters in CS / Electronics from a premier institute with 3-7 years of industry experience
Solid design, excellent programming and debugging skills on a Unix-based OS (Ubuntu, Fedora, OSX) and fluency with a DVCS like Git.
Programming Languages: Python, C++
Any of these – more the better!

Skilled with python packages: scikit-learn, pandas, numpy and scipy
Understanding of common algorithms and their application in solving real-world problems
Strong mathematical background in linear algebra, optimization and descriptive & inferential statistics
Understanding of machine learning concepts like generalization, regularization, linear models, neural network and expertise with using data to build systems based on machine learning techniques
We value intellectual curiosity, open communication and creative thinkers who know how to stand up and be counted. If this sounds like who you are, we should talk.

Write to deepa.m@careerxperts.com to get started!",-1,CareerXperts,India,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Science part time job/internship,-1,"About the company:
I am an author. I am planning to write a technical product management book. My co-author is an established professional in the data engineering domain.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Work on analyzing relevant data sources, preparing evaluation report of dataset for discussion 2. Develop models for forecasting, clustering and prediction 3. Develop data pipeline

Who can apply:
Only those students or freshers can apply who:
are available for the part time job/internship (it may be part time in-office or part time at home/work from home online)
have relevant skills and interests
can start the part time job/internship between 12th Jul'20 and 16th Aug'20
are available for duration of 3 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 1

Categories: Data Science",-1,Rishi Kant Upadhyay,Gurgaon,-1,-1,-1,-1,-1,-1,-1,-1
Sales Operations & Analytics Consultant | 6 to 9 Years |,-1,"Job Description
A Sales Operations Consultant contributes to effective sales management support as part of a sales operations team.
Responsible for running a well-defined sales support process.
Responsible for implementing sales operations plan set up by sales operations manager
Having skills of analyzing data and presenting views to Management on business flow providing decision-oriented insights to management
Support implementation of Sales Operations plan (offers, channels, process, partners and analytics) set up by Sales Operations Manager
Having expertise skills in Salesforce (Reports & Dashboards) and Power BI.
Generate and evaluate business development through the Sales Scorecard using online analytical tools.
Have good reporting capabilities. Advanced Analytical skills including forecasting a definite plus
Develop business knowledge and understanding of business issues in Focus Area
Support process quality and short response time.
Primary Skills
Sales & Analytics
Developing Business Acumen on Client/Industry
Quality Management
Sales Operations
Sales Operations Team Management
Knowledge of Salesforce
Experience in building reports in Power BI
Knowledge in MS office
Expert in Reporting skill
Secondary Skills
Operations
Competitor Analysis
Reporting and Tools",3.8,"Capgemini
3.8",Hyderabad,"Paris, France",10000+ employees,1967,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹500+ billion (INR),"Accenture, CGI, Sopra Steria"
Data Engineer,-1,"Experience : 3-8 Years
Location : Bangalore

We are looking for various roles
Significant experience in Data Engineering role.
Extensive hands-on experience with Spark/ Scala, Strong programming skills with Python
Strong Experience in Pyspark
Use of AWS stack including EMR, Lambda & EC2.
Proficiency using large data sets and relational and dimensional modelling.
Expertise in a Unix environment.
Experience with messaging and streaming platforms like Kafka, RabbitMQ or JMS will be an added advantage
A self-starter attitude with an enthusiasm to work in a start-up environment
What You Need for this Position

You should have knowledge of:
Spark/ Scala
Python
Pyspark
Kafka
RabbitMQ
JMS
EMR
Lambda & EC2.
Aditional
No. of Positions
Education level
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
Data Visualization,-1,"Data Visualization Specialists are responsible for converting data into captivating, elegant visual representations to help our clients make better, data-driven decisions. You will work to interpret and portray data to tell stories in a variety of different client situations. Additionally, your work will drive the next generation of data visualization software products. A successful candidate will have deep background in data visualization, prototyping and building interactive data experiences. You will work collaboratively with other data scientists, to bridge the fields of engineering, storytelling, design, and data. If you define yourself as part engineer, part designer, and part analyst, this role is for you.

Qualification :
Bachelor?s degree in Computer Science, HCI, Engineering, Information Design, a related subject, or commensurate work experience
Ability to communicate complex quantitative analysis and analytic approaches in a clear, precise, and actionable manner
Expertise in mapping and visualization (D3 strongly preferred, Tableau, GIS, or others)
Commanding grasp of HTML5, CSS, and Javascript
Demonstrated design and UX sensibilities
Familiarity with building web applications
Interest and ability to master new languages and technologies

Prefered Requirement :
5+ years of experience of building reports and dashboards
Familiarity with statistics and modeling
Comfort manipulating and analyzing complex and high-volume of data from varying sources
Experience working with data-distributed query tools a plus (Hadoop, Hive, Presto, etc.)

Send us the Resume at info@zettamine.com",3.8,"ZettaMine
3.8",Hyderabad,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
"Data Science Engineer, Metropolis",-1,"NVIDIA is searching for a Data Science Engineer for the development and prototyping a new class of products and appliances for our Metropolis platforms. We are developing and prototyping a new class of products and appliances that allow for integration of multiple AI IOT services at the edge and in the cloud to rapidly compose end to end solutions.

What you will be doing:

Data is the lifeblood of the modern city. Today, it’s being gathered by hundreds of millions of sensors worldwide, and that number is growing exponentially. This is creating a tsunami of information that’s impossible for humans to analyze. AI is the key to turning this information into insight. It’s transforming how we collect, inspect, and analyze data to impact everything from public safety, traffic, and parking management to law enforcement and city services. NVIDIA Metropolis is leading this AI revolution, providing the tools, technologies, and expertise to meet every challenge with smarter, faster applications.

This challenging role will require someone who deeply understands and can develop frameworks, and platforms capabilities that advance the application of artificial intelligence and machine learning to IOT from edge to cloud. Practical experience in the use and the building of data analytics tools and components in both cloud and on-premise infrastructure are helpful.

We are looking for Distributed software applications engineer & architect to join our Metropolis team. You will harness groundbreaking technologies, and build meaningful products, appliances and platforms that redefine the way AI is used at the edge and in the cloud to deliver AI IOT solutions. Your understanding and knowledge of complex applications built on both on-prem and cloud infrastructure, across operating systems and device classes and Cloud Services is a prerequisite. Your ability to develop integration frameworks for software services from multiple providers and orchestration will be vital to your success

What we need to see:
MS or Ph.D. in CS or equivalent engineering experience of 3+ years of experience in developing analytical libraries and capabilities using modern distributed computing software stack for real-time, streaming and batch analytics
Validated experience with multiple public and hybrid cloud platforms including Amazon AWS, Microsoft Azure, Google GCP, IBM RedHat
Demonstrated expertise in streaming analytics engines like Apache Spark, and NoSQL data stores like Cassandra and Elasticsearch
Demonstrated experience in using message oriented middleware such as Apache Kafka
Experience with containers and deployment automation tools such as Docker (Jenkins, Spinnaker) and orchestration technologies like Kubernetes
Strong programming skills in C++, CUDA, Java/Scala and scripting language (Python)
Experience with Deep learning frameworks such as Tensorflow, Keras, PyTorch will be beneficial
Ways to stand out from the crowd:
You will be working in an agile software development mode to develop an open framework for integrating different AI IOT analytical services to deliver end to end AI solutions in smart cities, healthcare, retail, Industry 4.0, physical security, smarter infrastructure, and environments.
A plug and play adaptive and flexible framework that allow multiple third-party ISVs and vendors to deploy their solutions in a configurable manner
Developing standardized APIs that allows for the development of schemas and creative system integration
Optimize performance of for underlying hardware and cloud configurations
Work with multiple software vendors and their products to enable ease of deployment and integration
Crafting ETLs for flawless integration and flow of data and metadata
NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people in the world working for us. Are you a creative and autonomous distributed systems engineer who loves challenges? Do you have a genuine passion for advancing the state of AI & machine learning across a variety of verticals? If so, we want to hear from you. Come and join our Metropolis team where you will help build our real-time, cost-effective computing platform driving our success in this exciting and quickly growing field.",4.5,"NVIDIA
4.5",Pune,"Santa Clara, CA",10000+ employees,1993,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),-1
MIS Executive / Data Analyst,-1,"MIS Executive / Data Analyst


Role description:
Excellent knowledge of MS excel like (V-lookup, H-Lookup, Pivot, Conditional formatting etc), Word (Mail merge), and Outlook
Excellent typing including speed and accuracy
Attention to detail, Dashboard, Compilation of Data
Good written and verbal communication skills
Knowledge of creating Macros will be given extra advantage
Will prefer someone with at least 1 year of experience as MIS executive.

Desired Profile:
Good excel skills (Macro / VBA / SQL would be an added advantage)
Experience- 1 year and above
Communication-average
Under Graduate/ Graduate/ Post Graduate",3.8,"PolicyBazaar
3.8",Gurgaon,"Gurgaon, India",5001 to 10000 employees,2008,Company - Private,Insurance Agencies & Brokerages,Insurance,₹10 to ₹50 billion (INR),-1
Product Data Analyst - Intern,-1,"We are looking for Data interns who can learn fast, jump in and make an impact quickly. The internship is for a period of 6 months.

You can expect to gain an understanding of the financial markets, writing efficient data queries, creating dashboards, and helping us set up robust data tracking mechanisms. This role is best suited for someone who is comfortable with learning new concepts quickly, and working on widely varying tasks on a day-to-day basis.

Responsibilities

* Collecting, constructing and summarizing data for case-specific needs.

* Performing directed data analysis.

* Use statistical methods to analyze data and generate useful business reports.

* Keen eye for numbers and analytical thinking.

* Working with engineering to implement, document, validate, and monitor data sanity.

Requirements

* Fluency in SQL/NoSQL.

* You are a quick learner and a self-starter

* Strong communicator: You effectively synthesize, visualize, and communicate your ideas to others.

* You are a critical thinker, self-aware, and use the available data to make decisions.

* You work effectively with teammates and win credibility quickly.

Good to have:

* Experience working with MongoDB.

* Experience working with tools like Mixpanel, Google Analytics, Clevertap etc.

* Experience working with Google Apps Script.",3.7,"smallcase
3.7",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Machine Learning Engineer,-1,"CreditVidya is looking for bright candidates for the position of Senior Machine Learning Engineer. The candidate is expected to:
Have demonstrated passion and enthusiasm for Machine Learning through projects, products, etc. Ability to develop new ML models from scratch.
Be sharp at Algorithm Design and Complexity Analysis, solving new problems with ease with effective and computationally efficient methods
Enjoy programming and be comfortable with one or more languages such as, C, C++, Java, Scala, and Python
Eager to quickly learn new concepts, languages, tools and technologies as required, for example, the credit underwriting fundamentals or new deep learning frameworks
Enjoy building products that are generic and can cater to multiple tenants, through appropriate parameterization/abstraction
Be ready to work on distributed programming and big data frameworks such as Spark and optimize the performance on multiple nodes
Be excited to work in a startup environment and take end-to-end responsibilities working with the co-team members
Key Skills:
BS/MS in a relevant field with 2-5 years' experience. Or PhD in a relevant field with 0-3 years' experience",4.5,"Creditvidya
4.5",Hyderabad,"Hyderabad, India",51 to 200 employees,2012,Company - Private,Banks & Building Societies,Finance,Unknown / Non-Applicable,-1
Python Development-Data Science Internship,-1,"About the company:
Industry360 is an industrial approach toward data science and analytics. 'Learn data science the way it should be learned'

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Imparting Python training to the staff 2. Imparting Python training to schools 3. Imparting Python training to colleges 4. Imparting python training to corporates 5. Preparing Python-based videos 6. Preparing Python-based blogs 7. Preparing Python-based tutorials 8. Preparing engagement material for the Python community 9. Handling vision towards data science 10. Learning of algorithm

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 15th Jun'20 and 4th Aug'20
are available for duration of 6 months
have already graduated or are currently in any year of study
are from Gurgaon and neighboring cities
Females willing to start/restart their career may also apply

Number of internships/jobs available: 2

Categories: Data Science,Python/Django,Web Development,Computer Science,Engineering",-1,Industry360,Gurgaon,-1,-1,-1,-1,-1,-1,-1,-1
"BIG DATA ENGINEER, SMART MFG & AI",-1,"Req. ID: 196181

Recruiter: NIRMAL BEHERA

Micron Technology’s vision is to transform how the world uses information to enrich life and our commitment to people, innovation, tenacity, collaboration, and customer focus allows us to fulfill our mission to be a global leader in memory and storage solutions. This means conducting business with integrity, accountability, and professionalism while supporting our global community.

Do you believe that data provides groundbreaking insight? Do you see data as an asset that builds a competitive advantage? Great…so do we!

Micron Technology operates in a highly competitive industry where innovation depends on hardworking minds extracting fresh insights from an ever-expanding data universe. We are seeking an experienced Data Engineer capable of designing and implementing large data solutions from data streams and intelligent systems, including transforming, supporting, configuring and enhancing existing data solutions. Are you experienced in applying Data Engineering and Machine learning to Big Data, never-before-solved problems for industrial manufacturing at scale? Does this sound like the right team for you? Apply today!

As a Big Data Engineer at Micron Technology Inc., you will be a key member of a multi-functional team responsible for developing and growing Micron’s methods and systems for extracting new insight for our expanding data streams. You will be collaborating with data scientists, engineers, technicians and data mining teams to design and implement systems to extract data from Micron’s business systems, transforming it into an actionable format, and as needed, creating dynamic presentation layers for use by high-level engineers and managers throughout the company. You will be creating new solutions, as well as, supporting, configuring, and improving existing solutions.

Responsibilities and Tasks


Understand the Business Problem and the Relevant Data
Maintain an intimate understanding of company and department strategy
Translate analysis requirements into data requirements
Identify and understand the data sources that are relevant to the business problem
Develop conceptual models that capture the relationships within the data
Define the data-quality objectives for the solution
Be a subject matter expert in data sources and reporting options
Architect Data Management Systems
Use understanding of the business problem and the nature of the data to select appropriate data management system (Big Data, OLTP, OLAP, etc.)
Design and implement optimum data structures in the appropriate data management system (Hadoop, Teradata, SQL Server, etc.) to satisfy the data requirements
Plan methods for archiving/deletion of information
Develop, Automate, and Orchestrate an Ecosystem of ETL Processes for Varying Volumes of Data
Identify and select the optimum methods of access for each data source (real-time/streaming, delayed, static)
Determine transformation requirements and develop processes to bring structured and unstructured data from the source to a new physical data model
Develop processes to efficiently load the transform data into the data management system
Prepare Data to Meet Analysis Requirements
Work with the data scientist to implement strategies for cleaning and preparing data for analysis (e.g., outliers, missing data, etc.)
Develop and code data extracts
Follow standard methodologies to ensure data quality and data integrity
Ensure that the data is fit to use for data science applications
Qualifications and Experience:

0-7 years of experience developing, delivering, and/or supporting data engineering, advanced analytics or business intelligence solutions
Ability to work with multiple operating systems (e.g., MS Office, Unix, Linux, etc.)
Experienced in developing ETL/ELT processes using Apache Ni-Fi and Snowflake
Significant experience with big data processing and/or developing applications and data sources via Hadoop, Yarn, Hive, Pig, Sqoop, MapReduce, HBASE, Flume, etc.
Understanding of how distributed systems work
Familiarity with software architecture (data structures, data schemas, etc.)
Strong working knowledge of databases (Oracle, MSSQL, etc.) including SQL and NoSQL.
Strong mathematics background, analytical, problem solving, and organizational skills
Strong communication skills (written, verbal and presentation)
Experience working in a global, multi-functional environment
Minimum of 2 years’ experience in any of the following: At least one high-level client, object-oriented language (e.g., C#, C++, JAVA, Python, Perl, etc.); at least one or more web programming language (PHP, MySQL, Python, Perl, JavaScript, ASP, etc.); one or more Data Extraction Tools (SSIS, Informatica etc.)
Software development
Ability to travel as needed
Education:


B.S. degree in Computer Science, Software Engineering, Electrical Engineering, Applied Mathematics or related field of study.

M.S. degree preferred.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We recruit, hire, train, promote, discipline and provide other conditions of employment without regard to a person's race, color, religion, sex, age, national origin, disability, sexual orientation, gender identity and expression, pregnancy, veteran’s status, or other classifications protected under law. This includes providing reasonable accommodation for team members' disabilities or religious beliefs and practices.

Each manager, supervisor and team member is responsible for carrying out this policy. The EEO Administrator in Human Resources is responsible for administration of this policy. The administrator will monitor compliance and is available to answer any questions on EEO matters.

To request assistance with the application process, please contact Micron’s Human Resources Department at 1-800-336-8918 (or 208-368-4748).

Keywords: Hyderabad || Andhra Pradesh (IN-AP) || India (IN) || SGA || Experienced || Regular || Information Systems and Technology || #LI-INHYD1 || Tier 4 ||",3.5,"Micron Technology
3.5",Hyderabad,"Boise, ID",10000+ employees,1978,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Samsung Electronics, SK hynix, Toshiba"
Data Engineer (Intern) - India UHR,-1,"Job Description – Data Engineer


In Cisco, we have an outstanding opportunity where we actually get to use the technology we build!

We are Innovators


We drive innovation to propel business transformation while maintaining operational quality.

We are Accelerators


We accelerate digital solutions to generate cost savings and efficiency gains for enterprise growth and success.

We are Transformers


As customer zero, we transform the customer experience by being our own customer first with agility, quality, and security, we continuously deliver business outcomes for our clients.

What You’ll Do


Builds / oversees platforms and systems to manage and store data from internal and external sources by leveraging both distributed and local structures

Establishes processes / structures based on business and technical requirements to channel data from multiple inputs and route appropriately using data structures available

Develops tools to facilitate data integration, analytics, data cleaning / transformation, and the deployment of ML/AI models

Creates and establishes design standards and assurance processes for software, systems and applications development to ensure compatibility and operability of data connections, flows and storage requirements

Participate in a variety of professional development opportunities, network with senior executive leadership team, give back to your local community, and socialize with a community of global technologists.

Who You Are
Currently pursuing a Masters of Engineering degree in Computer Science or Information Science
CGPA of 8.0 (out of 10) and above
The requirement is for 2021/22 passout only.
Excellent written and verbal communication skills. Must be fluent in English.
Savvy problem-solving instincts and abilities
Comfortable in fast-paced and multidimensional environments
Ability to work efficiently as part of a collaborative team
Diligent to detail
Proficient in software development with a focus in data/data systems (Java, C/C++), databases (SQL, Postgres, Mongo) and development technologies (GIT, JIRA)
Possesses knowledge of data pipelining, data integration, data warehouses, and databases
Why Cisco


At Cisco, each person brings their unique talents to work as a team and make a difference. Yes, our technology changes the way the world works, lives, plays and learns, but our edge comes from our people.

We connect everything – people, process, data and things – and we use those connections to change our world for the better.

We innovate everywhere - From launching a new era of networking that adapts, learns and protects, to building Cisco Services that accelerate businesses and business results. Our technology powers entertainment, retail, healthcare, education and more – from Smart Cities to your everyday devices.

We benefit everyone - We do all of this while striving for a culture that empowers every person to be the difference, at work and in our communities.

So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture enthusiast? Many of us are. Passion for technology and world changing? Be you, with us!

Disclaimer - “Please note this posting is to advertise potential job opportunities. The requirment is for 2021 /22 passout only. This exact role may not be open today, but could open in the near future. When you apply, a Cisco representative may contact you directly if a relevant position opens.”",4.3,"Cisco Systems
4.3",Bengaluru,"San Jose, CA",10000+ employees,1984,Company - Private,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Alcatel-Lucent, Juniper Networks"
Data Analyst Executive,-1,"Roles and Responsibilities:
Accurate timely generation of reports.
Keeping the report data bank ready for any requests received from time to time.
Coordinating with sales and marketing team for the data.
Knowledge of Google Sheets advance.
Data Collection, Analysis, and Updation.

What’s In It For You?

Be part of a fast growing Startup that is part of ATDC, a Georgia Institute of Technology, based startup incubator in Atlanta GA USA.
Work in exciting latest mobile/IOT/Wearable technologies and in the most happening Supply Chain domain
Ability to be promoted at a fast pace as the company grows.
Company provided MacBook Pro & free snacks.
Results Only Work Environment.",4.7,"SMART GLADIATOR
4.7",Chennai,"Atlanta, GA",1 to 50 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,₹100 to ₹500 million (INR),-1
Software Developer – Data Science and Engineering,-1,"Design, Architect and Develop Native iOS Apps based on suitable design patterns
Knowledge in basic OOPS concepts
Good knowledge in designing and implementing interface, protocols, Categories and other basic language features
Good knowledge and work experience in hardware specific features like
Location Detection
Accessing Camera and Photo Library
Good knowledge in Map Kit
Basic knowledge in third-party framework integrations like Facebook, Twitter, etc.

Good knowledge in gcd or NSOperationQueue
Basic knowledge in KVC
Good knowledge in UIKit framework
Good knowledge in APNS
Experience: 3 - 8 years",4.0,"Sulekha
4.0",Chennai,"Chennai, India",1001 to 5000 employees,2004,Company - Private,Internet,Information Technology,₹10 to ₹50 billion (INR),-1
FTC - Marketing Data Analyst & Campaign Support (WI),-1,"About the opportunity


Purpose of your role

Based upon their knowledge of customer data, the successful candidate will work with campaign teams to optimise their effectiveness through more enhanced / personalised target audience selection.

The candidate will work with campaign teams to define potential target audiences based upon available customer data from Marketo and any other relevant sources and then support the set up of the campaigns in Marketo. Diligence will be required to ensure that we are allowed to communicate with the specific customers based upon customer interests, preferences, business requirements and regulatory boundaries; this is critical as this role is the guardian of these rules.

Core elements of the role will also support the sourcing of data to collate and report upon the teams’ KPI’s and any subsequent actions that follow from them.

This role is part of a team supporting the WI business.

Key Responsibilities

Customer audience identification
Taking a campaign brief, identify an optimal target customer audience from the available customer base / data set.
Check what we are allowed to send to the respective audience based upon pre-set conditions.
Ensure the appropriate customer audience is available for marketing communications through relevant systems and tools.
Support the onboarding of new clients
Data Analytics
Support the wider analytics team and campaign managers in customer analytics such as performance measurement, segmentation analysis and behavioural analysis.
Experience and Qualifications Required
Experienced and competent at data handling.
Knowledge of asset management / financial services sector preferred (but not essential).
Sense of urgency and awareness of when to escalate issues.
Self-motivated, a proactive approach with an analytical, enquiring mind and willingness to learn.
Ability to work on own initiative to achieve objectives and goals, requesting support when and where required.
Strong sense of ownership with ability to work on challenging issues and overcome constraints and obstacles.
Timeliness and high productivity while working under pressure to meet deadlines.
Strong customer service orientation.
Commitment and professionalism.
About you


Essential Skills Required:
Strong analytical skills and very numerate.
Ability to analyse a request and produce innovative solutions.
Attention and care to detail - passion for data driven Insight
Good networking and communication skills (verbal and written).
Good organisation and coordination skills.
Good Microsoft office skills – Excel, PowerPoint, Word.
Desired Skills:
Some experience / knowledge of tools used by FIL e.g. Marketo, Power BI and Tableau (although training will be given)
About Fidelity International


Fidelity International offers investment solutions and services and retirement expertise to more than 2.4 million customers globally. As a privately-held, purpose-driven company with a 50-year heritage, we think generationally and invest for the long term. Operating in more than 25 locations and with $479.9 billion in total assets, our clients range from central banks, sovereign wealth funds, large corporates, financial institutions, insurers and wealth managers, to private individuals.

Our Workplace & Personal Financial Health business provides individuals, advisers and employers with access to world-class investment choices, third-party solutions, administration services and pension guidance. Together with our Investment Solutions & Services business, we invest $371 billion on behalf of our clients. By combining our asset management expertise with our solutions for workplace and personal investing, we work together to build better financial futures.",3.7,"Fidelity International
3.7",Gurgaon,"London, United Kingdom",5001 to 10000 employees,1969,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
Finance Analytics Data Scientist,-1,"Job Description

Job Description

TCS has proudly created an
exceptional leadership community with leaders like you to drive change, foster
innovation and retain TCS as the top player in the business market.

What we are looking for

Job Location: Mumbai/Kolkata

Must-Have:

1. Should have hands on experience with Machine learning
models like Logistics regression, Survival analysis model, Gradient Boost,
Collaborative filtering, Bayesian, SVM, Random Forest etc.

2. Prior experience in predictive model building using R/
Python

3. Excellent knowledge of R &-or Python (must) and other
statistical tools

4. Masters Statistics, Mathematics, Computer Science or
another quantitative field

5. Minimum 2-3 years’ experience in programing in R/ Python.
Excellent programming skills must

6. Minimum 1-2 years documentation/dashboarding skills using
R Markdown (knitting in both PDF and HTML), RShiny

7. Minimum 1-2 years documentation skills using GitHub based
data science solution development

8. Minimum 1-2 years’ experience in exploratory data
analysis with time series and non-time series data

9. Minimum 1-2 years’ experience in time series concepts
like stationarity, auto correlation, cross correlation, trend analysis, ARIMA/
ARMA and statistical modelling like regression and classification

10. Minimum 1-2 years’ experience in statistical concepts
like Normal, Poisson and Weibull Distribution, hypothesis testing, maximum
likelihood estimation

11. Minimum 2 years’ experience in Design of Experiment
(DOE), Simulation and Optimization.

12. Minimum 1-2 years’ experience in distributed agile

Good to Have:

1. Minimum 2 – 3 years of core data sciences experience
entailing programing in R/ Python, performing Exploratory Analysis and sound
knowledge in statistics with strong documentation background.

2. Excellent knowledge of Data Visualization in R/ Python/
Power BI / QlikView etc. and interpretation of Graph / Charts.

3. Excellent Knowledge of Excel functions and VBA
Automation.

4. Exceptional analytical and technical aptitude.

5. Excellent attention to detail.

6. The ability to manage time, prioritize tasks and work
under tight deadlines.

7. Concise and clear written and verbal communication when
presenting and explaining results and findings.

8. Knowledge of Platforms: R (Mandatory)/ Python

Responsibilities:

1. Ability to translate Business Problem to a Statistical
Problem and Statistical solutions to a viable Business solution.

2. Ability to perform statistical modelling (predictive,
regression, hypotheses testing, multivariate analysis, Time Series, Cluster,
forecasting, ARIMA) using R/ Python.

3. In-depth knowledge of Statistics and Machine Learning
concepts and should be able to apply them to business problems

4. Experience in collaborating with technology team and
support the development of analytical models with the effective use of data and
analytic techniques.

5. Data Extraction from EDW/Big Data Platform, Dataset
Preparation (creation of base data, aggregation, transformation), performing
EDA.

6. To validate the model results, Monitor model performance,
and articulate the insights to the business team.

7. Ability to create good visualization with the output
generated from the model

8. Write complex SQL queries to perform data extraction from
various data sources

9. Prepare client consumable presentations with actionable
insights for data driven decision making.

10. Ability to build use cases for the business and present
them to client as well as Project IT stakeholders

11. Self-motivated with the ability to take direction and
work independently

12. Document the model requirements in a suitable doc

13. Proven ability to mentor juniors and take full ownership
for end-to-end deliverables related to project/program

14. Driving the E2E execution starting from Business
interaction to deploy & support

15. Engage with internal/external stakeholders in collaborative
data science project management.

Minimum Qualification:

•

15 years of full-time education;

•

Minimum percentile of 50% in 10th, 12th, UG
& PG (if applicable)

Job Function

TECHNOLOGY

Role

Scientist

Job Id

159067

Desired Skills

Data Science | Statistics | Finance | QlikView

Desired Candidate Profile

Qualifications :
BACHELOR OF ENGINEERING",3.8,"Tata Consultancy Services
3.8",Mumbai,"Mumbai, India",10000+ employees,1968,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Accenture, IBM, Infosys"
Sr. Data Scientist,-1,"The person should have overall 7-8 years of experience out of which 4-5 years of experience should be in Machine & Deep Machine learning. Especially using Convolution Neural Network (CNN), Image Analytics TensorFlow, Open CV etc.

With our fast-growing data scientist’s team, we are looking to hire self-motivated smart individuals who are willing to take challenges in the field of AI predictive image analytics & machine learning.

Responsibilities :
The Machine & Deep Machine Learning Software Engineer (Expertise in Computer Vision) will be an early member of a growing team with responsibilities for designing and developing highly scalable machine learning solutions that impact many areas of our business.
The individual in this role will help in the design and development of Neural Network (especially Convolution Neural Networks) & ML solutions based on our reference architecture which is underpinned by big data & cloud technology, micro-service architecture and high performing compute infrastructure.
Typical daily activities include contributing to all phases of algorithm development including ideation, prototyping, design, and development production implementation.

Required Skills :
An ideal candidate will have background in software engineering and data science with expertise in machine learning algorithms, statistical analysis tools, and distributed systems.
Experience in building machine learning applications, and broad knowledge of machine learning APIs, tools, and open source libraries
Strong coding skills and fundamentals in data structures, predictive modelling and big data concepts
Experience in designing full stack ML solutions in a distributed compute environment
Experience working with Python, Tensor Flow, Kera’s, Sci-kit, pandas, NumPy, AZURE, AWS GPU
Excellent communication skills with multiple levels of the organization",-1,Claim Genius Making touchless claims a reality,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
Sr Big Data consultant - AWS Professional Services,-1,"Are you a Data Analytics specialist? Do you have Data Warehousing, Hadoop/Data Lake experience? Do you like to solve the most complex and high scale (billions + records) data challenges in the world today? Do you like to work on-site in a variety of business environments, leading teams through high impact projects that use the newest data analytic technologies? Would you like a career path that enables you to progress with the rapid adoption of cloud computing?

At Amazon Web Services (AWS), were hiring highly technical cloud computing architects to collaborate with our customers and partners on key engagements. Our consultants will develop, deliver and implement AI, IOT, and data analytics projects that help our customers leverage their data to develop business insights. These professional services engagements will focus on customer solutions such as Machine Learning, IoT, batch/real-time data processing, Data and Business intelligence.

This is a customer facing role. You will be required to travel to client locations and deliver professional services when needed.


· Expertise - Collaborate with AWS field sales, pre-sales, training and support teams to help partners and customers learn and use AWS services such as Athena, Glue, Lambda, S3, DynamoDB NoSQL, Relational Database Service (RDS), Amazon EMR and Amazon Redshift.


· Solutions - Deliver on-site technical engagements with partners and customers. This includes participating in pre-sales on-site visits, understanding customer requirements, creating packaged Data & Analytics service offerings.


· Delivery - Engagements include short on-site projects proving the use of AWS services to support new distributed computing solutions that often span private cloud and public cloud services. Engagements will include migration of existing applications and development of new applications using AWS cloud services.

· Insights - Work with AWS engineering and support teams to convey partner and customer needs and feedback as input to technology roadmaps. Share real world implementations and recommend new capabilities that would simplify adoption and drive greater value from use of AWS cloud services.

· Innovate - Engaging with the customers business and technology stakeholders to create a compelling vision of a data-driven enterprise in their environment

This role is open for Mumbai/Pune/Bangalore/Chennai/Hyderabad/Delhi/Pune.


Basic Qualifications


· Bachelors degree, in Computer Science, Engineering, Mathematics or a related field or equivalent professional or military experience

·12+ years of experience of IT platform implementation in a technical and analytical role

· 5+ years of experience of Data Lake/Hadoop platform implementation

· Hands-on experience in implementation and performance tuning Hadoop/Spark implementations.

· Experience Apache Hadoop and the Hadoop ecosystem

· Experience with one or more relevant tools (Sqoop, Flume, Kafka, Oozie, Hue, Zookeeper, HCatalog, Solr, Avro)

· Experience with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto)

· Experience developing software code in one or more programming languages (Java, Python, etc)


Preferred Qualifications


· Ability to think strategically about business, product, and technical challenges in an enterprise environment

· Masters or PhD in Computer Science, Physics, Engineering or Math


· Hands on experience leading large-scale global data warehousing and analytics projects

· Ability to collaborate effectively across organizations

· Understanding of database and analytical technologies in the industry including MPP and NoSQL databases, Data Warehouse design, BI reporting and Dashboard development

· Demonstrated industry efficiency in the fields of database, data warehousing or data sciences

· Implementing AWS services in a variety of distributed computing, enterprise environments

· Customer facing skills to represent AWS well within the customers environment and drive discussions with senior personnel regarding trade-offs, best practices, project management and risk mitigation

· Desire and ability to interact with different levels of the organization from development to C-Level executives",4.3,"Amazon
4.3",India,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Analyst,-1,"Designation : Data Scientist/Analyst

Requirements

Job Description- Must Have Skills:
R/ Python/SAS/SPSS programming skills
Experience of statistical techniques
Experience of data visualization tools like Tableau,ggplots etc.
Experience of how to build predictive models using machine learning algorithms
Fluency in English
Strong communication skills with the ability to communicate at all levels of the business
Team player attitude
Qualification –
Bachelor or Master’s degree in Engineering (Nice to have – Mechanical) or Computer Science/Computer application or Statistics background or a related field with solid portfolio of work.

Interested candidates kindly forward your resume on : ybidkar@sevenmentor.com",4.7,"SevenMentor.Pvt.Ltd
4.7",Pune,"Pune, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
"Lead Data Scientist - Data Analysis, Machine Learning (Exp 8 to 13 years)",-1,"What's the role?


At HERE Technologies in Automotive Product Engineering organization, we are looking for highly skilled, self-motivated, Sr/Lead Data Scientist who is passionate about innovating and developing machine learning and data analytics solutions to build our industry-leading map. We provide the opportunity to collaborate with an energetic and dedicated team that works on cutting-edge technology to create tools and services. The candidate will work with researchers, developers, architects, IT to develop, deploy, and maintain applications in multiple environments.

What You’ll Get:
Challenging problems to solve
Opportunities to learn cool new things
Work that makes a difference in the world
Freedom to decide how to perform your work
Variety in the types of projects
Feedback so you will know how well you are doing
Collaborative, Supportive Colleagues
Responsibilities:
Help design and build the next iteration of process automation in HERE Content Engineering employing a highly scalable Big Data infrastructure and machine learning as applied to global-scale digital map-making.
Build and test analytic and statistical models to improve a wide variety of both internal data-driven processes for map-making data decisions and system control needs.
Act as an expert and evangelist in areas of data analysis, machine learning, statistics, and predictive analysis and modeling.
Function as a predictive modeling or application team lead.
Who are you?


You are a fast learner, with an eye for detail, strong problem-solving and debugging skills. In addition you have:

• MS or PhD in a discipline such as Statistics, Applied Mathematics, Computer Science, Data Science, or others with an emphasis or thesis work on one or more of the following areas: statistics/science/engineering, data analysis, machine learning, computational geometry, and image processing.• 8+ years related, professional experience.• Knowledge of data mining and analytic methods such as regression, classification, clustering, association rules, decision trees, Bayesian network analysis, etc. expert-level knowledge in one or more of these areas.• Proficiency with a statistical analysis package and associated scripting language such as Python, C++, R, Matlab, SAS, etc. • Programming experience with SQL, shell script, Python, etc. • Knowledge of and ideally some experience with Cloud platform such as AWS, and the tools such as Pig, Hive, etc., for working with big data in Hadoop and/or Spark for data extraction and data prep for analysis.• Experience with and demonstrated capability to effectively interact with both internal and external customer executives, technical and non-technical to explain uses and value of predictive systems and techniques. • Demonstrated proficiency with understanding, specifying and explaining predictive modeling solutions and organizing teams of other data scientists and engineers to execute projects delivering those solutions.Preferred Qualifications: • Development experience with C++/Python/Shell Script• Development experience with Docker• Development experience with GIS data• Development experience with Relational Database/ NoSQL Database""

What we Offer

We will support you in delivering your day to day tasks and achieving your personal goals and develop your skills. Personal development is highly encouraged at HERE. You can take different courses and trainings at our online University and join cross-functional team projects within our Talent Platform. Our office is located with easy access by public transportation options. So, what are you waiting for? Apply now and make HERE your destination. We are just getting started...!

HERE is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, age, gender identity, sexual orientation, marital status, parental status, religion, sex, national origin, disability, veteran status, and other legally protected characteristics.

Make HERE your destination, we are just getting started! Apply now!

Who are we?


Ever checked in somewhere on social media? Ever tracked your online orders? You might be using HERE Technologies every single day without even realizing it. You can find us everywhere: in vehicles, smartphones, drones or third-party apps. We believe that with the right people, we will continue to be a game-changer in the technology industry and improve the daily lives of people around the world. Find out more by clicking the video below or going HERE.",3.7,"HERE Technologies
3.7",Mumbai,"Amsterdam, Netherlands",5001 to 10000 employees,1984,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Google, TomTom, Apple"
Data Engineer,-1,"Company Description

About Eurofins

Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate. Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 47,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2019, Eurofins generated total revenues of EUR € 4.56 billion, and has been among the best performing stocks in Europe over the past 20 years.

About Eurofins IT Solutions India Pvt Ltd

Eurofins IT Solutions India Pvt Ltd (A CMMI Level 3 Company) is a 100% full owned subsidiary of Eurofins. This young captive centre located in Bangalore was established in 2012 to be the largest IT Solutions group within Eurofins to cater to all the internal IT business needs. The primary focus of IT Solution group will be to develop the next generation LIMS (Lab Information Management system), Customer portals, Ecommerce solutions, ERP/CRM system & B2B platforms for various Eurofins Laboratories and businesses.

EITS India is a Young, Dynamic and Growing organization with lot of career growth prospects. We strongly believe that ‘Our people are our assets’ and we ensure that all our staff are provided with great work environment, good benefits and challenging Global projects to enable a fulfilling career. We are committed to provide enriching experience to our employees.

Job Description

POSITION TITLE: Data Engineer

REPORTING TO: Manager

REPORTING LOCATION: Bangalore

WORKING LOCATION: Bangalore

SUMMARY OF POSITION AND OBJECTIVES:

We are looking for a savvy Data Engineer to join our team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. Person in this role will support our software developers, database architects, data analysts and scientists as well as business owners on data initiatives and will ensure an optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives mainly based on event streams to support real time analytics and right presentation of it using tools like Tableau, PowerBI.

POSITION & OBJECTIVES:

Job description:
Create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Azure ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Work with Data Visualization tool esp. Tableau, Tableau Desktop/ Power BI Desktop.
QUALIFICATIONS AND EXPERIENCE REQUIRED:

SKILLS REQUIRED:
Advanced working SQL knowledge and experience working with relational databases, mainly MS SQL, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.
Basic Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with Azure or AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with data manipulation languages: Python, R, (Power)Shell, etc.
Experience with the preparation of data for visualization (e.g. data profiling, data cleansing, volume assessment and partitioning, modeling data, etc.).
Experience of working on SSRS and SSIS, good to have SSAS.
Experience working with Data Visualization tools esp. Tableau (mandatory) / Power BI.
ADDITIONAL SKILLS REQUIRED:
Knowledge on NoSQL DB / MongoDB will be an added advantage.
Experience with cloud-based data sources (e.g. Dynamics 365, Azure DW, Azure SQL, Azure Data Factory).
Some experience and ability to learn how to work with unstructured data sources.
Experienced in interacting with business users to analyze the business process and requirements and transforming requirements into visualizations and reports.
Knowledge with the selection of appropriate data visualization strategies (e.g., chart types) for specific use cases. Ability to showcase complete dashboard implementations that demonstrate visual best-practices (e.g., color themes, visualization layout, interactivity, drill-down capabilities, filtering, etc.).
Knowledge of dashboard visualization development best practices.
Experience in gathering and translating end user requirements into effective efficient dashboards.
Experience in working in a fast-paced, dynamic and Agile development lifecycle
Experience in optimizing user queries and dashboard performance.
Proven experience in estimating work and break down implementations into tangible modules.
Good to have some experience in embedded analytics (i.e., embedding visual data analytics in other transactional and operational systems).
EXPERIENCE
Candidate with 5+ years of experience in a Data Engineer role
Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Candidate should be a technical hands-on person with proven experience.
Understanding of Product Development Lifecycle and Lean Agile Scrum Methodologies
Excellent Communication, Interpersonal and Presentation skills.
Fluent written and oral English is essential.
Methodology we have in place and expect to be used:
Scaled Agile, Lean, Kanban, Zero Defect development method
Daily Stand-ups with other developers directly involved
Scrum of Scrums, Innovation Sprints
Continuous integration
Automatic Build and Deployments
Automated Unit & Functional Testing
Follow Development guidelines and coding style
SonarQube based Static Code Analysis
Qualifications

Graduate degree in Computer Science, Statistics, Informatics, Information

Additional Information",3.4,"Eurofins Scientific
3.4",Bengaluru,"Luxembourg, Luxembourg",10000+ employees,1987,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹100 to ₹500 billion (INR),-1
Data Engineer II,-1,"The Appstore Technology team in Bangalore is responsible for building curated catalog of high quality third party mobile apps. The team uses cutting edge technologies to develop large-scale platforms to ingest huge number of app submitted by mobile app developers and making these available for millions of Amazon Appstore customers.

The Datalytics Platform team is building a brand new data warehouse for digital goods processed by the Appstore and Alexa teams, and also a few other digital good providers.
As a part of this team, you will be building and enhancing this new data platform, and be the owner of data ingestion, processing and presentation. In this role, you will be working with multiple people across the org and geographies to cater to their data needs. You will get deep understanding of the business requirements, and own the transformation and storage of the data that can be consumed by the customers to drive the business forward. In a data driven company like Amazon, this role would come with a lot of responsibilities and exciting challenges.

Roles and Responsibilities:

Own data processes; write queries that meet stakeholder business requirements, lead work with SDEs for full-scale automation.
Mentor engineers on Data Engineering concepts.
Liaise with stakeholders to understand the requirements and translate into data model, processes, and tie them back to source
Have the capability to handle large data sets in analysis through the use of additional tools/scripts
Define analytical approach; review and vet analytical approach with stakeholders.
Proactively and independently work with stakeholders to construct use cases and associated standardized outputs.

Basic Qualifications

· 3+ years of experience as a Data Engineer or in a similar role
· Experience with data modeling, data warehousing, and building ETL pipelines
· Experience in SQL
Bachelors degree or higher in an engineering or technical area such as Computer Science, Physics, Mathematics, Statistics, Engineering or similar.
5+ years of experience as a Data Engineer dealing with large complex data scenarios.
High level of aptitude with SQL, Excel (pivot tables) required
Strong understanding of BI technologies and their application including database warehousing and dashboarding experience.
Experience on at least one data visualization tools such as OBIEE and Tableau .
Experience with Big data technologies like S3, Hadoop, Spark, PIG
A self-starter who loves data!

Preferred Qualifications

Masters degree at a well-regarded institution in an analytical field with deep understanding of underlying technologies preferred
High degree of comfort to own/lead statistical/quantitative analysis and reach sound conclusions and disseminate findings to key stake holders and/or senior management",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Engineer,-1,"Looking for Senior Data Engineers

Skills required

Apache Kafka - 3 yrs.

Pyspark -3+yrs

Apache Airflow – 1+yr

Prefer Redshift exp.

Job Type: Full-time

Pay: ₹590,522.00 - ₹1,761,682.00 per year

Experience:
work: 1 year (Preferred)
total work: 6 years (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.9,"dotSolved Systems India Pvt Ltd
4.9",Chennai,"Pleasanton, CA",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,₹100 to ₹500 million (INR),-1
Data Analyst (SQL),-1,"Casepoint provides full eDiscovery capabilities through a powerful, secure, cloud-based platform. We are repeatedly chosen by leading law firms and multinational corporations for their largest matters. On an upward trajectory for almost a decade, Casepoint is looking to expand its team globally. Team cooperation, “work hard, play hard” attitude, open communication, and kindness mark Casepoint’s culture.

Number of positions currently vacant:
10 positions

Job description:
We are seeking Data Analysts to fill twenty positions. Data analysts are comfortable with data importing, exporting, processing, manipulation, and analysis. You will build and improve tools to efficiently automate data analysis and/or manipulation tasks. As a data analyst, you will also face clients for specific requests, too.

Key job responsibilities:
Load, manipulate, process, and analyze data
Convert, normalize, and migrate data from a variety of databases
Convert text and image files to various formats
Scripting in MS SQL
Provide technical leadership with Project Managers and outside clients as needed
Understand and resolve technical details
Assist in tracking project progress
Meet ad-hoc request for clients
For example, a one-time report in a specific format, a complicated data migration and cleanup, or any complex analytical data and file manipulation task
Report daily to manager

Required skills & experience:
0 to 3 years experience

Required skills include:
Data import-export
Data processing and analysis
VBA

Scripting and database experience in:
MS SQL
MS Access
Database maintenance

Compensation & culture:
Excellent culture produces an excellent product. We value our team members, so we provide a nurturing environment of camaraderie. We recognize talent with competitive compensation and career empowerment.

Location:
Surat, India

To apply, please submit your resume to talent@casepoint.in",3.5,"Casepoint
3.5",Surat,"Washington, DC",51 to 200 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
AWS Data Lab Solution Architect,-1,"Are you a data and analytics specialist? Do you have deep expertise in AWS services for managing data at speed and scale? Do you think big about how data can change the world, and love building software? Would you like a career that gives you opportunities to help customers and partners use cloud computing services to build new solutions, faster, and at lower cost?


At AWS, were hiring highly technical cloud computing architects and engineers to collaborate with our customers on building solutions in database, data management, and analytics. AWS Data Lab is located in Seattle, New York, Herndon, London, and now Bangalore. You will focus on real time and batch-based data processing, business intelligence, analytics, and machine learning systems. These solutions are built alongside the customer and quickly put into production use in a matter of weeks. You'll work closely with AWS Field Teams including Solution Architects, Technical Account Managers, and AWS Service Developers to partner with customers to solve hard problems with data. Every day, you'll be working with AWS Services and Data Lab Customers to determine the optimal implementation, build it, prove it works, extract documents and CloudFormation templates to speed project delivery. If you are builder, and love data, then this could be your ideal job!




Roles & Responsibilities
· Understand customer requirements and render those as architectural models that will operate at large scale and high performance. Where customers have architectures prepared, validate them against non-functional requirements and finalize the build model.
· Work alongside customers to build data management platforms using Elastic Map Reduce (EMR), Redshift, Kinesis, Amazon Machine Learning, Amazon Athena, Lake Formation, S3, AWS Glue, DynamoDB, ElastiCache and the Relational Database Service (RDS)
· Render working, high performance data management solutions, as CloudFormation and reusable artifacts for implementation by the customer
· Prepare architecture and design briefs that outline the key features and decision points of the application built in the Data Lab
· Work with customers to advise on changes as they put these systems live on AWS
· Extract best-practice knowledge, reference architectures, and patterns from these engagements for sharing with the worldwide AWS solution architect community

Basic Qualifications

· Highly technical and analytical, possessing 3 or more years of Database and/or Analytics Systems development and deployment experience, IT systems and engineering experience, security and compliance experience, etc.
· Possess significant experience of software development and/or IT and implementation/consulting experience.
· Strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external organizations and virtual teams.
· Ability to think understand complex business requirements and render them as prototype systems with quick turnaround time.
· Implementation and tuning experience in the Big Data Ecosystem, (such as EMR, Hadoop, Spark, R, Presto, Hive), Database (such as Oracle, MySQL, PostgreSQL, MS SQL Server), NoSQL (such as DynamoDB, HBase, MongoDB, Cassandra, design principles) and Data Warehousing (such as Redshift, Teradata, Vertica, schema design, query tuning and optimization) and data migration and integration.
· Track record of implementing AWS services in a variety of business environments such as large enterprises and start-ups.
· Knowledge of foundation infrastructure requirements such as Networking, Storage, and Hardware Optimization.
· BS level technical degree required; Computer Science or Mathematics background preferred. [DB1]
· AWS Certification, eg. AWS Solutions Architect, Developer, or AWS Certified Big Data - Specialty

Preferred Qualifications

· Hands on experience leading large-scale global database, data warehousing and analytics projects.
· Demonstrated industry leadership in the fields of Database and/or Data Warehousing, Data Sciences and Big Data processing.
· Deep understanding of data, application, server, and network security
· Experience with Statistics, Machine Learning and Predictive Modelling.
· Hands on experience as a database, data warehouse, big data/analytics developer or administrator, or work as a data scientist.
· Experience working within the software development or Internet industries is highly desired.
· Technical degrees in computer science, software engineering, or mathematics
· Working knowledge of modern software development practices and technologies such as agile methodologies and DevOps.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer, and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, disability, age, or other legally protected status.",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
CIEL/SEL/14460: Lead Data Scientist,-1,"Data Science Lead
:
Manage a team of data scientists, machine learning engineers and big data specialists
Lead data mining and collection procedures
Proven experience as a Data Scientist or similar role
Solid understanding of machine learning
Knowledge of data management and visualization techniques
A knack for statistical analysis and predictive modeling
Good knowledge of R, Python and MATLAB
Experience with SQL and NoSQL databases
Strong organizational and leadership skills
Excellent communication skills
A business mindset
Ensure data quality and integrity
Interpret and analyze data problems
Conceive, plan and prioritize data projects
Build analytic systems and predictive models
Test performance of data-driven products
Visualize data and create reports
Experiment with new models and techniques
Align data projects with organizational goals
Degree in Computer Science, Data Science, Mathematics or similar field",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
Data Engineer,-1,"Wavelabs is an AI-First, new-age Technology company for the Digital, Cognitive & Industry 4.0 Era. We help you rethink and reinvent, while adapting to the inevitable change technology evolutions bring.

We leverage cutting-edge technology to become an enabler of fundamental innovation and disruption. We drive business outcomes with Data and Data Analytics to go beyond the existing platforms for insights and become agile on execution. We intend on leveraging the advances in artificial intelligence (AI) and machine learning (ML) to build solutions that are loved by all.

This is who we are. We are a community looking to deliver true flagship experiences. We focus on the things that matter most to us – design and customer experience. Most importantly, we’re not just doing it for ourselves. We are here to share the best technology and build beautiful products hand-in-hand with you.

Data Engineer - 3 - 5 years- Hyderabad

Job Description
Should have experience in GCP (Google Compute Platform) and Google AutoML.
Should have experience in Pyspark and Python skills
Should have experience in Data handling, SQL queries etc.",4.4,"WAVELABS TECHNOLOGIES
4.4",Hyderabad,"Hyderabad, India",51 to 200 employees,2015,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Data Analyst - Finance Reporting,-1,"Profile Required

Should have at least 4 to 8 years of experience in IB Operations under Finance function or handling of Second Level Controls for Finance function

Preferably Exposure to Capital Markets

Core/Key Responsibilities (include below but not limited to):

-Ability to analyze the risk of the process and understand the control built to mitigate/ minimize the risk.

-Ability to perform in- depth end to end control testing.

- Review of control execution for the Key Controls related to finance to ensure Controls are well followed.

 Strong communication skills and knowledge of Second Level Controls

-Assist in implementing the controls framework with Finance team with objective to achieve efficiency and exhaustiveness

 Strong interpersonal skills

Why Join Us

“We are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status”

Business Insight

A 100% owned subsidiary of European banking and financial services major Societe Generale (SG), Societe Generale Global Solution Centre (SG GSC) came into existence in 2000. Established as an offshore development centre in Bangalore, also having a presence in Chennai, SG GSC has 15 years of sustainable delivery expertise to its credit, and develops global best practices to promote the strategic objectives of the Societe Generale Group.
SG GSC possesses in-depth understanding of the business processes and cutting-edge technologies across domains of Societe Generale’s diverse portfolio. We deliver best-in-class solutions to the Group’s entities in the realm of corporate and investment banking, retail banking, specialized financing and insurance, private banking, and global investment management and services.
We place the highest importance on our employees and provide extensive opportunities for career progression and development. SG GSC conforms to the group diversity principles, and has a multi-cultural staff representing seven nationalities, and speaking 20 languages. Women comprise 25% of our workforce.",3.5,"WAVELABS TECHNOLOGIES
4.4",Bengaluru,"Paris, France",10000+ employees,1864,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"BNP Paribas, Natixis, Calyon Securities USA"
Junior Research Scientist,-1,"Role title : Jr.
Chemist / Chemist / Jr Research
Scientist
Location : Goa

Role
Purpose:

4 years’ experience in R & D/ process
chemistry/agrochemical industry is desirable
Good experimental
skills with appetite for learning and updating latest developments in synthetic
organic chemistry.
Is capable to work with
chemical safety and with a high hygiene standard
Good understanding of
physical separation operations in the lab (distillation, crystallization,
extraction etc.) and analytical
methods like LCMS, GC,
HPLC, NMR etc.
Able to plan and organize synthetic
chemistry work on small to medium scale to achieve a high level of productivity
and to meet important deadlines.
Experience
with the use of hard-copy and computer-based chemical information storage and
retrieval systems.
Understand the
principles of organic chemistry and standard transformations
Ensure own laboratory
work recorded and reported to agreed Syngenta standards
Provide timely
communications and feedback to stakeholders
This role is based in
Goa R&T
Education – Msc
(Organic Chemistry)
Incumbent will be part
of global function with a local line management
.

Role title : Jr.
Chemist / Chemist / Jr Research
Scientist
Location : Goa

Role
Purpose:

4 years’ experience in R & D/ process
chemistry/agrochemical industry is desirable
Good experimental
skills with appetite for learning and updating latest developments in synthetic
organic chemistry.
Is capable to work with
chemical safety and with a high hygiene standard
Good understanding of
physical separation operations in the lab (distillation, crystallization,
extraction etc.) and analytical
methods like LCMS, GC,
HPLC, NMR etc.
Able to plan and organize synthetic
chemistry work on small to medium scale to achieve a high level of productivity
and to meet important deadlines.
Experience
with the use of hard-copy and computer-based chemical information storage and
retrieval systems.
Understand the
principles of organic chemistry and standard transformations
Ensure own laboratory
work recorded and reported to agreed Syngenta standards
Provide timely
communications and feedback to stakeholders
This role is based in
Goa R&T
Education – Msc
(Organic Chemistry)
Incumbent will be part
of global function with a local line management
.",4.0,"Syngenta
4.0",India,"Basel, Switzerland",10000+ employees,2000,Company - Public,Chemical Manufacturing,Manufacturing,₹500+ billion (INR),-1
Data Analyst,-1,"Department :Infrastructure

Level : 3

Location : Hyderabad

Shifts (if any) 5:30pm to 2:30am

About ATG

Founded in 2012, ATG is a global services company providing technology, business process management and consulting services to some of the leading global organizations. We have a proven track record of helping our clients identify and deliver significant bottom line improvements using our expertise in finance, legal, HR and information technology related services. Our unique business engagement model is purpose-built to offer our client partners with best-in-class service through dedicated resources such as people, technology, infrastructure and top management support.

For more information, log on to http://www.aeriestechnology.com

About web.com

Web.com's Systems Infrastructure team manages DNS, load balancers, virtualization, and internal tool development to support thousands of servers and millions of small business websites. We're seeking an engineer with solid Python and Linux experience to help build and maintain automation tools in our environment.

log on to http://www.web.com

About the Role: Position summary & Main tasks/activities (short and precise definition of the role and most important activities listed)

Essential Duties and Responsibilities:
Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing Infrastructure reports, Service Maps and performance indicators
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities Strong knowledge and experience in securing an application’s integration with relational database management systems such as MS SQL

Job Requirements

Proven working experience as a Data Analyst or Business Data Analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (MySQL,SQL etc), programming (Python/R, Java, .Net)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
Good Communication and Presentation skills
Support 24x7 Infrastructure Models
Exposure on Tools like JIRA, Power BI, tableau, Customer Support Tools

Skills

2-3-year experience in data reporting.
Strong written and verbal communication skills.
Must have good analytical ability and logical understanding/reasoning.
Hands-on in Advanced Excel.
Understanding of data management programs (SQL, MySQL etc.)/Programming languages (R, Python)
Knowledge of data visualization platforms (Tableau, Power BI etc.)
Familiarity with working with large data sets and creating a cohesive story",4.1,"Aeries Technology Group
4.1",Hyderabad,"Mumbai, India",501 to 1000 employees,2012,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),-1
DATA ANALYST - FOOD INDUSTRY,-1,"Requirement
Responsible for gathering or mining data, modeling, cleaning and structuring them to extract useful information, trends, patterns and other necessary matrices that can be converted into insights.
These insights are used to drive better business decisions and market strategies.
Data analysts collect, analyze and extract important information from data and then, present them in a simpler form to better business, products, and other undertakings.

Company Profile

An Food E-commerce Company operation for organic food products.

Respond To priyap@livecjobs.com",4.0,"Live Connections
4.0",Chennai,"Chennai, India",201 to 500 employees,1996,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
Data Engineer II / Sr Data Engineer,-1,"Relocation Assistance Offered Within Country
# 83461 - Mumbai, Maharashtra, India

We are looking for a savvy Data Engineer to join our growing team of analytics experts. Data Engineers will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoy optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Roles and Responsibility:
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Experience
We are looking for a candidate with minimum 2 years of experience in a Data Engineer role
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Experience supporting and working with cross-functional teams in a dynamic environment.
They should also have experience using the following software/tools:
Experience with relational SQL and NoSQL databases: MongoDB, Neo4j, etc
Experience with cloud services: GCP, AWS, etc
Experience with object-oriented/object function scripting languages: Python, Java, etc.
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with Data Flow, Data Pipeline and workflow management tools: Cloud Composer, Airflow, Luigi, etc.
Qualification & Competencies
Bachelor’s degree required, Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field is preferred
Working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Strong analytic skills related to working with unstructured datasets.
Strong problem solving skills with an emphasis on product development.
Strong experience with test driven development methodologies.
Strong oral & written communication skills with an ability to express complex technical concepts in business terms and business needs in technical specifications
A drive to learn and master new technologies and techniques.
Equal Opportunity Employer
Colgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, veteran status (United States positions), or any other characteristic protected by law.

Are you interested in working for Colgate-Palmolive? You can apply online and attach all relevant documents such as a cover letter and resume or CV. Applications received by e-mail are not considered in the selection process. Become part of our team. We look forward to your application.

Colgate-Palmolive is a leading global consumer products company, tightly focused on Oral Care, Personal Care, Home Care and Pet Nutrition. Colgate sells its products in over 200 countries and territories around the world under such internationally recognized brand names as Colgate, Palmolive, elmex, Tom’s of Maine, Sorriso, Speed Stick, Lady Speed Stick, Softsoap, Irish Spring, Protex, Sanex, Elta MD, PCA Skin, Ajax, Axion, Fabuloso, Soupline and Suavitel, as well as Hill’s Science Diet and Hill’s Prescription Diet.

For more information about Colgate’s global business, visit the Company’s web site at http://www.colgatepalmolive.com. To learn more about Colgate Bright Smiles, Bright Futures® oral health education program, please visit http://www.colgatebsbf.com. To learn more about Hill's and the Hill’s Food, Shelter & Love program please visit http://www.hillspet.com. To learn more about Tom’s of Maine please visit http://www.tomsofmaine.com.

Reasonable accommodation during the application process is available for persons with disabilities. Please contact Application_Accommodation@colpal.com with the subject ""Accommodation Request"" should you require accommodation.",4.0,"Colgate-Palmolive
4.0",Mumbai,"New York, NY",10000+ employees,1806,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),-1
Big Data Engineer,-1,"At VMware, we are committed to helping our people grow professionally. Our talented employees exemplify our shared values and continue to drive our company to new heights. If you see a position that might be right for you, we encourage you to apply and continue to be a part of our EPIC2 community.

VMware is the leader in virtualization and cloud infrastructure solutions that enable our more than 350,000 enterprise and SMB customers to thrive in the Cloud era. A pioneer in the use of virtualization and automation technologies, VMware simplifies IT complexity across the entire data center to the virtual workplace, empowering customers with solutions in the software-defined data center to hybrid cloud computing and the mobile workspace.

Our team of 20,000+ people working in 50+ locations worldwide is committed to building a community where great people want to work long term by living our values of passion, innovation, execution, teamwork, active learning and giving back. If you are ready to accelerate, innovate and lead, join us as we challenge constraints and problem solve for tomorrow today.

Job Description

VMware Data Engineering team is seeking a highly motivated, experienced Big Data Engineer within Data & Analytics group located in Bangalore, India. This position is responsible for hands on development work on all aspects of Big Data, data provisioning, modeling, performance tuning and optimization. The candidate will work closely with both Enterprise and Solution Architecture teams to translate the Business/Functional requirements into technical specifications that drive Big Data solutions to the meet functional requirements.

Qualifications & Skills
Bachelors degree or equivalent required with preference for Computer Science or Engineering. MS degree would be highly desirable
Big Data consultant/ engineer with at least 3+ years of overall experience and hands-on experience in Hadoop - MapReduce, HDFS, Hbase, Hive, Sqoop, MongoDB, NoSQL or Cassandra.
Hands on Experience with Cloudera Distribution & expertise in Spark & Python/Scala/Go (any one).
Experience with Kafka and Presto would be highly desirable.
Proven expertise in a wide variety of database technologies, from Postgres, SQLServer to NoSQL systems such as MongoDB, Cloudant, Cassandra, and/or Elasticsearch, and can explain their varied use cases
Desired Qualifications:

- - Familiarity with SAP HANA Information Models within the Enterprise HANA platforms

- - Knowledge of Data Integration Platforms- Informatica PowerCenter, SAP BODS , SDI, SLT

- -Experience with Cloud technologies

Location - Bangalore, India

Category : Engineering and Technology
Subcategory: Software Engineering
Experience: Manager and Professional
Full Time/ Part Time: Full Time
Posted Date: 2020-07-27

VMware Company Overview: At VMware, we believe that software has the power to unlock new opportunities for people and our planet. We look beyond the barriers of compromise to engineer new ways to make technologies work together seamlessly. Our cloud, mobility, and security software form a flexible, consistent digital foundation for securely delivering the apps, services and experiences that are transforming business innovation around the globe. At the core of what we do are our people who deeply value execution, passion, integrity, customers, and community. Shape whats possible today at http://careers.vmware.com.

Equal Employment Opportunity Statement: VMware is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: VMware is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at VMware are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. VMware will not tolerate discrimination or harassment based on any of these characteristics. VMware encourages applicants of all ages. Vmware will provide reasonable accommodation to employees who have protected disabilities consistent with local law.",4.3,"VMware
4.3",Bengaluru,"Palo Alto, CA",10000+ employees,1998,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),-1
Data Engineer,-1,"Responsibilities:
Writing reusable, testable, and efficient code
Contribute to R&D for future
Design and implementation of low-latency, high-availability, and performance applications
Testing, debugging and deploying data (Machine Learning and Computer Vision) applications
Assess and prioritize feature requests
Coordinate with internal teams to understand user requirements and provide technical solutions
Integration of user-facing elements developed by front-end developers with server-side logic
Skills and Qualifications:
1-2 years of work experience as a data engineer/ML engineer/Data Scientist
Understanding of common computer vision and image processing techniques
Working experience of SQL.
Familiarity with common front-end technologies (like JavaScript, CSS and HTML5)
Good problem-solving skills
Demonstrated ability to integrate multiple data sources and databases into one system
Good understanding of server-side templating languages such as Jinja2, Mako, etc.
C, C++ and Python programming. GPGPU computing a strong plus (Cuda C and C++/OpenCL, PyCUDA/PyOpenCL).
Understanding of fundamental design principles behind a scalable application
Familiarity with event-driven, asynchronous and multithreaded programming in Python and C++.
Understanding of the differences between multiple delivery platforms, such as mobile vs desktop, and optimizing output to match the specific platform
Able to create database schemas that represent and support business processes
Proficient understanding of Git
Experience:
CS/Math/EE/Physics — B.Tech/M.Sc. with 2 years of experience,
M.Tech. with 0-1 years ofexperience
Ph.D.
Location: Bangalore

Please send your resume to hello@tsaasg.com",-1,The SAAS Group,Bengaluru,"Berlin, Germany",1 to 50 employees,2014,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Business Intelligence Analyst,-1,"Position Summary

The Business Intelligence (BI) Engineer will work in a business facing role to develop and generate reports/dashboard to meet the business users’ needs and provide them with timely information that enables them to make various business-related decisions. The role requires the candidate to build and maintain complex large-scale data models for an enterprise system and the underlying business processes. Analyse data and create meaningful reports that captures various key business metrics. Automate reports, dashboards, scorecards etc. requested by business users. The ideal candidate needs to work collaboratively with teams, formulate recommendations for further initiative refinement based on current data evidence.
Organization Grade 2.3/3.1
Position Title Business Intelligence Analyst
Department Business Intelligence
Reporting Relationships Manager – Business Intelligence
Cross Functional Relationships Product Mgmt., Analytics, Finance, Compliance
Location Chennai

Critical Business Activities
S No Roles and Responsibilities Weight-age
1 Work with business users to develop and analyse business intelligence needs. 10%
2 Analyse business processes and requirements. Interpret business requirements and determine optimum BI solutions to meet the needs. 10%
3 Develop and manage BI solutions. Design reports and dashboards for business users. 20%
4 Support stakeholders on their ad-hoc reporting, data and analysis needs 20%
5 Perform analysis for a wide range of requests using data in various platform. Explores the data and discovers patterns, meaningful relationships, anomalies and trends. 20%
6 Create and maintain documentation including requirements, design, data marts and codes. Follow process laid out for each phase of BI development 10%
7 Update, manage and maintain reporting data marts 10%

Desired skills and Experience
Bachelor’s degree in computer science, Information Systems, Business Management or specialized training/certification or equivalent work experience.
3+ years of experience with Business Intelligence. Experience working with SAP Business Objects along with one or more dashboarding tools like Tableau, Power BI, AWS Quick Sight, Qlik.
Good understanding on data warehouse concepts and great experience working with database, creating complex SQL queries.
Experience with Python or other scripting language.
Strong analytical and communication skills. Good understanding of statistics, data analysis and produce insights from large datasets.
Results-Driven with ability to take initiatives and meet deadlines in a fast-paced changing environment.",3.8,"Global Analytics
3.8",Chennai,"San Diego, CA",201 to 500 employees,2003,Company - Private,Lending,Finance,₹10 to ₹50 billion (INR),-1
Director Data Science,-1,"Description:

At Walmart, were accelerating a journey towards becoming the worlds leading data driven retailer. As the worlds largest retailer, we have the opportunity to use an unmatched retail data asset to deliver lower prices and better products for our customers and suppliers. As the Value Realization Lead, youll be leading a team that works across functions and domains to deliver analytics and data science-based solutions to complex business challenges. Youll be at the forefront of working across business, product, technology and data teams to deliver algorithmic solutions to drive top-line and bottom-line results across Walmart businesses. This role is a central element in Walmarts overall data strategy mission of accelerating data driven automation.

As the Value Realization Lead, you will be applying your expertise to analyze complex business use cases, and design and build analytics-based solutions. You will work with business leaders, data engineering teams, product teams, and data scientists to prioritize and develop strategic use case roadmaps and deploy solutions for the prioritized use cases.

The ideal candidate will be:

Curious: You stay up to date with the latest technology developments in the data science community, and are excited to enable high-impact outcomes in the face of complex problems and large datasets

Bold and with a bias for action: Youre a doer, thriving on the challenges of delivering hardened and optimized models as part of production systems

Pragmatic and focused on results: You like working in a fast-paced environment and making practical trade-offs to test, learn and deploy analytics solutions that have material impact on Walmarts business

Key Responsibilities:

• As team lead, grow a team of analytics consultants to drive business value through application of advanced analytics and data science.

• Coordinate across functional teams of data scientists, analysts, product managers, engineers, and business operators on value realization initiatives

• Develop and leverage a consistent framework to identify and prioritize uses cases based on business value

• Collaborate with data engineering teams to identify data sets needed to support value use cases

• Apply algorithmic and other analytical models as appropriate to address business use cases

• Identify opportunities to further automated decision making goals based on data

• Develop and leverage internal and external partnerships and networks to maximize the achievement of business goals

• Support implementation of automated data quality checks in product roadmaps

• Architect, develop, and deploy large-scale data analytics services from prototype through production that meet key business requirements (performance, reliability, speed, monitoring, self-service, etc.)",3.3,"Walmart
3.3",Bengaluru,"Bentonville, AR",1001 to 5000 employees,1962,Company - Public,"Department, Clothing, & Shoe Shops",Retail,₹500+ billion (INR),"Target, Costco Wholesale, Amazon"
"Principal, Applied Scientist",-1,"Do you want to be part of a new team at Amazon that is making history? Do you want to build technology and new science that millions of people will use? Are you excited about working on large scale Natural Language Processing (NLP), Machine Learning (ML), and Deep Learning (DL)?

We in Amazon search are embarking on a multi-year journey to rethink the shopping experience on Amazon starting with a solid understanding of the customers shopping mission based on their search query and using that to present products that they will like, view, and purchase. We are challenging the established idea that a list of results is the best experience when customers are looking to shop for the right product and that we should be designing shopping pages rather than search pages. But all that begins with a deep and accurate understanding of the query and very high precision matches of the query to products in our product catalog. And we believe that the latest advances in deep learning technology can help us realize our teams long-term vision of making shopping effortless on Amazon.

We are looking for a tenured researcher to work on improving multilingual search on Amazon using NLP, ML, and DL technology. This is a highly visible role with a huge impact on Amazon customers and business. As a part of this role, you will be lead an inter-disciplinary team of scientists and engineers to develop high precision, high recall, and low latency solutions for multilingual search. Your solutions should work for all languages that Amazon supports including but not limited to German, French, Italian, Spanish, Japanese, Chinese, Portuguese, Dutch, etc. and will be used in all Amazon locales world-wide. You will work with leaders across search to develop a strategic vision and long term plans to improve multilingual search on Amazon. You will be technically fearless and will develop scalable science and engineering solutions that work successfully in production.

This is a position on a new Multilingual Search team in Bangalore (India). We are moving fast to change the way Amazon search works. As a Principal Applied Scientist, you will lead scientists and engineers in Bangalore and serve as a point of contact with Search leaders in Seattle and Palo Alto. Together with a multi-disciplinary team you will work on building solutions with NLP/ML/DL at its core. Along the way, youll learn a ton, have fun and make a positive impact on millions of people.



Basic Qualifications

· PhD in Computer Science, Machine Learning, Statistics, or a related quantitative field
· 10+ years industry experience building successful production software systems
· Experience with machine learning technologies, Deep Learning, Natural Language Processing ( NLP), information retrieval and/or related applications
· Experience in a modern programming language (Python, Java, or similar)
· Experience communicating with executives and non-technical leaders
· Strong Computer Science fundamentals in data structures, algorithm design, and statistics

Preferred Qualifications

· Significant peer reviewed scientific contributions in Natural Language Processing, Speech Recognition, Computer Vision or relevant field.
· Expertise on a broad set of ML approaches and techniques, ranging from Artificial Neural Networks to Bayesian Non-Parametric methods
· Expert in more than one more major programming languages (Java, C++, or similar) and at least one scripting language (Perl, Python, or similar)",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Analyst,-1,"Department: AnalyticsQualification: BTech/BSc IT Reports to: VP Technology Skills : SQL + Tableau + R 2 to 5 years of experience in the Analytics industry. Experience in OTT sphere will be an added advantage. Data crunching, insights generation, strategic thinking. Good communication skills to convey technical and advanced concepts in precise and clearly understandable terms to a variety of audiences.

Requirements : Candidate should have strong analytical and logical thinking Should be able to work on a large dataset Able to write complex SQL queries to create an aggregate table Able to create dashboards in Tableau, also able to take care of the server side activities Must have knowledge of deck creation for upper management Knowledge of scripting language: Javascript would be an added advantage Submit your cv at careers@balajitelefilms.com",2.6,"altbalaji
2.6",Mumbai,"Mumbai, India",51 to 200 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Position Title
Data Engineer

14-Jul-2020

Job ID
298921BR

Job Description
Support the planning, design, development and delivery of system solutions for a specific business or technology area. Capture new IT demand and ensure IT services provided to business are being delivered to requirements and that business user expectations and satisfaction levels are met.
Act as a point of contact for the business-specific business capability, for existing and new services to ensure that agreed services are being delivered to requirements and business user expectations and satisfaction levels are met. -Ensure service adherence with quality, compliance and security standards and delivery of associated corrective service actions; handle and resolve customer feedback. -Design, develop and/or deliver solutions that meet business requirements. Job Purpose Purpose of the role is to build is to design and build solutions to ingest data from variety of sources in to Data and Analytics platforms at Alcon. As part of the Analytics team, work closely with Business stakeholders to understand Analytics needs, create, support or enhance Analytics products that align with Alcon’s Data and Analytics strategy and standards. Essential Job Functions •As part of the Analytics sprint team before data engineering to ingest data from various sources into data lake solution on AWS Cloud as per the roadmap •Deliver business solution on Alcon’s analytics platform through end-to-end implementation that includes data security, governance, cataloging, preparation, automated testing, and data quality metrics. •Contribute towards building high performing platform/product DevOps agile teams •Automate, optimize, migrate and enhance existing solutions. •Perform data modeling, data analysis and providing insights using various tools.
-Completeness and accuracy of business demand capture -Project/solution delivery execution (quality, time, cost) -Process efficiency -IT service risks recorded / managed -Customer Satisfaction -Service/solution quality: timely and accurate reporting (i.e. Service performance and CSAT analyze) -Adherence to solution architecture and architecture roadmaps -Adherence to SLAs.
Applied Business Insights Digital & Technology Savvy Organizational Savvy Project Excellence Continuous Learning (Dyn. Knowledge Development) Interpersonal Savvy Being resilient.

Minimum requirements
Collaborating across boundaries Cross Cultural Experience Organization Scope; Scale and Complexity Ambiguity Accountability English IT Data Analysis IT Systems Design Programming / Software development IT Systems Integration IT Testing IT Customer Service Support IT Service Level Management.

•Education: Bachelor’s degree or equivalent years of applicable experience •Experience: 3+ years of applicable experience in Data Warehousing and BI Solutions. 3+ years of experience in writing code in spark engine using python, scala or java Language The ability to fluently read, write, understand and communicate in English. Specific Job Posting Content •Good understanding of traditional and latest data and analytics platforms architecture models. •3+ years experience in data engineering which includes data ingestion, preparation, curation, provisioning, automated testing, and quality checks. •2+ years of Big Data, and Analytics Technologies – hands-on experience is a must Big Data cloud platforms, Data Lakes, and Data Warehouses Familiarity with Visualization and Reporting Tools like Tableau, Salesforce Einstein Analytics and QlikSense 3+ years experience in languages to ingest data is a must – SQL, Java, Python, & Scala 

Job Type
Full Time

Country
India

Work Location
Bangalore

Functional Area
Information Technology

Division
ALCON

Business Unit
NON-NVS AL INFORMATION TECHNOLOGY

Employment Type
Regular

Company/Legal Entity
Alcon Ind

Shift Work
No",3.6,"Alcon
3.6",Bengaluru,"Fort Worth, TX",10000+ employees,1945,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),Allergan
Applied Scientist,-1,"Bachelor’s/Master Degree in Computer Science with advanced degrees preferred.
·
5+ years of hands on experience in building machine learning systems for large data sets
·
Strong skills in problem solving, programming and computer science fundamentals
·
Expertise in using Python, Java / C++, or other programming languages, as well as with Spark ML, scikit-learn, Theano, Tensorflow or similar machine learning tools
·

The Selection Monitoring team is responsible for making the biggest catalog on the planet even bigger. In order to drive expansion of the Amazon catalog, we use machine learning and cluster-computing technologies like MapReduce, Spark and Hive to process billions of products and algorithmically find products not already sold on Amazon. We work with structured and unstructured content such as text and images and apply algorithms like deep learning, computer vision, NLP and image processing . The role demands a high-performing and flexible candidate who can take responsibility for success of the system and drive solutions from research, prototype, design, coding and deployment.
We are looking for Applied Scientists to tackle challenging problems in the areas of information retrieval at internet scale using data science and distributed systems. You should have depth and breadth of knowledge in text mining, information retrieval and machine learning. You should also have programming and design skills to manipulate unstructured data and systems that work at internet scale.
You will encounter many challenges, including

·
Scale (build models to handle billions of pages),
·
Accuracy (extreme requirements for precision and recall),
·
Speed (generate predictions for millions of new or changed pages with low latency),
·
Diversity (models need to work across different languages, market places and data sources)
·
You will help us to

·
Build a scalable system which can algorithmically identify relevant sources and retrieve information from world wide web,
·
Intelligently cluster web pages to predict pages that have a high propensity for change using predictive analytics.
·
Build systems that will identify newer domains for crawling using social feeds, offline data etc.
·
MS / PhD, specialized in Information Retrieval and Machine Learning
·
Experience in designing and implementing information retrieval, web mining and neural network and other classification algorithms.
·
Big thinker that can take broad visions and concepts and develop structured plans, actions and measureable metrics and then execute those plans.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Analyst - Looker,-1,"Role:- Data Analyst (Looker)

You will play a crucial role in implementing, improving, and maintaining Looker reports. This includes partnering and consulting with business and analytics teams to provide guidance and assistance in creating and streamlining Looker reports.

Responsibility:-
Interacting with clients, to understand their needs and come up with an end-to-end solution
Translate business requirements to actionable data tasks (English <-> SQL)
Use Looker to create a metadata repository (LookML), Views, and dashboards.
Become a subject matter expert on Looker, both as a development platform and visualization tool
Be responsible for maintaining security and data access models within Looker
Monitor and optimise the performance of our Looker instance
Implement best practices for LookML coding and data model design
Control and monitor data access
Qualification :-

B.Tech any stream (preferably CS, IT, Electronics)

Requirements:
Strong technical knowledge in SQL and
Data analysis skills
Expertise in visualization technologies including Tableau, Looker and/or another BI tool
Strong business intuition and ability to understand complex business systems
Optional Requirement
Experience on spectacle (https://spectacles.dev/)
Minimum Experience - 0-1 year

CTC - 4-6LPA",3.4,"VinSol
3.4",New Delhi,"New Delhi, India",51 to 200 employees,2000,Private Practice / Firm,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Scientist- Marketing Analytics -Manager,-1,"Job Title
Data Scientist- Marketing Analytics -Manager

Job Description

#LI -SR1

About the organization

Philips Global Business Services LLP is a limited liability partnership organization with Royal Philips of the Netherlands. Royal Philips is a diversified technology company, focused on improving people's lives through meaningful innovation in the areas of Health Systems and Personal Health.

Royal Philips (NYSE: PHG, AEX: PHIA) is a leading health technology company focused on improving people's health and enabling better outcomes across the health continuum from healthy living and prevention, to diagnosis, treatment and home care. Philips leverages advanced technology, deep clinical, and consumer insights to deliver integrated solutions. Headquartered in the Netherlands, the company is a leader in diagnostic imaging, image-guided therapy, patient monitoring and health informatics, as well as in consumer health and home care. Philips' health technology portfolio generated 2017 sales of EUR 17.8 billion and employs approximately 74,000 employees with sales and services in more than 100 countries.

For information on Royal Philips, please visit www.philips.com

JD: Data Science Manager/Deputy Manager

Job location: Bangalore

Responsibilities

Analyzes, measures, and facilitates optimization of our marketing return on investments and tactics across multiple channels. Drive excellent practices and technical standards for establishing KPIs and goals for Marketing, developing information suites (Dashboards, reports, visualizations) fit for C-level consumption, and marketing campaign tracking and measurement.
Leverage machine learning models to address key growth challenges such as lifecycle marketing, predictive LTV, cross-channel spend allocation, response modelling, campaign/channel performance measurement methodologies, Program effectiveness and media attribution.
Develop and improve marketing mix and A&P models and frameworks to assign credit for traffic and conversions across a variety of Marketing channels and touchpoints.
Leverage Philips’ data to scale our ability to optimize marketing across the customer journey to optimize return on investment through analysis, modelling, experiments and pre-post analyses.
Develop and implement marketing data management practices
Ability to use data for Exploratory, descriptive, Inferential, Prescriptive, and Advanced Analytics - Mandatory
Ability to share dashboards, reports, and Analytical insights from data – Mandatory

Technical Knowledge and Skills required

Econometrics, Market mix modeling, some Operations research and affinity modeling experience is mandatory
Track record in delivering strong and impactful; competitor and market tracking insights
High affinity with applying new IT platforms / dash boarding software tools for reporting and Experience in a consumer focused, complex, matrixed, multinational environment, e.g. consumer goods, online services, e-commerce, or mobile applications
Competitor insight generation
Strong background into Database design, modeling and architecture – preferred Fluency in web analytics and deep technical understanding of how data are created from first party and third-party web beacons
Proficiency with R and/or Python libraries commonly used in data science

Soft Skills Required

Good communication and presentation skills
Highly driven, energetic, flexible, resourceful & ability to multitask
Clarity of thoughts and vision
Ability to ideate and bring solutions to the table
Adherence to timelines, without sacrificing quality of output
Hands on and detail oriented, with a strong ability to co-ordinate across different Geographies and with different stakeholders at Exec and Director levels
Straightforward, honest and succinct communicator. Can organize, clarify and communicate complex ideas quickly, succinctly and accurately.
Creative. Demonstrated ability to think innovatively—connecting the dots where others cannot when it comes to consumer/ customer and user data to create business building insights

Work Experience

Minimum 3-8 years of increasingly responsible experience in high impactful marketing analytics individual contributor roles
Can be from e-Commerce companies like Amazon, Flipkart etc.
In depth knowledge of multivariate statistical techniques including marketing mix modeling, attribution modelling, TURF, RAD, clustering, churn, customer scoring, neural networks amongst others
High affinity with AI powered insight tools and engines and application of data science to marketing problems
Rich experience in Marketing analytics with a strong understanding of the full range of online marketing channels, how they work, how they can be integrated, and how to evaluate them

Academics

Master’s degree in a quantitative discipline, e.g., Math, Statistics, Physics, Operations Research, Economics, Econometrics
MBA /BTech-BE from IIT/NITs or Tier 1 engineering schools only, , MS Analytics from Tier 1 schools; special preference to MBA from Mudra Institute of Communication, Ahmedabad or MBA schools that excel in Marketing
Strong exposure to Statistics – Predictive Analytics – Mandatory

Contact

If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Bengaluru,"Amsterdam, Netherlands",10000+ employees,1891,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),-1
Associate Data Engineer,-1,"Role: Associate Data Engineer, Quantitative Research
Job DescriptionThe Group: Morningstar’s Quantitative Research Group creates independent investment research and data-driven analytics designed to help investors and Morningstar achieve better outcomes by making better decisions. We utilize statistical rigor and large data sets to inform the methodologies we develop. Our research encompasses hundreds of thousands of securities within a large breadth of asset classes including equities, fixed income, structured credit, and funds. Morningstar is one of the largest independent sources of fund, equity, and credit data and research in the world, and our advocacy for investors’ interests is the foundation of our company.The Role: As an Associate Data Engineer, you will work along with Quant Researchers, Data Scientists to support all Data engineering initiatives. This role requires exploring Microservices, Big Data and Batch Data pipelines for structured/unstructured data to help ingest massive amounts of data required for statistical, machine learning & AI model execution. This role requires interaction with business, data collections, Development teams across Data and Research. As an Associate Data Engineer, you would be keen to develop proficiency in Big data technologies and be comfortable programming in Python.
You are an individual who possesses strong technical skills, loves cloud technology, has good problem solving & consulting skills, and has an eye for picking up challenging opportunities. You also enjoy working with cross-functional technical teams on complex problems and are always looking to improve yourself and others around you. Responsibilities:
• Build/ Support Data Engineering pipelines leveraging massive amounts of structured, unstructured financial/non-financial data.
• Research varied cloud/ AWS Tools (Microservices, Big Data & Batch Services) for building data pipelines to ingest massive amounts of big data.
• Program Python, SQL queries to support varied data pipeline requests.
• Support/ build data-marts (SQL/NoSQL) to support various dashboarding needs.
• Interacting with cross-functional business and technical teams for Building Data Dictionaries.
• Effectively communicate with data and technical team to understand the requirement and gain the knowledge about integrating varied data types.
• Create and track issues and validate to completion
Requirements:
• Knowledge of programming experience in Python(Pandas/ Numpy) and OOPS principles.
• Good knowledge of SQL/NoSQL (preferred)databases.
• Knowledge of Hadoop stack is preferred (SQOOP, HDFS, Hive, Spark).
• Good knowledge of software engineering practices.
• BS degree in engineering, computer science, statistics, mathematics or equivalent practical experience
• Knowledge of AWS ecosystem (Lambda, EC2, RDS, EMR, Athena, Glue)
• Experience with UNIX/Linux including basic commands and shell scripting
• Familiarity with mutual fund, fixed income, and equity data is a plus
• Intellectual curiosity for the world of quantitative research
• Fluent in both oral and written English.

Morningstar is an equal opportunity employer.I10_MstarIndiaPvtLtd Morningstar India Private Ltd. (Delhi) Legal Entity",4.1,"Morningstar
4.1",Mumbai,"Chicago, IL",5001 to 10000 employees,1984,Company - Public,Financial Analytics & Research,Finance,₹100 to ₹500 billion (INR),"Thomson Reuters, FactSet, Bloomberg L.P."
Machine Learning Engineer,-1,"OakNorth is the next-generation credit and monitoring platform that provides banks and lending institutions with the insight and foresight needed to create a better borrowing experience for the Missing Middle – the growth business who are the backbones of communities and economies globally but who have been in banking’s blind spot for decades.

The business was founded in 2015 by Rishi Khosla and Joel Perlman, who previously co-founded Copal Amba and grew it to 3,000 employees over 12 years, before selling it to Moody’s (NYSE: MCO) in 2014, returning 125 times capital to seed investors.

Since its inception, OakNorth has secured over $1bn from several investors, including: Clermont Group, Coltrane, EDBI of Singapore, GIC, Indiabulls, NIBC, Toscafund, and SoftBank’s Vision Fund.

The Platform has been deployed at various banks across North America, Europe, and Asia, and in the UK where OakNorth lends off of its own balance sheet via OakNorth Bank. The platform has helped OakNorth Bank become the fastest-growing business in Europe according to the Financial Times FT 1000 (2020), profitably lending over £4bn to date. In terms of the impact this has had on the economy, OakNorth Bank’s loans have directly helped with the creation of 13,000 new homes and 17,000 new jobs in the UK, as well as adding several billion pounds to the economy.

With offices in London, New York, Manchester, Singapore, Hong Kong, Shanghai, Istanbul, Gurgaon and Bangalore, the global team across the OakNorth Holdings group is over 800 people.

SME are crucial in global economy. Although they account for 99% of business in the UK/US, their financing need is increasingly difficult to be met by major banks, due to higher risk of default and heterogeneity of different sectors in SME.
To solve these challenges, OakNorth is building a platform to improve productivity of SME lenders. From credit appraisal, to loan monitoring, the OakNorth Machine Learning team has identified multiple key areas that can be optimised by recent advances in Machine Learning (ML), Natural Language Processing (NLP), Computer Vision (CV), and Information Retrieval (IR).
We are looking for a passionate machine learning and/or software engineer who will be joining the fastest growing and profitable fintech in Bangalore. You enjoy solving challenging tasks, creating and maintaining impactful and data-driven products with innovative techniques.
We expect you to
have experience in ML, CV, NLP, IR, or related fields
have a master (or PhD) degree with 3 years' experience in industry
able to learn new technologies and comprehend academic literatures independently.
We would love to see
Experience with modern deep learning frameworks (e.g. PyTorch, Tensorflow, Jax)
Experience working on distributed software system (e.g. Spark, Hadoop, ElasticSearch)
Publications in related academic venues (e.g. ACL, CVPR, EMNLP, ICML, KDD, NeurIPS)
You will
Convert research findings into production-level software systems and maintain them.
Research and evaluate techniques that can improve/solve a concrete business workflow/problem.
Work with domain experts to shape the future of our platform.
Thank you very much for your interest in OakNorth. We are happy to consider you for roles within our group of companies. If we can identify a match between your skill set and our immediate recruiting needs, please expect to hear from us very soon. If we are unable to identify a fit in the near term, please note that we intend to retain the data you send to us so we may contact you in the future.",4.1,"OakNorth Bank
4.1",Bengaluru,"London, United Kingdom",51 to 200 employees,2015,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
Data Science Internship,-1,"About the company:
Vumonic Datalabs is a data intelligence company that is in the business of furnishing competitive insights and consumer behaviour data to online businesses.

About the internship/job:
Selected intern's day-to-day responsibilities include: 1. Identify valuable data sources and automate collection processes 2. Undertake preprocessing of structured and unstructured data 3. Analyze large amounts of information to discover trends and patterns 4. Build predictive models and machine-learning algorithms 5. Combine models through ensemble modeling

Who can apply:
Only those students or freshers can apply who:
are available for full time (in-office) internship
have relevant skills and interests
can start the internship between 23rd Jul'20 and 27th Aug'20
are available for duration of 3 months
have already graduated or are currently in any year of study
Females willing to start/restart their career may also apply

Number of internships/jobs available: 2

Categories: Big Data,Data Science",-1,Vumonic Datalabs,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
DATA SCIENTIST - Machine Learning / Artificial Intelligence (PhD Degree),-1,"We are seeking a Data Scientist for one of the top reputed firms in Trivandrum/Thiruvananthapuram, who is smart and passionate, so should you be!

We are not looking for Ninjas but we are keen on hearing from you, who is settled to make a Great Mark in Career.

Our Client will help you achieve your Goals of Continuous Professional Development and Regular Career Progression sessions.

We think you fit the best, If :
You hold a PhD Degree (Ph.D / Doctor of Philosophy)
You have 1-8 years of solid experience in Machine Learning / Artificial Intelligence
You have strong hands-on experience in Computer Vision algorithms and Image/text/voice Processing
You can effectively multitask and operate problem in a team environment
You have the capability to interact with tremendous communication skills.
When you are onboard,
You will be responsible for Developing Technical and Functional Solutions for business ideas & concepts.
You will participate in every aspect of building and deploying creative new automation and machine learning algorithm for advanced text, voice, data analytics, knowledge graph creation.
You will be responsible to deliver significant and tangible results through innovative thinking and in-depth sector expertise.
Our Client embraces diversity and equal opportunity in a serious way. They are committed to building a team that represents a variety of backgrounds, perspectives, and skills.",3.7,"Roljobs Technology Services Pvt Ltd
3.7",Thiruvananthapuram,"Bengaluru, India",51 to 200 employees,2002,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Engineer Intern,-1,"JOB SUMMARY:
TRIARQ Health is a Physician Practice Services company that partners with doctors to run modern patient-centered practices so they can be rewarded for delivering high-value care.

TRIARQ’s Physician-led partnerships simplify practices’ transition to value-based care by combining our proprietary, cloud-based practice, care management platform and patient engagement services to help doctors focus on better outcomes.

LOCATIONS:
India: TRIARQ Health 5th floor, Rushiraj Tower, Jehan Circle, Gangapur Road Nashik -422013
US: TRIARQ Health, 1050 Wilshire Drive, Suite 300, Troy, Michigan 48084

REQUIREMENT:

We are looking for a Data Engineer Intern that will help us discover the information hidden in vast amounts of data and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

RESPONSIBILITIES:
Defining and Modifying data base structure as per application requirements.
Creating stored procedures and function.
Creating data models by understating business logic.
Data processing, Data cleansing, Data wrangling and verifying the integrity of data used for analysis.
Managing and monitoring data redundancy.
Integrate data base connection in services (Java /Python).
SKILLS AND QUALIFICATIONS:
Experience with query languages, Data Modeling, Database Design, Dimensional and Relational Modeling, Database Schemas
Good database scripting and programming skills Python, SQL, BigQuery, PostgreSQL, MySQL
Basic understanding of machine learning techniques and algorithms, such as Linear Regression, Classification, SVM, Decision Forests, etc.
Data-oriented personality.
Data science certification should add an advantage.
BENEFITS:

TRIARQ Health is the people’s first company work within a great company culture.
Individuals can develop from technical to communication to leadership. Proactively build your career - with help from your manager, set the path you would like to take - and then do it!

Gain incredible experience working with numerous technologies.

Job Type: Full-time

Interested candidates can call at Mob Number: 9420869028.

Website: www.TRIARQhealth.com

Job Types: Full-time, Contract

Education:
Bachelor's (Required)
Work Remotely:
Temporarily due to COVID-19",4.6,"TRIARQ Health
4.6",Nashik,"Troy, MI",51 to 200 employees,2005,Company - Private,Healthcare Services & Hospitals,Healthcare,₹500 million to ₹1 billion (INR),-1
Data Analyst,-1,"About The Role
As a Product Data Analyst at PeopleGrove, you will have a unique opportunity to collaborate with a dynamic product, design, and engineering team to shape PeopleGrove’s product strategy. You’ll create insights that drive our product roadmap — identifying product opportunities, recommending changes, understanding the results of experiments, and helping define metrics for the business. Using your skill for synthesizing and visualizing data, you’ll help ensure we’re making the best investments for our users in the best career and alumni mentorship and coaching platform in the market.

For this role, we’re looking for an experienced data analyst who will help develop the strategy and evaluate/improve product initiatives. Reporting to our VP of Product you will help us define and track KPIs, support strategic initiatives, design experiments, and evaluate A/B tests. You’ll communicate data insights and recommendations to marketing, product and leadership teams and help define and build a strong data culture.

What You’ll Do
Develop deep analytical insights to inform and influence product roadmaps and business decisions and help improve the consumer experience.
Work cross-functionally to build and communicate key insights, identify product opportunities and offer recommendations to leadership
Implement metrics, dashboards, reports, and deep-dive analysis to measure how well we are meeting the needs of our partner teams and inform where we should invest to improve mobile software development.
Work closely with product and engineering to author and develop core data sets that empower analyses.
Help build a data-driven product culture by driving awareness and understanding of metrics with dashboards and reports
Contribute to efforts to build self-service analytics tools and dashboards for our partner teams.
Partner with product to design A/B experiments to guide product direction with iterative innovation and measurement
Dive deep into the data to understand how user behaviors change with the evolution of our product

Who You Are
3+ years of professional experience as a business or data analyst
Demonstrated ability to collaborate with product managers to define metrics for product areas, understand the right questions to ask in ambiguous situations on complex problems
Ability to start, own, and drive projects to completion with minimal guidance in a complex, constantly changing environment
Experience designing and assessing impact of A/B experiments
High level of comfort creating dashboards in Mixpanel, Periscope, or comparable software and create dashboards, reports, and deep-dive analysis
Ability to independently break down datasets and synthesize inputs from multiple sources
Ability to partner with product managers to analyze and make decisions based on data from our systems, logs, surveys, and more.
Can craft a compelling story from data and present data-driven recommendations
Excellent communication skills and ability to explain learnings to both technical and non-technical partners
Excitement about collaborating with a diverse, global team

Bonus Experience
Familiarity with a programming language, such as Python or R
Interest or experience in machine learning techniques (such as clustering, decision tree, and segmentation)
Experience using, and building, ETL pipelines to process large amounts of data",4.8,"PeopleGrove
4.8",Mumbai,"San Francisco, CA",1 to 50 employees,-1,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"Role and responsibilities *
DATA RESEARCH & ANALYSIS.
Collecting and interpreting data.
Analyzing results using statistical techniques.
Reporting the results back to the relevant members of the business.
Identifying patterns and trends in data sets.
Working alongside teams within the business or the management team to establish business needs.
Defining new data collection and analysis processes.
Qualifications and education requirements

BACHELOR’S BSC IT ,

ADVANCE EXCEL

EXPERIENCE : 1 year (preferred)

Expected Start Date: 12/8/2020

Job Types: Full-time, Contract

Pay: ₹10,000.00 - ₹15,000.00 per month

Experience:
Data Analysis: 1 year (Preferred)
Education:
Bachelor's (Required)
Work Remotely:
Temporarily due to COVID-19",-1,Priminox Overseas,Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Data Analyst,-1,"Data Analyst With Good English And Typing Skill
Job Type: Full-time
Pay: ₹10,000.00 - ₹11,000.00 per month
Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Diploma (Preferred)
Industry:
IT Operations & Helpdesk
Work Remotely:
No",-1,E DATA TRANSC,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Scientist/ Machine Learning Consultant ( UK,-1,"Job Location:
London - United Kingdom

Salary Per Annum:
40,000 + Bonus

UK - Work permit / visa will be sponsored by the company

Qualification:
B.Tech / M.Tech / MCA / M.Sc or equivalent

Experience Needed:
Over all: 5+ Years IT experience
Solid 1+ Year experience in Machine learning development projects

Job Skills & Responsibilities:
Experience in machine learning
Exposure to machine learning models and corresponding statistics like K-means, Bayesian, Clustering
Strong technical skills with Python along with NumPy, Pandas, Scikit-Learn
Machine learning experience -> predictive and prescriptive modelling
Data wrangling and data cleansing experience
Strong analytical skills
Any experience with Node.JS would be beneficial.
statistical/mathematical background
Business Verticals:
Financial / Banking
Telecom
Travel
Healthcare",-1,Imurgence,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
MNA Data Engineer 2,-1,"Nokia is a global leader in the technologies that connect people and things. With state-of-the-art software, hardware and services for any type of network, Nokia is uniquely positioned to help communication service providers, governments, and large enterprises deliver on the promise of 5G, the Cloud and the Internet of Things.
Serving customers in over 100 countries, our research scientists and engineers continue to invent and accelerate new technologies that will increasingly transform the way people and things communicate and connect.
Nokia is an equal opportunity employer that is committed to diversity and inclusion.
At Nokia, employment decisions are made regardless of race, color, national or ethnic origin, religion, gender, sexual orientation, gender identity or expression, age, marital status, disability, protected veteran status or other characteristics protected by law.
Position description:
The Advanced Analytics Practice team is looking for a proactive key member who will have a key role in its development and maintenance. It is a unique opportunity to become part of a world-class team that is developing and managing the next generation, global analytics-as-a-service practice for Nokia. This is a hands-on technical role using state-of-art Microsoft Azure Platform in a dynamic agile environment, working directly with developers, architects, test engineers, product management and internal customers.
Responsibilities:
Solution maintenance, enhancements, troubleshooting, problem investigation, solution defects fix up
Modeling in SQL DB/DW and Azure Analysis Service
Handling application service requests
Responsibility for single assignments in task level of user stories in Microsoft DevOps tool (VSTS)
Solution source coding components, such as Azure Data factory, SQL DB/DW, web app service
Development of PowerBI reports
Unit testing for each source function and function test for each user story
Review the source code quality from peer developers
Design, implement and integrate features based on the platform and solution architecture
Assure application backups and recovery
Assure solution knowledge management
DevOps housekeeping
Implement telemetry and monitoring on Azure platform and solutions

Required skills:
Bachelor’s degree in computer science, software/computer engineer or related relevant field
5+ years of combined experience in Microsoft Azure cloud platform services, data and analytics solutions
Proeficient in ETL coding for Azure Data Factory
Proeficient in SQL database programming
Proeficient in complex data modelling on Azure Analysis Services
Experience in PowerBI reports development
Azure security knowledge
Experience in Azure DevOps processes
Experience in software design/development and/or operations
Experience in delivering applications in Azure with source control systems (GIT)
Experience in deploying application and services to Azure PaaS and IaaS
Excellent communication skills in written and verbal English

Desired skills:
Certifications in Microsoft Azure and Power BI is a plus
Ability to work in and with cross-functional distributed teams, including working across multiple time zones and providing remote support
Be an independent self-learner with the “let’s get this done” approach
Experience in implementing telemetry and monitoring in Azure environments
Experience in TDD/Agile development environment and unit testing tools
Required Qualifications: (Education, Technical Skills/Knowledge)
Above 5 years of hands-on experience in software design/development and/or operations
Background in Development, Systems Architecture, and/or Operations.
Experience delivering applications in Azure.
Experience with configuration management tools
Experience with source control systems such as TFS and GIT.
Work experience deploying web and application services to Azure PaaS and IaaS.
Experience working with Microsoft SQL Server
Working knowledge of DNS, Monitoring, SSL Certificates, File Servers, Security, Performance, High Availability, Redundancy, and Disaster Recovery.
Working knowledge of Microsoft OMS
Experience in Automated Deployments with Continuous Integration workflows.
Excellent written and oral communication skills.
Excellent interpersonal skills.
Highly self-motivated and directed.
Proven analytical, evaluative, and problem-solving abilities.
Ability to motivate and inspire team members
Adaptable to changing environment
Ability to effectively prioritize and execute tasks in a fast-paced environment
Desired Qualifications: (Education, Technical Skills/Knowledge)
Experience on Python, PowerShell, Javascript is a plus
Experience with business intelligence application is a plus
Azure, Scrum certifications considered as a plus
Willing to learn new technology and open mind for sharing is a plus
Bachelor in computer science, Master Degree considered as a plus

Apply now.",4.2,"Nokia
4.2",Bengaluru,"Nokia, Finland",10000+ employees,1865,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Ericsson-Worldwide, Huawei Technologies, Microsoft"
Data Engineer,-1,"Title: Data Engineer

Skills: Data Warehouse, Big Data, Power BI, Hadoop, ETL, Machine Learning, Python, cloud, Data Governance, Mongo DB

Location: DLF Cyber Hub, Gurugram

Company Summary:
We’re the global leader in workspace scheduling technology. We make it easy to find and book space to meet up and work together. We provide workspace scheduling software to over 1,000 of the world’s biggest brands, integrating meeting room and workspace reservation solutions that help remove friction in the workplace and free businesses and their people up to get the most out of their working day.

Responsibilities:
Building the right infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Building data pipelines.
Data warehousing, and building ETL pipelines.
Understand the Business context, objectives and requirements.
Involvement in Requirement Analysis, Design, Development, Unit Testing, System Integration Testing and other facets of testing for example but not limited to Performance Testing.
Convert functional specifications from business requirements into programming instructions for technical development of analytics data pipelines.
Develop industrialized solutions leveraging Agile and DevOps methodologies.
Monitor operating efficiency and optimize solution execution performance.
Work with stakeholders including the product owner, data and design teams to assist with data-related technical issues and support their data infrastructure needs.
Create and maintain optimal data pipeline architecture.
Solve Big Data and Distributed Data Streaming problems using latest technologies.
Perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Manipulate, process and extract value from large disconnected datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
About You:
Experience with Power BI or other BI tools such as Qlikview, Tableau, Spotfire, Cognos is required.
Hadoop, Spark, Kafka, Scala, Python, DB2, MySQL, Oracle, no-SQL databases like MongoDB, Elastic Search.
Preferred Technical and Professional Expertise.
Enterprise data lakes, data analytics, reporting, in-memory data handling, enterprise integration tools, etc.
Experience with data warehousing and building ETL pipelines.
Good understanding of industry best practices for data governance and security.
Possess strong knowledge in designing database models to store structured & unstructured data efficiently and in creating effective data tools for analytics experts.
Comfortable in building effective analytical tools that utilize the data pipeline to provide actionable insights into data synchronization, reporting, operational efficiency and related areas.
Expert in setting up effective pipelines to capture data from multiple sources into the enterprise centric storage.
Good communication skills.
Benefits:
Health insurance fully paid – Spouse, children and Parents
Accident insurance fully paid
Transport allowance
Gratuity fully paid
25 days holiday
7 paid sick days
10 public holidays
Company Information:
Follow us on Twitter | LinkedIn | YouTube
Condeco are proud to be an equal opportunity employer. We are committed to treating all individuals in a fair and equal manner by creating an inclusive and open environment for all employees",3.8,"Condeco
3.8",Gurgaon,"London, United Kingdom",201 to 500 employees,2005,Company - Private,Computer Hardware & Software,Information Technology,₹1 to ₹5 billion (INR),"Teem, Asure Software"
Market Research Data Analyst,-1,"KEY RESPONSIBILITIES:
Highly refined analytic and communication skills
The ability to manage multiple tasks simultaneously
Explaining the results to research executives
Helping research executives present the findings in a way that the client can understand and use.

CANDIDATE REQUIREMENTS:
0 – 2 years of relevant work experience.
Please email us at careers@ro-bas.com",3.0,"Robas Research
3.0",Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Who we are:

We are reinventing personal communication for the digital era.

TouchNote is a creative platform that lets people send custom-made cards, straight from their phone to those they love anywhere in the world. Our easy to use app has helped people nurture their most meaningful relationships over 15 million times and was awarded the Good Web Guide’s App of the Year 2018.

We are a team of passionate and creative individuals trying to make a difference. We’re proud to offer a highly collaborative, solution-focused environment that celebrates diversity and has been listed in Deloitte’s Technology Fast 50 and The Financial Times Future 100 UK.

The Role:

We are looking for a savvy Data Engineer to join our growing data and analytics team.

Our ideal candidate is an experienced data pipeline builder and data wrangler who enjoys both optimising existing data systems and building new capabilities from the ground up. They will be working alongside our Data Lead and Data Analysts to formalise and expand our data collection and delivery architecture - ensuring information is accurate, timely, consistent, meaningful, and enabling our teams to build analytics simply on top of robust fundamentals.

They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimising or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

What you'll do:
Create, maintain and monitor an efficient data pipeline architecture, including working with scheduled jobs, replication, monitoring and partitioning.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Handle changes in application logic and develop supporting data transformations.
Ensure data integrity and consistency throughout, and enable teams to easily verify this in end analysis.
Own database and data flow documentation.
Develop and maintain a large event stream to enable real-time customer analytics.
Work with a wide variety of business stakeholders to assist with data-related technical issues and support their data infrastructure needs.
Create data tools alongside Data Analysts and Data Scientists in a collaborative fashion to support business outcomes
Work alongside the rest of the Data team to enable best use of our Looker instance, ideally through writing and optimising LookML.
Requirements
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), as well as working familiarity with a variety of databases (PostgreSQL and MySQL preferably).
Database administration and data performance management, including the details of indices, normalisation, query optimisation and resultant execution plans.
Building and optimising ‘big data’ data pipelines, architectures and data sets.
Root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores
The successful candidate will have 3+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Informatics, Information Systems or another quantitative field.
Must-haves:
Cloud Based ETL Tools: Stitch, FiveTran, Matillion.
Relational SQL and NoSQL databases: MySQL, Postgres, Redshift and DynamoDB
Data pipeline and workflow management tools: DBT, Dataform, AWS Glue, AWS Data pipeline, Singer.io, Luigi, Airflow, etc.
Data visualisation tools: Looker (including LookML experience)
AWS cloud services: EC2, EMR, RDS, Redshift
Object-oriented/object function scripting languages: Go, PHP, Python, Scala, etc.
Nice to haves:
Kafka, Hadoop and Spark
R and Jupyter Notebooks
Benefits
Company laptop (Mac or PC - you choose!)
Choice of wellbeing benefits which include Private Medical Insurance and/or a gym membership
20 days holiday plus bank holidays
Friday drinks
Team lunches
Team socials every month
Free TouchNote credits to use our product!
Reporting to Data Lead

Salary competitive and dependent on experience

This is a full-time position (Monday - Friday: 11AM - 8PM)",5.0,"TouchNote
5.0",Hyderabad,"London, United Kingdom",1 to 50 employees,2008,Company - Private,Internet,Information Technology,₹1 to ₹5 billion (INR),"Minted, Moonpig, Shutterfly"
Senior Data Engineer,-1,"About the Group:

The mission of the Juniper Digital Experience and Automation (DEA) team (part of the Juniper Global Services (GS) Organization) is to delight external and internal customers by delivering efficient, innovative solutions that are proactive, easy to use and self-service focused.

DEA is at the heart of the Global Services digital strategy. We buy, build and integrate innovative technologies that enables the Global Services business with a focus on business agility and efficiency. Through partnerships with business subject matter experts we identify need, ideate, determine idea value (ROI) and ultimately realize new capabilities. Automation, Data Science / Machine Learning and Advanced Analytics are critical components of that innovation work.

About the position:

We are looking for a savvy Data Engineer to join our growing DEA Team. The hire will be responsible for building, expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our citizen data scientists, data analysts and other DEA team members on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Responsibilities for Data Engineer
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Snowflake and AWS ‘big data’ technologies.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Strong communication skills
Required Qualifications:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Strong communication skills with a growth and learning mindset
Comfort working in a dynamic, research-oriented group with several ongoing concurrent projects
Familiarity with git repo and willing to provide DevOps support for a brief period
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with at least 5+ years of experience in a Data Engineer role. The ideal candidate should have experience using the following software/tools:
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Snowflake, Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Preferred Qualifications
MS in Computer Science, Electrical Engineering or other Engineering majors with 7+ years of total experience.
Knowledge and experiences using machine learning frameworks such as NumPy, ScikitLearn, MLlib, Tensorflow
Knowledge and experiences working with Kubernetes
Juniper Networks is an Equal Opportunity/Affirmative Action Employer.

ABOUT JUNIPER NETWORKS

Juniper Networks is in the business of network innovation. From devices to data centers, from consumers to cloud providers, Juniper Networks delivers the software, silicon and systems that transform the experience and economics of networking. Our products and technology run the world’s largest and most demanding networks today, enabling service providers, enterprises, and governments to create value and accelerate business success. Everyday our 9,000+ colleagues come together across 46 countries to realize our company vision – Connect Everything, Empower Everyone. We are innovating in ways that empower our customers, our partners and ultimately, everyone, in a connected world. These customers include the top 130 global service providers, 96 of the Fortune 100 and hundreds of public sector organizations.

WHERE WILL YOU DO YOUR BEST WORK?

Wherever you are in the world, whether it’s downtown Sunnyvale or London, Westford or Bangalore, Juniper is a place that was founded on disruptive thinking – where colleague innovation is not only valued, but expected. We believe that the great task of delivering a new network for the next decade is delivered through the creativity and commitment of our people. The Juniper Way is the commitment to all our colleagues that the culture and company inspire their best work—their life’s work. At Juniper we believe this is more than a job - it is an opportunity to help change the world...",3.8,"Juniper Networks
3.8",Bengaluru,"Sunnyvale, CA",5001 to 10000 employees,1996,Company - Public,Telecommunications Services,Telecommunications,₹100 to ₹500 billion (INR),-1
Data Analyst,-1,"Job ID: 13409

Job location(s):
Oragadam, IN

Job Description

Reporting analyst who has experience in managing data, reporting & analytics, forecasting, budgeting, inventory etc with an eye for detail and providing value add analytics in reporting. Also dealing with vendor/customer delivery performance databases. You will be part of the Global Service Center organization and will report to Operations Manager Reporting & Analysis and support global organization across time zones.

We offer you a platform to utilize your strong analytical abilities, data interpretation skills in preparing performance management reports, dashboards and provide insightful information to the stake holders to take right decisions

Job Responsibilities
Reporting & Analytics across functions and Business units
Standardizing and automating reports to provide meaningful insights
Maintaining and updating Access database
Dealing with Material Master data in terms of updating, validation and maintenance of data
Budgeting, Forecasting reporting with Value add analytics
Handling orders and Vendor/ Customer delivery performance internally & externally and reporting accurately
Driving continuous improvement across all processes
Updating, reviewing & maintaining SOPs on a regular basis
Background & Skills
BCom/MCom/MBA, any degree related to Finance
5 – 7 years of experience
Working experience in SAP is MUST
Excellent in handling Access Database
Excellent in Excel, Power BI and Presentation
Good Communications skills
Stakeholder Management in a multinational company
Good Team player
Eye for Details and Passionate towards work with multi tasking
Danfoss – Engineering Tomorrow

At Danfoss, we are engineering solutions that allow the world to use resources in smarter ways – driving the sustainable transformation of tomorrow. No transformation has ever been started without a group of passionate, dedicated and empowered people. We believe that innovation and great results are driven by the right mix of people with diverse backgrounds, personalities, skills, and perspectives, reflecting the world in which we do business. To make sure the mix of people works, we strive to create an inclusive work environment where people of all backgrounds are treated equally, respected, and valued for who they are. It is a strong priority within Danfoss to improve the health, working environment and safety of our employees.

Following our founder’s mindset ‘action speaks louder than words’, we set ourselves ambitious targets to protect the environment by embarking on a plan to become CO2 neutral latest by 2030.",3.7,"Danfoss
3.7",Tamil Nadu,"Nordborg, Denmark",10000+ employees,1933,Company - Private,Industrial Manufacturing,Manufacturing,₹500+ billion (INR),-1
Tracer Analytics - Data Scientist,-1,"Job Description

Job Title: Data Scientist

Location: Mumbai

Experiance Range- 8 - 14 Years

Job Description:

TCS has proudly created an exceptional leadership community with leaders like you to drive change, foster innovation and retain TCS as the top player in the business market.

As a Data scientist, you must have ability to translate business problem to a statistical problem and statistical solution to business solutions.

What we are looking for:

Must have:

1. Should have hands on experiance with machine learning models.

2. Prior experiance in predictive model building using python.

3. must have minimum 2-3 years' experiance in python/pyspark(Mandatory) / scala. Excellent knowledge of python (must) and other statistical tools like pyspark/scala.

4. Masters statistics/mathematics/computer science or another quantitative field.

5. Minimum 1-2 years' experiance in documentation/dash boarding skills using pyhton flask (knitting in both PDF and HTML), Rshiny etc.

6. Minimum 1-2 years' experiance in documentation skills using Github based data science solution development.

7. Minimum 1-2 years' experiance in exploratory data analysis with time series and non time series data.

8. Minimum 1-2 years' experiance in ARIMA/ARMA, trend analysis, auto correction, cross correlation, stationary.

9. Minimum 1-2 years' experiance in distributed agile.

Good to Have:

Responsibilties:

1.Ability to perform statistical modelling (predicctive, regression, hypotheses testing, multivariate analysis, t, time series, cluster, forecasting, ARIMA) using Python/Pyspark.

2. In-Depth knowledgeof statistics and machine learning concepts and should be able to apply them to business problems.

3.Experiance in collaborating with technology team and support the development of analytical models with the effective use of data and anallytic techniques.

4.Data extraction from EDW/Big Data platform, dataset preparation (Creation of base data, aggregation, transformation), performaing EDA.

5. Ability to create good visualization with output generated from the model.

6. Write complex SQL, queries to perform data extraction from various data sources.

7. Ability to build use cases for the business and present them to client as well as Project IT stakeholders.

8.Self-motivated with the ability to take decision and work independently.

9.Engage with internal/external stakeholders in collaborative data science project management.

Minimum Qualification:

1. 15 years of minimum education;

2. Minimum percentile of 50% in 10th, 12th, UG & PG (if applicable)

Job Function

TECHNOLOGY

Role

Database Administrator

Job Id

159147

Desired Skills

Artificial Intelligence | BigData | Machine Learning | Python

Desired Candidate Profile

Qualifications :
BACHELOR OF TECHNOLOGY",3.8,"Tata Consultancy Services
3.8",Mumbai,"Mumbai, India",10000+ employees,1968,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Accenture, IBM, Infosys"
Lead Data Scientist,-1,"Data Scientist role @ ThoughtWorks India

Bangalore, India

We are passionate technologists who believe in the power of software and technology as tools for social change. The 1000+ people in ThoughtWorks India are as diverse in personality as we are in our backgrounds, culture, and expertise.

If you're someone who's passionate about technology, by joining ThoughtWorks, you become a part of a community. People join because they get to talk to the people who wrote the books that influenced them, work with tools they wish to use, and collaborate on projects that propel change in the real world.

ThoughtWorks India is looking for talented Data scientists passionate about building large scale Machine Learning Solutions to help manage the ever-growing information needs of our clients.

As a Data Scientist Practitioner, here's what you can do at ThoughtWorks:

Understand business challenges and goals of a client to formulate the approach for data analysis and model creation that will support their business decision making
Create advanced analytics models using statistical and machine learning methods
Work with software developers and solutions designers to deliver analytics-driven solutions
Interact with clients in a variety of domains, who have a spectrum of challenging problems
Represent ThoughtWorks and Data community in various online and offline forums (events, conferences)
Work in a dynamic, collaborative, transparent, non-hierarchical, and ego-free culture where your talent is valued over a role title
Develop your career outside of the confinements of a traditional career path by focusing on what you're passionate about rather than a predetermined one-size-fits-all plan

Here is what you will bring:
PhD/MS/BS or equivalent in Applied mathematics, statistics, physics, computer science or operations research background.
At least 2-3 years commercial experience with PhD or at least 8+ years of experience with MS/BS degree
Depth of knowledge in advanced analytics methods such as parametric, non-parametric and graphical models
Breadth of knowledge across statistical methods and machine learning algorithms
Programming skills in languages like R and Python is a MUST
Familiarity with large scale data processing tools like Hadoop and Spark
Strong algorithmic problem-solving skills
Ability to design effective experiments in business and social environments
Understand how to harvest complex data from a variety of sources
Consultative skills and the ability to communicate complicated technical and analytical information to non technical audiences
Other desirable skills include: relational databases, NoSQL and visualisation techniques, knowledge and experience in any software technologies along with research experience

If you relish the idea of being part of ThoughtWorks' Data Practice that extends beyond the work we do for our customers, you may find ThoughtWorks is the right place for you. If you share our passion for technology and want to help change the world with software, we want to hear from you!

#LI- RP1",2.8,"Referrals Only
2.8",Bengaluru,"Carlsbad, CA",51 to 200 employees,-1,Company - Private,Advertising & Marketing,Business Services,₹500 million to ₹1 billion (INR),-1
Data Engineer,-1,"In this role, the individual will be part of the engineering team in Global Product Data Services Organization and will be responsible for.
Work as part of a team to design and develop code, scripts and data rails that integrate and transform data (structure / unstructured) from across multiple sources.
Design and build automated test frameworks to enable validation of the solution for consistency, accuracy and repeatability @scale and TTM.
Participate in the analysis, architecture and design of data Lake solutions.
Collaborate with management team to help define the engineering rigor and process and motivated to adopt it.
Ability to prototype ideas and demonstrate pros and cons and make recommendations using demos and slides.
Ability to use data to draw insights or drive decisions. Be able to explain complex technical concepts to management, product managers and other engineers.
Motivated and interested in delivering results, especially in the area of writing high-performance, reliable and maintainable code.
Ability to adapt to new development environments, changing business requirements and learning new systems highly desired.
Good team player, able to effectively work across multiple teams onsolutions that have complex dependencies and requirements in a fast-paced environment
Excellent verbal and written communication skills.
Skills and Experience
A Master or bachelors degree in computer science or equivalent with 10+ years of data engineering experience
Experience in EDW and ETL Development using Teradata BTEQ is Mandatory
Understanding and experience with building large scale enterprise applications using Teradata and Hadoop
Knowledge and experience working with various data sources like web services (rest, soap), unstructured data files, flat files, message queues, xml-based events, and databases.
Ability to deal with both structured and unstructured data sets & hence uses different methods to data architecture and applications in building data pipeline.
Experience in EDW and ETL Development using Teradata BTEQ is Mandatory.
Working knowledge on any ETL tool (i.e. Informatica/ Ab Initio) is a plus.
Expertise in database programming and performance tuning techniques.
Excellent debugging skills with a solid understanding of data and testing to capture data quality gaps/issues.
Strong analytical and problem-solving skills including the ability to define problems, collect data, establish facts, and draw valid conclusions.
Familiar with data movement techniques and best practices to handle large volumes of data.
Working experience in an Agile methodology is highly preferred.
Experience with Tableau or other visualization tools is a plus.
Knowledge of Scheduling Tools is a plus
Intermediate level knowledge on following technologies, with expertise on few of them:
Data Transformation tools like informatica
Strong Database fundamentals (Teradata)
Basic level knowledge on following business domains is a plus:
Payments and banking
eCommerce",3.7,"PayPal
3.7",Chennai,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Data Analyst,-1,"Job Role - Conducting full life-cycle analysis to include requirements, activities and design. Data analysts will develop analysis and reporting capabilities, also monitor performance and quality control plans to identify improvements.

Responsibilities
Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.
Acquire data from primary or secondary data sources and maintain databases/data systems.
Identify, analyze, and interpret trends or patterns in complex data sets.
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems.
Work with management to prioritize business and information needs.
Locate and define new process improvement opportunities.
*only male candidates preferred.

Job Type: Full-time

Experience:
total work: 4 years (Preferred)
Education:
Bachelor's (Preferred)",4.6,"Chandigarh University
4.6",Kharar,"Mohali, India",501 to 1000 employees,2012,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Data Analyst,-1,"What it’s like to work with the world’s fastest-growing Healthcare Technology Company

At Innovaccer, we go beyond the normal. We believe in doing things differently. So, don’t expect - old-school cubicles, slow pace, and anything remotely dull. What you can expect is plenty of support and guidance from your colleagues, freedom to take risks, and opportunities to learn from each other. The healthcare industry is witnessing a transformational shift and we are committed to helping healthcare work as one. Taking on new challenges head-on and building something that can create a huge impact is a part of our culture.
We love organized chaos. So, if you are looking for a typical 9 to 5 job where you are told what to do, this may not be for you. When you work with Innovaccer, you are your own boss.


Your Role


We at Innovaccer are looking for Data Analyst to build the most amazing product experience. You’ll get to work with other engineers to build delightful feature experience to understand and solve our customer’s pain points


A Day in the Life


● To work end-to-end on integrating new data sources coming in from different projects
into the Datashop platform.
● Data Acquisition: Analyse data from varied sources like databases, CSVs,
XMLs and other formats and write SQL commands/scripts/code to bring it in
● Data Management: Handle incoming data, validate it to ensure usability, map
it to platform specifications and perform verification on the same
● Platform ingestion: Get trained on and then build pipelines to import incoming
data onto the Data Activation Platform
● Issue analysis and resolution: Own the process end-to-end and identify issues,
resolve the same


What You Need


● 1-5 years of experience with a start-up mentality and high willingness to learn
● SQL and good knowledge of databases
● MS Excel – advanced level
● An understanding of XML and XSL/HTML
● An understanding of SFTP, FTPS and other file transfer protocols
● Strong analytical ability and problem solving skill
● Bachelor's degree in Computer Science/Software Engineering.

What We Offer


● Industry-focused Certifications: We want you to be a subject matter expert in what you do. So, whether it’s our product or our domain, you will dive straight in and be certified by the best in the world.
● Quarterly Rewards and Recognition Programs: We foster learning and encourage people to take moonshots. When you achieve your goals, we recognize and reward your hard work.
● Health Benefits: We cover health insurance for you and your loved ones.
● Sabbatical Policy: We encourage people to take time off and rejuvenate, upskill and pursue their interests so that they can generate new ideas for innovating at Innovaccer.
● Pet-friendly office and open floor plan. No mundane cubicles.


Apply Here


Job Title

Data Analyst


Department

Customer Engineering


Employment Type

Fixed Term (3 Months)


Location

Noida",3.6,"InnovAccer
3.6",Noida,"San Francisco, CA",501 to 1000 employees,2014,Company - Private,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),Health Catalyst
Data Analyst,-1,"NIBMG Recruitment 2020 - Data Analyst Vacancies - 40,000 Salary - Apply NowNIBMG Recruitment 2020-21: Employees State Insurance Corporation (NIBMG) announced Job notification to hire candidates who completed B.Tech/B.E,M.Sc,M.E/M.Tech for the position of Data Analyst. To Apply for the job posting from NIBMG, please click on the Apply Now button below.Company Name: NIBMG
Post Name: Data Analyst
No of Posts: 2
Salary: 40,000 (Per Month )
Experience: 2 - 5 years
Education: B.Tech/B.E,M.Sc,M.E/M.Tech
Location: Nadia
Last Date: 11-08-2020

Selection Procedure:
Only the shortlisted candidates will be called for online Interview. The decision of NIBMG in all matters relating to eligibility, acceptance or rejection of application, mode of selection, and conduct of interviews will be final and binding on the candidates. In exceptionally meritorious cases, the eligibility requirements may be relaxed by competent authorities relaxed by the competent authority.

How To Apply:
These positions are contractual and appointments will be initially given as per tenure of the project, extendable depending upon performance and requirements of the project. Please apply online at https://apply.nibmg.ac.in (no other form of application will be accepted). The last date of application is 11th August, 2020 upto 5PM. Please visit our website www.nibmg.ac.in for further information.",4.5,"NIBMG
4.5",West Bengal,"Calcutta, India",51 to 200 employees,2010,Government,Government Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer,-1,"Position Name - Data Engineers

Job Description:
Mandatory Skills - Data Structure, Data Quality Management, Data Governance, Stakeholder Management, Enterprise Information Management,
At least 5 years of work experience with databases, SQL coding

Experienced with BI and data visualization tools (e.g., Looker, Tableau, etc.) is a plus;
Knowledge of methodologies Quality Assurance, as well as some tools and concepts (e.g., Quality inspection, auditing), are also a plus;
Bachelor's degree in Computer Science, Mathematics, related quantitative field, or equivalent practical experience.
If interested, please send your profile to ambree.shah@calsoftinc.com / careers@calsoftinc.com
00-14.00 Years
Masters in Technology (M.Tech/M.E/M.Sc), Bachelor Of Computer Application (B.C.A), Master in Computer Application (M.C.A), Bachelor Of Technology (B.Tech/B.E)",3.0,"Calsoft Private Limited
3.0",Pune,"Pune, India",501 to 1000 employees,1998,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1
Data Analyst,-1,"Vous êtes unique, comme le sont votre parcours, votre expérience et votre façon de voir les choses. Ici, on vous encourage et on vous motive donner le meilleur de vous-même, et on vous donne les moyens de le faire. Vous travaillerez avec des collègues dynamiques experts dans leur domaine qui sont impatients de partager leurs connaissances avec vous. Vous aurez des gestionnaires inspirants qui vous aideront développer votre potentiel et atteindre de nouveaux sommets. Chaque jour, vous aurez de nouvelles occasions de rendre la vie de nos Clients plus radieuse ils sont au cœur de tout ce que nous faisons. Découvrez comment vous pouvez faire une différence dans la vie des gens, des familles, des collectivités ici et partout dans le monde.

Description de poste:

Join a team that is transforming business intelligence at Sun Life Financial (SLF) Canada. Sun Lifes Client Solutions is aggressively enhancing its member insights capability with new tools, and most importantly, new talent. As part of Client Solutions Analytics, you will work closely with our business partners to enable digital engagement, understand our customer needs in new ways, and ultimately enable a leading customer experience. As Analyst Data Analytics you will be leveraging our Big Data capabilities to enable these objectives through performance analytics, reporting and digital capability enablement. In joining Client Solutions you will be part of one of the fastest growing areas of our business, representing the future of our business and our industry.

Given this mandate, the role requires an experienced analyst (4-6 years) with diverse analytical and business-focused skills. The candidates must have relevant experience in the following areas:
Business/market analysis i.e. marketing campaign performance metrics, market analysis
Business communication i.e. effective storytelling (written and verbal)
Marketing dashboards and related tools - i.e developing and operationalizing dashboards with leading edge eporting tools (Tableau, SAS)
Main Accountabilities:
Work directly with business audiences to structure analytical problems and approaches, identifying the right questions to ask and structuring the appropriate analytical approaches in a way that business audiences understand
Support cross functional Scrum teams through campaign design, insights data mining and reporting
Run and manage weekly and monthly reports and underlying databases
Conduct analyses that identify/assess business opportunities and address key business challenges.
Formulate and execute queries, with reports that clearly answer business questions related to cross-selling, up-selling, lifestage purchase patterns, etc.
Design, develop and implement performance metrics to support campaign measurement, analysis, and reporting and measure effectiveness of predictive modeling efforts
Enable leaders to make timely data-driven product, market-development, and distribution decisions.
Comply fully with all privacy, confidentiality, do not contact, SLF Code of Business Conduct, data security, and other requirements related to customer data.
Maintain current knowledge on quantitative data mining tools and techniques.
Catégorie d'emploi:

Advanced Analytics

Fin de l'affichage:

26/08/2020",3.7,"Sun Life Financial
3.7",Gurgaon,"Makati, Philippines",201 to 500 employees,-1,Company - Private,Insurance Operators,Insurance,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Data Engineer
from 4 to 9 year(s) of Experience
Hyderabad
Apply

Job Description
Looking for Data Engineer
4+ years of experience in working with large and varieties of data.

Strong experience in Relational /NoSQL/Graph Data bases.

Experience with big data tools: Hadoop, HDFS, Spark, Hive, Sqoop, Kafka, Yarn, Zookeeper etc.

Experience in Scala, Python, pySpark, Java, Rest API, Microservices etc.

Experience in data engineering, data pipelines in any of Cloudera, Azure, AWS, and Google Cloud platforms.

Experience in Structured and Unstructured Data sets.

Experience in Ticketing tools like Zendesk, Service Now, JIRA.

Masters/bachelor’s degree/diploma in computer science or equivalent.

Required Candidate profile

Experience: 4-9 Years
Skill sets: NoSQL, Big Data, Scala, Python, pySpark, Java, Rest API, Microservices.
Location: Hyderabad
Notice: Immediate - 15 Days

Salary: Not Disclosed by Recruiter

Industry:Internet / Ecommerce

Functional Area:IT Software - Application Programming, Maintenance

Role Category:Programming & Design

Role:Software Developer
Keyskills
JavaNoSQLScalaBig DataAPIpySparkMicroservicesPython
Desired Candidate Profile
Please refer to the Job description above
Company Profile
Harjai Computers Pvt Ltd
Harjai Computers Pvt. Ltd. is the preferred partner of top IT and Multinational companies all over INDIA and around the world for providing the best talent via Staff Augmentation (Temp Staffing / Subcontracting). Over the years, we've assisted our numerous clients scale new heights by deploying top professionals.",4.3,"Harjai Computers
4.3",Hyderabad,"Mumbai, India",201 to 500 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"Technical functions:
Shouldhave experience in an engineering industry
Experienceof 2-3 years of analysing data & identifying trends & reportingsuggestions.
Candidatewith readiness to learn in engineering / manufacturing company.
Createand implement data archive systems.
Dataanalysts must prepare and present reports to various departments andexecutives.
Dataanalysts often work with various departments to establish statistical methodologyand reporting standards
Qualifications:
Must : Should be graduate in statistics with minimum firstclass;
Desired :
Age : 25-30 years",3.5,"Engineering manufacturing company
3.5",Vadodara,"East Hartford, CT",51 to 200 employees,1946,Company - Private,Transportation Equipment Manufacturing,Manufacturing,Unknown / Non-Applicable,-1
Senior / Lead Data Engineer,-1,"Company Description

Innova Solutions is a global information technology company combining a global reach with a local touch. Headquartered in Santa Clara, California, Innova employs more than 1,800 technology professionals worldwide, with field offices in New York, Chennai, Bangalore, Hyderabad, Pune, and Taipei. From Cloud Transformation to Data Services to Managed IT Operations, Innova provides a broad array of proven, tested, cost effective and enterprise scale technologies and services that leverage latest technology and delivery models to deliver high value in the cloud, in the data center, and across complex inter connected environments.

Global Information Technology Managed Services Provider • Privately held , $77MN Annual Revenue run rate with 1800 Employee Base • Focused Technology Practices – Development /Engineering Services, Cloud Services, Migration Services, Data Management and Mobility Management Our Value to an organization is about Embracing, Advancing and Accelerating • Demonstrating ongoing Business Value for IT Services • Cloud Adoption (without ""single source"" lock in) • Accelerating the Business with Analytic and Big Data Management Services

Job Description

Summary:

Come work as a Senior - Data Engineer at growing company that offers great benefits with opportunities to advance and learn alongside accomplished leaders, For Leading Global investment firm in collaboration with technology services company Innova Solutions

Innova Solutions is a global information technology company combining a global reach with a local touch. Headquartered in Santa Clara, California, Innova employs more than 1,800 technology professionals worldwide, with field offices in New York, Chennai, Bangalore, Hyderabad, Pune, and Taipei. From Cloud Transformation to Data Services to Managed IT Operations, Innova provides a broad array of proven, tested, cost-effective, and enterprise-scale technologies and services that leverage the latest technology and delivery models to deliver high value in the cloud, in the data center, and across complex interconnected environments.

Position Overview:

Data engineers are mainly tasked with transforming data into a format that can be easily analyzed. They do this by developing, maintaining, and testing infrastructures for data generation. Data engineers work closely with our data scientists and are largely in charge of architecting solutions for data, scientists that enable them to do their jobs.

What are we looking for?

We are looking for an accountable, multi-talented Data Engineer to facilitate the operations of our Data Scientists. The Data Engineer will be responsible for employing machine learning techniques to create and sustain structures that allow for the analysis of data while remaining familiar with dominant programming and deployment strategies in the field.

During various aspects of this process, you should collaborate with coworkers to ensure that your approach meets the needs of each project.

To ensure success as a Data Engineer, you should demonstrate flexibility, creativity, and the capacity to receive and utilize constructive criticism. A formidable Data Engineer will demonstrate unsatiated curiosity and outstanding interpersonal skills.

Responsibilities and Duties
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
Work with stakeholders, including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications for Data Engineer
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing 'big data' data pipelines, architectures, and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured data sets.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
A successful history of manipulating, processing and extracting value from large disconnected data sets.
Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environments.
Requirements:

We are looking for a candidate with 3+ years of relevant experience in a Data Engineer Position with the following technology stack.

1) Experience with big data tools: Hadoop, Spark, Kafka, etc.
2) Experience with relational SQL and No SQL databases, including PostgreSQL and Cassandra.
3) Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
4) Experience with AWS cloud services: EC2, EMR, RDS, Redshift
5) Experience with stream-processing systems: Storm, Spark-Streaming, etc.
6) Experience with object-oriented/object function scripting languages: Python, Java, C++, etc.",3.0,"innova solutions
3.0",Chennai,"Santa Clara, CA",1001 to 5000 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Scientist - Machine Learning (India),-1,"At least one-year experience in Python
At least one-year experience in Java
Technical Requirements:
Python 3, Flask, NLTK, OpenCV
AWS Services such as (Elastic Beanstalk, S3, ec2,
Google Cloud services as (Google Vision, Firebase)
At least one-year experience in Java, SQL database (Required)
At least one-year experience in Python. (Required)
At least one-year experience in developing backend or microservices. (Required)
Version Control/Git
Testing/Debugging (Browser developer tools like inspector and JavaScript console)
Knowledge of JSON
Roles & Responsibilities

Perform professional and technical engineering work relative to microservices related to data extraction from pdf, image processing and natural language processing in python
Working with other services such as Git, AWS and Google Cloud to manage and support application infrastructure, development and deployments
Some understanding of basic machine learning algorithms and neural networks.
Some experience with natural language processing such as named entity recognition, Part-of-speech tagging, etc.
Some experience using Google Vision API, Auto ML, or similar services preferred.
Some experience using OpenCV for image processing preferred.
Required understanding of back end/micro services development, json
Able to Monitor, identify production and non-production application issues and immediately come up with solutions to fix issues.
Responsible for testing software functional, design and quality requirements for the components, document and Simulate complex customer issues to find solutions and fixes to issues reported by customer.
Analyze functional requirements and seek clarification for better understanding the requirement, define timeline estimates based on the requirements, complexity and in-house capabilities.
Conduct coding as per design; Follow coding standards and best practices to check code quality; Share developed code supervisor; Rework on code based on inputs if required.
Conduct feed forward meeting with Manager to seek suggestions to improve.
Should be an effective communicator, excellent team player, eager to learn from others and share skills with colleagues.
Should be flexible to learn new programs and script languages.
Should show good levels of enthusiasm and interest in all computer related things.
Promptly attend scheduled meeting with due deliverables.",-1,Accrualify Inc,Nagpur,"San Mateo, CA",1 to 50 employees,2015,Company - Public,-1,-1,₹50 to ₹100 million (INR),-1
Data Engineer,-1,"Min. Exp: 1 year
Ahmedabad, India
Job Role
Skills Required
Personality
Job Role
Create and maintain optimal data pipeline architecture.
Build the infrastructure required for optimal ETL of data from a variety of data sources using AWS technologies.
Build large-scale batch and real-time data pipelines with data processing frameworks like Spark, Storm or other AWS technologies.
Skills Required
Good understanding on Java / Python.
B.Tech / M.Tech in CS with major in 'Data Engineering'/'Big Data'.
Understanding of Spark & other big data technologies.
Added advantage if the candidate has experience in data modeling, ETL design, implementation and maintenance.
Personality
You want to work in a small, agile team.
You mentor other developers when needed.
You work hard and don’t need much oversight.
You like variety in your projects.
You want to be proud of what you do at your job.
Interested applicants should send their resume and cover letter at career@iqm.com",-1,iqm.com,Ahmedabad,"New York, NY",1 to 50 employees,2014,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"We are looking for a Mid to Senior level Data Engineer to join our busy and dynamic Development team in our Hyderabad office.

Data analysts do not apply. Strong Java Developer with strong SQL Server only apply (rest please ignore and do not waste your time)

Who we are looking for?

You will have:
Strong hands-on experience in Java and Python, willing to work with NodeJS
Solid SQL skills, working with relational databases (SQL Server)
Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.
Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.
Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.
Willingness to work in US timings (up to 3PM PT)
Requirements

As an ideal candidate, you will have:
8+ years of relevant experience, well-versed in Java, Python, Node JS, Database (SQL)
Strong numerical and analytical skills
Experience supporting and working with cross-functional teams in a dynamic environment
Ability to work independently as sole contributor and as well as with a team
Experience in building distributed data pipelines and cloud functions in GCP or Azure is a plus
Experience in AdTech domain is a big plus
ML and API experience is a plus",5.0,"Stebr, Inc
5.0",Hyderabad,"San Jose, CA",Unknown,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Data Engineering - Senior Associate,-1,"Data Engineering – Job Description Location: Bangalore

Responsibilities

• You will be responsible for maintaining large-scale data processing systems, data warehouses and data lakes to help manage the ever-growing information needs of our clients. • Your technical challenge will be to test and optimize systems that ingest, aggregate and visualize terabytes of data that solve business relevant problems of our customers.

• Work with business users to refine analytical requirements for quantitative data (view-through, clickstream, acquisition, product usage, transactions), qualitative data (survey, market research) and unstructured data (blog, social network). • Designing and developing schema definitions and support data warehouse/mart to enable integration of disparate data sources from within Client environment and outside, aggregate it and make it available for analysis. • As a key member of the team drive adoption of new technologies, tools, and process improvements to build world class analytical capabilities for web analytics, optimization, experimentation and personalization. • Develop high performance, scalable implementations of the statistical/machine learning models developed by our Data Scientists.

Qualifications

• BS/MS in computer science or equivalent work experience. • 6 to 8 years’ experience in developing Data Models, DB schemas, creating ETLs, and familiar with Hadoop Ecosystem • 2+ years experience with data ingestion through batch and streaming methodologies using open source or public tools like Kafka, Airflow, Azure Data Factory etc..

• Experience with databases both RDBMS and NoSQL (Vertica, Netezza or Oracle and AWS data services tech). Through understanding of SQL (any variant) • Good understanding of Data Ware House methodologies. • Hands on experience in any of the programming languages (Shell scripting, Python, Scala, Java, etc)

Good to have

• Knowledge of Big Data ecosystem like Hadoop M/R, Pig and Hive is a strong plus. • Understanding of IN memory distributed computing frameworks like Spark (and/or DataBricks) and its parameter tuning, writing optimized queries in Spark • Scheduling and Monitoring of Hadoop and Spark jobs • Good understanding of any reporting tools such as Tableau, Pentaho or Jasper is a big plus. • Experience in design, development and deployment of one or more tools - ETL (Informatica, OWB, ODI), reporting (Business Objects, QlikView, Tableau)",3.6,"TheMathCompany
3.6",Bengaluru,"Bengaluru, India",201 to 500 employees,2016,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
CSII - Item and inventory - Senior Manager I - Data Scientist,-1,"Our Company

We help people around the world save money and live better -- anytime and anywhere -- in retail stores, online and through their mobile devices. Each week, more than 220 million customers and members visit our 11,096 stores under 69 banners in 27 countries and e-commerce websites in 10 countries. With last fiscal revenues of approximately $486 billion, Walmart employs 2.2 million employees worldwide.

@ Walmart Labs in Chennai, we use technology for the charter of building brand new platforms and services on the latest technology stack to support both our stores and e-commerce businesses worldwide.

Our Team:

CSII Team is responsible for building data driven highly optimized supply chain suite of products to manage entire gamut of supply chain lifecycle for our retail and ecommerce lines of business. With our rapidly increasing footfalls in stores and exponential growth in online orders; this all has to be done to scale millions of owned and marketplace SKUs complete inbound and outbound fulfilment lifecycles.

Teams mission - Enable customers to receive their orders when and where they want in an innovative and cost effective way for Walmart derives from Walmarts mission statement - Save Money. Live Better complementing our organizations philosophy to deliver low prices every day, on everything.

How we achieve this, comes down to the team of smartest technologists from India focused on the entire suite of supply chain management products for the Walmart Supply Chain at a massive scale. From forecasting & replenishing inventory for millions of items worth billions of dollars, sourcing of millions of orders, to route optimization & last mile delivery to Warehouse Management Systems to most advanced grocery & order management systems; technology is the backbone behind the entire platform enabling the massive cloud-scale supply chain from India.

With over 4,000 associates in Silicon Valley, San Diego, Portland, Brazil, United Kingdom and India, were bringing together some of the best professionals from around the world. If youre inspired by the opportunity to solve complex problems at scale and make a difference for our customers and members, join us.

Your Opportunity

Data Science

This position Data Science , will be on the Walmart Labs Supply Chain team, focused on building Walmart's best in class Supply Chain. At Walmart Labs, you will Work with small teams of talented analyst to build a best-in-class supply chain at Walmart. Be given the freedom to try new things and prove the value of your own ideas and innovations and own them all the way to production Identify and facilitate the removal of team impediments and escalate as appropriate Foster a motivating culture of openness, collaboration, and continuous improvement Ensure business needs are being met using Data Science best practices Participate in internal hackathons and innovation challenges!.

Your Responsibility

· Drive product and process improvements across the broad spectrum of projects in Item and Inventory organisation

· Mentor and manage junior analysts,

· Develop interactive statistical models using the latest frameworks.

· Develop Machine learning modelling leveraging existing frameworks and customizing to problem.

· Find workable solution in case of data inconsistency and inconclusive data

· Drive projects with minimal guidance. Provide thought leadership by researching best practices and conducting experiments

· Evaluate various analytical/statistical methods and procedures and provide recommendation of relevance, applicability, efficiency of those to Walmart Catalog teams

· Work with cross functional group consisting of Engineering, Product, Program managers to drive data based decisions

Your Qualifications

· Bachelors degree in computer science or related discipline with 12+ years experience (8+ Relevant)

· Lead major analytical and Operational excellence projects across multi-functional team and bring data driven decisions that maximize customer experience/Business impact at minimal possible cost.

· practical experience with SAS, ETL, data processing, database programming and data analytics

· Proficient is Sql and no-sql languages, R, Python

· Worked on gathering data from Cassandra, Kafka, MongoDBs. Work with big data on GCP and Azure.

· Advanced statistical modelling skills

· Handled multi-million records of data. Troubleshooting and fixing data issue

· Data Visualization in any BI tools like Tableau, PowerBI, etc.,

· Collected, analyzed, and reported data to meet customer needs.

· Understanding and application of statistical concepts to solve business problems",3.3,"Walmart
3.3",Chennai,"Bentonville, AR",1001 to 5000 employees,1962,Company - Public,"Department, Clothing, & Shoe Shops",Retail,₹500+ billion (INR),"Target, Costco Wholesale, Amazon"
Research scientist,-1,"Job Description

Initiates the design, development, execution and implementation of scientific research projects to fuel Intel's growth in the areas of computing, communication, technology and manufacturing and new business opportunity. Investigates the feasibility of applying scientific principles and concepts to potential inventions and products typically 7+ years prior to landing on a product roadmap. Plans and executes laboratory research. Maintains substantial knowledge of state-of-the-art principles and theories, and contributes to scientific literature and conferences. May participate in development of intellectual property. May coordinate interdepartmental activities and research efforts. Typically holds a PhD.

Qualifications

Inside this Business Group

Intel Labs is the company's world-class, industry leading research organization, responsible for driving Intel's technology pipeline and creating new opportunities. The mission of Intel Labs is to deliver breakthrough technologies to fuel Intel's growth. This includes identifying and exploring compelling new technologies and high risk opportunities ahead of business unit investment and demonstrating first-to-market technologies and innovative new usages for computing technology. Intel Labs engages the leading thinkers in academia and industry in addition to partnering closely with Intel business units.",4.0,"Intel
4.0",Bengaluru,"Santa Clara, CA",10000+ employees,1968,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),-1
Applied Scientist - Intern,-1,"Basic Qualifications
A Masters and/or PhD in CS, Machine Learning, Operational research, Statistics or in a highly quantitative field.
Experience in predictive modelling and analysis, predictive software development.
Strong problem-solving ability
Good skills with Java/Scala or C++, Perl/Python (or similar scripting language)
Experience in using R, Matlab, or any other statistical software
Strong communication and data presentation skills
Excited by Big Data, Machine Learning and Predictive Software? Interested in creating new state-of-the-art solutions using Machine Learning and Data Mining techniques on Terabytes of Data?

At Amazon Bangalore, we are developing state-of-the-art large-scale Machine Learning Services and Applications on the Cloud involving Terabytes of data. We work on applying predictive technology to a wide spectrum of problems in areas such as Amazon Retail, Seller Services, Customer Service, Alexa, Chatbots and so on. We are looking for talented and experienced Machine Learning Scientists (Ph.D. in a related area preferred) who can apply innovative Machine Learning techniques to real-world e-Commerce problems. You will get to work in a team dedicated to advancing Machine Learning technology at Amazon and converting it to business-impacting solutions.

Major responsibilities
Use machine learning, data mining and statistical techniques to create new, scalable solutions for business problems
Analyze and extract relevant information from large amounts of Amazon’s historical business data to help automate and optimize key processes
Design, develop and evaluate highly innovative models for predictive learning
Establish scalable, efficient, automated processes for large scale data analyses model development, model validation and model implementation
Research and implement novel machine learning and statistical approaches
Preferred Qualifications
Experience handling gigabyte and terabyte size datasets
Experience working with distributed systems and grid computing
Knowledge of the latest and state of the art ML technology.
Publications or presentation in recognized Machine Learning and Data Mining journals/conferences",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Sequoia was founded in the year 2001 by Greg Golub with the vision of becoming one of the largest independent benefits, insurance, and HR consulting firm. We’ve come a long way since our launching in May of 2001 with just a benefits services offering, one location, and five employees. Now, we have offices in 5 US locations, 1 global location and have big plans for the future. And with more than 1000 clients in the US market alone, we take care of our customers by unifying the benefits, HR, retirement, and insurance services which they require to scale and protect their business, through our guidance, service, and technology.

Sequoia is the partner for people-first companies. Along with Web and Mobile Applications, Sequoia’s engineering team is working towards building a cool solution for People Insights, a term we use to describe the kind of inputs smart leadership teams need in order to see what’s going on in their company with regards to the employee experience. Sequoia applies its robust integration engine, along with data science and machine learning to derive actionable outputs from the large dataset. At Sequoia, we take pride in making the complex simple, doing things right, and building an incredible community among our clients, clients like HackerRank, mongoDB, Udacity, Persistent Systems and the list goes on.

We are looking for a savvy Data Engineer to join our growing team. The person will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architect, devops architect and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout the system. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
What You'll Do:
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources through third party APIs.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer data, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems
What You'll Need:
Experience in building the data pipeline where there are multiple data sources through third party APIs
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing data pipelines, architectures and data sets
Expert with any one of the object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable data stores. Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools.
Good To Have:
Experience with any one of the data engineering tools: Hadoop, Spark, Kafka, neo4j, etc.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
What we offer?
Fun & Work at the same place with an amazing group and work culture
Flexible work timings
Competitive salary + performance-based bonus programs
Join us and be part of our success journey!",4.1,"Sequoia Consulting Group
4.1",Bengaluru,"San Mateo, CA",201 to 500 employees,2001,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Location:Port Blair
category:IT Software – Other
experience:2 – 5 Years
Company:Tradeindia com Infocom Network Ltd,

Source URL: https://www.wisdomjobs.com",5.0,"Tavat Consultancy
5.0",India,"Ahmedabad, India",1 to 50 employees,2018,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Senior Consultant - Data Engineer,-1,"Job Title: Senior Consultant - Data Engineer
Location:TRIL GTC Chennai
GCL: D1

Job description:


AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. The Science & Enabling Units IT is AZs global IT capability function supporting key business areas operating out of sites across the US, UK, Sweden, India & Mexico.

We are looking for a passionate Data engineer who will leverage tools & technology best practices to improve delivery performance & data engineering capabilities in the D&A space.

Roles & Responsibilities:
Provide data engineering (ETL, ODS, Marts, Reports) support to R&D IT portfolio
Deliver cost-effective solutions to support data engineering activities, for example, data ETL workflows
Test and quality assess new D&A solutions, to ensure they are fit for release: code assurance, Unit and System Integration Testing, Data testing, release management control and support of UAT processes
Ensure that business data and information assets are made available as data services and artefacts for consumption by the wider AZ enterprise
Mandatory skills:

Experience of working with a range of data analytics architectures. These may include: traditional warehousing, distributed computing, visualization analytics
Experience with & knowledge of Talend including:
Use of enterprise version of Talend Software preferably in a virtualized environment like AWS
Development of both standard ETL jobs deployed on JobServers and services (REST, SOAP) deployed on Talend ESB infrastructure
Familiar with using version control (branching, merging etc), ideally Git
Knowledge of working with Talend project branches, merging them and publishing and deploying code to runtime environments
Knowledge of techniques for optimising Talend code
Experience in Talend best practices for error handling, optimization, job layout, job design and naming conventions
Experience and familiarity with data models and artefacts
Any DB experience like Redshift, Netezza, Teradata, etc
Interpret data, process data, analyze results and provide ongoing support of productionized applications
Strong analytical skills with the ability to resolve production issues
Understanding of business area/process in scope
Willing to work in a cross-cultural environment. Ability to work effectively independently or as part of a team to achieve objectives
Eager to learn and develop new tech skills as required
Good written and verbal skills, fluent English
Desired skills:

Domain knowledge (processes & data): Pharma R&D
Experience of working with NoSQL, virtualization, data streaming etc
Amazon Web Services: Connecting, loading and reading data from AWS database technologies like MySQL, Aurora, AWS Redshift, PostgresSQL
Experience with Talend Metadata Manager and Talend Data Preparation an advantage
MS Power BI knowledge or any other reporting tools
Agile/Scrum process
ITIL knowledge
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",4.0,"AstraZeneca
4.0",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
Data Engineer-IND,-1,"Dell Technologies Presales Engineer


Turkey |
Istanbul,
İstanbul
Job ID: 35419
Job Description

Position at Armada

Armada is a value added distributor of server, storage, virtualization, network, IP PBX, video conference, security and infrastructure products, hand terminals, software and other products and components used by computer manufacturers during production process in IT market.

We are looking for a Presales Engineer to work in our Dell Technologies Team to create great solutions for our customers.

Qualifications:

- BS Degree in Computer, Electrical and Electronics or related Engineering Faculties, 4 years university,
Minimum 5 years of experience on Dell technologies and devices
Fluency in English (written and verbal),
For male candidates, military service must be completed or exception

Job Description:


- Installation and management of regarding products
Knowledge of Dell principles, technologies & products,
Working in cooperation with product sales team in projects.
Strong customer and partner focus, with the ability to manage requirement of project and customer expectations appropriately
Help the Sales and product team members for the finalized projects
Establish effective relations with the key partners and customer(technical account management)",3.3,"Ingram Micro
3.3",Chennai,"Irvine, CA",10000+ employees,1979,Company - Private,Computer Hardware & Software,Information Technology,₹1 to ₹5 billion (INR),"Copaco, Tech Data, COMPAREX"
Consultant - Data Engineer,-1,"Job Title: Consultant - Data Engineer
Location:TRIL GTC Chennai
GCL: C3

Company


AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. But we're more than one of the world's leading pharmaceutical companies. At AstraZeneca, we're proud to have a unique workplace culture that inspires innovation and collaboration. Here, employees are empowered to express diverse perspectives and are made to feel valued, energized and rewarded for their ideas and creativity.

Department Data & Analytics, R&D IT


R&D IT is a global IT capability supporting Drug Research, Drug Development, Product & Portfolio Strategy, Medical Affairs, Finance, HR, Compliance, Legal and Global Business Services. We are organized around 7 key capability areas: Business Partnering, Solution Delivery, Architecture, Application Support, Data & Analytics, Change & Operations, operating out of sites across the US, UK, Sweden, India and Mexico.

The Data & Analytics team provides technical support to analytics and data insight services and solutions critical to the Data & AI/ML emerging strategy and mission of R&D Science IT and AZ. Data & Analytics is organized into teams specializing in Information Architecture, Data Engineering, Visual Engineering, Knowledge Management, Data Science, Data Analysis and Information Governance.

Role


We are looking for a Data Engineer to help us build intelligent applications that make use of our structured and unstructured data to derive key insights. As part of the R&D Data Foundation engineering group, you will work together with ML engineers and data scientists to build the data foundations supporting R&D.

We are building a global Competitive Intelligence platform that will provide industry-leading competitive intelligence across our R&D and Commercial organizations. As a member of our team, you will be primarily responsible for implementing ETL processes.

You should be well-versed in the design and development of ETL and database developments for large data products, as well as maintaining and supporting production environments.

Key Accountabilities
Part of a DevOps team implementing and supporting ETL workflows. Data sources will be: structured, semi-structured and unstructured.
working with suppliers, data scientists, machine learning engineers, and platform teams to acquire and process data.
analysing data requirements, source data, model the source, and determine the best methods in extracting, transforming and loading the data into the data lake and processing the data through the layers of the lake.
providing technical input around design, architecture, integration and support of the entire data sourcing platform with a focus on high availability, performance, scalability and maintainability.
act as the ETL technical liaison working with technical infrastructure teams to resolve problems and implement solutions to technical issues impacting application performance
managing data administration tasks such as scheduling jobs, troubleshooting job errors, identifying issues with job windows, assisting with backups, rollback and performance tuning.
test, document and quality assess new data solutions, to ensure they are fit for release.
communicate and coordinate with members of the development team to work across multiple projects. Explore, actively support and work on new technology initiatives that may be of interest to the organization.
manage automation of all ETL processes within a job workflow
documentation of data engineering workflows to support downstream use
Testing of data in analytics applications, to ensure data validity and reconciliation to source systems
Development of subject matter expertise in sub-domains of the Science & Enabling Unit portfolio understanding of the business process, data flows, data provenance, data restrictions and data use.
Highly Desirable Knowledge, Skills and Experience
6 years+ experience on data engineering ETL workflows
B.Tech/ M.Tech/MSc in Computer Science.
A strong understanding of databases and source systems, including experience with, RDBMS, NoSQL and Graph technologies.
Experience writing ETL pipelines/orchestrations including code (Java, Python, C#).
Good software development skills with demonstrable knowledge of Python and Java, and source control (GIT)
Working knowledge of cloud environments (AWS preferred)
Experience of semi-structured (XML, JSON) and unstructured data handling including extraction and ingestion via web-scraping and FTP/SFTP.
Additional skills and experience sought


In addition, these are the bonus skills (not mandatory) for this position:
Excellent communication and facilitation skills.
Good written and verbal skills, fluent English.
Experience of working with data scientists and their methods: understanding of how data needs to be prepared for use by data scientists.
Experience of delivering solutions within IT projects delivered through Agile and Waterfall methodologies.
Experience of working within a range of data architectures.
Supporting a data-centric application.
Working with APIs (support or development).
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",4.0,"AstraZeneca
4.0",Chennai,"Cambridge, United Kingdom",10000+ employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Roche, GlaxoSmithKline, Novartis"
Data Engineer,-1,"OakNorth is the next-generation credit and monitoring platform that provides banks and lending institutions with the insight and foresight needed to create a better borrowing experience for the Missing Middle – the growth business who are the backbones of communities and economies globally but who have been in banking’s blind spot for decades.

The business was founded in 2015 by Rishi Khosla and Joel Perlman, who previously co-founded Copal Amba and grew it to 3,000 employees over 12 years, before selling it to Moody’s (NYSE: MCO) in 2014, returning 125 times capital to seed investors.

Since its inception, OakNorth has secured over $1bn from several investors, including: Clermont Group, Coltrane, EDBI of Singapore, GIC, Indiabulls, NIBC, Toscafund, and SoftBank’s Vision Fund.

The Platform has been deployed at various banks across North America, Europe, and Asia, and in the UK where OakNorth lends off of its own balance sheet via OakNorth Bank. The platform has helped OakNorth Bank become the fastest-growing business in Europe according to the Financial Times FT 1000 (2020), profitably lending over £4bn to date. In terms of the impact this has had on the economy, OakNorth Bank’s loans have directly helped with the creation of 13,000 new homes and 17,000 new jobs in the UK, as well as adding several billion pounds to the economy.

With offices in London, New York, Manchester, Singapore, Hong Kong, Shanghai, Istanbul, Gurgaon and Bangalore, the global team across the OakNorth Holdings group is over 800 people.

Data Engineer

Responsibilities
Using internal tools, codebase, and other technologies, build ETL pipelines to ingest external sources into the data platform.
Write web scraping scripts to automate retrieval of data from online sources.
Work closely with the data platform team in London o Structure unstructured data in pre-agreed formats to facilitate ingestion.
Analyze and interpret acquired data from external data sources and develop validations and a quality control process.
Perform due diligence on new sources quickly and identify data questions and concerns o Construct and maintain data dictionaries.
Required:
2-6 years professional experience in a data engineering role.
Strong analytical skills o Excellent organizational skills, including attention to precise details.
Have a solid knowledge of at least one programming language.
Knowledge of Python is a plus o Familiarity with Spark and AWS technologies is a plus.
Financial industry experience is a plus.
Thank you very much for your interest in OakNorth. We are happy to consider you for roles within our group of companies. If we can identify a match between your skill set and our immediate recruiting needs, please expect to hear from us very soon. If we are unable to identify a fit in the near term, please note that we intend to retain the data you send to us so we may contact you in the future.",4.1,"OakNorth Bank
4.1",Bengaluru,"London, United Kingdom",51 to 200 employees,2015,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
Data Analyst,-1,"Qualification:
Any graduate with 2-5 years experience in data analysis, decision support, including demonstrated proficiency with analytical software.
Proficient in PL/SQL, PowerPivot, Excel, VBA, Macros, MySQL DB and Microsoft PowerPoint.
Strong communication skills and should be fluent in written and spoken English.

JOB ROLE & RESPONSIBILITIES:
Perform complex data analysis in support of ad-hoc and standing customer requests.
Deliver data products in report/ presentation format, or verbally, to management's specifications and timelines.
Write excel and SQL programs to analyze and extract valuable information from healthcare data.
Perform basic statistical analyses for projects and reports.
Develop graphs, reports, and presentations of project results.
Create and present quality dashboards.
Promote an image of a high quality organization through expertise and responsiveness.
Takes responsibility for assignment completion and follow-through.
Good working relationships with internal and external customers.",3.6,"Anion Healthcare BPO
3.6",India,"Hyderabad, India",1 to 50 employees,1999,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Science,-1,"As a Data Scientist, Geospatial you will work on our machine learning platform and actively contribute to the development of our state-of-the-art preprocessing and modeling capabilities. You will join some of the best and brightest Data Scientists in the world in order to build innovative predictive modeling solutions that allow end-users to build more accurate models faster.

We are looking for talented people with excellent computer skills and deep knowledge of Statistical Learning who can analyze problems, develop innovative solutions, and implement them for real-world use on top of our machine learning platform.

DataRobot is based around delivering best-in-class data science solutions and this position provides the opportunity to develop key components of our platform.

Skills
Highly motivated and passionate about machine learning and computer science

Strong experience working with Geospatial data

Deep knowledge of different statistical and machine learning approaches and problem domains

Hands-on experience applying machine learning to real-world problems

Hands-on experience working in a fast-paced environment in Python

Hands-on experience writing testable, documented and maintainable code

Strong analytical and problem-solving skills

Ability to work with raw data sources in a variety of formats

Bonus
Experience with distributed computation frameworks

Outstanding achievements in “Kaggle like” competitions

Proficiency with C/C++ or Java (Scala, Clojure)

Experience in a management role

Contribution to open source solutions

Familiarity with either R, SAS or Matlab",-1,lemark institute of art,Mumbai,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer: Data Integration,-1,"Introduction
At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

As Data engineer, you will develop and move data from the operational and external environments to the business intelligence environment using Ab Initio software. Skills include designing and developing extract, transform and load (ETL) processes.
Responsibilities:
Coordinate with multiple technical teams to ensure apt integration of functions to identify and define necessary system enhancements to deploy new products and process improvements
Provide expertise in area and advanced knowledge of applications programming and ensure application design adheres to the overall architecture blueprint
Utilize advanced knowledge of system flow and develop standards for coding, testing, debugging, and implementation
Develop comprehensive knowledge of how areas of business, such as architecture and infrastructure, integrate to accomplish business goals
Resolve variety of high impact problems/projects through in-depth evaluation of complex business processes, system processes, and industry standards
Provide in-depth analysis with interpretive thinking to define issues and develop innovative solutions

Required Technical and Professional Expertise
Minimum 6+ years of experience in Abinitio development
Expertise in advanced Abinitio components
Ability to demonstrate micro / macro designing and familiar with Unix Commands and basic work experience in Unix Shell Scripting
Demonstrated ability in solutioning covering data ingestion, data cleansing, ETL, data mart creation and exposing data for consumers
Preferred Technical and Professional Expertise
You love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologies
Ambitious individual who can work under their own direction towards agreed targets/goals and with creative approach to work
Intuitive individual with an ability to manage change and proven time management
Proven interpersonal skills while contributing to team effort by accomplishing related results as needed
Up-to-date technical knowledge by attending educational workshops, reviewing publications
About Business Unit
IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter business by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world. What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft"
Data Analyst,-1,"Send your resume to growth@gaddieltech.com quoting the Job Code Titlle
Job Description
Analyzing, Mining and Reporting Data
Predictive analysis from structured and unstructured data
Application of standard statistical methods for analysis, documentation and presentation

Desired Candidate Profile:
Keen knowledge in statistical methods
Hands on in different ETL Tools
Critical thinking and providing educated guesses where data is sparse or sporadic
Experience: 6+ Years

Key Differentiator:
Good analytical skill, keen attention to detail and knowledge in modeling tools",-1,Gaddiel Technologies,Tiruchchirappalli,"Tiruchirappalli, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"â€¢8+ years of experience in Data warehousing or similar analytic data experience
â€¢3+ years of experience creating and managing complex data architectures.
â€¢5+ of years of experience in database design, development and data modeling.
â€¢3+ years of experience in developing flows using data streaming, batch processing, and Microservices
â€¢Experience with Amazon EMR/EC2 or Cloudera (with Hadoop, HDFS, MapReduce, Hive, Pig).
â€¢Familiarity with Linux
â€¢Familiarity with Jenkins and CI/CD
â€¢Excellent analytical, communication, organizational and problem-solving skills coupled with a strong work ethic.
â€¢Initiative to improve quality and make projects successful.
â€¢Knowledge of Agile/Scrum methodology.
â€¢Able to work effectively under pressure, independently, and within a collaborative team-oriented environment using sound judgement and decision making.
00-10.00 Years
Bachelor Of Technology (B.Tech/B.E), Masters in Technology (M.Tech/M.E/M.Sc), Bachelor Of Computer Application (B.C.A), Master in Computer Application (M.C.A)",-1,TalentFirst HR Consulting Private Limited,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"What we are looking for:
Must be proficient in advanced working SQL, experience working with a variety of databases and a stronghold in Hadoop (Spark, Spring)/Google Cloud technology (AWS) for extracting and analyzing large datasets
Hands on experience with one or more of Java, Scala or Python language
Experience working in various data warehouses, reporting/ analytic tools and environments
Good to have an exposure to and fundamental understanding of advanced statistical techniques
Knowledge of deep learning and AI tools and their application in the Retail domain will be preferred

Responsibilities:
Design, construct, install, test and maintain highly scalable data management systems

Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and cloud-based ‘big data’ technologies

Create data catalog, data flow diagrams and interprets data results to users

Use data and their analytical ability to find and interpret rich data sources; manage large amounts of data; merge data sources; ensure consistency of datasets; create visualizations to aid in understanding data; aid in building mathematical/statistical models using the data; and present and communicate the data insights/findings and produce and present results with dashboard

You must be:
A team player who likes to work hard and play harder, have excellent interpersonal, organizational and time-management skills

Able to think strategically and analytically to effectively complete assigned work within given timelines

Someone who possesses excellent written and oral communication skills and have an attention to detail

A person with an ability to multi-task on multiple projects and tasks at the same time

A person who gives importance to attention to detail and be highly organized

Positive and upbeat with the ability to learn quickly

Be able to laugh. At others and most importantly at yourself. Need a sense of humor

You can expect:
A fast-paced, high-growth startup environment where you will gain a career and not just a job

The company to invest in your personal and professional development. We support your ongoing education and training by reimbursing you for relevant educational courses

An open office culture, no cabins or cubicles and a place that is looking for your input to help us grow

The support of your teammates to always do better. Own it and win together!

Exposure of International Retail market. Learn about a high growth industry and build critical skill-set

Excellent employee referral program. Refer your friends, work with your friends and be awarded for it

Work along with the smart, creative and energetic team who truly believe in ‘working hard and partying harder!’

Educational Requirement:
UG – B.Tech/B.E.",4.9,"Profectus
4.9",Bengaluru,"Schaumburg, IL",1 to 50 employees,2017,Company - Private,"Department, Clothing, & Shoe Shops",Retail,Unknown / Non-Applicable,-1
Data Analyst,-1,"We have a wide variety of career opportunities around the world — come find yours.

Overview

Extract data and use statistical modeling and data analysis to drive incremental value. You will focus on leveraging existing technology capability to drive revenue growth in current year. You will also be supporting the team's strategic goals of defining the technology and data infrastructure roadmap to enhance performance of existing products and/or create new revenue streams, in partnership with the internal stakeholders. You will be collaborating with a number of internal and external teams to accomplish these goals.

It is essential that you are quantitatively orientated, results focused and of a “test-and-learn” mindset. Airline experience is not required for this position. People with retail experience and mentality will be successful in this role. This role requires business intuition and a working knowledge of analytical tools.

Responsibilities

Execute solutions to business problems using data analysis, data mining, optimization tools, statistical modeling and machine learning techniques
Develop and validate evaluation metrics and models to analyze business performance and areas of opportunity
Act independently to identify opportunities for improved analysis or improved efficiency through better use of statistical tools
Identify practical approach to test and learn key hypotheses to extend analytic insight
Leverage new data and/or experimental results to extend analytical frameworks/algorithms
Design experiments and analyze results to determine effectiveness of programs, policies and strategies
Collaborate with internal and external teams, help business owners make faster, smarter decisions
Socialize key initiatives with stakeholders
Create and deliver presentations as required

This position is offered on local terms and conditions. Expatriate assignments and sponsorship for employment visas, even on a time-limited visa status, will not be awarded.

Knowledge/Skills

Must have a proven, strong background in statistical concepts and working knowledge of statistical software (i.e. SAS, STATA, R etc.)
Ability to communicate complex quantitative analysis and algorithms in a clear, precise and actionable manner required
Excellent written and oral communication skills required
Must be fluent in English (written and spoken)
Experience using database querying tools and ability to write complex queries using Teradata SQL and/or Microsoft TSQL required
Familiarity with SQL Server Reporting Services required
Ability to learn new technologies required

Experience

Demonstrated experience in empirical research and for answering hard questions with data required
Experience in data mining and experimental design and analysis required
Demonstrated experience in manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources to highlight patterns and relationships required

Other

About 4-6 weeks of travel to US in a year required
Must be legally authorized to work in India for any employer without sponsorship
Successful completion of interview required to meet job qualification
Reliable, punctual attendance is an essential function of the position

Equal Opportunity Employer – Minorities/Women/Veterans/Disabled/LGBT",3.0,"United Airlines Inc.
3.0",Gurgaon,"Lorton, VA",201 to 500 employees,1983,Company - Private,Building & Construction,"Building, Repair & Maintenance",₹1 to ₹5 billion (INR),-1
Senior Data Scientist,-1,"Extensive experience working with large complex data sets and big data platforms
Proficiency in programming in Python, R, SQL and familiarity with REST based API’s
Strong understanding of feature extraction and data cleansing
Strong background in applying statistical machine learning techniques to predictive modelling and experience with Machine Learning libraries (Python, R)
Strong written and communication skills",-1,Intellithink,Chennai,"Chennai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"Company Description

PubMatic is a digital advertising technology company for premium content creators. The PubMatic platform empowers independent app developers and publishers to control and maximize their digital advertising businesses. PubMatic’s publisher-first approach enables advertisers to maximize ROI by reaching and engaging their target audiences in brand-safe, premium environments across ad formats and devices. Since 2006, PubMatic has created an efficient, global infrastructure and remains at the forefront of programmatic innovation. Headquartered in Redwood City, California, PubMatic operates 13 offices and nine data centers worldwide.

Job Description

PubMatic is looking for a sharp analytical individual to work as a Data Analyst in the Finance Reporting & Insights function. People with a penchant for extracting the truth out of numbers and summarizing it for the finance and operations teams would be best fit for the role.

Responsibilities:
The Data Analyst will be responsible for collecting and analyzing tremendous data sets using tools such as Microsoft Excel, Access, SQL and hive databases and presenting them in easy-to-understand formats.
The Data Analyst will be expected to retrieve data from publishers, ad networks & aggregators UI and develop spreadsheets and excel macros to filter, analyze, generate reports and draw conclusions from that data. It will be important to focus on the primary metrics while understanding the business requirements of the different teams within the business.
Apart from reporting tasks, the Data Analyst will work closely with other functions in the Pune Billing Team to assist with preparation of monthly publisher statements, tools that will improve productivity and the revenue yield generated for our publishers.
Requirements:
Exposure to business analysis, tracking metrics and building revenue monitoring tools
Should be involved in MIS functions requiring independent analysis of data
Exposure to financial modeling and operations analysis is a plus
Basic knowledge of running mapreduce jobs in hive databases
Basic programming knowledge
Technical Skills:
MS Office products including strong grasp of Excel (Charting, Formulae, Pivots
Advance Excel/Access: VB Macros in Excel and MS Access
VBA programming exposure is a plus
MS-SQL / MySQL
Hands on experience on Hive Database / Data Analytics tools
Added advantage if hands on experience in HTML / PHP / Java Script / Python
General attributes:
Any graduation, as specified by role, with good academic record / Masters is a plus
Total work experience of 3 to 5 years in a fast paced change-oriented environment
Worked in shifts interacting with US or UK clientele / vendors
Logical reasoning ability, problem solving and analytical mindset
Pro-active, quick learning, detail oriented
Excellent written and spoken English with ability to handle communication across levels.
Working hours would be 8PM to 5AM
Qualifications

Graduation in Math, Statistics, Science or Engineering

#LI-MD1

Additional Information

Coronavirus notice: PubMatic is actively working to ensure candidate and employee safety. Currently, all hiring and onboarding processes at PubMatic will be carried out remotely through virtual meetings until further notice.

Benefits: Our benefits package includes the best of what leading organizations provide, such as stock options, paternity/maternity leave, healthcare insurance, broadband reimbursement. As well, when we’re back in the office, we all benefit from a kitchen loaded with healthy snacks and drinks and catered lunches and much more!

Diversity and Inclusion: PubMatic is proud to be an equal opportunity employer; we don’t just value diversity, we promote and celebrate it. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",4.3,"PubMatic
4.3",Pune,"Redwood City, CA",501 to 1000 employees,2006,Company - Private,Internet,Information Technology,₹10 to ₹50 billion (INR),AdMeld
Scientist,-1,"Act as domain expert and lead person for training and supervising the curators of various databases/resources of IBDC related to his/her area of domain expertise.

Design metadata, database schema in coordination with Database Managers.

Design the portal for data submission, interact with researchers for data collection and help them in high throughput data analysis

Salary:
As per company standard

Other Benefits:
Industry:
IT-Hardware & Networking

Functional Area:
IT Software - Application Programming, Maintenance

Role:
Head/VP/GM-Technology(IT)/CTO

Desired Candidate Profile

Education-

UG:
PG:
M.Tech in Any Specialization or Ph.D in Any Specialization

3-6 Years",3.8,"CCS Computers
3.8",India,"New Delhi, India",201 to 500 employees,1993,Company - Private,IT Services,Information Technology,₹100 to ₹500 billion (INR),-1
Lead Data Scientist,-1,"Responsibilities

Lead & mentor the data analysts and data scientists to achieve business goals of BigTapp and its customers
Responsible for leading the development, validation and delivery of algorithms, statistical models and business analysis
Develops algorithms and statistical predictive models and determines analytical approaches and modeling techniques to evaluate scenarios and potential future outcomes
Lead and coach Data Science team members with latest machine learning algorithms including decision trees, probability networks, association rules, clustering, regression, and neural networks
Establish scalable, efficient, automated processes for large scale data analysis, model development, model validation, model implementation and model ops
Provide thought-leadership and dependable execution on diverse projects
Identify emergent trends and opportunities for future client growth and development

Education and Experience Requirement

Experience: 5 to 8 years’ experience in data sciences and should have handled a team of data engineers, analysts and scientists

Proven experience in:
Developing actionable insights and recommendations for business leaders
Presenting results and recommendations to non-technical business audience to drive the decision-making process
Deployed data science solutions with proven business benefits
Should have an educational background in statistics/data sciences/actuarial sciences. PhD will be an added advantage
Innovative and strong analytical and algorithmic problem solvers
Proficiency with open source analytical tools and one or more of Data Science Platforms (AWS Sagemaker/ Azure ML/ H2O.AI etc)
Subject Matter Expertise in effective machine learning tools and technologies including Tensorflow, Spark / Spark MLib, Flink, Mahout or any packaged cognitive solutions
Database programming in SQL
Proficiency with software development technologies (e.g. Python, Java)
Excellent critical thinking skills, combined with the ability to present your beliefs clearly and compellingly verbally and in written form
Domain expertise in any one or more of the following domains: Insurance, Banking, Manufacturing, Retail & FMCG
Experience and familiarity with common business use cases of analytics

Good To Have:
Experience with big data tools (e.g., Hadoop, HDFS, Cassandra, Storm)
Programming in NOSQL environments
Experience at data visualization and presentation using tools like Tableau, Qlik Sense & Power BI
Expertise in unstructured analytics: NLP, Computer Vision and Audio Analytics
Expertise in web scraping

Salary: Commensurate with experience and demonstrated competence
Contact: [email protected]",3.4,"BigTapp
3.4",Chennai,"Singapore, Singapore",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"UiPath is the fastest-growing enterprise software company in history. Our team grew to over 2,900 employees today, across 53 offices in 25 countries... In just a few years.
Our culture is embedded into our DNA, guiding us every step of the way. We’re fast, immersed, humble and bold. And that’s not just words on the walls.
Eliminating time-consuming tasks means people get to do more of what they love. It’s an inspiring, high stakes challenge that motivates us, and this common passion bonds UiPath employees globally. We all strive every day to be better and to accelerate human achievement.
We make robots, but we hire people. Would you like to be part of this journey?
Here's what you will do at UiPath:-
Use machine learning & deep learning techniques to create new, scalable solutions for business problems.
Develop NLP, NLU, NLG, NER, computer vision models and technologies for acquiring, parsing, interpreting and visualizing structured and unstructured data
Running regular benchmarking tests and perform statistical analysis, draw conclusions on the impact of your research-based optimizations to provide thought leadership to the team
Analyze and extract relevant information from large amounts data to help in automating the workflows and optimizing key processes.
Help the team in building large scale online learning system.
Help the team to build research to production pipeline.
Stay current with the latest research and technology and communicate your knowledge throughout the enterprise
Here's what you will bring to UiPath:-
MS or PhD degree in Computer Science or related technical field.
4+ years of relevant work experience.
2+ years of work or educational experience in Machine Learning or Artificial Intelligence.
Experience with two or more general purpose programming languages including but not limited to: Java, C/C++/C# or Python.
Experience with one or more of the following: Natural Language Processing, text understanding, machine reading comprehension, classification, pattern recognition, recommendation systems, ranking systems or similar.
Experience with one deep learning frameworks, TensorFlow or PyTorch
Knowledge about RPA.
Life at UiPath like a lot of startups, can sometimes feel like a roller coaster. It comes with changes and challenges, but also with the opportunity to shape how work is done, to have great impact and learn a great deal.
At UiPath, we value a range of diverse backgrounds experiences and ideas. We pride ourselves on our diversity and inclusive workplace that provides equal opportunities to all persons regardless of age, race, color, religion, sex, sexual orientation, gender identity and expression, national origin, disability, military and/or veteran status, or any other protected classes.

UiPath is committed to working with and providing reasonable accommodation to individuals with disabilities. If you have a medical condition or disability which inhibits your ability to complete any part of the application process, and are in need of a reasonable accommodation to complete the process, please contact us @ TALeaders@uipath.com and let us know how we may assist you.

This notice together with our Privacy Policy and Terms of Use of this website and any other documents we mention here are meant to inform you on what personal data about you we collect, use, disclose, share or otherwise process when you are applying for a job at UiPath or when UiPath contacts you for recruitment purposes. Please read this policy carefully to understand our views and practices on how we protect your personal data.",3.6,"UiPath
3.6",Bengaluru,"New York, NY",1001 to 5000 employees,2005,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Automation Anywhere, WorkFusion, Blue Prism"
Machine Learning Engineer,-1,"departmentEngineering

Experience

2+ years

Qualification

B.Tech/B.E.
No. of Positions

1
Location

Ahmedabad

Innovify is seeking a Machine Learning Engineer, who enjoys solving complex problems using clean, efficient and performant methods and putting those solutions into action whilst working in a team.

Key Responsibilities
Overall responsible for the Implementation of the Tasks allocated during the sprint
Ensure the software is developed confirming the project architecture, coding standards and NFRs
Support L2 engineer to analyse the User Requirements, NFRs and Technical requirements for the project
Identify any unknowns i.e. missing scenarios, etc and consult with PO to ensure those are defined either as a User story or UAC
Identify ways to implement stories and select the approach that is best suited for the project. Consult with L3 as required
Break down user stories along with the team to identify technical tasks
Provide detailed estimates before the start of the sprints. Need to work with the Team to get the estimates
Proactively pre-plan the sprints to achieve 90+% confidence of delivery
Create Technical documents as required for the project in Jira, Confluence or other tools
Provide POs and ADMs with daily updates of the team via Jira and Slack
Proactively communicate with other members of the team
Provide HR and Management with any relevant information to help improve organisation culture & performance
Key Skills
Expertise in object-oriented programming skills
Expertise in python with multithreading
Sound knowledge of machine Language and deep learning
Experience in developing and deploying ML models
Strong experience with framework like Pytorch or Keras
Be able to perform code reviews
Can unit test to perfection
Can produce code level logs
Be able to debug the defects
Knowledge of Source code repository including Git, Bitbucket, Mercurial or anything similar
Knowledge of AWS
Education & Experience
B Tech or B. E. (Computer Science / Information Technology)
2-5 Year experience of ML as a Software Engineer
Analytical & Person Skills
Must have good logical reasoning and analytical skills
Good communication skills and extrovert
Positive attitude and a team player
Openness to learning new concepts
Attention to details
Take own initiatives to achieve goals",3.8,"innovify
3.8",Ahmedabad,"London, United Kingdom",51 to 200 employees,2011,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Consultant,-1,"We are looking for a Data Consultant with experience in Analytical Solutions Consulting and sound knowledge in Machine Learning.

Mate Labs has built ""Mateverse"" for Data Analysts so that they can build customized machine learning and data science models for a quick prediction like sales forecasting without writing even a single line of code. At Mate Labs, we are solving a unique problem of Algorithm & Hyperparameter selection in the field of Artificial Intelligence.

Machine Learning has transformed industries and is ready to revolutionize the way you live, work and commute. It has created millions of new job opportunities and will continue to do so. This industry is going through a very exciting phase and at Mate Labs, we want to be at the forefront of this revolution. If it sounds exciting and you want to be a part of this revolution, join Mate Labs. Apply Now.

Job Responsibilities:

* Understanding the clients problems and Architecting Solutions around it.
Recommend design and develop state-of-the-art data-driven analysis using statistical & advanced analytics methodologies to solve clients problems.
Build deep client relationship, network & be a thought partner.
Excellent communication skills to be able to present findings to senior stakeholders
Working with Business Development / Sales team to customize solutions for the client
Working with the Data Science team on deliverables and owning it.

Skills Required:

* Proficiency in Python, Statistical/Predictive modeling and Machine Learning Algorithms (Regression & Time-series forecasting (MUST), Classification, Clustering)
Proven experience working on multiple business use-cases across various domains.
Subject matter expertise in solving Supply Chain related problems would be a plus.
Problem-solving, Project management, and communication skills & Creative thinking
Ability to think on his/her feet and engage with both the business and analytical community

Requirements:

* 3 - 5 years of experience
B.Tech or A degree in a quantitative field like Statistics, Mathematics, Economics, etc. or post-grad in management with strong technical skills.

Benefits:

*Startup culture(immense scope to learn and grow).
Amazing team to work with.
Health Insurance for the employees.",4.7,"Matelabs Innovations Pvt. Ltd.
4.7",Bengaluru,"Bengaluru, India",1 to 50 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,₹10 to ₹50 million (INR),-1
DATA ANALYST,-1,"posted by Mahima Gaur

2 - 5 years Delhi

Job Description
Experience in data processing
Experience in data cleaning and data tabulation activities
Strong analytical, communication and team management skills
Strong understanding of data management using SPSS and research techniques
Competency in a Tabulation software (decipher / wincross / quantum etc), Excel, Powerpoint
Ability to summarize findings, draw conclusions, and put together a presentation using Powerpoint
Role Category : Data Analyst

Employment Type : Permanent Job, Full Time",4.9,"Knowledge Excel Services.
4.9",New Delhi,"New Delhi, India",1 to 50 employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Science,-1,"Experience : 3 – 6 years

Location : Pune
Good knowledge and experience on Machine learning, predictive analytics, Decision trees,NLP etc. Good communication and innovative mind set. Educational background – Bachelors degree In Computer Science and statistics/Mathematics.",3.9,"Nitor Infotech
3.9",Pune,"Pune, India",201 to 500 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Business Intelligence Analyst II,-1,Function: Information Technology,3.7,"TE Connectivity
3.7",Bengaluru,"Schaffhausen, Switzerland",10000+ employees,2007,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),-1
IT Data Analyst,-1,"Join a team recognized for leadership, innovation and diversity


The Data Analyst supports multiple ERP deployments providing leadership in driving data solutions and data migration activities utilizing established processes with a primary focus in one or more functional areas. The Data Analyst is responsible to provide technical leadership, data functional excellence with the ability to translate business requirements into technical solutions.

Primary Responsibilities

Data Solutions Strategy Design

· Enforce common development methodologies for Data Migrations into core ERP applications

· Enforce the Management Operating System (MOS) for the Central Data Services organization

· Establish or enforce best practices needed for new data solutions implementations working closely with the functional COE, other data stakeholders and co-source partners

· Establish or enforce implementation & release management policies

· Establish or enforce data quality assessment processes

· Support Data Leads in managing data delivery

Implementing Data Migrations Policies, Standards and Training

· Assume the ownership of ERP Global Design Model data solutions, working closely with Functional teams and data leads to drive data migration delivery for ERP deployments, projects and enhancements

· Drive data rationalization process, implementation and change management

· Drive data quality standards as part of ERP deployments

· SME on technical environment/ tools for own area of expertise

· Provide oversight and direct activities related to analysis, design and implementation of technical data management solutions on larger projects

· Functional and technical impact analysis of potential changes to the Integration environment

· Creation of design documents and estimates for new project efforts

· Overall ETL solution design and creation of design specifications to implement changes

· Comply with standards and guidelines related to the design, construction, testing and deployment activities as established by departmental and organizational standards

· Support development, testing and deployment project deliverables

· Research, evaluate, identify alternative approaches, recommend, design and code efficient and effective solutions for challenging problems ranging from small to large work efforts for low to high complexity problems

· Collaborate with data leads, developers in support of project planning, technical design, development and solution delivery

· Identify opportunities in business processes, system capabilities and delivery methodologies for continuous improvement

· Works autonomously as a data analyst and lead a diverse range of tasks and is relied upon to coach others

Project Management

· Partner with data leads in the overall data delivery plan with the extended data services team members, deployment project managers, and co-source partners

· Ability to multi-task supporting multiple projects concurrently

· Collaborate with the EIM/Data Management organization to ensure data quality standards and measures are met

· Actively participate in walkthrough, inspection, review and user group meetings for data migration implementation, with a high focus on data quality

· Communicate and interact with appropriate areas on problems, changes and enhancements that may impact data, workflows and /or functionality within Information Technology software

· Create metrics and status reports for projects

· Manage and run meetings with co-source colleagues, Data Leads and other data stakeholders for various projects

YOU MUST HAVE
Bachelor of Science in Computer Science, Information Technology or equivalent
3+ years of Data Integration experience as a technical lead in an onshore/offshore model environment
Minimum of 3 full cycle deployments or projects providing end-to-end data migration support
3+ years of hands-on experience with ETL Application - Informatica Power Center, Analyst and Data Quality tools
3+ years of Hands-on experience with Oracle SQL Server development or similar
2+ years of functional experience in any ERP related systems
Excellent communication (verbal and written) and presentation skills
WE VALUE
Master of Science in Computer Science, Information Technology or equivalent
Ability to collaborate and influence across the organization
Knowledge on Azure on Data Bricks, Paxata, Robotic Process Automation, or AI/ML capabilities
Working knowledge of SAP Hana, BO, Tableau, Google Sheets or any visualization tool is a plus
Six Sigma Green Belt preferred
Agile methodology experience is plus
Additional Information
JOB ID: req237350
Category: Information Technology
Location: Devarabisanahalli Village, KR Varturhobli,,East Taluk - Phase I,Bangalore,KARNATAKA,560103,India
Exempt
Business Services",3.7,"Honeywell
3.7",Bengaluru,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
Big Data Engineer,-1,"Role Brief:

Our Big Data capability team needs hands-on developers who can produce beautiful & functional code to solve complex analytics problems. If you are an exceptional developer with an aptitude to learn and implement using new technologies, and who loves to push the boundaries to solve complex business problems innovatively, then we would like to talk with you.

Responsibilities:
You would be responsible for evaluating, developing, maintaining and testing big data solutions for advanced analytics projects
The role would involve big data pre-processing & reporting workflows including collecting, parsing, managing, analyzing and visualizing large sets of data to turn information into business insights
The role would also involve testing various machine learning models on Big Data, and deploying learned models for ongoing scoring and prediction. An appreciation of the mechanics of complex machine learning algorithms would be a strong advantage.
Qualifications & Experience:

1 to 4 years of demonstrable experience designing technological solutions to complex data problems, developing & testing modular, reusable, efficient and scalable code to implement those solutions.

Ideally, this would include work on the following technologies:
Expert-level proficiency in at-least one of Java, C++ or Python (preferred). Scala knowledge a strong advantage.
Strong understanding and experience in distributed computing frameworks, particularly Apache Hadoop (YARN, MR, HDFS) and associated technologies -- one or more of Hive, Sqoop, Avro, Flume, Oozie, Zookeeper, etc..
Hands-on experience with Apache Spark and its components (Streaming, SQL, MLLib) is a strong advantage.
Operating knowledge of cloud computing platforms (AWS/Azure ML)
Experience working within a Linux computing environment, and use of command line tools including knowledge of shell/Python scripting for automating common tasks
Ability to work in a team in an agile setting, familiarity with JIRA and clear understanding of how Git works
In addition, the ideal candidate would have great problem-solving skills, and the ability & confidence to hack their way out of tight corners.

Experience:

Must Have (hands-on) experience:
Scala or Python expertise
Linux environment and shell scripting
Distributed computing frameworks (Hadoop or Spark)
Cloud computing platforms (AWS/Azure ML).
Desirable (would be a plus):
Statistical or machine learning DSL like R
Distributed and low latency (streaming) application architecture
Row store distributed DBMSs such as Cassandra
Familiarity with API design
Education:

B.E/B.Tech in Computer Science or related technical degree",-1,Fractal.ai,Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Research Scientist,-1,"Experience 2-3 years of experience in generic formulation development of injectables for regulated markets(US/EU/Japan) from reputed company
Location Gurgaon
Description

RESPONSIBILITIES:
Planning, coordination and execution of product development activity for global markets.
Evaluation of literature and patents related to products under development.
Planning of stability studies and reviewing of development and stability data.
Compilation of Technology Transfer Dossier related documents.
Scale-up and technology transfer of products to manufacturing locations.

TECHNICAL EXPERIENCE:
Handling of Para IV ANDA products for US market.
Good understanding of regulatory requirements of global markets.
Good understanding of Patent and IPR strategies.
Execution of exhibit batches and technology transfers to manufacturing locations.

PERSONAL ATTRIBUTES:
Commitment, ownership, integrity, adherence to time lines.
Should have good planning and organizing capabilities.
Should be self motivated and having positive attitude.
Should have good drafting and communication skills.
Should have good team spirit.",3.7,"Fresenius Kabi Oncology
3.7",Gurgaon,"Gurgaon, India",501 to 1000 employees,-1,Subsidiary or Business Segment,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹100 to ₹500 billion (INR),-1
Data Science,-1,"Location: Hyderabad

Job Requirements

Experience with managing large real time data sets is an advantage.
An eye for detail with strong analytical skills and a curious mind.
Excellent communication, presentation and written skills with a passion to connect with people.
Independent and highly passionate about technology.
Efficient, responsible and self motivated with a focus on outcome and customer excellence.
Strong leadership, articulate and loves to meet and engage with people.

Qualifications

Degree / Masters/PhD in quantitative fields such as Mathematics, Statistics, Information Technology Engineering or Science.
Minimum 2 years of relevant working experience.
Knowledge of statistical and data mining techniques, which may include data modelling, regression, time series models, clustering algorithms and others.
Working experience with R and/or Python, SQL, ETL concepts, Data Governance and Big Data frameworks such as Hadoop, SPARK, etc.
Exposure to Business Intelligence tools such as Tableau, Qlikview, SAS and other BI tools will be an added advantage.
No Of Positions : 3",3.5,"Web Synergies
3.5",India,"Singapore, Singapore",201 to 500 employees,1998,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Business and Data Analyst,-1,"Locations: Bangalore, Data Science & Analytics, Mountain View, New Jersey

We are looking for a Business and Data Analyst for a growing portfolio of customers. As a member of the TV Retargeting products, analytics and business operations team, you will have a huge impact on our business and the success of our customers. You should have an interest in solving business challenges using data, gathering requirements, analyzing use cases and working towards efficient solutions.

For campus recruiting: see our blog for sample test questions and group discussion topics.

Responsibilities:
Work with our Sales and Account Managers to understand customers’ KPIs and goals
Work with Business Operations team to launch new and optimize ongoing TV Retargeting digital media campaigns
Create case studies by analyzing past viewership and exposure data
Work closely with the data engineering team to understand the underlying drivers of positive and negative performance across our customers
Develop and run data science experiments and interpret the results
Implement the insights gained from your experiments across customers
Proactively communicate the key insights from the performance to the relevant internal teams: sales, account management and engineering
Communicate your ideas for improvement for our internal toolset within the TV Retargeting product and engineering team

Requirements:
Strong analytical background and critical thinking
Strong organizational skills and attention to detail
Ability to thrive in a fast-paced, high-volume, and deadline-driven environment
Engineering and Technical degree preferred
Marketing / Advertising / Analytics related experience is preferred but not necessary
Familiarity with the TV or Digital advertising ecosystem is helpful, but not required
Experience with a scripting programming language and SQL is helpful, but not required",4.1,"Alphonso
4.1",Bengaluru,"Mountain View, CA",51 to 200 employees,2012,Company - Private,TV Broadcasting & Cable Networks,Media,Unknown / Non-Applicable,-1
Sr. IT Data Analyst,-1,"Join a team recognized for leadership, innovation and diversity


The Sr. Data Analyst supports multiple ERP deployments providing leadership in driving data solutions and data migration activities utilizing established processes with a primary focus in one or more functional areas. The Sr. Data Analyst is responsible to provide technical leadership, data functional excellence with the ability to translate business requirements into technical solutions.

Primary Responsibilities

Data Solutions Strategy Design

· Enforce common development methodologies for Data Migrations into core ERP applications

· Enforce the Management Operating System (MOS) for the Central Data Services organization

· Establish or enforce best practices needed for new data solutions implementations working closely with the functional COE, other data stakeholders and co-source partners

· Establish or enforce implementation & release management policies

· Establish or enforce data quality assessment processes

· Support Data Leads in managing data delivery

Implementing Data Migrations Policies, Standards and Training

· Assume the ownership of ERP Global Design Model data solutions, working closely with Functional teams and data leads to drive data migration delivery for ERP deployments, projects and enhancements

· Drive data rationalization process, implementation and change management

· Drive data quality standards as part of ERP deployments

· SME on technical environment/ tools for own area of expertise

· Provide oversight and direct activities related to analysis, design and implementation of technical data management solutions on larger projects

· Functional and technical impact analysis of potential changes to the Integration environment

· Creation of design documents and estimates for new project efforts

· Overall ETL solution design and creation of design specifications to implement changes

· Comply with standards and guidelines related to the design, construction, testing and deployment activities as established by departmental and organizational standards

· Support development, testing and deployment project deliverables

· Research, evaluate, identify alternative approaches, recommend, design and code efficient and effective solutions for challenging problems ranging from small to large work efforts for low to high complexity problems

· Collaborate with data leads, developers in support of project planning, technical design, development and solution delivery

· Identify opportunities in business processes, system capabilities and delivery methodologies for continuous improvement

· Works autonomously as a data analyst and lead a diverse range of tasks and is relied upon to coach others

Project Management

· Partner with data leads in the overall data delivery plan with the extended data services team members, deployment project managers, and co-source partners

· Ability to multi-task supporting multiple projects concurrently

· Collaborate with the EIM/Data Management organization to ensure data quality standards and measures are met

· Actively participate in walkthrough, inspection, review and user group meetings for data migration implementation, with a high focus on data quality

· Communicate and interact with appropriate areas on problems, changes and enhancements that may impact data, workflows and /or functionality within Information Technology software

· Create metrics and status reports for projects

· Manage and run meetings with co-source colleagues, Data Leads and other data stakeholders for various projects

YOU MUST HAVE
Bachelor of Science in Computer Science, Information Technology or equivalent
7+ years of Data Integration experience as a technical lead in an onshore/offshore model environment
5+ years of full cycle deployments or projects providing end-to-end data migration support
5+ years of hands-on experience with ETL Application - Informatica Power Center, Analyst and Data Quality tools
5+ years hands-on experience with Oracle SQL Server development or similar
3+ years of functional experience in any ERP related systems
WE VALUE
Master of Science in Computer Science, Information Technology or equivalent
Ability to collaborate and influence across the organization
Some functional experience with SAP R/3 Applications or any other ERP system
Knowledge on Azure on Data Bricks, Paxata, Robotic Process Automation, or AI/ML capabilities
Experience working with SAP Hana, BO, Tableau, Google Sheets or any visualization tool is a plus
Excellent communication (verbal and written) and presentation skills
Six Sigma Green Belt preferred
Agile methodology experience is plus
Additional Information
JOB ID: req237371
Category: Information Technology
Location: Devarabisanahalli Village, KR Varturhobli,,East Taluk - Phase I,Bangalore,KARNATAKA,560103,India
Exempt
Business Services",3.7,"Honeywell
3.7",Bengaluru,"Charlotte, NC",10000+ employees,1885,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"GE, Johnson Controls, United Technologies"
Machine Learning Engineer (f/m/d),-1,"Machine Learning Engineer (f/m/d)



Permanent employee, Full-time
· Pune, India

Impact Description

Are you a technology enthusiast and enjoy being challenged towards development of superior software using innovation? Have you been part of high performing teams delivering world-class products? Join us in our drive to make robust products with assured quality available to our customers.

You will be responsible for setting up the right code architecture, leveraging emerging tools and trends while keeping the vision of our product intact. You will be part of our core R&D team working in Pune, India.

Your Profile

WHAT YOU ALREADY KNOW
Strong fundamental understanding of machine learning algorithms, with good hold on under-the-hood mathematical and statistical concepts
Research oriented mindset : Should be able to review existing research publications for applicability in the current problem and also publish research papers at forums / events
Programming experience with Python
Experience with machine learning frameworks such as Tensorflow, Keras and commonly used python libraries
Able to build data pipelines to train and build your models
Able to deploy models in Docker containers
Able to do Linux shell scripting
Able to use at least one of the following database and data processing technologies such as MongoDB, Apache Hadoop and/or Apache Spark
Ability to provide a compelling story / narrative on work through dashboards and presentations
Experience:

2-3 Years

What We offer You

Beautiful Office Spaces
Our team has added a personal touch to our office spaces, which is a reflection of our work culture: unique, fresh and innovative.
A Young, global Team
We are employee driven. We have a diverse team, a flat structure and encourage a healthy balance between work and play.
Passion for Technology
We are enthusiastic about our work and go the extra mile. Jump headfirst into the deep end, ready to do what no one else has done.
We make a change
We clean up your code and get it to speed with the times, assuring good quality and robustness at all times.
We're empowering
We make your code visual and beautiful, making it easy to understand by anyone to make well informed decisions.
We love challenges
We revel in expectations and widening our horizons. We are always eager to learn, grow and trudge into new territories.
We have fun
We take pride in making work a place we look forward to coming to each day. We love our work and this shows in the work we do.
We are efficient
We do great work and utilize resources effectively, making our services accessible and affordable to our clients.

Contact Us

Embold Software Pvt.Ltd
HR India
Office No. 302-303,
Third Floor, Pride House,
Pune University Road, Chattushringi,
Pune- 411016
India

E-Mail: hrindia@embold.io

About us

Our Vision is to change the Paradigm of Software Development by helping our users to create great software products.
We develop the infrastructure and tools that fuel the transformation of software development with the power of artificial intelligence and support our customers in dealing with complex challenges in their software development processes with our software analytics platform.

Apply for this position

Your Application

Thank you for considering a career at Embold Technologies GmbH. Please fill out the following form. In case you are experiencing problems with the document upload, mail your documents to hrgermany@embold.io.

Name *

Email *

Something went wrong

Phone

Location


Documents
Please upload here the application documents required for the position (e.g. curriculum vitae, certificates, etc.).

Click to select multiple files or use drag-and-drop

Available from

Expected salary



I hereby confirm that I have read and understood the Data privacy statement.

Uploading document. Please wait.

Send application

Cancel",4.0,"Embold Technologies
4.0",Pune,"Frankfurt am Main, Germany",51 to 200 employees,2008,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Big Data Engineer,-1,"We need TM1 application developers! Within Amazons Corporate Financial Planning & Analysis team (FP&A), we enjoy a unique vantage point into everything happening within Amazon. As part of that, our team designs, builds & maintains an integrated planning & reporting platform that enables hundreds of finance representatives across the globe.
In addition to requiring a high level of technical expertise within Cognos TM1, this role is about understanding the needs of the business, the data behind it, and how to transform this information into technical solutions that allow the business to make swift, informed decisions. Ideal candidates will have expertise in all phases of the software development life cycle in building models that scale over time while balancing accuracy, flexibility and speed.
The data flowing through our platform directly contributes to decision-making by our CFO and all levels of finance leadership. If youre passionate about building tools that enhance productivity, improve financial accuracy, reduce waste, and improve work-life harmony for a large and rapidly growing finance user base, come join us!





Basic Qualifications

- Bachelor's degree in Information Systems, Computer Science, Finance, Accounting, Economics, Mathematics or a related technical discipline.
- 4+ years of Cognos TM1 work experience in developing end-to-end analytics solutions, including system configuration, model building, data security, and reporting.


Preferred Qualifications

- Experience advocating and proliferating best practices in reporting and analysis, including data integrity, test design, analysis, validation, and documentation - Experience in providing risk assessment for new functionality and enhancements, and identify process improvement opportunities to drive innovation - Relevant corporate finance experience exhibiting knowledge of financial planning functions and related processes. - Excellent communication (verbal and written) and interpersonal skills, and an ability to effectively communicate with both business and technical teams. - Quick learner with a positive attitude and professional demeanor, and strong analytical and troubleshooting skills.- Direct experience using Business Intelligence (BI) reporting tools, preferably Cognos v10x (Report Studio, Analysis Studio, Workspace, Framework Manager), or similar technology (OBIEE, Business Objects, Tableau, MicroStrategy, SAP, etc.). - Experience developing scorecards and dashboards. - Experience with dimension management software processes and MDM tools (Oracle DRM) - Advanced knowledge of SQL, Oracle, OLAP, and data warehousing concepts. - Familiarity and development experience with web services technologies is a strong plus (e.g. HTTPS, REST, XML, JSON, etc). - JAVA/PERL/Ruby/Python scripting language experience. - Experience with third-party ETL tools (IBM DataStage or Data Manager, Informatica, etc). - Familiarity with AWS solutions such as EC2, DynamoDB, S3, Redshift, and Aurora.
Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Corporate and Investment Bank - Quantitative Research CLO Trading and Relative Value Tools - Vice President,-1,"Key responsibilities could include:
Development of models and support infrastructure to price CLO securities for use in risk analysis and trading.
Model performance analysis, reserve methodology specification, regulatory analysis
Analysis of hedging strategies
Integration of pricing, risk, and P&L functionality in our risk system, Athena
Ongoing desk support
Working closely with technology on integration of models in applications
Communicating with Model Review Groups in order to make models pass strict in-house standards
Essential skills:
Very strong mathematical and financial modeling skills.
Strong interest in programming and design. C++ coding is required, and experience with Python and R would also be a plus.
Experience on both Linux and Windows systems.
Experience with Intex C-Subroutines is a plus.
Ability to work in a high-pressure environment.
Pro-active attitude. Should have a natural interest to learn about our business, models, and infrastructure
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.",3.9,"J.P. Morgan
3.9",Mumbai,"New York, NY",10000+ employees,1799,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Data Analyst,-1,"We are looking for dynamic, energetic and result oriented business / data analyst to be a part of team and work closely and/ or independently on specific projects. You will be an independent operator and will need to deliver the set priorities in timely and most diligent manner. Your analysis will form the basis for making appropriate recommendations to customers to help them achieve the set objectives.

The successful candidate will convert data into information, information into insight and insight into business decision for the assigned project / client.

Data analyst responsibilities include conducting full lifecycle analysis to include requirements, activities and design. Data analyst will develop analysis and reporting capabilities. They will also monitor performance and quality control plans for identifies improvement opportunity.

The key goal of the position is to own components of the consulting / implementation projects and drive the maximization of value preposition for the client organization.

Key responsibilities:
Define and carry out the analysis of the data and information to prepare actionable insights.
Build a robust understanding of the customer business focused towards opportunities to improve customers business performance for the assigned areas.
Interpret data, analyze results using statistical techniques and provide ongoing reports.
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiencies and quality
Acquire data from primary or secondary data source and maintain them for suitable actionable usage.
Identify, analyze and interpret trends or patterns in complex data sets.
Filter and “clean” data for review reports and key performance indicators, specific to the project or work areas.
Work with company’s management team to prioritize business and information needs.
Locate, define, seek alignment and implement process improvement opportunities.

Requirements:
Proven working experience as a business data analyst.
Technical expertise regarding data models, database design, data mining and segmentation analysis.
Strong knowledge and experience with reporting packages.
Knowledge of statistics and experience using statistical tools and packages for analyzing data.
Proficient level expertise in MS Excel & Power Point.
Strong analytics skills with ability to collect, organize, analyze and disseminate significant amount of information with attention to details and accuracy.
Adept at queries, report writing and presenting finding.
BSc in Mathematics / Economics / Computer Science, Information Mgt. or Statistics.

Qualification and experience:
BSc in Mathematics / Economics / Computer Science, Information Mgt. or Statistics.
Minimum 2 to 5 years of relevant experience.
Proven track record.
Compensation: in line with the market and commensurate with the relevant experience.",-1,Augmenter Consulting,Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"FiFyles is changing lives!

As a Lead Architect for Data, you’re eager to jump into a brand new learning experience. We need a Lead Architect for Data to have fun analyzing complex, massive data sets, building amazing tools and gaining insights from it all. If this sounds like you, please read on!

Who You Are

You entrepreneurial instincts recognize the opportunity of working at a startup-within-a-startup
You are extraordinarily well versed in the latest data architectural and modeling principles
You are likeable
You believe every experience, good or bad, is an opportunity to learn and do better.
You are convinced that the best use of experience is to leverage it to learn more
You are like a kid in a candy shop when it comes to new database technologies
You are respected and your opinions have enormous influence among your peers
Your enthusiasm easily persuades others
You believe that deadlines are sacrosanct
People come to you to solve their disagreements
You are a data-modeling god
You can navigate the maze of columnar and NoSQL databases as comfortably as your keyboard
You’re politically neutral within your organization

What You Want From Your Next Career Move

To change the world by managing a team of data researchers, engineers and analysts. To learn and grow. To help people engage with their health and well-being through data.

Why We Need You

FitFyles is using data to deliver the best health information to the users that need it. Find insights in data to help us save lives. At FitFyles, our success is based on our ability to dive deep into complex and data-intensive challenges to find scalable solutions to some of today's most pressing health care problems.

We need your unique skills to:
Build tools and products that will help us discover unexpected insights and understand data to drive better decisions
Help define and track, alongside our product and engineering teams, the metrics that will measure our success, from the utility of new features to our ultimate goal of measurably prolonging life expectancy
Pioneer new uses of data to create meaningful user growth and engagement
Grow and manage a team of top-tier data researchers, engineers, and analysts to help change the way people think about and relate to their health and health data

How You’re Changing Global Healthcare

Using data, you’ll connect people with trustworthy physicians,to bring concierge medicine and peace of mind to millions of people around the world.

What you’ve accomplished:
Masters Degree (PhD is a plus) in a quantitative discipline (applied mathematics, statistics, CS, or related field)
3+ years of experience in big data analysis- especially in building large scale, efficient and real-time solutions
Very strong logical problem solving abilities and a solid knowledge of the tools of the trade, including common and open data and analytical frameworks like- Spark, Spark SQL, Hadoop, SQL, R, etc.Working knowledge of scripting languages, especially Ruby on Rails, and Python.
A thorough understanding of A/B testing and experience implementing it at scale (preferred)
Startup or equivalent experience (preferred) and the drive to live the dream (required)",-1,Fitfyles,New Delhi,"New Delhi, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"Salesforce experience an advantage
Job Type: Full-time
Salary: ₹50,000.00 - ₹60,000.00 per month
Experience:
Analysis: 4 years (Preferred)
SQL: 4 years (Preferred)
Education:
Required
Additional Compensation:
Bonuses
Work Location:
One location",-1,EW Technologies,Kochi,"Farnborough, London, England, United Kingdom",Unknown,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"Company Description

DemandMatrix is a team of smart data scientists, data analysts and technologists who have the domain expertise of tech product analytics and market analytics. We work with Fortune 500 tech companies as a solution partner to help them identify their right target customers, in turn, helping them increase their target addressable market.

Job Description

To be a great fit for our team, you:
Must have 2-4 years of experience in handling data
Must have the ability to interpret large amounts of data and to multi-task
Must have strong knowledge of and experience with programming (Python), Linux/Bash scripting, databases(SQL etc)
Must have Strong analytical and critical thinking to resolve business problems using data and tech
Must have domain familiarity and interest of – Cloud technologies (GCP/Azure Microsoft/ AWS Amazon), open-source technologies, Enterprise technologies
Must have Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
Must have good communication skills
The job involves the following responsibilities:
Understanding technology domain especially the role of various technologies.
Mapping business use case to data solution.
Working with varied data formats like JSON, CSV, XML, HTML, ec to extract information for the business case.
Predominantly implementing Python based tools, scripts and code on Linux in a cloud based environment.
Qualifications

Few good to have qualities, we are looking for in you:
Good to have exposure to Agile methodology
Good to have knowledge in Reporting Tool (Tableau/Power BI) and generating data insights
Working knowledge / exposure to ElasticSearch, PostgreSQL, Athena, PrestoDB, Jupyter Notebook
Additional Information
Flexible Working hours
Work From Home
Birthday Leave",4.2,"DemandMatrix
4.2",Pune,"San Jose, CA",51 to 200 employees,2015,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Science,-1,"Job Summary

We are searching for talented engineers and science majors to join our team. We are searching for top talent that will help solve some of the most challenging problems in the IT world using data science methodologies. You will have access to the best facilities, technology and expertise within the industry and will work on challenging problems that would include looking at large volumes of data and deriving insights from them. You will be working to build algorithms to solve some of our advanced initiatives. You will also have opportunities to work on several business initiatives and be empowered to lead problem solving. This is an excellent opportunity to be in high-impact teams, where you can truly develop your skill set and knowledge and bring impact to the business.

Responsibilities
Analyzing raw data, assessing quality, cleansing, structuring for downstream processing.
Design accurate and scalable prediction algorithms.
Work within a team, collaborate and add value through participation, provide comments and suggestions, work with cross-functional teams to bring analytical prototypes to production and to achieve goals.
Derive key insights for business improvement based on unstructured data from several source
Education
Masters in Technology (M.Tech)
Deep knowledge of Statistics/predictive modeling/ Data Mining/Machine Learning/clustering and classification techniques, and algorithms.
Skills Needed
Solid programming skills with Python/C/C++/Java or other equivalent language.
Familiarity with Big Data frameworks and visualization tools like Cassandra,/Hadoop/Spark/Tableau.
Who you are
A team player. You get along well with your colleagues and are always ready to help get things done. You enjoy working on projects with multiple people and share knowledge.
Passionate about learning. You thrive on complex technical challenges and are always eager to learn the latest technologies.
Organized and detailed-oriented. You think ahead of time about how best to implement new features, and your code is clean, well-organized and properly documented.
Innovative. You are always proactively looking for opportunities to problem solve using innovative methods that impact the business.
Keywords
Artificial IntelligenceData ScienceData ScientistDeep LearningMachine Leaning",3.0,"XenonStack
3.0",SAS Nagar,"Chandigarh, India",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),-1
Risk - Quantitative Research - IBQR Data Team - Associate,-1,"Description:

IBQR Data team provides excellent exposure on Credit Risk, Basel regulations, CECL/IFRS9 forecasting and stress forecasting. The team works across the Wholesale bank and is closely aligned with firm-wide partners including Quantitative Research, Finance, Model Risk Governance, Chief Data Office, Technology and the Regulatory Capital Management Office. We seek candidates with strong skills in corporate finance, data analytics, big-data architecture and communication.

Roles & Responsibilities:

• Work in an Agile framework to write business requirements in the form of JIRA epics & user stories to develop data and system requirements for credit risk modelling platform

• Perform data analysis to support model development and analytics

• Liaise with various lines of business and risk modelers, thoroughly understand various models for BASEL, CCAR, CECL and other credit risk models

• Work with multiple stakeholders to elicit, analyze, refine and document business process and data requirements

• Collaborate through the entire Software Development Life Cycle (SDLC) including planning, analysis and testing of new applications and enhancements to existing applications.

• Define data models , metadata and data dictionary that will enable data analysis and analytical explorations

• Perform user acceptance testing and deliver demos to stakeholders by SQL queries or Python scripts

Qualifications:

• Bachelor's or Master's in Computer Science, Data Analytics or equivalent discipline

• Data Analysis and data manipulation skills using SQL , Python & MS Excel is Required

• Data Visualization tools like Tableau, Qlik View, Power BI etc is nice to have.

• Strong analytical skills in forecasting and interpreting results and comfortable working with large quantities of data

• Familiarity with Traditional Credit Products (Loans, Letter of Credit, Stand By Letter of Credit, Syndications etc)

• Detail oriented and strong organizational skills

• Excellent communication abilities, both written and oral;

• Ability to solve problems creatively while working in a dynamic and challenging environment under tight deadlines

• Eagerness to learn about Credit Risk, Risk Parameters, Regulatory and Accounting conceptsJPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.",3.9,"J.P. Morgan
3.9",Mumbai,"New York, NY",10000+ employees,1799,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Data Analyst,-1,"About us.

Brave finds rising star talent for high growth companies. That means we’re always on the lookout for brilliant folks like you. We work to understand your work interests, career goals, and talents. And then put you in touch with our clients who might want to interview you. Feel free to share our details with a friend or peer. We’d be happy to link them with jobs too.

About our client.

Our client is a venture-backed technology company operating in East Africa. We build and deploy cloud-connected retail outlets, which serve as consumer access points for goods and services delivered in partnership with major suppliers. Their first consumer solution delivers significant cost savings and quality of life improvements.

If you share their passion for technology and vision for global impact and think that you will thrive in a fast-paced work environment, this is the role for you!

About your role.

As a Data Analyst, you will drive our analytics function by generating data-driven insights to guide commercial and operating strategy; developing metrics, dashboards, and statistical analyses; helping to shape our overall vision & strategy.

What You Will Do.

Build models to identify trends, forecast performance, and identify improvements to the company strategy, products, and operations
Design and run data analyses to guide decision-making
Design and prepare company dashboards and other key stakeholder reporting
Design and develop automation tools to streamline day-to-day activities
Identify and coordinate data infrastructure improvements with the software team
Drive cost-saving and increased revenue processes through data insights
Enable the success of the team members by supporting them in accessing, understanding, and utilizing data
Ensure consistency, accuracy, and overall integrity of business metrics
Develop and maintain business intelligence documentation, training materials, best practices, and overall data toolkit

Skills.

Bachelor’s degree, ideally in Computer Science, Math, Statistics, or Economics (Master's degree a plus)
Experience in data analysis, consulting, finance, or other quantitatively rigorous roles (ideally, 3-5+ years)
The ability to balance priorities, clarify stakeholder requirements, pay keen attention to detail, and generally keep deliverables on schedule
Proficiency with Tableau and/or Looker, SQL, Excel, and statistical methods (Python an added plus)
Ability to communicate technical details clearly and concisely to management & external Stakeholders
Ability to perform people and process analysis
Passion for problem-solving, data, and analytics",3.4,"Brave Venture Labs
3.4",Pune,"Nairobi, Kenya",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
BI Reporting Developer – (Big Data) - Analyst,-1,"Job Description:


Job Title: BI Reporting Developer – (Big Data)

Corporate Title: Analyst

Location: Cary, NC

Overview

Join a dynamic cross functional team on the front lines of transformation across the Credit Risk domain. Credit Risk IT is in a multi-year journey of upgrading their technology stack, transforming their way of working and facilitating the streamlining and automation of critical business processes. We are looking for an energetic and flexible developer with experience or aptitude to learn BI Reporting and other technologies to partner on an exciting Big Data project. The team will be working across multiple technologies and will need to work together to ensure delivery of business value.

What We Offer You:
We offer competitive health and wellness benefits, empowering you to value life in and out of the office
On-site gym, cafeteria, and health center
Open floor plan for Agile working, with communal meeting areas
Conveniently located nature trails, accessible year-round
Hear from our people and look inside our office: DB@The Muse

Your Key Responsibilities:
Help analyze user requirements and design appropriate Big Data solutions that best fit those requirements. Work in a cross functional Agile Scrum team to design, develop, test, and maintain solutions
Ensure that solutions are in line with department and domain architecture strategies and contribute to defining and improving those strategies
Help build, maintain, and continually implement tests for an automated testing framework that drives integration tests front to back across components
Contribute to meetings, Agile ceremonies and support deployment and system execution within a global organization
Work collaboratively - sharing your knowledge and learning from teammates areas outside your expertise
Your Skills and Experience:
Experience in software development projects in one or more of these areas OF Business Intelligence Reporting – Tableau, Java/Scala development, familiarity with Spring Boot is a plus
Familiarity with and/or demonstrated aptitude to learn Big Data technologies (Hadoop, HDFS, Spark, Hive, Impala, Yarn, Oozie), Artificial Intelligence / Machine Learning
Understanding of foundational computer science and architectural design patterns
Experience setting up CI/CD pipelines in a containerized deployment environment (Openshift, Cubernetes, Jenkins, etc.)
Excellent problem solving skills
For external candidates: Please note, we are unable to consider external candidates who require sponsorship for work visas for this position. Please continue to review the Deutsche Bank Careers website for other opportunities.

Our values define the working environment we strive to create - diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer.

We promote good working relationships and encourage high standards of conduct and work performance. We welcome applications from talented people from all cultures, countries, races, genders, sexual orientations, disabilities, beliefs and generations and are committed to providing a working environment free from harassment, discrimination and retaliation.

Click here to find out more about our diversity and inclusion policy and initiatives.

We are an Equal Opportunity Employer - Veterans/Disabled and other protected categories. Click these links to view the following notices: EEO is the Law poster and supplement; Employee Rights and Responsibilities under the Family and Medical Leave Act; Employee Polygraph Protection Act and Pay Transparency Nondiscrimination Provision.",3.5,"Deutsche Bank
3.5",North,"Frankfurt am Main, Germany",10000+ employees,1870,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),-1
Quantitative Analyst,-1,"The successful candidate will be a highly analytical individual with hands on programming skills. The candidate will work closely with the research team and clients towards the ongoing development and integration of new investment strategies, models and tools on Axle

Location

Mumbai
Responsibilities

Perform daily/weekly/monthly tasks of performance and risk reporting
Develop and automate investment processes and strategies via VBA and Matlab
Develop tools to integrate trading decision systems with risk management systems
Ad hoc tasks (such as operational tasks, internal documentation tasks and preparation of marketing materials)
Skills/Experience

Excellent programming skills in Matlab/Excel-VBA
Thorough with financial concepts and calculations like Drawdown, VaR, Eloss etc.
Understanding of financial market products like options, futures, FX forwards etc.
Working knowledge of Bloomberg is preferred
Should be self-driven and detail oriented with an analytical mindset
Should be a proactive and quick learner; a team player showing enthusiasm and drive to accomplish results in a fast paced environment
Min. 2 years of relevant work experience
Qualifications

B.Tech/M.Tech/MBA/CFA/FRM",5.0,"B&B Analytics
5.0",Mumbai,"Zug, Switzerland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"Candidate should have:
Knowledge of catastrophe data collection like Flood data, Earthquake data, Image processing data from satellite, LIDAR and Drone
Synthesizing and visualizing data for internal and external reporting

Personal Profile:
Education: MS / M tech/ M.Sc. in Geo Informatics or Environmental Science or Geology
Excellent written and verbal communication skills
Self-starter with an ability to collaborate actively with others in a cross-functional team
Problem solver and technology enthusiast
Creativity, innovation, and resourcefulness
Willingness to learn, and to innovate in a rapidly changing market
Ability to deal with ambiguity and change
""Roll-up your sleeves"" attitude to get things done

To Apply for this position send us your CV at careers@advancedRiskAnalytics.com",-1,Wayzontech Services,Pune,-1,-1,-1,-1,-1,-1,-1,-1
Data Analyst,-1,"We are currently looking out for a Data Analyst for one of our Client.
Minimum Qualification

3 Openings
6 month-1 years of experience in data-analytics; experience in the e-commerce industry is preferred
Must have a firm grasp and analyst-level understanding of database structures and strong hands-on ability to write SQL queries for data exploration/aggregation
Must have demonstrated hands-on development experience using Tableau or similar analytics/visualization tools
Advanced Excel proficiency including Pivot tables, vlookup / hlookup, graphs etc.
Strong sense of urgency
Self-starter with ability to work in a fast-paced environment
Preferred Qualification
Data Driven: Sharp aptitude and excellent numerical acumen; ability to sift through large volumes of data
Communication Skills: Good written and oral communication skills with the ability to present and clearly explain data to non-technical audiences
Industry and domain expertise: Sound knowledge on various trends, relevant statistical tools and also have the ability to understand the business environment & grasp the business expectations.",5.0,"BLEUMING TECHNOLOGIES
5.0",Chennai,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
DATA ANALYST,-1,"Job Description:
Interpret data, analyse results using statistical techniques and provide ongoing reports Develop and implement data collection systems, data analytics and other strategies that optimize statistical efficiency and quality Acquire data from primary or secondary data sources and maintain data set/data system Identify, analyse, and interpret trends or patterns in complex data set Filter and clean data by reviewing reports and performance indicators Prioritize business and information needs Define new process improvement opportunities Strong knowledge of SQL, programming (R, Python, Scala, Spark etc) Knowledge of statistics and experience using statistical packages for analysing datasets (Excel, SPSS, SAS etc) Strong analytical skills with the ability to collect,organize, analyse, and disseminate significant amounts of information with attention to detail and accuracy Adept at queries, report writing and presenting findings Responsibilities include conducting full lifecycle analysis to include requirements, activities and design with analysis and reporting capabilities. They will also monitor performance and quality control plans to identify improvements.
00-8.00 Years",-1,Advance Jobs Private Limited,Noida,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"“Make every logistics journey your best one yet” - Quincus
The Company.
At Quincus, our technology is designed to ease shipping issues—wherever in the world they may be. We commit ourselves in designing the most effective total end to end supply chain solutions through a dedicated technology ecosystem. This offers our users a personalized experience that bypasses traditional and expensive logistics options.
By combining advanced technology, data analytics, and hands-on experience, we eliminate traditional and expensive logistics options.

The Opportunity.
As our business continues to grow, we are looking for a Data Analyst to join our team who will discover the information hidden in vast amount of data and help make smarter decisions for better products. The primary role involves interpreting data, analyzing results using statistical techniques.
Your day to day.
-Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.
-Acquire data from primary or secondary data sources and maintain databases/data systems.
-Identify, analyze, and interpret trends or patterns in complex data sets.
-Identifying patterns and trends in data sets.
-Define new process improvement opportunities.

Who you are.
-3+ years of working experience as a data analyst or business data analyst.
-Hands on experience in MS Office Package with Advance Excel (Vlookup, Pivot table, HLookup, Conditional Formatting, UDFs, etc.)
-Technical expertise regarding data models, database design development, data mining and segmentation techniques.
-Knowledge of statistics and experience using statistical packages for analyzing datasets.
-Ability to analyse large datasets.
-An analytical mind and inclination for problem-solving.

What’s in it for you.
-People: Work with passionate, smart, and entrepreneurial go-getters.
-Fun environment: cool office space, stocked pantry, and team bonding.
-Compensation: competitive salaries and benefits.",4.4,"Quincus
4.4",New Delhi,"Singapore, Singapore",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Job Description

Eyeota is looking for an exceptional Data Engineer who can contribute to building a world class big data engineering stack that will be used to fuel our Machine Learning product pipeline. This person will be contributing to the architecture, operation and enhancement of:

1.) Our petabyte-scale data platform with a key focus on finding solutions that can support the Machine Learning product roadmap. This platform ingests terabytes of data daily which need to be made available to a variety of Machine Learning use cases.

2.) Our bespoke Machine Learning pipelines. This will also provide opportunities to contribute to the prototyping, building and deployment of Machine Learning models.

The candidate should have significant experience developing and operating a modern data pipeline platform and should have a keen interest in Machine Learning and Data Science

You:

· 2+ years related experience

· Deep technical understanding of Python Programming

· Production experience with Java and Golang is a plus

· Experience includes working in Agile/Lean model

· Experience with supporting and troubleshooting large systems

· Exposure to configuration management tools such as Ansible or Salt

· Exposure to IAAS platforms such as AWS, GCP, Azure

· Exposure to modern Big Data tech: Cassandra/Scylla, Kafka, Ceph, the Hadoop Stack, Spark, Flume, Hive, Druid etc while at the same time understanding that certain problems may require completely novel solutions

· Exposure to one or more modern ML tech stacks: Spark ML-Lib, Tensorflow, Keras, GCP ML Stack, AWS Sagemaker

· Good addition - Experience working with large-scale data

· Good addition - Good to have experience architecting, developing, and operating data warehouses, big data analytics platforms, and high velocity data pipelines

About Eyeota

Eyeota provides a dynamic, fun workplace filled with passionate individuals. We are at the cutting edge of advertising technology and there is never a dull moment at work.

We have a truly global footprint, with our headquarters in Singapore and offices in Berlin, London, Melbourne, New York, Sydney, and Tokyo.

Powered by JazzHR",3.2,"Eyeota
3.2",Pune,"Singapore, Singapore",51 to 200 employees,2010,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,"Lotame, Krux"
APAC Resources Consulting - Reliability Analytics Consultant - 9,-1,"Job Description

About Accenture:
Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries - powered by the world's largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com

About Accenture
Accenture is a leading global professional services company providing a broad range of services and solutions in strategy consulting digital technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions — underpinned by the world’s largest delivery network — Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With 492000 people serving clients in more than 120 countries Accenture drives innovation to improve the way the world works and lives. Visit us at www.accenture.com

Key responsibilities of the role:
To bring industry knowledge world class capabilities innovation and cutting-edge technology to our clients in the Resources industry to deliver business value.
To work with leading Resources clients major customers and suppliers to develop and execute maintenance and reliability strategies.
To harness extensive knowledge combined with an integrated suite of methods people and assets to deliver sustainable long term solutions.
Experience:
5-7 years of experience in Upstream OandG Downstream Refining and Petrochemicals Power Generation Utilities Mining Chemical plants
Hands on experience in Reliability centered maintenance .RCM. Asset Life Cycle Asset Criticality analysis Risk Management framework Maintenance Best Practices and Strategies
Hands on experience in tools such as SAP PM or Maximo or infor APM tools as – GE Meridium or Bentley asset wise or Aveva NRX Asset Hub Asset Answers
Qualifications
Qualification: • Engineering Degree .Tier-1 institutes. MBA or PGDM .preferred though not mandatory.",3.9,"Accenture
3.9",Gurgaon,"Dublin, Ireland",10000+ employees,1989,Company - Public,Consulting,Business Services,₹500+ billion (INR),"Cognizant Technology Solutions, EY, McKinsey & Company"
Data Analyst,-1,"Data Research Analyst
Research online to identify and capture accurate contact information of clients
Quality contacts based on project requirement
Maintaining and updating list/database on Excel or CRM
Make outbound calls to verify the information captured through online research
Be a team player, help achieve team goals and project timelines
Achieve monthly goals and targets
You are suitable for this role, if
You are internet savvy, and like reading, analyzing available online information
You can read and write in English language
You want to part of evergreen and growing IT industry
You can operate MS Excel and have typing speed of at least 25 WPM",3.6,"Unbound B2B
3.6",Pune,"Pune, India",51 to 200 employees,2017,Unknown,Publishing,Media,₹500 million to ₹1 billion (INR),-1
Data Analyst,-1,"Position Summary:
The Data Analyst is responsible for supporting activities associated with reporting and quality assurance of data in the technology development, implementation, and operational analysis. The data analyst will work to support a wide range of projects and requirements including report processing, data analysis, quality checking the data through generation of various reports, and working with customers to rectify data discrepancies and missing data in the operational processes. The data analyst must be able to use their analytical skillset to help prioritize development requirements with the highest value. The candidate will serve as the business mediator to the tech development team for all report related issues and enhancements. The Data Analyst will deliver business cases to schedule and develop reports using inputs from all functional areas of the company such as finance, operations, clinical, pharmacy services, etc.

Roles and Responsibilities:
Use data from company’s enterprise system to develop reports
Process information and data files to create invoices
Use BI tools and resources to Interpret data, analyze results using statistical techniques
Developing and implementing data analyses, data collection systems and other strategies that optimize statistical efficiency and quality
Acquiring data from primary or secondary data sources and maintaining databases
Provide support with management and maintenance of master data in the enterprise systems
Validate and Quality check sources of data, information, files, and consolidate them to create consistent reports
Develop, design, and maintain dashboards and reports for business owners in various functional areas such as Finance, Operations, Sales, etc.
Work closely with the technical team in extraction and development of data management tools and data to crate business/user friendly metrics, KPIs, and reports that can allow business owners to make decisions.
Produce actionable reporting products.

Technical Skills:
Proven work experience as a data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Knowledge and experience to use statistical packages for analyzing datasets (Excel etc.)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Expertise at resolving queries, report writing and present findings
Must have proficiency with MS Office and advance excel, internet and web-based applications
Strong writing skills for technical and business writing in ENGLISH

Specialized Skills:
Should be able to communicate effectively and confidently with business partners, project team members and senior management
Excellent verbal, written communication with the ability to develop and present information in various formats
Candidate should have ability to prioritize work, meet deadlines and work independently. Additionally, should be proactive to handle multiple projects and activities in a timely manner
Detailed experience in data management and reporting tools and applications
Excellent verbal and written communication in English
Ability to work with US, UK, and Canada based business owners in a professional business conducive communication style

Professional Experience:
0-3 years’ experience

Qualification:
Bachelor’s degree in any Analytics, Data, Business Intelligence or equivalent course.

Perks:
Monday to Friday – 5 Days work schedule
Health insurance benefits
Accidental and disability insurance benefits
Opportunity to grow and promote from within
Staff development activities

Do not apply if:
Unwilling to work in Night Shift. Must have proven experience in working with US based clients in the Night Shift
Not able to work on Advanced Excel
Not fluent in speaking, reading, writing English as this position requires fluent English language-based communication.",3.3,"kyte Tech Consulting LLP
3.3",Ahmedabad,"Ahmedabad, India",51 to 200 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"Working directly for the Head of Engineering and Analytics this role will include researching and developing data models as well as working with our internal team to support global clients to analyse big data sets from multiple sources and identify anomalies and key trends.

This role will include:
Working with developers on the development of software and tools
On-going research on new ideas and concepts around D&I
Assistance on social media and communications tasks relating to data
Bringing together disparate data sources & metrics from both internal and external data sources leveraging the latest cloud technologies and programming languages
Build data pipelines, data models & utilise predictive analytics that answer key questions in relation to the respective business units
Create relevant and meaningful outputs that enable data sharing and aid decision making
Make improvements and efficiencies to existing processes
Ability to report and present the analytical process and resulting insight

Knowledge and experience:
Ability to investigate data, find trends, forecast performance and provide insightful recommendations
Previous experience with data lakes and or data warehouses, preferably within AWS
Skilled in writing performant SQL & Python.
Experience with Google Cloud Data Analytics Products such as BigQuery, Data Flow, Data Proc etc. (or similar cloud-based platforms)
Experience with statistical programming languages
Working knowledge of data science modelling concepts
Enthusiasm to explore new technologies, methods and techniques.
Strong analytical and problem-solving skills
Sound understanding of mathematical concepts behind data analysis
Thorough knowledge of probability theory and statistics
Background in mathematics / statistics / probability

Experience in one of the functional areas below is essential, exposure to more than one is extremely beneficial.

Solid data engineering experience preferably using AWS services
Solid data visualisation and MI reporting experience

Additional details:
In Diverse Company works with global organisations to help build inclusive cultures and develop diverse workforces. This is at the heart of what we do for our clients, and we ensure we are maintaining an inclusive environment for all our employees too. We are a fast-growing start-up organisation, currently building our client base with lots of exciting opportunities around the world.

In Diverse Company is committed to promoting a diverse and inclusive workplace – a place where we can all be ourselves and succeed. We offer a range of family friendly, inclusive employment policies, flexible working arrangements, facilities and services to support employees from all different backgrounds. We are committed to providing development opportunities to all our employees.

Competitive salaries are offered for all roles.

This role will be based in our office in Mumbai, however there may be the need to travel.",-1,In Diverse Company,Mumbai,"Prairieville, LA",1 to 50 employees,-1,Company - Public,-1,-1,Less than ₹10 million (INR),-1
AI/Machine Learning Engineer {Premium Colleges only},-1,"Requirements

We are looking for applicants with a strong background in Analytics and Data mining (Web, Social and Big data), Machine Learning and Pattern Recognition, Natural Language Processing and Computational Linguistics, Statistical Modelling and Inferencing, Information Retrieval, Large Scale Distributed Systems and Cloud Computing, Econometrics and Quantitative Marketing, Applied Game Theory and Mechanism Design, Operations Research and Optimization, Human Computer Interaction and Information Visualization. Applicants with a background in other quantitative areas are also encouraged to apply.

We are looking for someone who can create and implement AI solutions. If you have built a product like IBM WATSON in the past and not just used WATSON to build applications, this could be the perfect role for you.

All successful candidates are expected to dive deep into problem areas of Zycus’ interest and invent technology solutions to not only advance the current products, but also to generate new product options that can strategically advantage the organization.

Skills:
Experience in predictive modelling and predictive software development
Skilled in Java, C++, Perl/Python (or similar scripting language)
Experience in using R, Matlab, or any other statistical software
Experience in mentoring junior team members, and guiding them on machine learning and data modelling applications
Strong communication and data presentation skills
Classification (svm, decision tree, random forest, neural network)
Regression (linear, polynomial, logistic, etc)
Classical Optimization(gradient descent, newton raphson, etc)
Graph theory (network analytics)
Heuristic optimisation (genetic algorithm, swarm theory)
Deep learning (lstm, convolutional nn, recurrent nn)
Must Have:
Experience: 1-9 years
The ideal candidate must have proven expertise in Artificial Intelligence (including deep learning algorithms), Machine Learning and/or NLP
The candidate must also have expertise in programming traditional machine learning algorithms, algorithm design & usage
Preferred experience with large data sets & distributed computing in Hadoop ecosystem
Fluency with databases
Benefits",3.3,"Zycus
3.3",Mumbai,"Princeton, NJ",501 to 1000 employees,1998,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),"SAP Ariba, GEP, Coupa Software Inc"
Machine Learning Engineer/Junior Data Scientist,-1,"Looking for Machine Learning Engineers/Junior Data Scientist having 2+ years experience in Machine Learning, Data Science and Artificial Intelligence.

Job Types: Full-time, Walk-In

Experience:
Machine Learning: 2 years (Preferred)
work: 2 years (Preferred)
total work: 2 years (Preferred)
Education:
Bachelor's (Preferred)",-1,Sonicsoft Solutions Pvt Ltd,Visakhapatnam,-1,-1,-1,-1,-1,-1,-1,-1
MACHINE LEARNING ENGINEER,-1,"Duties and Responsibilities
Looking for passionate individuals with strong machine learning background.
Hands-on expertise in Artificial Intelligence, Machine Learning, Neural Networks, Applied Mathematics and Computer Vision.
Develop and design algorithms and frameworks in terms of API to leverage the data.
Work closely with technical leads and Product Managers to meet deliverables and contribute to data-driven the development of cutting-edge technologies.
Good Knowledge on the database can be an added advantage.
Exposure to IoT, Human-Robot/Human-Computer interaction, big data interpretation/crunching to unleash the power of data, generate predictions which can help automated solutions for improved user experiences.",4.4,"Neva Ventures
4.4",Bengaluru,"Menlo Park, CA",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Your Profile
Design and implementation of analytics execution framework
Implementation of model workflows to prepare/analyse/learn/predict and supply the outcomes through API contract(s)
Establishing programming patterns, documenting components and provide infrastructure for analysis and execution
Set up practices on data reporting and continuous monitoring
Provide excellence, open to new ideas and contribute to communities
Industrialise the data science models and embed intelligence in product & business applications
Collaborate with multiple groups and produce operational efficiency

Your Checklist
BE/Masters in Computer Science
2+ relevant work experience in Big Data ecosystem handing petabytes of data as Data Engineer
Working experience in HDFS, Big table, MR, Spark, Hive, Pig,Flume etc..
Advanced proficiency in Java/Scala, SQL, NoSQL
Strong knowledge in Shell/Perl/R/Python/Ruby
Proficiency in Statistical procedures, Experiments and Machine Learning techniques.
Exceptional problem solving abilities",3.7,"BookMyShow
3.7",Mumbai,"Mumbai, India",1001 to 5000 employees,2007,Company - Private,Ticket Sales,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1
Zensar is hiring for Data Engineer Professionals,-1,"1.Document DB (Preferably Couchbase/cosmos) (Good to have)
2.ADF (Should have)
3.Python (Must have)
4.Kafka (Must have)
5.Azure Synapsis (DW) (Good to have)
6.Azure HD Insight (Should have)
7.Working experience with campaigns and mobile apps data (Structured/Semi structured data) (Must have)
8.Knowledge on Data Governance Tools (Should have)

5.00-10.00 Years",3.3,"Zensar Technologies Limited
3.3",Bengaluru,"Pune, India",5001 to 10000 employees,2001,Company - Public,IT Services,Information Technology,₹10 to ₹50 billion (INR),-1
Data Analyst India,-1,"Roche is an equal opportunity employer.
Information Technology, Information Technology > IT Architecture",4.1,"Roche
4.1",Mumbai,"Basel, Switzerland",10000+ employees,1896,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹500+ billion (INR),"Novartis, AstraZeneca, Siemens Healthineers"
Bioinformatic (Data Scientist) -Variant analyst,-1,"Job Location – Pune – India
Required experience – 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial

Innoplexus at its core uses AI to provide non-obvious insights to researchers by acquiring and analyzing the word’s knowledge in bioinformatics.

Our products leverage proprietary algorithms and patent pending technologies to help global Life sciences & Financial services organizations with access to relevant data, real time intelligence & intuitive insights, across the life cycle of the products.

We automate the collection, curation, aggregation, analysis & visualization, of billions of data points from thousands of data sources, using domain-specific language processing, ontologies, computer vision, machine learning, network analysis and more.

You are the right person in our team if you can:
Understand Biological data, molecular biology, computational biology, proteomics and genomics data
Should have a very fair understanding of Adverse Events and Toxicity
Application of Machine Learning or Deep Learning experience in biological data
Sound understanding of uses of NLP in biological data
Hands on experience of Applied Statistics in Life Science data
Understand R, Python, Weka, Spark and latest technologies in data sciences
Knowledge of Proteins, Drugs, Clinical trials and Literatures databases is required

We need you to have:
BTech or MSc or M Pharma or PhD in Biotechnology/Bioinformatics/Cheminformatics/Pharmacoinformatics/Pharmacy

To excel in this job, you must bring 3-5 Years with M.Sc. or 2-4 Years with PhD of academic/Industrial with experience in:

Good presentation and communication skills
Strong leadership qualities. Ready to own the work
Experience in CRO or Pharma is desirable
Working experience on Adverse Events and Toxicity module
Good analytical and reasoning skills
Track record of managing small team is an advantage
Understanding of Biological data and databases is a plus
Knowledge of databases like Proteins, Drugs and Literatures databases is desirable
Research paper publications in good journals

Innoplexus believes in the power of collaboration and teamwork. You will work and grow alongside creative thinkers to turn great ideas into reality. We will help you develop your skills with training courses and knowledge sharing.",4.1,"Innoplexus
4.1",Pune,"Frankfurt am Main, Germany",201 to 500 employees,2011,Company - Private,Consulting,Business Services,₹100 to ₹500 million (INR),"Palantir Technologies, Mu Sigma, IQVIA"
Data Engineer,-1,"About Us:
HealthifyMe was founded in 2012 by Tushar Vashisht and Sachin Shenoy, and incubated by Microsoft Accelerator. Today, we are India and South East Asia's largest and most loved health & fitness app, with over 16 Million users from 300+ cities in India+SEA and rated over 4.6/5. The HealthifyMe mobile app has been rated as the top Health/Fitness app on Play Store by Google for the last 3 years, and has received the prestigious 'Editor's Choice' badge by Google.Our coaching services are delivered by a world class team of over 500 coaches including nutritionists, trainers and yoga instructors. We combine the power of artificial intelligence and human empathy to deliver measurable impact in the lives of our consumers. We launched the world's first AI nutritionist 'Ria' with learnings developed from billions of data points on consumer lifestyles, coupled with 400 man-years of nutritionist/fitness intelligence.

HealthifyMe has raised over $25 Million in funding from marquee investors such as Sistema, IDG, Inventus, Blume and Samsung Next. HealthifyMe works with over 75 corporates across the country to deliver employee wellness solutions. We aspire to be a leading health and fitness platform across the globe.

Data Engineer Responsibilities:
Design, construct, install, test and maintain data pipeline and data management systems.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Collaborate with members of your team (eg, Data Architects, the Software team, Data Scientists) on the project’s goals.
Recommend different ways to constantly improve data reliability and quality.

Data Engineer Requirements:
Experience in a related field with real-world skills and testimonials from former employees.
Familiar with data warehouses like Redshift, Bigquery and Athena.
Familiar with data processing systems like flink, spark and storm.Develop set
Proficiency in Python and SQL.Possible work experience and proof of technical expertise.
You may also consider a Master’s degree in computer engineering or science in order to fine-tune your skills while on the job. (Although a Master’s isn’t required, it is always appreciated).
Intellectual curiosity to find new and unusual ways of how to solve data management issues.
Ability to approach data organization challenges while keeping an eye on what’s important.

Look forward to:
Working with a world-class team.
Fun & work at the same place with an amazing work culture and flexible timings.
Get ready to transform yourself into a health junkie
Join HealthifyMe and Make History!",3.7,"HealthifyMe Wellness Private Limited
3.7",Bengaluru,"Bengaluru, India",501 to 1000 employees,2012,Company - Private,Healthcare Services & Hospitals,Healthcare,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ref #:
5576285

Department:
Information Technology

City:
Bangalore

State/Province:
Karnataka

Country:
India

Company Description
Ralph Lauren Corporation (NYSE:RL) is a global leader in the design, marketing and distribution of premium lifestyle products in four categories: apparel, home, accessories and fragrances. For 50 years, Ralph Lauren's reputation and distinctive image have been consistently developed across an expanding number of products, brands and international markets. The Company's brand names, which include Ralph Lauren Purple Label, Ralph Lauren Collection, Double RL, Polo Ralph Lauren, Polo Ralph Lauren Children’s, Ralph Lauren Home, Lauren Ralph Lauren, RLX, American Living, Chaps and Club Monaco, constitute one of the world's most widely recognized families of consumer brands.

Position Overview
Who we are:

The Ralph Lauren Corporation, a global leader in luxury fashion and design. Our Global Development Center (GDC) is focused on building high-quality technology solutions to enhance the business & customer experience across channels and geographies.

Ralph Lauren is embarking on a multi-year Transformational journey to Digitize the Value Chain (DVC) which will reinvent the way we work by leveraging our talent and creativity with the latest innovations, lean processes, data driven & implementing modern technologies.

The Program will consist of COE teams across 4 Tracks: Product Transformation, Supplier Collaboration, Supply & Demand Alignment and a Data team that will consist of a hybrid of talent with business, technology and analytical experience.

The Data Engineer, DVC is an emerging role in Ralph Lauren’s DVC Data team and will play a pivotal role in delivering insights for the most critical data and analytics initiatives for Ralph Lauren.

Purpose & Scope: Based in Bengaluru, India this Data Engineer will work with the DVC program & Global Analytics team to build, maintain, and optimize data pipelines for key data and analytics consumers including business and data analysts and data scientists covering our digital and physical channels and value chain. Data engineers also need to guarantee compliance with data governance and data security requirements while creating, improving and operationalizing these integrated and reusable data pipelines. This would enable faster data access, integrated data reuse and vastly improved time-to-solution for Ralph Lauren’s data and analytics initiatives. The data engineer will be measured on their ability to integrate analytics and (or) data science results with Ralph Lauren’s business processes.

This role will require both creative and collaborative working with IT and the wider business. It will involve evangelizing effective data management practices and promoting better understanding of data and analytics. The data engineer will also be tasked with working with key business stakeholders, IT experts and subject-matter experts to plan and deliver optimal enterprise data assets.

Essential Duties & Responsibilities
Build data pipelines: The primary responsibility of data engineers is to architect, build, and maintain data pipelines that will provision high quality data ready for analysis. This includes ingestion, exploration, modeling, and curation of high value data.
Drive Automation through effective metadata management: The data engineer will be responsible for using innovative and modern tools, techniques and architectures to partially or completely automate the most-common, repeatable and tedious data preparation and integration tasks in order to minimize manual and error-prone processes and improve productivity.
Learning and using modern data preparation, integration and AI-enabled metadata management tools and techniques.
Tracking data consumption patterns.
Performing intelligent sampling and caching.
Monitoring schema changes.
Recommending — or sometimes even automating — existing and future integration flows.
Educate and train: The data engineer should be curious and knowledgeable about new data initiatives and how to address them. This includes applying their data and/or domain understanding in addressing new data requirements. They will also be responsible for proposing appropriate (and innovative) data ingestion, preparation, integration and operationalization techniques in optimally addressing these data requirements. The data engineer will be required to train counterparts such as data scientists, data analysts, LOB users or any data consumers in these data pipelining and preparation techniques, which make it easier for them to integrate and consume the data they need for their own use cases.
Participate in ensuring compliance and governance during data use: It will be the responsibility of the data engineer to ensure that the data users and consumers use the data provisioned to them responsibly through data governance and compliance initiatives. Data engineers should work with data governance teams (and information stewards within these teams) and participate in vetting and promoting content created in the business and by data scientists to the curated data catalog for governed reuse.
Become a data and analytics evangelist: The data engineer will be considered a blend of data and analytics “evangelist,” “data guru” and “fixer.” This role will promote the available data and analytics capabilities and expertise to business unit leaders and educate them in leveraging these capabilities in achieving their business goals.

Experience, Skills & Knowledge
Education and Experience
A bachelor's or master's degree in computer science, statistics, applied mathematics, data management, information systems, information science or a related quantitative field is required.
The ideal candidate will have a combination of IT skills, data governance skills, analytics skills and Retail industry knowledge with a technical or computer science degree.
At least 5 years or more of work experience in data management disciplines including data integration, modeling, optimization and data quality, and/or other areas directly relevant to data engineering responsibilities and tasks.
At least 3 years of experience working in cross-functional teams and collaborating with business stakeholders in Retail in support of a departmental and/or multi-departmental data management and analytics initiative.
Deep Retail Industry knowledge or previous experience working in the business would be a plus.

Technical Knowledge/Skills
Strong experience with advanced analytics tools for Object-oriented/object function scripting using languages such as R, Python, Scala, or similar.
Strong ability to design, build and manage data pipelines in PySpark and related technologies for data structures encompassing data transformation, data models, schemas, metadata and workload management. The ability to work with both IT and business in integrating analytics and data science output into business processes and workflows.
Strong experience with popular database programming in relational and nonrelational environments including on AWS Redshift, AWS Aurora, SQL Server and similar platforms.
Experience in working with large, heterogeneous datasets in building and optimizing data pipelines, pipeline architectures and integrated datasets using traditional data integration technologies. These should include ETL/ELT, data replication/CDC, message-oriented data movement and upcoming data ingestion and integration technologies such as stream data integration and data virtualization.
Strong experience in working with and optimizing existing ETL processes and data integration and data preparation flows and helping to move them in production.
Experience in working with both open-source and commercial message queuing technologies such as Kafka, Amazon Simple queuing Service, stream data integration technologies such as Apache Nifi, Apache Kafka Streams, Amazon Kinesis and stream analytics technologies such as Apache Kafka KSQL.
Basic experience working with popular data discovery, analytics and BI software tools like MicroStrategy, Tableau, Qlik, PowerBI and others for semantic-layer-based data discovery.
Basic understanding of popular open-source and commercial data science platforms such as Python, R, KNIME, Alteryx, others are a strong plus but not required/compulsory.
Basic experience in working with data governance, data quality, and data security teams and specifically and privacy and security officers in moving data pipelines into production with appropriate data quality, governance and security standards and certification.
Demonstrated ability to work across multiple deployment environments including cloud, on-premises and hybrid, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service and others.
Experienced in agile methodologies and capable of applying DevOps and increasingly DataOps principles to data pipelines to improve the communication, integration, reuse and automation of data flows between data managers and consumers across an organization

Interpersonal Skills and Characteristics
Strong experience supporting and working with cross-functional teams in a dynamic business environment.
Required to be highly creative and collaborative. An ideal candidate would be expected to collaborate with both the business and IT teams to define the business problem, refine the requirements, and design and develop data deliverables accordingly. The successful candidate will also be required to have regular discussions with data consumers on optimally refining the data pipelines developed in nonproduction environments and deploying them in production.
Required to have the accessibility and ability to interface with, and gain the respect of, stakeholders at all levels and roles within the company.
Is a confident, energetic self-starter, with strong interpersonal skills.
Has good judgment, a sense of urgency and has demonstrated commitment to high standards of ethics, regulatory compliance, customer service and business integrity.
#LI-AD1

Data Engineer",3.6,"Ralph Lauren
3.6",Bengaluru,"New York, NY",10000+ employees,1967,Company - Public,Other Retail Shops,Retail,₹500+ billion (INR),-1
Machine Learning Engineer,-1,"Kanpur

ITH Technologies Pvt. Ltd. is a leading technology infrastructure development and consulting ﬁrm that offers a complete suite of an End-To-End solution to clients and partners around the globe. We build strong and unique business relationship with partners, as most of the times we don’t charge in up-front money but in equity. This helps us create capital, corporate, and entity for a stable future and also brings in-house like quality to our partner products.

By combining practical industry-speciﬁc knowledge with cutting-edge business management practices, we ensure our clients get increased efficiency and better business performance. We have a team with a passion for developing and delivering enterprise-grade applications. Our passion is not dependent on the size of the enterprise. Hence, we are able to architect a solution with the best and latest of tech even for a Startup or SME.

About BrainAlive Research

BrainAlive, a technology research and development company parented by ITH technologies, is currently developing a non-invasive, wearable bio-signal acquisition and monitoring system that would empower you to develop a crisp, conscious understanding of your physiology, especially relating to your cognitive abilities. The system acquires various physiological parameters from your skin, analyzes the acquired data and provides tangible conclusions in the form of easily understandable and interactive visuals. It gives you a clear image of your level of involvement in any activity, and helps you to understand the factors influencing it. BrainAlive has the ultimate goal of helping you understand, and minimise, the elements limiting your potential, thereby enhancing your overall productivity, and the quality of results.

ROLE : DIGITAL SIGNAL PROCESSING – MACHINE LEARNING ENGINEER ...
We are looking for highly talented and motivated Digital Signal Processing (DSP) Engineers, preferably with experience in analyzing biosignals, to join our Embedded & Robotics team.
You will be part of a team of researchers & engineers where you will focus on designing and implementing algorithms for advanced brain-computer interface.
Your research & development will help power the coming generation of EEG-based human- machine interfaces.
ROLES AND RESPONSIBILITIES ...
Conducting data processing and analysis, using DSP techniques and methods, to extract information of the EEG signal data for detection of various attributes of the mental state of a subject. Designing Machine Learning algorithms for electro-physiological signals in numerical analysis languages : Matlab, Python, C/C++etc.
Demonstrating algorithms meeting accuracy requirements on general user population through statistical analyses and error estimation.
Writing technical reports summarizing development, analysis, training and validation of the algorithms.
BASIC QUALIFICATIONS ...
B.Tech./M.Tech/Ph.D in Computer Science or Electronics (Machine Learning, AI, Statistics, or equivalent);
Strong technical skills, deep understanding, work experience and or exposure to DSP implementations, filtering, transforms, data visualization, machine learning, timing and signal recovery.
Willingness to divert from the conventional methods to explore alternative approaches.
Knowledge of optimization, multi-threaded development and cross-platform development.
Experience in statistical analysis and programming projects on data analysis algorithms / signal processing.
Experience using Python , , C++ , R, MATLAB, Java or similar scripting language;
PREFERRED QUALIFICATION ...
More than 2 years of industrial/academic experience in building ontology mapping and extraction models
Experience with real-time signal processing.
Experience in advanced signal analysis of physiologic signals required with specific knowledge in EEG preferred.
Extensive practical experience in several of the following areas: ML, Natural Language Processing, Ontology mapping, Clustering techniques, applied ML or AI features/products/systems
Ability to handle multiple competing priorities in a fast-paced environment
Significant peer reviewed scientific contributions in premier journals and conferences
Proven track record of production achievements
Strong personal interest in learning, researching, and creating new technologies with high customer impact
Experience with defining research and development practices in an applied environment
Superior verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts.
Strong fundamentals in problem solving, algorithm design and complexity analysis",4.1,"ITH Technologies
4.1",Kanpur Nagar,"Kanpur, India",51 to 200 employees,2008,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"About Us:

Paxcom a leading Digital Solution Provider is a part of PaymentUs now, a leading electronic bill payment provider. PaymentUs leads the North American marketplace in electronic bill payment solutions and have recently signed partnerships with Paypal and Alexa.

We are looking for passionate programmers skilled in Java, Python, Angular, Dotnet, NodeJS, Python, Jenkins, Postgresql, Docker, Kubernetes, Spark and AWS to join our development team.

For more details please visit https://paxcom.ai/

Job Description:
In this position, the AI/ML Specialist will work with stakeholders and technical team members to deliver capabilities through agile acquisition, by leveraging advanced latest technology.
Must have at least 2+ years relevant experience in Data Science / Engineering
BS, Master's or PhD in data science, math, computer science, or a related field
2+ years of machine learning experience.
Experience with machine learning and artificial intelligence techniques and their implementations in open source technologies.
Experience in retrieving, manipulating, fusing, and exploiting multiple structured and unstructured data sets from various sources.
Experience with analyzing large volumes of data using distributed processing architectures with open source tools (e. g. Spark, Python, or R).
Should have leverage knowledge of data science, methodologies, and processing techniques to analyze vast amounts of chat data for monitoring & support.
Work with an agile team to develop machine learning analytics across different domains where chat has been implemented.
Experience with performing statistical analysis, data mining, temporal and pattern analysis,correlation of events, predictive modeling, and pattern recognition for various use cases.
Good with document and visualize analytics both temporally and spatially, and present analytic results and uncertainty to decision-makers.
What we expect from you?
You have the ability to work in a fast-paced environment adapting to changing priorities
You are focused and detail oriented but know when to seek help from others
You have excellent written and verbal communication skills to articulate problems and solutions to both technical and non-technical audiences
You possess superior troubleshooting and analytical skills to determine the root cause of issues
You strive to identify areas of improvement and work proactively to prevent issues from occurring
You are a self-starter with an appreciation for tackling technical challenges of varying complexity
You are diligent when making decisions and can easily justify your actions.
Why Join us?
You hate micromanagement and freedom to work is important to you
Enjoy flexible and relaxed work environment
Work life Balance is important to you
Enjoy Motivating Working Conditions
A friendly, Supportive, Professional and achievement-oriented management team
Competitive remuneration
An opportunity to learn new things every day and work on latest technologies",3.5,"Paxcom India Pvt. Ltd
3.5",New Delhi,"Gurgaon, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Junior Data Analyst (contract - 6 months),-1,"As the research and analysis division of the Economist Group, The Economist Intelligence Unit (EIU) helps leaders prepare for opportunity, empowering them to act with confidence when making strategic decisions. The EIU is the global standard in providing quality, actionable intelligence to the public and private sector, assessing issues that impact the marketp for over two hundred countries.
We are are seeking junior data analyt(s)–on a contractual basis–to implement upgradation to data structures that underpins our in-house economics modelling platform/engine. The data analyst(s) would work within the quantitative economics team, under a team leader and would work very closely with the data engineering team for the solution implementation.
This role will be based in Gurgaon. It will be a 6 months contract, extendable by 1 or 2 more months if required.

How you will contribute:
Creation and collation of source data file(s)
Solution implementation for the development of the data customization engine
Validation of rule(s) that will govern the customization engine
Perform quality assurance test(s), as when required

The ideal skills for this role are:
Graduate/Post-Graduate degree in economics/statistics/mathematics/engineering or similar field(s)
Advanced Microsoft Excel skills – experience with formula auditing, manipulating and cleaning large data sets in excel, knowledge of advanced functions like VLookup/HLookup, Match, Offset, Index, Indirect, Nested If-Then-Else and similar
Basic proficiency in Python programming is desirable
Demonstrable proficiency in handling large, multivariate datasets
Domain knowledge – Basic unnderstanding of macro-economic data and indicators is desirable
Proficiency in use of Haver database in desirable",4.1,"The Economist
4.1",Gurgaon,"London, United Kingdom",1001 to 5000 employees,1843,Company - Private,Publishing,Media,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"The Senior Data Scientist will participate in requirement gathering including data discovery, system design, model implementation, code reviews, testing and maintenance of the platform developing applications Python, predictive modelling and analysis. The role will require a deep understanding of Computer Vision, deep learning, machine learning techniques and you will be part of a highly focused development team that includes data scientists, data engineers and business analysts and guiding them to help build products and specialized services on offer to our clients across multi-platform environment. The role offers a high degree of challenge and provides opportunity to experiment offerings that speaks of innovation.

Skills required

6+ years of relevant industry or research experience with strong knowledge of data mining, machine learning techniques, algorithmic optimization techniques, developing applications using predictive modelling and analysis.
Work closely with data engineering and technology teams to transfer knowledge and processes into production environment. Demonstrated experience in designing Platform Roadmap for key products and solutions.
Strong in Predictive and Prescriptive analytics approaches and experienced in operating tools like R and in programming using Python.
Understanding python integration with MySQL, Django, flask and REST API.
Knowledge of Image processing libraries such as OpenCV, PIL, and pytesseract.
Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems. A thought leader with excellent written and verbal communication skills.
Familiarity with the fast-paced startup environment and culture that fosters a shared purpose among team by building a collaborative work environment
Capable of building & sustaining long-term relationships with businesses and internal & external stakeholders.
Ability to simultaneously mantle project responsibilities and with limited supervision.

Education

PhD/MTech/MS/M. Stat or equivalent degree in Computer Science or Economics or Mathematics or Operational research (OR) or Statistics.

For any query, you may reach amitabh.ranjan@karvy.com.

About Karvy Analytics

Karvy Analytics is a new age arm of the leading Karvy Conglomerate. A focussed Analytics company, the young and forward thinking team is building world class solutions for the global analytics universe in Banking & Financial Services, Healthcare and Retail domain. Karvy Analytics offers a range of solutions that bring immediate business benefits to our global customers by leveraging big data, statistical and mathematical modelling techniques, social analytics, and mobile descriptive analytics for new business insights.

We provide an integrated decision support ecosystem of services across-industry, enabling and transforming the way decisions are taken.",1.0,"Karvy Analytics
1.0",Hyderabad,"Hyderabad, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst - Credit and Risk,-1,"Job Description:


·
Work closely with business teams to identify
specific insights that can drive business impact. You will be a part of the
Credit and Risk team.

·
Hands-on experience on SQL

·
Ability to effectively engage with business
stakeholders and translate business requirements into high impact reports and
visualizations

·
Developing new capabilities for our clients
beyond static reports and spreadsheets (focus on PowerBI, Data Studio and
Tableau products.

·
Hands-on experience on integrating, querying and
preparing datasets for reporting and analytics

·
Data mining within the organization as well as
enrich data from 3rd party databases

·
Experience working in an agile development
environment.

·
Work proactively with Product functions to
translate insights into actionable items.

Requirements and qualifications

·
Experience of 2+ yrs of experience in Data
Visualization & Reporting.

·
Bachelor Degree in Computer Science / IT /
Electronics / Statistics / Mathematics
Role Category:

Credit & Risk

Location:

Mumbai, India, Asia

Employment Type:

Full time

Key Skills:",3.0,"FlexiLoans Technologies
3.0",Mumbai,"Mumbai, India",201 to 500 employees,2016,Company - Private,Lending,Finance,Unknown / Non-Applicable,"LendingKart, Capital Float, NeoGrowth Credit"
Data Scientist Lead role chennai (IT Jobs),-1,"The Data Scientist Lead is responsible for Identify, develop and implement the appropriate statistical techniques, algorithms and Deep learning / ML Models to create new, scalable solutions that address business challenges across industry domains.

Position : Permanent
Location : Chennai
Salary : upto 50L p.a based on experience

Job Details:
Data Scientist Lead Role :
Responsibilities :
Responsibilities include Identify, develop and implement the appropriate statistical techniques, algorithms and Deep learning / ML Models to create new, scalable solutions that address business challenges across industry domains , as well as provide actionable insights with a clear impact on ROI.

Define and develop, maintain and evolve data models, tools and capabilities

Communicate your findings to the appropriate teams through visualisations

Collaborate and communicate findings to diverse stakeholders Provide solutions but not limited to: Object detection/Image recognition, natural language processing, Sentiment Analysis, Topic Modeling, Concept Extraction, Recommender Systems, Text Classification, Clustering , Customer Segmentation & Targeting, Propensity Modeling, Churn Modeling, Lifetime Value Estimation, Forecasting, Modeling Response to Incentives, Marketing Mix Optimization, Price Optimization, Ability to build, train and lead a team of data scientists

Qualifications and Experience : Bachelors/ Masters/ PhD degree in Math, Computer Science, Information Systems, Machine Learning, Statistics, Econometrics, Applied Mathematics, Operations Research or related technical degree with ability to break a complex business problems

Experience : 10 plus years total experience with minimum of 5 years of experience in a related position, as a data scientist or business analyst building predictive analytics solutions for various types of business problems

Advanced knowledge of statistical techniques, machine learning algorithms and deep learning frameworks like Tensorflow, Theano, Keras, Pytorch

Minimum 5 years of Programming background and expertise in building models using at least one of the following languages: SAS, Python, R ,Java

Bonus points for implementation of deep learning based models for image classification, Document classification models, object detection, logo detection and ML packages etc.

Strong individual planning and project management skills, able to juggle multiple tasks and priorities Self-motivated and driven to deliver agreed results on-time

Strong story-telling & articulation skills - ability to convert analytical output into clear, concise, and persuasive insights & recommendations for technical & non-technical audience

Strong influence and relationship management skills; comfortable interacting with all management levels; Prior experience in providing strategic analysis and consulting

Track record of delivering strong business results.

Seniority Level : ?Senior /Specialist

?Job Location :? ?Chennai

Employment Type : ?Full-time? ?Annual Compensation : ? ?25 to 50 L p.a based on Exp.",-1,HR Inc Consultants,Chennai,"Orlando, FL",Unknown,-1,Private Practice / Firm,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"Emtec is a Global consulting company that provides technology-empowered business solutions for world-class organizations. Our Global Workforce of over 800 consultants provide best in class services to our clients to realize their digital transformation journey. Our clients span the emerging, mid-market and enterprise space. With multiple offices worldwide, we are uniquely positioned to deliver digital solutions to our clients leveraging Microsoft, Java and Open Source with a focus on Mobility, Cloud, Data Engineering and Intelligent Automation. Emtec’s singular mission is to create “Clients for Life” - long-term relationships that deliver rapid, meaningful, and lasting business value.
At Emtec, we have a unique blend of Corporate and Entrepreneurial cultures. This is where you would have an opportunity to drive business value for clients while you innovate and continue to grow and have fun while doing it. You would work with team members who are vibrant, smart and passionate and they bring their passion to all that they do – whether it’s learning, giving back to our communities or always going the extra mile for our client.

This position requires the ability to act as Digital Data Engineer. We are seeking a talented and energetic individual with strong work ethics, a natural problem-solver with advanced communication and interpersonal skills, a positive 'can do' attitude and a passion for software development.
Must Have Skills:
4-7 years of total work experience
At least 3 years experience in development of analytics based solutions that produce quantitative and qualitative business insights
Should have good experience in Azure/AWS BI services
Experience of implementing robust data pipelines within Microsoft Azure/AWS stack
Good knowledge of programming languages like C#, Python, Javascript, R
Should be well versed with BI tools integrations like PowerBI/Tableau
At least 4 years experience in all aspects of software lifecycle - application, structure, debugging, performance, security and deployment
At least 3 years experience in developing with Microsoft SQL server or equivalent database backend
Professional Skills:
Ability to work independently and collaboratively with a team
Ability to work under pressure, adapt to demanding situations, and consistently meet project deadlines
Excellent written and verbal communication skills
The candidate should have an ability to work in a team environment as well as work individually, should be a self-starter, and should be able to motivate the team
Emtec is an equal opportunity employer",3.7,"Emtec, Inc.
3.7",Pune,"Jacksonville, FL",501 to 1000 employees,1995,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹10 to ₹50 billion (INR),-1
Data Analyst,-1,"The candidate must have extensive experience in SQL and Advanced SQL with strong ability to process and analyse complex data
Multistep Query execution / Optimized SQL queries
Functionality with Staging Tables
Handling multiple data with 30 or 40 column
The candidate should also have an ability to design, build, and maintain the business's and data warehouse The candidate will also demonstrate expertise in data modeling and query performance tuning on SQL Server,
Excellent at communicating and articulating ideas and an ability to influence others as well as drive towards a better solution continuously.
Experience working in python, Hive queries, spark, sparkSQL,
Programmatic Thinking
Relate Metrics to product
Good Communication
Product functionality understanding
Knowledge / understanding in analytics experience.
00-5.00 Years
Other",3.9,"Confederation of Real Estate Developers' Associations of India
3.9",Chennai,"Mumbai, India",10000+ employees,-1,Non-profit Organisation,-1,-1,Unknown / Non-Applicable,-1
Data Analyst (Power BI),-1,"Writing the future. Together.
Avaloq is a value driven, fast-paced financial technology and services company and we are committed to developing the banking solutions of tomorrow.

By joining Avaloq, you’ll become a key part of our effort to power the digital transformation of the financial services industry. Our ambition is big and bold – to provide full end-to-end digital solutions by combining our leading efficiency with a flexible, responsible digital user experience. Headquartered in Zurich, Avaloq has over 2,000 employees globally. More information is available at www.avaloq.com

Your team
You will work for the focused and international “Global Inventory & Reporting” team, collaborating with outstanding colleagues. The “Global Inventory & Reporting” team is the competence center for inventory and reporting functions in the global Customer Service Delivery Division (CSDO). The team operates and evolves the reporting processes and tools. The Reporting functions will be consolidated on a Microsoft BI platform.

Your mission
Develop and manage on a portfolio of existing, Power BI based reports
Data validation and reconciliation
Facilitate stakeholder discussions and evaluate requirements
Ensure the timely delivery of standard reports
Ad-hoc data analysis for senior management
What you need
Strong Microsoft BI skills and experience.
Microsoft Office Package proficiency
International mindset – integration into global delivery model.
Flexibility to work at times outside business hours
Strong analytical and organizational skills
Excellent communication and interpersonal skills on management level.
Ability to multi-task and prioritize in a challenging, fast-paced, dynamic environment.
You will get extra points for the following
Experience with IT KPIs
Experience with ITIL or similar frameworks.
Background in data warehouse design, dimensional modelling, and tabular modelling
Extraordinary organizational talent and project lead experience.
Deep experience in Cognos and Tableau experience will be a plus.
Europe working hours strong plus.
Now let’s talk about perks and compensation
We offer competitive base salaries and if you prove yourself as a super-star, you might be entitled to an extraordinary achievement reward. Depending on the performance in the respective year, Avaloq aims to share the success with all employees by paying out so called Success Share Units.
Place of work
Pune, India

Don’t be shy – apply!
Noopur Jha
Recruitment Executive

https://www.avaloq.com/en/job-openings

Please only apply online.

Note to Agencies: All unsolicited resumes will be considered direct applicants and no referral fee will be acknowledged.

Apply online",3.5,"Avaloq
3.5",Pune,"FREIENBACH, Switzerland",1001 to 5000 employees,1985,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Finnovative, Temenos"
Medical Imaging Scientist,-1,"Location:
Defence Colony, New Delhi

Job Purpose Summary:
Responsible for driving several research projects for India's leading medical imaging provider. Specific responsibilities will include:
Designing and executing internal scientific research projects
Performing MRI scans and analysing fMRI (and other) image datasets
Designing technical and clinical presentations for senior doctors.
Coordinating with research partners like MIT-Cambridge, IIT-Delhi, AIIMS-Delhi etc.
Extracting data from PACS and hospital information system for research purposes",4.0,"Mahajan Imaging
4.0",New Delhi,"New Delhi , India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"VARITE is looking for a qualified Data Analyst for one of its clients located in Noida (Sec 144) . If you are interested in this opportunity, kindly respond ASAP with your updated resume. We will be glad to represent you to our client and help in your job search. WHAT THE CLIENT DOES? A system integration and one of the largest IT Services companies. WHAT WE DO? VARITE is a global IT company providing software and engineering consulting and team augmentation services to Fortune 1000 companies in USA, CANADA and INDIA. VARITE is currently a primary and direct vendor to the leading corporations in the areas of Cloud, Data Sciences, Infrastructure Application Software, Mobility, Robotics, Banking & Financial Systems.
Salary Negotiable
Industry IT Software
SubIndustry Software Development
Functional Area IT Software Development
Specialization Database Architect/Designer
Role Executive / Officer Level
Keyskills
Data AnalysisAdvance ExcelPivot Table
Desired Candidate Profile
Please refer on JD
Education
Highest Qualification
Graduation B.E/B.Tech",5.0,"Fine Jobs
5.0",Noida,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior/Lead- Data Engineer- Java/NoSql/Data warehousing,-1,"ZYCUS OVERVIEW

Zycus is conducting a drive for a Senior/Lead Data Engineer-Java with a Experience of about 4-8 years, and having expertise with SQL, NoSql, Data warehousing, Java, and data messaging.

Zycus is a leading global provider of A.I. powered Source-to-Pay suite for procurement, finance, and AP organizations. Our comprehensive product portfolio includes eProcurement, eInvoicing, Spend Analysis, eSourcing, Contract Management, Supplier Management, Financial Savings Management, Project Management, Request Management, Supplier Network, Insight Studio, and Merlin A.I. Suite.

The Merlin A.I. Suite is a unique platform of pre-packaged intelligent BOTs to automate run-of-the-mill procurement and A.P. tasks with intelligent and predictive suggestions. It enables teams to improve productivity through optimal efforts, enhance accuracy with minimal human intervention, and focus on strategic activities. Driven by Artificial Intelligence, Zycus’ Merlin A.I. BOTs introduce cutting edge technologies in procurement operations, making it truly autonomous and cognitive.

Our spirit of innovation and passion to help organizations create a more significant business

impact is reflected among the hundreds of procurement solution deployments that we have undertaken over the years.

Know more about the LEADER of: Gartner’s 2013, 2015 & 2017 Magic Quadrant for Strategic Sourcing Application Suites and The Forrester Wave™: eProcurement, Q2 2017

MARKET SIZE

USD 5 Billion and grows tremendously during economic downturns

Job Description:
Building and optimizing large, complex data pipelines on different types of data sets.
Working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Working knowledge of message queuing, stream processing, and highly scalable ‘no-sql’ data stores.
Should be strong with No SQL working with large database.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Maintaining, enhancing, bug fixing the code. Follow the standard documentation process laid down for the project
Collaboration with different teams
Automation for delivery so that implementation of Zycus Products is optimized, standardized & automated.
Requirements
4 - 8 years’ experience in Core Java, Data messaging.
Should be good with data Structure, multithreading, and collections.
Should be good with NoSql.
Strong in creating data pipeline and data messaging
Expertise in Java and associated technologies - (Spring Boot, Hibernate, Web Services)
Strong understanding of APIs (REST/SOAP)
Good knowledge in API design.
Proficient understanding of RDBMS Concepts
Strong understanding of Databases.
Strong Understanding of Application Servers – jBOSS (Community/Enterprise ), Weblogic, Apache
Understanding of middle ware framework like JMS, Redis, etc
Understanding of SOA based frameworks
Knowledge of Agile product management.
Understanding of Micro service architecture
Good communication skills.
Good to have knowledge on Python
Quick learner and pursue new technologies. Research on open source frameworks/technologies and integrate them into application
Mandatory Skills: SQL, NoSQL, Metadata, Java, Data warehousing , UI
On boarding:· Will be able to enhance his knowledge by getting into new technologies/ frameworks (technology is not a restriction).
Benefits

WHY ZYCUS? :
Be a part of one of the fastest growing product Company in India
Come join a young, dynamic & enterprising team
Work on the latest technologies
Flexible working hours (As per business requirement)",3.3,"Zycus
3.3",Mumbai,"Princeton, NJ",501 to 1000 employees,1998,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),"SAP Ariba, GEP, Coupa Software Inc"
Data Analyst,-1,"If the below JD is matching to your tech stack. please sharwe your updated CV to benchire.com

Key Responsibilities
? Building dashboards using techniques for advanced analytics, interactive dashboard
design, and visual best practices to convey the story within the data
? Absorbing and managing complex analytical requests.
? Building solution driven views and dashboards in Tableau or another BI Suite
? Develop and maintain databases and build scripts that will make the data evaluation
process more flexible or scalable across data sets
? Analyse data and translate it into actionable conclusions
? Prioritize and manage multiple tasks simultaneously
? Conduct excellent research, work independently, and pay attention to detail.
? Identify trends and opportunities for growth through analysis of complex data sets
Knowledge, Skills & Experience
? Should have at least 3+years of experience
? Bachelor’s degree in Mathematics, Computer Science, Economics, or Statistics
? Proven analytic skills, including mining, evaluation, analysis, and visualization
? Technical writing experience in relevant areas, including queries, reports, and
presentations
? Strong SQL, NOSQL, Excel, and Tableau skills with the ability to learn other analytic
tools
? Experience in data management and analysis using quantitative and qualitative
methods for different types of research and evaluations
? Experience analysing data from 3rd party providers: Google Analytics etc.
Perks and Benefits
? Competitive Salaries
? Generous Equity
? Flexible Work Hours
? Pet-Friendly Environment
? Work From Home",-1,Benchire,Gurgaon,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"NEWJ is looking for young dynamic Data Engineers who can design, build, and implement the data systems that fuel machine learning and AI analytics.

Who we’re looking for:

Data Engineer

Roles & Responsibilities:
Create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies
Build analytics tools that utilize the data pipeline to provide actionable insights into user acquisition, operational efficiency and other key business performance metrics
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs
Keep our data separated and secure across national boundaries through multiple data centres and AWS regions
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product/social media presence into an innovative industry leader
Work with data and analytics experts to strive for greater functionality in our data systems
Skills and Abilities Required:
We are looking for a candidate with 1 to 3 years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:
Experience with relational SQL and NoSQL databases
Experience with Azure cloud services
Experience with object-oriented/object function scripting languages: Python, R, etc.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Experience managing databases on the cloud platforms, AWS/Azure either should be fine
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Strong analytic skills related to working with unstructured datasets
Build processes supporting data transformation, data structures, metadata, dependency and workload management
A successful history of manipulating, processing and extracting value from large disconnected datasets
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores
Strong project management and organizational skills
Experience supporting and working with cross-functional teams in a dynamic environment
About:

NEWJ, is a tech media start-up, working towards disrupting the current media ecosystem through interesting & innovating visual storytelling that appeals to the heart of India. The recent exponential growth of the video content market provides a huge opportunity for innovative visual storytelling in India.

The company intends to fill this demand for quality content in the social and digital media space. The venture was founded by a team of young entrepreneurs led by Shalabh Upadhyay.

Website: https://thenewj.com/

Social Media Handle:

https://www.facebook.com/NEWJplus/
https://twitter.com/NEWJplus
https://www.instagram.com/newjplus/
https://www.youtube.com/channel/UCvTAAa8-yBQEVgLLCKYbAiQ

Job Type: Full-time

Work Remotely:
Temporarily due to COVID-19",4.0,Benchire,Mumbai,"Mumbai, India",51 to 200 employees,2018,Company - Private,Publishing,Media,Unknown / Non-Applicable,-1
Lead Data Scientist,-1,"Exp: 5 - 10 years

CTC: 25 - 35 LPA

BE/Btech/MBA From a Tier 1 School

Talents from BFS/Internet Firms

• Build solutions which generate unique insights & knowledge to the core business users within Financial Services

• Exhibit deep knowledge in advanced analytics, including knowing how to transform complex data into easily understandable action items within a business context

• In-depth understanding of ML techniques, time-series/AI based forecasting, feature engineering, dimensionality reduction, optimization and deep learning techniques

• Work closely with business stakeholders in automating and building appropriate process visualizations for operational support

• Collect, analyse, screen and manipulate different exogenous/ related data sets and tags required for modelling and support all decision making process

• Work with Cloud based Big Data platforms and tools to design and deploy applications.

• Conduct testing / validation of Machine Learning models, model tuning and parameter optimization

• Exhibit interpersonal /communication skills to communicate effectively in a multi-functional leadership team. Must have:

Experience in at least 2 Analytics Projects in BFSI

• Expertise in Machine Learning, Statistical Modelling, Visualization and Data Mining Techniques

• Must have engaged with top management for data driven decision and insights

• Must have experience of leading teams",-1,Staffio HR,Mumbai,"Bengaluru, India",1 to 50 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Analytics - Consultant,-1,"Designation : Data Analytics - Consultant
Location : Chennai
Experience : 1+ Yrs
Job Code : IT 1000
No Of Positions : 5
Job Description Experience in data analysis
Proficiency in SAS, SQL, Excel/VBA, Statistical modeling (Logistic / Linear regression, GLM modeling, Time-series forecasting, Scorecard development, Clustering, Segmentation",4.2,"Infiniti Software Solutions
4.2",Chennai,"Chennai, India",201 to 500 employees,2005,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹5 to ₹10 billion (INR),-1
Data Analyst,-1,"Designation: Data Analyst

Job Location – Bhiwandi ( we have drop and pick facility from different locations in Mumbai)
Experience – 4+ years
Qualification – Graduate

Data Analyst

We are a Sales & marketing organization in 8 Industrial sales. many activities happen- We want a data Analysis to identify what is working:
Like Lead Conversion
Inventory Forecast
Collection
Attrition etc.
Skills and Experience

Data Analyst with minimum 4 yrs of experience who has worked on algorithms
TOOLS
Tools & Data Management (Intro to Excel, R/Python, SQL)
Data Inspection and Pre-Processing Techniques (using R/Python)
Descriptive Analytics – Data Visualization (using Tableau or Python or R)

ALGORITHMS
Predictive Analytics
Regression (Linear/Non-Linear/Logistic)
Classification
Time Series analysis
Text Analytics
Social Network Analysis
Clustering
Prescriptive Analytics
Simulation (using Excel)
Optimisation (using Excel)
Big Data/ML
Big Data Big data technologies,Machine Learning & Artificial Intelligence

Email ID – hireme@vashielectricals.com
Contact HR – Atika Shaikh-7045454374",3.4,"Vashi Electricals
3.4",Bhiwandi,"Thane, India",201 to 500 employees,1978,Company - Private,Wholesale,Business Services,₹100 to ₹500 billion (INR),-1
Data Analyst,-1,"Job Description:
We’re looking for a Data Analyst who will be responsible for assisting in the efficient planning, collection, and maintenance of data sources to
join our analytics team. If you meet the following requirements, wish to enter a creative, collaborative, and fun environment, and work alongside people dedicated to the success of our company, please apply online at careers.liventus.com

Job Responsibilities:


Build Tableau reporting
Identify, clean, and combine data to solve relevant business problems
Research and troubleshoot data related questions, tickets, and issues
Monitor and maintain our existing data to ensure it remains clean, accurate, consistent, and impactful
Transform data into meaningful insight and recommendations for business partners from various areas and companies, including but not limited to the Executive and Sales teams
Work with other members of Data Analytics team to develop business workflows that will help us make better decisions and be more efficient in our daily work
Coordinate development of test data, system testing, and documentation for all phases of our data migration processes (ETL)
Stay up-to-date on emerging technologies
Occasionally perform ad hoc reporting to answer specific business questions from upper management
Support users by developing thorough and complete documentation

Job Requirements:


Candidate must have the following:
3 - 6 years of experience in data analysis using query tools required
Strong Tableau report building skills
Strong SQL skills with the ability to perform advanced queries and create stored procedures
Experience with dashboard reporting, scorecards, and executive presentations focused on analytics
Understanding of CRM reporting capabilities
Ability to gather business requirements and translate to technical specifications
Bachelor’s degree in Management of Information Systems (MIS), Mathematics, Statistics, Computer Science, or Business with an analytics focus
Data manipulation skills within Excel, such as VLOOKUP, Pivot Tables, VBA, etc.
An understanding of statistical and predictive modeling techniques and concepts
Strong analytic/problem-solving, documentation, and prioritization skills
A desire to learn new things and an ability to adapt to change and innovation
Ability to work on a team and manage individual prioritized workload
Candidate must be able to effectively communicate in English (written & verbal)
Knowledge of any scripting language e.g. Shell script, JavaScript, etc.
Knowledge of any ETL Tool e.g. SSIS

Benefits:


Group Mediclaim policy
Accident policy
Parental Health Insurance
Retirement benefits (Provident Fund)
Gratuity",4.8,"Liventus
4.8",Bengaluru,"Northbrook, IL",51 to 200 employees,2002,Company - Private,IT Services,Information Technology,₹500 million to ₹1 billion (INR),-1
Sr. Data Scientist,-1,"Roles and Responsibilities

Must have skills:

Expert in any 2 of the following and knowledge/awareness in all the following genres of Data Science:
Descriptive & Exploratory Data Analysis
Time Series Forecasting, Predictive Modelling, Supervised & Unsupervised Machine Learning (ML) Methods
Optimization / Operations Research (OR) Techniques
Computer Vision Convolution Neural Network (CNN) Modeling
Natural Language Processing (NLP) / Text Mining
Experience working with Python programming.
Ability to research and work following any research paper, scholarly article etc.
Ability to write & publish papers
High sense-of-ownership
Ability to work independently
Good communication skills
Ability to translate business requirements into an end-to-end Data Science solution and to facilitate the ‘art of the possible’ discussions with the business and IT
Good stakeholder management skills
Good mentoring skills

Nice-to-have Skills/Exposures:

Exposures to Foods, Manufacturing or similar industries
Exposures to Supply Chain Management, Logistics, Transportation or similar business functions
Ability to integrate and deploy a model into a cloud native environment leveraging AWS/GCP tools
Ability to work in a CI/CD environment (not necessarily build CI/CD, just integrate and interact with)
Some usage skills on docker, pipelines, orchestrators, and interacting with kubernetes
Some experience in working on projects with IoT integration (using edge hardware or hybrid of cloud and edge)

Job Type: Full-time

Salary: ₹45,000.00 - ₹60,000.00 per month

Experience:
AI: 4 years (Preferred)
total work: 5 years (Preferred)
Education:
Bachelor's (Preferred)
Industry:
Software Development
Work Remotely:
Temporarily due to COVID-19",-1,yumbo tech,New Delhi,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"HP is the world’s leading personal systems and printing company, we create technology that makes life better for everyone, everywhere. Our innovation springs from a team of individuals, each collaborating and contributing their own perspectives, knowledge, and experience to advance the way the world works and lives.

We are looking for visionaries, like you, who are ready to make a purposeful impact on the way the world works.

At HP, the future is yours to create!

We are Pricing Analytics Team; our main objective is to help the business to decide optimal price for the HP products in a scientific way through statistical and predictive analysis.

If you are our Data Engineer in India, you will get an opportunity to work on below.

Designs and establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data pipelines, repositories or models for structured data.
Analyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.
Writes and executes complete pipeline plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs and creates solutions for issues with data sources and integration into data system architecture.
Collaborates and communicates with project team regarding project progress and issue resolution. Represents the data engineering team for all phases of larger and more-complex development projects. Provides guidance and mentoring to less experienced staff members.

Are you a high-performer? We are looking for an individual with.

Well versed knowledge on SQL servers and database solutions.
Python programming language to create efficient data flow
Various operating systems like Linux, windows, Unix which will enable data interconnection Data warehousing and ETL tools Good to have.
Knowledge on R and visualization tools such as Power BI / Tableau/ R Shiny Data architecture skills to create effective data flow Team player to interact and understand the data based on data scientists and analysts
#LI-Post",3.3,"HP
3.3",Bengaluru,"Houston, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
MACHINE LEARNING ENGINEER,-1,"CodeData is looking for a Machine Learning Engineer with a passion for data and algorithms to join us. The ideal candidate has some experience using Java/Scala/Python to build analytics platforms/data pipelines. She must be a team player, self-directed and comfortable working in a high performance startup culture.

RESPONSIBILITIES:
Build creative, reliable and scalable machine learning and analytics platform in an agile software development environment.

Continually evolve the platform as the business changes- maintain and improve the platform running in AWS/Azure and automate key processes.

Provide simple solutions to complex data problems.

EDUCATION REQUIREMENTS:
Bachelors or Masters degree in Computer Science or Engineering

LOCATION:
Multiple Locations, India

WORK EXPERIENCE REQUIREMENTS:
3+ years hands-on experience with requirements analysis, design, coding and testing patterns as well as experience in developing quality software platforms and large-scale data infrastructures.

2+ years experience (strong) in Java/Python/Scala is required.

1+ years of hands-on experience building data pipelines using Kafka, Spark, Machine Learning, HDFS/Cassandra/NoSQL or comparable technologies is mandatory.

1+ Experience working with cloud computing environments, preferably AWS is must.

Understand how algorithms work and have experience building high-performance algorithms.

Enjoy solving complex problems on a daily basis.

Excellent verbal and written communication skills.",4.0,"CodeData
4.0",India,"Danville, CA",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"Job Role:
Data mining through secondary research and primary interviews with top execs across companies
Building and maintaining data sets and analyzing financial indicators of companies
Close collaboration with core market research personnel to reconcile findings with the industry scenario
Developing and innovating the competitive landscape in the study
Skill Set:
Excellent verbal and written communication
Analytical bent of mind
Familiarity with accounting principles and financial reports would be a bonus
Job Type: Full-time
Pay: ₹15,000.00 - ₹20,000.00 per month
Education:
Bachelor's (Required)
Work Remotely:
Temporarily due to COVID-19",-1,"CodeData
4.0",India,-1,-1,-1,-1,-1,-1,-1,-1
Data Analyst,-1,"Location : Dadar,Mumbai
HSC / Graduate with minimum 6 months to 2 years of relevant experience
Candidate with back office experience will be preferred
Good written and verbal communication skills (B28 high)
Proficiency in Ms-Office (Excel, Word, PowerPoint)
Quality check of the Data
Share the report of the QC in given time
Complete the given task within service level
Shift timings
7:00 am to 3:00 pm / 3:00 pm to 11:00 pm
Age
Upto 35 years
Job Type: Full-time
Salary: ₹11,000.00 - ₹14,000.00 per month
Experience:
Quality check of the Data : 1 year (Required)
MS Word/Excel/Powerpoint: 1 year (Required)
back office work: 1 year (Required)
Education:
Higher Secondary(12th Pass) (Required)
Location:
Mumbai, Maharashtra (Required)
Work Remotely:
No",-1,Catalyst Placement Solutions,Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Data Analyst- Supply Chain - Relocation to UAE,-1,"Data Analyst- Supply Chain

We are Chalhoub Group, a leading family business in the world of beauty, fashion and gifts. We have blended our Middle East expertise and intimate knowledge of luxury to offer service excellence to all our partners and a unique experience to all our customers for over 60 years

As we continue to grow, it’s our vision to become a hybrid retailer, bringing luxury experiences to the fingertips of customers everywhere.

Our passionate teams drive our vision forward, without them, we couldn’t create luxury experiences for our customers. Through opportunities, development and support, we empower each and every employee to achieve their career goals – and beyond. It’s an exciting journey we’re on, and one you could be part of.

The Supply Chain Data Analyst is responsible for mining multiple sources of data, derive actionable insights, and translate complex results or algorithms into simple conclusions that will empower others to take action to improve efficiencies and results across the Group Supply Chain. The job holder will be a primary driver of delivering insights that will educate and influence key business decision-making with our Customer and Brand teams.

You will assist in maximizing supply chain efficiency through KPIs, ad hoc reporting and effective modeling. You will provide Supply Chain with analytical, technical, and financial expertise in support of overall operations, and support in the development of Supply Chain tools, optimization models, and data analytics to help drive the Group’s strategic direction.

What you'll be doing:

Data Analytics and Data Visualization:
Deliver Supply Chain & Logistics analytic insights across several business domains including Retail, Distribution, E-Commerce, Omnichannel, Finance, Marketing and Digital
Lead business process re-engineering initiatives to increase productivity, quality and effectiveness of Supply Chain related activities
Identify data sources, develop integrated tools and assist with corporate Supply Chain KPIs/metrics analysis methodology
Anticipate critical business questions and opportunities and deliver key insights to the business that make significant impacts
Build analytic capabilities to grow organizations knowledge
Develop in-depth business, analytical and systems knowledge to improve analytical solutions, approaches and business recommendations
Establish data visualization (Power BI, Tableau, etc.) and analytic tools (R, SAS, JMP, Python, Spark, etc.) to grasp the business insights
Collaborate with multi-functional teams (Commercials, Consumer Research, Finance, Accounting, Marketing, IT, Sales)
Perform detailed analysis and provide KPIs/metrics to Group leadership and executive Supply Chain stakeholders as needed
Design, build, and maintain optimization tools to identify global Supply Chain network opportunities and determine optimal distribution sites
Research and extract Supply Chain data from Chalhoub Group systems and create meaningful reporting to identify trends, performance metrics and issues
What you'll need to succeed in this role:
Bachelor's or Master’s degree in in Computer Science, Engineering, Mathematics, and Statistics or equivalent subject
Minimum 5 years of experience in Supply Chain, Finance or Commercial operations or Analytics (Business Intelligence, Data Engineering or Data Warehousing).
Advanced knowledge of Big Data Platforms (Data Lake, HDFS, Cloud Infrastructure platforms, etc.)
Proven hands-on experience on Business Intelligence/Visualization platforms (Power BI, Tableau, MicroStrategy, etc.)
MBA, APICS CPIM and APICS CSCP certification would be an asset
Knowledge of operational supply chain processes including the flow of materials and information would be an asset
Experience in the Retail industry (Preferable)
Experience with ERP systems (preferably Oracle) cross-modules (Preferable)
Ready to join our exciting transformation to become a hybrid retailer, bringing luxury experiences to the fingertips of our customers everywhere? Now’s your chance. By being part of our journey here at Chalhoub Group, you can make a real impact on customers and some of the finest brands in the world. In return, you’ll have everything you need to innovate your career.

What we can offer you

We will help shape your journey with us through enriching experiences, learning and development opportunities and exposure to different assignments within your role or through internal mobility.

Our Group offers the opportunity to support careers that may span different teams, different job roles, different categories and even different countries. We offer diverse career paths for those who show drive and passion as well as the desire to learn and grow.

Amazing benefits

We recognise the value that you bring, and we strive to provide a competitive benefits package which includes health care, life insurance, child education contribution & exclusive employee discounts.

Job Segment:
Retail Sales, Retail

Apply now",3.7,"Chalhoub Group
3.7",Mumbai,"Dubai, United Arab Emirates",10000+ employees,1955,Company - Private,"Department, Clothing, & Shoe Shops",Retail,Unknown / Non-Applicable,"AL Tayer, MH Alshaya, Gucci"
Senior Data Scientist - Retail & Insurance,-1,"The QuaXigma (U.S. based) was launched with a mission to make A.I accessible and affordable and deliver AI Products/Solutions at scale for the enterprises by bringing the power of Data, AI, and Engineering to drive digital transformation. We believe without insights, businesses will continue to face challenges to better understand their customers and even lose them; Secondly, without insights businesses won't’ be able to deliver differentiated products/services; and Finally, without insights, businesses can’t achieve a new level of “Operational Excellence” is crucial to remain competitive, meeting rising customer expectations, expanding markets, and digitalization.

The Senior Data Scientist (Retail & Insurance Analytics) is responsible for applying advanced analytics including both descriptive and predictive analytics to support the business use cases in retail and insurance industry such as to prevent customer churn, identify cross-sell and up-sell opportunities, implement customer personalization, pricing, new customer acquisitions, insurance risk management. This role will need to understand business requirements, conduct quick research, and generate fast prototyping by working closely with business partners. This role will need to communicate findings to ensure models are well understood and incorporated into business processes.

This role is required to work flexible hours to work with US team and clients.

Key Responsibilities
Design and build models/algorithms to drive predictive & prescriptive analytics to accelerate business decisions and drive real-time analytical insights
Research and brainstorm with internal stakeholders to identify advanced analytics opportunities to advance automation, help with knowledge discovery, support decision-making, gain insights from data, streamline business processes, and enable new capabilities
Lead efforts in advanced analytics solutions to produce value corporate’s unstructured and structured data assets utilizing methodologies from machine learning, deep learning, artificial intelligence, and natural language processing
Develop end-to-end efficient model solutions that drive measurable outcomes. Manage the model development lifecycle, including both working with data engineers to identify what data are needed, and training the business end-users on how to leverage the modeling output
Work with clients in development, assessment, improvement, and transfer of solutions to stakeholder teams as needed
Prepare documentation, reports, and presentations that explain advanced analytics concepts, technology, and inner workings of solutions to broader teams including non-technical audiences
Job Qualifications
5-7 years relevant industrial experience (either retail or insurance industry), in solving complex business problems using data science, statistical techniques & machine learning to build predictive & prescriptive solutions to grow customer base and sales
Minimum MS degree, but PhD strongly preferred in a quantitative field such as data science, statistics, economics, operations research, computer science, applied mathematics, engineering, etc.
Proven experience in managing and manipulating large, complex datasets
Demonstrated experience in executing on complex projects, extracting, cleansing, and manipulating large, diverse structured and unstructured data sets on relational – SQL, NOSQL databases
Working knowledge of machine learning/artificial intelligence. These technical skills include, but not limited to, regression techniques, neural networks, decision trees, clustering, pattern recognition, probability theory, stochastic systems, Bayesian inference, statistical techniques, deep learning, supervised learning, unsupervised learning
5+ years of hands-on experience with programming languages such as Python (preferred), R and common machine learning packages such as dplyr, xgboost, glmnet, randomForest, H2o, Numpy, Pandas,scikit-learn, keras, tensorflow, etc.
Experience in Spark environment is a plus
Hands-on experience in developing and productionizing solutions using tools in Azure and AWS such as Azure ML service, Databricks, Sagemaker
Good communication and presentation skills, with the ability to tailor the communication style to the right audience
Experience working in an agile environment with iterative development & business feedback
Experience providing insights to support strategic decisions, including preparing and delivering insights and recommendations
Job Type: Full-time

Pay: ₹50.00 - ₹70.00 per hour

Experience:
Data Science: 5 years (Required)
Retails or Insurance: 3 years (Required)
Education:
Master's (Required)
Industry:
Insurance
Work Remotely:
Temporarily due to COVID-19",-1,Quaxigma,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
CIB R&A - Data Analyst- Associate,-1,"JPMC is looking at expanding our digital capabilities and we are investing in growth opportunities for various businesses. We are looking for commercially minded, customer focused, hands on engineers, who want to be a part of building exciting product offering. A core responsibility is to produce secure, scalable technical solutions to support our market leading products.

Culture is as important to us and we are looking for intellectually curious and honest, passionate, hungry individuals who would like to expand their skills whilst working on a new exciting venture for the firm. This role will be based in Bangalore, India. A JPMorgan Chase & Co.'s global team of technologists and innovators, helps to positively impact the company, as well as our clients and our business partners around the world.

The success of this business relies on the platform that will be built - we will be using a stack that is cloud native relying on cutting edge technology and seek full stack minded engineers.

In this role, the candidate will be responsible for providing analytical SQL support to various functions within the business. Over time, the support will also extend to providing statistical analysis and consequently, this role will suit a candidate looking to extend their analytical capabilities.

Key Responsibilities
Provide analytical support using SQL in order to help Business-LOBs to measure KPIs or perform ad-hoc data exploration
Gain familiarity with a variety of data sources ranging from incoming event-streams to tabular data across various LOBs
Help the LOB stakeholders innovate through data-driven decisioning by querying data and merging information from diverse data sources to create rich datasets that enable better decision-making
Work with other Analytics teams and multi-task on projects to summarize and synthesize data and present recommendations to the businesses in a clear and logical manner
Identify unexplored data opportunities for the business to unlock and maximize the potential of digital data within the organization
Support ongoing technology evaluation process and proof of concept projects

Qualifications
Proven working experience as a data analyst or business data analyst
Knowledge of modern MPP databases and big-data (Hadoop) concepts
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
Experience with relational databases utilizing SQL to pull and summarize large datasets, report creation and ad-hoc analyses
Experience in agile reporting development and ability to interpret unstructured data and draw objective inferences given known limitations of the data
Demonstrated ability to think beyond raw data and to understand the underlying business context and sense business opportunities hidden in data
Strong written and oral communication skills; ability to communicate effectively with all levels of management and partners from a variety of business functions
Self-starter who can provide insights and drive results in a dynamic and fast evolving environment
Ability to define and track project deliveries through to implementation
Proactive/self-starter with the ability to deliver value-added support to business partners in a dependable, timely and accurate manner
Adept at multi-tasking and meeting deadlines in high-pressure environment
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.",3.9,"J.P. Morgan
3.9",Bengaluru,"New York, NY",10000+ employees,1799,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Data Analyst,-1,"We are looking to hire a Data Analyst to join our data team. Your responsibility would include for developing reports, and troubleshooting data issues. To do well in this role you need a very fine eye for detail, experience as a data analyst, and deep understanding of the popular data analysis tools and databases.

Role & Responsibilities:
Graduate or Post Graduate in Computer Science
Work experience: 3+ as a data analyst or in related field.
Experience with SQL
Ability to understand and analyze SQL queries.
Should have prior experience with executing SQL.
Should have the ability to prepare sample test data for testing
Should have the ability to implement business logic requirements via SQL and test the code developed by Development team.
Understands Data model and have ability to build data model
Understands Entity relationship based on data entities.
Experience of BFS domain and knowledge of domain terminology is added plus

Job Location: Pune
To apply for this exciting opportunity, please email us your profile on careers@hexanika.com",4.2,"Hexanika
4.2",Pune,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"Welcome to Thrillophilia ! 1.5 Million users come every month to plan their trips on Thrillophilia . We are your one stop solution to book your tours, activities, staycations and much more.

At Thrillophilia, we’re proud to stand at the forefront of the Big Data revolution. Using the latest analytic tools and processes, we’re able to maximize our offerings and deliver unparalleled service and support. To help carry us even further, we’re searching for an experienced data analyst to join our team. The ideal candidate should be highly skilled in all aspects of data analytics, including mining, generation, and visualization. Additionally, you should be committed to transforming data into readable, goal-driven reports for continued innovation and growth.

Responsibilities

Interpret data, analyze results using statistical techniques and provide ongoing reports

Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality

Acquire data from primary or secondary data sources and maintain databases/data systems

Identify, analyze, and interpret trends or patterns in complex data sets

Locate and define new process improvement opportunities

Use data to create models that depict trends in the customer base and the consumer population as a whole

Develop, implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks

Identify trends and opportunities for growth through analysis of complex data sets

Evaluate organizational methods and provide source-to-target mappings and information-model specification documents for data sets

Create best-practice reports based on data mining, analysis, and visualization

Requirements

Proven 1-year experience as a data analyst.

Technical expertise regarding data models, database design development, data mining and segmentation techniques

Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc)

Strong Knowledge of Excel, Python, r language

Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy

Adept at queries, report writing and presenting findings",4.5,"Thrillophilia
4.5",Jaipur,"Bengaluru, India",51 to 200 employees,2009,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Sr Data Scientist,-1,"Our Company

We help people around the world save money and live better -- anytime and anywhere -- in retail stores, online and through their mobile devices. Each week, more than 220 million customers and members visit our 11,096 stores under 69 banners in 27 countries and e- commerce websites in 10 countries. With 2014 fiscal revenues of approximately $486 billion, Walmart employs 2.2 million employees worldwide.

@Walmart Labs in Bangalore, we use technology for the charter of building brand new platforms and services on the latest technology stack to support both our e-commerce and stores businesses worldwide.

Our Team

The Marketing Technology Team @Walmart Labs has the mandate of increasing the rate of customer acquisition, retention, and revenue by optimising products and inventing new marketing channels. We are a bunch of super talented and passionate engineers, data scientists and analysts working together on an array of impactful problems in domains ranging from organic search channels, displaying ads on the Open web and Social Marketing on walmart.com and other properties owned by Walmart. Application of SEO principles and best practices plays a crucial role in driving growth by enhancing and maintaining search ranking of Walmart products.

Job Overviewe

We are looking for self driven Sr data scientist to join our growing team. They will play a crucial role in developing, analysing and enhancing the SEO experience of Walmart.com site. Application of SEO principles and best practices plays a crucial role in enhancing and maintaining the search ranking of Walmart products. Analyse huge datasets and create powerful visualisations to derive insights, build DS algorithms and partner with the product team to brain storm and act on opportunities. Partner with data engineers and leverage data to maximise data driven impact. You must be able to clearly articulate and present recommendations to product and business partners to drive decisions. You must be able to accurately prioritise projects, make sound judgments, work to improve the processes, and get the right things done.

Job Responsibilities
Play a key role to solve complex problems, pivotal to Walmarts business and drive actionable insights from terabytes of data
Analyze large, complex data sets by developing advanced statistical and machine learning models based on business initiatives
Utilize big data analytics and advanced data mining techniques to direct the gathering of data, assess data validity and synthesize data into large analytics datasets to support project goals
Build and train scalable models using best practices, enabling re-use for future project
Utilize product mindset to build, scale and deploy holistic analytical products after successful prototyping.
Clearly articulate and present recommendations to business partners, and influence future plans based on insights
Promote and support company policies, procedures, mission, values, and standards of ethics and integrity
Must have skills
Bachelor's with years of relevant experience OR Masters with years of relevant experience OR PHD in Statistics/Mathematics with minimum of 5 years experience
Experience in analyzing complex problems and translate it into analytical approach
Experience in Statistical Learning: - Predictive & Prescriptive Analytics, Web Analytics, Parametric and Non-parametric models, Regression, Time Series, Dynamic/Causal Model, Statistical Learning, Guided Decisions, Topic Modeling, Recommendation systems
Experience in Machine Learning, supervised and unsupervised: - Forecasting, Classification, Data/Text Mining, NLP, Decision Trees, Adaptive Decision Algorithms, Random Forest, Search Algorithms, Neural Networks, Deep Learning Algorithms
Experience with big data analytics and advanced data mining techniques to analyze data
Experience with identifying trends, patterns, and outliers in data
Experience with statistical programming languages, analytical packages/libraries (R, Python)
Experience with statistical tools (R studio, Revolution R, Python notebooks)
Experience with SQL and relational databases, data warehouse platforms, NoSQL databases
Experience with big data platforms - Hadoop(Hive, Pig, Map Reduce, HQL)/Spark/H2O
Good to have skills
Domain Knowledge of one or more divisions in Retail
Published papers or given talks in leading academic and research journals
Published papers or given talks in Data Science Forums
Hold data science related patents
Experience with data warehouse platforms No SQL Databases (Cassandra)
Experience with GPU/CUDA for computational efficiency",3.3,"Walmart
3.3",Bengaluru,"Bentonville, AR",1001 to 5000 employees,1962,Company - Public,"Department, Clothing, & Shoe Shops",Retail,₹500+ billion (INR),"Target, Costco Wholesale, Amazon"
Data Analyst (with P&C Insurance),-1,"A little about us...

L&T Infotech is one of the largest global technology consulting and digital solutions company -holding an annual revenue of $1.4 bn.
We were founded 20 years ago as the information technology arm of the Larsen & Toubro group.
We are currently partnered with more than 350 clients (66 of which are Fortune 500 companies).
We operate in 28 countries, employing over 28,000 employees world-wide !
We lead in providing the best experiences for our clients and their customers.
We provide our employees with a learning environment that promotes growth and creativity.
To learn more please visit us at www.lntinfotech.com follow us on Twitter @LTI_Global.

Job Details:
Minimum 7 years of experience as business analyst/Data analyst in P&C Insurance.
Hands on expertise in Data Analysis, Data Mapping and Data Integration.
Experience of working on data integration projects.
Good to have Demonstrate strong techno-functional experience in Guidewire Data Hub, SQL, SAP BODS ETL and in Property & Casualty (P&C) insurance.
Provide IT test plans, and ensure that the proper testing plans have been completed.
Strong Interpersonal skills and logical skills.
How will you grow?
Role-based Training programs
Continuing Education Programs (CEP) to enhance your knowledge, skills, and attitude as a professional
We encourage you to acquire various beneficial international certifications, with costs s reimbursed
Our role-based workshop helps us groom future leaders for LTI
What's in it for you?
Excellent benefits plan: medical, dental, vision, life, FSA, & PTO
Roll over vacation days
Commuter benefits
Excellent growth and advancement opportunities
Certification reimbursement
Rewards and recognition programs
Innovative and collaborative company culture
“LTI values diversity and inclusion and is committed to the principles of Equal Employment Opportunity EOE/Minority/Female/Veteran/Disabled/Sexual Orientation/Gender Identity.”

Nearest Major Market: Springfield
Job Segment:
Database, Consulting, ERP, Business Analyst, SQL, Technology",3.5,"LTI
3.5",Mumbai,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
Research Scientist,-1,"Key Roles/Responsibilities:
Should able to get maximum productivity from his team.

Should be able to troubleshoot difficult organic reaction problems and purification problem independently.

Should have excellent literature skill and should able to independently propose for single or multiple step transformations and implement.

Uses good judgment based on chemical knowledge of reactivity, functional group compatibility, and side product analysis to propose and implement alterations to reaction conditions to fit the case at hand

Should able to demonstrate excellent interpretation skill for IR, NMR, LC-MS and HPLC.

Should able to develop the process chemistry for scale up compound.

Able to identify, troubleshoot and provide solutions to synthetic bottle necks.

Should able to communicate with Client effectively through Conference, Reports, Tracking sheet and emails.

Should able to coordinate effectively with various internal departments like ADL/QA/EHS/SCM/Projects etc.

Able to effectively present results and conclusions at team and department meetings as well as to other internal parties as needed

Contributes effectively to patent, report and scientific publication writing

Demonstrates and excellent understanding and knowledge of, and provides recommendations on, laboratory tools and procedures as appropriate

Should able to ensure Safety and quality practice in the lab.

Qualifications
M.sc/M.Pharm : 5-8 years in CRO/API industry
PhD : 4-7 years
Primary Location: India-Gujarat-Ahmedabad
Work Locations: Ahmedabad Plot No:-19,PHARMEZ, Sarkhej-Bawala NH-8A Village Matoda Tal-Sanand Ahmedabad 382213
Job: R & D
Organization: Pharma Solutions
Day Job
Job Posting: 03-Jul-2020, 6:21:16 AM",-1,Pharma Solutions,Ahmedabad,"Dublin, Ireland",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Company: PayU Finance India Private Limited Location:

Bangalore/Mumbai

Roles and Responsibilities:
Perform diagnostic and predictive analytics to help create a portfolio segmentation strategy considering, among others, macroeconomic environment, industry and micro-industry concentrations, product, lifetime value, usage, risk appetite, geography, seasoning, term, credit performance, etc. Influence, monitor, and assess impacts to Family Capital Funding's portfolio as a result of pricing, product, acquisition strategy, underwriting policy, fraud detection, and portfolio monitoring and collections. Create predictive early detection credit deterioration capabilities using internal and external performance data. Investigate, create, implement and validate various risk and financial forecasts using complex data including cohort and time series analysis of loan balances, revenue performance, net income performance, portfolio dynamics, etc. and ensure an enterprise wide consistency in estimations. Interface with Acquisition, Pricing, Product, Marketing, Finance, and Operations teams to help build relationships, set goals and track operations performance, providing an actionable feedback loop as it relates to portfolio performance across key Family Capital Funding metrics. Ensure sound credit control by taking a pro-active approach to risk management within the risk guidelines of Family Capital Funding. Demonstrate governance, control and risk management behaviours in alignment with Family Capital Funding policies and practices. Document all new processes per Enterprise policy Assist with developing and enhancing credit structuring/packaging and risk assessment capabilities to identify and maintain good business opportunities with new and existing clients. Perform detailed analysis and interpret information to make recommendations to Senior Management on critical strategies including non-standard and ad-hoc requests as determined by management. Ensure the timely and effective communication of forecasting results & variance drivers; anticipating potential needs in an effort to establish and maintain good working relationships with key business stakeholders.
Qualifications and Experience:

Undergraduate degree in Economics, Engineering, or Mathematics 2 to 5 years of related experience in a Business Analytics, Finance, Strategy, or Product functional area Excellent business judgment and risk assessment as demonstrated by previous work or academic experience in an analytic role related to economic or business analysis Strong Analytical and Problem-Solving Skills as demonstrated by previous experience in developing creative solutions to business strategy, technological, and operational problems Excellent SQL and analytic programming skills (R, Python, SAS, Excel), willingness to work closely with large data sets and get into the details with business processes Knowledge and experience with statistical concepts and financial analytics (break-even analysis, NPV estimation, downside risk assessment) Desire to help small businesses by eliminating inefficiencies and excessive costs in the lending business",3.5,"PayU
3.5",Bengaluru,"Hoofddorp, Netherlands",1001 to 5000 employees,-1,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"It's fun to work at a company where people truly believe in what they are doing!

Job Description:

Data Analyst – Epiq Service Cloud (Legal Solutions)

Key Responsibilities:

The Epiq Service Cloud Data Analyst will focus on analyzing, modeling and delivering data models for a key strategic product. They will work directly with stakeholders and team members to define, design and deliver actionable insights.

Requirements:
Bachelor's Degree in Computer Science / Computer Engineering or equivalent experience in the field of Computers and Information Technology.
4 to 6 years of experience in delivering data warehouse and business intelligence solutions.
Experience of Data Warehouse and ETL solutions.
Fluent in Relational Database (RDBMS) concepts and Flat File processing concepts.
Hands-on Team / Individual contributor on delivery of data solutions.
Intermediate to advanced experience with building or contributing to OLAP data modeling and Business Intelligence reporting design and implementation.
Intermediate to advanced experience using any ETL tools (Informatica PowerCenter, SQL-Server SSIS, Talend, Ab Initio) and preferably BI tool - Power BI with MS-SQL (Microsoft SQL Server).
Able to present data in a way that is simple to interpret and cascade out to the organization whilst making insightful recommendations.
Able to link data interdependencies and communicate complex information simply.
Track-record and strong understanding of KPI / Metric principles.
Must be knowledgeable in software development lifecycles/methodologies specifically Agile.
Experience Required:
Creating data models for target OLAP databases / data warehouse.
Creating and designing data visualizations using Power BI.
Experience building dashboards and analytics visualizations to derive actionable insights.
Analyzing Excel sources / sheets to identify and extract meaningful data models.
Working in a global, collaborative team environment.
Experience on any of the following: -
Working with Data Lake / Data Warehouse technologies such as Snowflake.
Working with Data Integration, Data quality and automated Data processing software / tools like Snaplogic, Informatica, Talend etc.
Exposure to / Experience with DevOps and fully automated deployments.
Responsibilities:

Business Intelligence Data Analyst
Assess and analyze data to identify required data modeling for target data store.
Analyze product metrics and deliver new or enhance existing data models.
Implement the data models to enable smooth transition and transformation of data from source to target.
Build cubes, dimensions, and facts as required to enable OLAP on existing data warehouse.
Evangelize self-service BI and visual discovery while helping to change Excel based culture
Work closely with development team manager to ensure prioritization of corporate and departmental objectives and projects.
Champion data quality, integrity and reliability throughout the department by designing and promoting best practices.
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!

It is Epiq’s policy to comply with all applicable equal employment opportunity laws by making all employment decisions without unlawful regard or consideration of any individual’s race, religion, ethnicity, color, sex, sexual orientation, gender identity or expressions, transgender status, sexual and other reproductive health decisions, marital status, age, national origin, genetic information, ancestry, citizenship, physical or mental disability, veteran or family status or any other basis protected by applicable national, federal, state, provincial or local law. Epiq’s policy prohibits unlawful discrimination based on any of these impermissible bases, as well as any bases or grounds protected by applicable law in each jurisdiction. In addition Epiq will take affirmative action for minorities, women, covered veterans and individuals with disabilities. If you need assistance or an accommodation during the application process because of a disability, it is available upon request. Epiq is pleased to provide such assistance and no applicant will be penalized as a result of such a request. Pursuant to relevant law, where applicable, Epiq will consider for employment qualified applicants with arrest and conviction records.",3.6,"Epiq
3.6",Hyderabad,"New York, NY",5001 to 10000 employees,1988,Company - Private,Legal,Accounting & Legal,₹100 to ₹500 billion (INR),-1
Senior Data Engineer for Technology,-1,"Senior Data Engineer for Technology (India)

No. of Positions: 1

Are you a high-energy thought leader with a passion for technology innovation? Are you an adaptable self-starter with strong communication skills? Are you willing to teach and coach others as well as continuously learn and grow in your own career?

We are recruiting for a hands-on leader who can inspire others and easily adapt to our dynamic marketplace, mentoring our young engineers and collaborating with other leaders in the business, in India and Australia.

About Rubicon Red: We believe digital technology provides the catalyst to reimagine what’s possible and continuously innovate to transform businesses. We are a boutique provider of custom cloud solutions and specialize in enterprise connectivity and intelligent automation, fundamental to achieving effortless digital experience. Our mission is to help our customers ‘cross the Rubicon’ by transforming the way digital solutions are delivered, to achieve rapid results through continuous innovation in a low risk and cost-effective way.

Rubicon Red is committed to our customer’s success, and to this end, we live by our Brand Promise of Innovation Leadership, Lean Delivery, and Effortless Partnership.

To be successful in this role, you will have:
At least 4+ years of experience in the Data Engineering domain
Extensive hands-on exposure to popular ETL tools such as Informatica, ODI, Pentaho, etc.
Extensive programming knowledge in Python or equivalent language
Good hands-on experience with Hadoop frameworks such as Spark, Hive, Hbase, Ganglia, Zeppelin.
Diverse experience working with various kinds of data sets such as structured, semi-structured and unstructured with file formats such as Parquet and ORC.
Expert knowledge in SQL and associated variants such as Spark SQL, PL / SQL, etc.
Decent understanding of modern data platforms such as data lakes, data warehouses, data marts, etc.
Deep knowledge in building data pipelines for cleansing, processing, curating and aggregating large data sets in the order of GBs and TBs
Decent exposure to at least one BI analytics tool such as Power BI, Tableau
Strong data modeling knowledge with an awareness of dimensional modeling techniques
Excellent communication and client representation skills
Knowledge in AWS data platform technologies such as S3, Glue, Athena, EMR is an added advantage
Knowledge in Data Warehouses such as Snowflake and Redshift is an added advantage",4.2,"Rubicon Red
4.2",Hyderabad,"Brisbane, Australia",51 to 200 employees,-1,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,-1
"Senior Data Analyst, Reinsurance Administration",-1,"Position Overview

Under the responsibility of Chief Executive Officer, India, the Senior Data Analyst – Reinsurance provides a lead role along with the Chief Manager - Reinsurance Administration in order to manage and address data needs per treaty parameters, interpret client data to conform to RGA requirements, and test the processes that map and load client data into Reinsurance Administration systems. The Senior Data Analyst – Reinsurance develops, improves and optimizes programs and tools used for managing data received from clients and insures that good quality data can be used downstream by the various RGA business units

Responsibilities

Key Relationships (Internal & External):
The Senior Data Analyst – Reinsurance establishes a symbiotic relationship with the Chief Manager – Reinsurance Administration in order to support the following groups:

RGA - Finance Department
RGA - Valuation Department
RGA - Operations Department (Includes Claims and Underwriting administrators)
RGA - Data Analytics Department
RGA - Pricing Department
External - Appropriate contacts at client companies

Duties and Responsibilities:
Collect and analyze business needs from users; provide lead role for the team and contribute to effective planning and implementation of identified projects
Support, develop and maintain specialized applications; be an active member and participate in setting data management, data quality and performance goals for the company
Support the process to ensure reinsurance data is received from the client as per agreed timelines, is reconciled with accurate premiums paid for by clients and accurate claims paid to clients & as per treaty terms
Identify the areas of improvements in the processes followed by the Reinsurance Administration team and implement best practices
Develop, maintain and improve data validation processes to ensure the accuracy & quality of client data, including quality assurance and automated testing & validation
Maintain documentation on the processes that map client data to the common formats ensuring consistency across clients and Reinsurance Administration systems
Support the Chief Manager Reinsurance with data compliance requirements & documentation of operations procedures to adhere to SOX process controls and regulatory requirements
Act as backup for the Chief Manager – Reinsurance Administration (peer level)

Requirements

Job Requirements:
Qualifications and Experience:
University Master’s degree in Computer Science, Information Technology or Software Engineering
2-4 years of work experience
Entry level candidates will be considered; motivation to learn and help develop office operations is key

Skills and Attributes:
Required:
Keen sense of data management
Knowledge in SQL and/or PL/SQL and eagerness to learn and manage large relational databases
At ease in managing large Microsoft Excel files, scripting, validation and automation
Creativity and keen interest in business process automation and Visual Basic Macro development
Client focused and self-starter, driven in pursuit of targets
Interest in the insurance industry
Ability to work well within a team environment and participate in department/team projects
Autonomy, accuracy, attention to details
Ability to cope with competing demands and to prioritize tasks
A positive attitude to dealing with people, shares openly and willingly, demonstrates accountability, cooper

Ability to gather proper information and demand training when needed

Company Overview

Reinsurance Group of America, Incorporated (NYSE: RGA) is one of the largest global providers of life reinsurance, with offices around the world. RGA delivers expert solutions in individual life reinsurance, individual living benefits reinsurance, group reinsurance, financial solutions, facultative underwriting and product development. Our mission is to enhance our clients’ prosperity by supporting their financial and risk management capabilities.

Job Reference: IND00213",3.9,"RGA
3.9",Mumbai,"San Francisco, CA",1 to 50 employees,1980,Company - Private,Staffing & Outsourcing,Business Services,₹100 to ₹500 million (INR),-1
Passionate Data Analyst,-1,"Job Overview:


Solve the data problem at scale. Build models that will power the future of logistics and transportation.
Execute analytics leveraging software such as MS Excel, SQL, Tableau, R, Python, etc. and a lot of common sense!
Deliver powerful visualization to stakeholders to make sense of data and let them make the critical decision with multi-crore impact.
In addition to solving the data problems, interact with the leading companies including logistics supply chain companies and the Fortune 500 to tell them how to use their data (once you are a senior wizard).
Understand the macro and micro picture of how the logistics industry will evolve, what trends the data shows and how can customers derive value from them.
Build trust, perform advanced analytics and impact a $100 billion+ logistics industry!

Responsibilities and Duties:


You need to be awesome!
Experience with data analytics: analyse mountains of data in minutes and live deadlines.
Advanced knowledge of statistical analysis which you can use while walking to office.
Ability to learn new tools and technologies fast.
Excellent communication skills as you will be talking to clients over time.
Resourcefulness and troubleshooting aptitude to find the answers when data is incomplete, inaccurate or both.
Accuracy, speed and attention to detail matters, as clients will make decisions based on your analysis.

Good To Have:


Web development.
Familiarity with MS Excel, Tableau and other BI tools, SQL, R, Python etc.
A desire to change the world.

Apply Now!",3.4,"LogisticsNow
3.4",Mumbai,"Mumbai, India",1 to 50 employees,2016,Company - Private,Logistics & Supply Chain,Transportation & Logistics,Unknown / Non-Applicable,-1
Data Engineer,-1,"Requirements
2+ years of experience in DBMS domain
Proven SQL Server 2008/2012 skills
Responsibilities
Development of methodologies and tools to extract/update data from different data sources and put it into database",4.0,"Knoema
4.0",Bengaluru,"Washington, DC",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Scientist - LCM,-1,"Position Description

Business Division: CSM AgChem

Department: Technical Services

Location: Jambusar

Position Title: Scientist - Life Cycle Management

Level: Executive Level

Reporting To : Lead - Life Cycle Management

Position Purpose

Scientists - Life Cycle Management are responsible for managing and improving targeted Yield & Quality and upgrading processes to reduce wastes, solvents and utilities consumption, trouble shoot process problems efficiently to ensure targeted productivity and timely delivery of products.

Strategic Responsibilities

Help achieve entire STRIVE initiatives (2.5 % of COGS)

Operational Responsibilities
Planning & execution of experiments w.r.t., the STRIVE action points for continual improvements of existing processes - for higher Yields, better quality, higher productivity, Recycling of solvents, reducing effluents and improved EHS performance. 2. Demo to Technology Transfer / Technical Services Team / Operation Team. 3. Provide support at time of implementation of STRIVE action points at Commercial scale. 4. Help in trouble shooting of the processes problems at commercial stages. 5. Participate in Route Cause Analysis of process problems. 6. Stress / Deviation / MOC studies for successful implementation of the STRIVE action points. 7. Observation of critical operating parameters and recording in the lab/Electronic note book. 8. Process write-up/ TOP/SOP/BFD preparations. 9. Binding of experimental analytical data sheets and submission of lab documents to library. 10. Performance tests of raw materials and its report submission. 11. Review and update of quality plan. 12. Literature search and its compilation. 13. Preparation of daily report / Man-hours utilization / Fume Hood Occupancy. 14. Use relevant MSDS for safe handling and disposals of chemicals/intermediates/final. 15. Coordination with QC for analytical support. 16. Raw materials planning. 17. Proper housekeeping and use of PPE’s. 18. To ensure proper maintenance of lab equipment’s.
Financial Responsibilities
People Responsibilities
Actively participate to encourage the initiatives in conjunction with the Middle Management Team for better performance of the team.
Training need identification and coordinating with the middle management team for upgrading to the requisite skills.
Inspire & motivate employees through demonstrated commitment to PI’s values, vision & mission and active participation in various team engagement activities
Education Qualification

MSc/PhD in Organic Chemistry

Work Experience

5 - 8 Years Experience in R&D and process development of Agrochemicals, Fine chemicals and their intermediates

Industry to be Hired from

Agro-Fine-Chemicals

Functional Competencies
Experience in managing R&D or process development
Strong technical knowledge to provide guidance to team members/juniors
Understands the broader business drivers with ability to work collaborately with key functions areas such as R&D, Production, QC/QA and EHS
Interaction Complexity and Team Work

Interaction

Frequency

Purpose of Interaction

Internal:
Head Technical Services

Sr. GM / GM / DGM-TS/ Lead LCM

As required for the business

Strive objectives, Process trouble shooting, Improvement projects, new technology

External:
Site head, EHS head, R&D head, QA/QC head

As required for the business

Discuss business requirements, resolve queries and escalations",3.3,"PI Industries Ltd.
3.3",Jambusar,"Gurgaon, India",1001 to 5000 employees,-1,Company - Private,-1,-1,₹500+ billion (INR),-1
Manager Data Science,-1,"Job Responsibilities :
Specify, design, and implement new data science applications,
methodologies,models,and algorithms
Help analyze business cases, formulate the problems and provide
practical solutions
Design and implement large scale predictive analytics machine
learning algorithms
4. Develop code with high-level languages and technologies: R, Python,
Java/Scala, SQL, Map Reduce
Help analyze business cases, formulate the problems and provide
Quantify and measure impacts of solutions
Understand, categorize, organize, and interpret heterogeneous data
sets8. Design experiments, test hypotheses,and build prototypes and
models
Be involved in the transition from prototyping to production
Education Requirement :
B.E./B.Tech/M.E/M.Tech/MS

Experience Requirement :
Maximum 5 Years & above

Skills & Competencies :
Expertise in providing an end to end BI solution by configuring
metadata and building Analytics Repository,dimensional modeling design,
building business models,generating reports and creating dashboards
using Analytics
Strong technical knowledge of Pentaho and related BI Applications,
including approach to implementing, extending and supporting using third
party modules
Strong technical understanding of data structures generated by mobile
applications and networks, and how they relate to establishing data
warehousing, data management and analytic architectures

Location Map : Residential IOT Engineering,Bengaluru,Karnataka",3.6,"Reliance Jio Infocomm Limited
3.6",Bengaluru,"Mumbai, India",5001 to 10000 employees,2010,Company - Private,"Cable, Internet & Telephone Providers",Telecommunications,Unknown / Non-Applicable,-1
Sr. Research Scientist,-1,"Experience 3 - 6 years experience in formulation development of injectables for regulated markets including US / EU / Japan from a reputed company
Location Gurgaon
Description

RESPONSIBILITIES:
Planning, coordination and execution of product development activity for global markets.
Evaluation of literature and patents related to products under development.
Planning of stability studies and reviewing of development and stability data.
Compilation of Technology Transfer Dossier related documents.
Scale-up and technology transfer of products to manufacturing locations.

TECHNICAL EXPERIENCE:
Providing product related technical support to marketing and manufacturing locations.
Good understanding of regulatory requirements of global markets.

PERSONAL ATTRIBUTES:
Good understanding of regulatory requirements of global markets.
Good understanding of IPR strategies for global markets.
""Hands On"" experience of technology transfer to plants.",3.7,"Fresenius Kabi Oncology
3.7",Gurgaon,"Gurgaon, India",501 to 1000 employees,-1,Subsidiary or Business Segment,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,₹100 to ₹500 billion (INR),-1
AWS Data Engineer-Staff,-1,"EY-Consulting
Data and Analytics – Staff – AWS Data Engineer

EY's Consulting
Services is a unique, industry-focused business unit that provides a broad
range of integrated services that leverage deep industry experience with strong
functional and technical capabilities and product knowledge. EY’s financial
services practice provides integrated Consulting services to financial
institutions and other capital markets participants, including commercial
banks, retail banks, investment banks, broker-dealers & asset management
firms, and insurance firms from leading Fortune 500 Companies. Within EY’s Consulting
Practice, Data and Analytics team solves big, complex issues and capitalize on
opportunities to deliver better working outcomes that help expand and safeguard
the businesses, now and in the future. This way we help create a compelling
business case for embedding the right analytical practice at the heart of
client’s decision-making.

The
opportunity
We’re looking for Staff –
Big Data Experts with Experience on AWS services
Your key
responsibilities
Experience building on AWS
using S3, EC2, Redshift, Glue, DynamoDB, Lambda, Step functions, etc
preferred.
Experience with Streamsets,
Kafka, Hive, Pyspark and Python are preferred.
Experience on orchestration
tools like Airflow preferred
Good analytical skills with
excellent knowledge of SQL.
Experience in writing Spark
jobs
Experience using software
version control tools (Git, Jenkins, Apache Subversion)
AWS certifications or other
related professional technical certifications
Experience with cloud or
on-premise middleware and other enterprise integration technologies
Demonstrated strength in
architecting data warehouse solutions and integrating technical components
3+ years’ experience in Big
Data stack environments (EMR, Hadoop, MapReduce, Hive)
3+ years of work experience
with very large data warehousing environment
Excellent communication
skills, both written and verbal
1+ years of experience data
modelling concepts
3+ years of Python and/or
Java development experience
Flexible and
proactive/self-motivated working style with strong personal ownership of
problem resolution.
Excellent communicator
(written and verbal formal and informal).
Ability to multi-task under pressure
and work independently with minimal supervision.
Strong verbal and written
communication skills.
Must be a team player and
enjoy working in a cooperative and collaborative team environment.
Adaptable to new
technologies and standards.
Skills
and attributes for success
Use an issue-based approach
to deliver growth, market and portfolio strategy engagements for
corporates
Strong communication,
presentation and team building skills and experience in producing high
quality reports, papers, and presentations.
Experience in executing and
managing research and analysis of companies and markets, preferably from a
commercial due diligence standpoint.
Exposure to tools like
Tableau, Alteryx etc.
To
qualify for the role, you must have
BE/BTech/MCA/MBA
Minimum 3 years hand-on
experience in one or more key areas.
Minimum 4 years industry
experience
What we
look for
A Team of people with
commercial acumen, technical experience and enthusiasm to learn new things
in this fast-moving environment
An opportunity to be a part
of market-leading, multi-disciplinary team of 1000 + professionals, in the
only integrated global transaction business worldwide.
Opportunities to work with
EY Consulting practices globally with leading businesses across a range of
industries
What
working at EY offers

At EY,
we’re dedicated to helping our clients, from start–ups to Fortune 500 companies
— and the work we do with them is as varied as they are.

You get
to work with inspiring and meaningful projects. Our focus is education and
coaching alongside practical experience to ensure your personal development. We
value our employees and you will be able to control your own development with
an individual progression plan. You will quickly grow into a responsible role
with challenging and stimulating assignments. Moreover, you will be part of an
interdisciplinary environment that emphasizes high quality and knowledge
exchange. Plus, we offer:

Support,
coaching and feedback from some of the most engaging colleagues around

Opportunities
to develop new skills and progress your career

The
freedom and flexibility to handle your role in a way that’s right for you

About EY

As a
global leader in assurance, tax, transaction and Consulting services, we’re
using the finance products, expertise and systems we’ve developed to build a
better working world. That starts with a culture that believes in giving you the
training, opportunities and creative freedom to make things better. Whenever
you join, however long you stay, the exceptional EY experience lasts a
lifetime. And with a commitment to hiring and developing the most passionate
people, we’ll make our ambition to be the best employer by 2020 a reality.",3.8,"EY
3.8",India,"London, United Kingdom",10000+ employees,1989,Company - Private,Accounting,Accounting & Legal,₹500+ billion (INR),"Deloitte, KPMG, PwC"
Machine Learning-data Scientist,-1,"Machine Learning â€“ Data Scientist

Must have skills
6 to 10 years of experience in Machine learning, Predictive modeling
MS/PhD in Statistics, Machine Learning, Natural Language Processing or related field
Statistical modeling like linear, logistic regression, classification, hypothesis testing, ANOVA, PCA, SVD, etc.
Machine learning knowledge like Decision trees, support vector machine and artificial neural networks (ANN), deep learning, random forest and k means clustering
Knowledge of NLP concepts like TFIDF, N-gram modelling, stemming and lemmatization, Entity extraction, sentiment mining, word embedding like word2vec, Glove, doc2vec
Good hands on experience on any one from R, Python, SPSS, SAS, RapidMiner, Weka.
Skills with architecting large-scale high performant distributed systems
Technical discretion in design, execution and interpretation of experiments that contribute to project goals
Ability to work with Pre-sales team to help on initial prospect discussions/presentations
Flexible to work on any domain or verticals
Good to have skills
Knowledge on big data systems like Hadoop, Spark, spark ML, H2O, Tensorflow, Keras, etc.
Experience in core development of Chatbot like systems
Programming languages like Java, CPP
Database systems like MySQL, Postgres, Mongo DB
Participate in scientific conferences and make contributions to publications, research journal write ups and patents
Updated with the latest technologies and research in the field
Main Work Location : Pune
Good communication skills

Working Days : 5 Days a Week ( to )
Job Nature : Full Time

Experience 6 - 10 Years
Salary 20 Lac To 22 Lac 50 Thousand P.A.
Industry IT Software - Application Programming / Maintenance
Qualification Professional Degree
Key Skills Machine Learning

About Company

Email ID getintouch@saffroncareers.in",-1,Saffron Consultancy Services,Pune,"Gurgaon, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"Job Description : Job Responsibilities include: • Creating excel templates for data collection and reporting • Collating and consolidating raw data from various sources • Transforming the raw data to metrics using MS Excel /SQL • Presenting the metrics in simple, comprehensible & neat / readable format • Distributing the reports to the end users & management as per schedule • Ensuring timely delivery and quality of reports & basic analysis • Responding to queries by end users of reports • Automating reports using VB Macros & SQL • Catering to ad-hoc reporting requests by the management • Pulling data and reports from SAP ERP • Assisting in other functions of the department including implementation of new programs and initiatives.

Eligibility : Should have 2 -3 years of relevant experience in MIS / Reporting / Analytics and a Bachelors Degree in Science / Statistics / Operations Should know Advanced MS Excel / VBA / Coding concepts and have working knowledge of automation using MS Excel. Candidates knowing basic SQL and ERP would be preferred.

Venue Locaiton : Bandra",4.2,"ROCHEM Separation Systems
4.2",Maharashtra,"Mumbai, India",501 to 1000 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
"Data Analytics- Interns, Data Analysts",-1,"Data Analytics- Interns, Data Analysts

by Careerxperts Team on August 30, 2014

The Data Analytics team is the lead generation team at CX. You will analyze lot of complex data which in turn can be used by the Recruitment team. This “go getter” team will generate lot of prospective leads which in turn can be utilized and converted to successful sales in the end. Keeping track of the hiring ecosystem of our clients and be involved in market research. Companies hiring “A+ talent”, paying above market compensation and latest technologies, all will be on the radar.

Qualification
Eye for details
Organized, research oriented
Graduates / MBA",-1,CareerXperts Consulting,Bengaluru,"Bangalore, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Engineer,-1,"Date: Jul 25, 2020

As the tech firm that created the mobile world, and with more than 54,000 patents to our name, we’ve made it our business to make a mark. When joining our team at Ericsson you are empowered to learn, lead and perform at your best, shaping the future of technology. This is a place where you're welcomed as your own perfectly unique self, and celebrated for the skills, talent, and perspective you bring to the team. Are you in?

Come, and be where it begins.

Our Exciting Opportunity

As a Senior Data Engineer, you shall be a part of our growing team of MI specialists. As a team leader, you will be evolving and optimizing our data and data pipeline architecture, as well as, optimizing data flow and collection for cross functional teams. You are an expert data pipeline builder and data wrangler who enjoys optimizing data systems and evolving them!

You will
Define the business metrics of success for DE projects and translates them into performance or scalability metrics.
Design and implement the data platform; and build a reporting and analytics engine/platform
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and cloud-based ‘big data’ technologies from AWS, Azure and others.
To be successful in the role you must have
Bachelors/Masters/Ph.D. in Computer Science, Information Systems, Data Science, Artificial Intelligence, Machine Learning, Electrical Engineering or related disciplines.
Overall industry experience of around 10+ years, at least 5 years’ experience as a Data Engineer.
5 plus years of experience in the following:
Software/tools: Hadoop, Spark, Kafka, etc.
Relational SQL and NoSQL databases, including Postgres and Cassandra.
Data and Model pipeline and workflow management tools: Azkaban, Luigi, Airflow, Dataiku, etc.
Stream-processing systems: Storm, Spark-Streaming, etc.
Object-oriented/object function scripting languages: Python, Java, Scala (Advanced level in one language, at least)
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and seek opportunities for improvement.
Experience in Data warehouse design and dimensional modeling
Advanced SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of other databases/date-sources.
What´s in it for you?

Here at Ericsson, our culture is built on over a century of courageous decisions. With us, you will no longer be dreaming of what the future holds – you will be redefining it. You won’t develop for the status quo, but will build what replaces it. Joining us is a way to move your career in any direction you want; with hundreds of career opportunities in locations all over the world, in a place where co-creation and collaboration are embedded into the walls. You will find yourself in a speak-up environment where empathy and humanness serve as cornerstones for how we work, and where work-life balance is a priority. Welcome to an inclusive, global company where your opportunity to make an impact is endless.

What happens once you apply?

To prepare yourself for next steps, please explore here: https://www.ericsson.com/en/careers/job-opportunities/hiring-process

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

Do you believe that an organization fostering an environment of cooperation and collaboration to execute with speed creates better business value? Do you value a culture of humanness, where fact based decisions are important and our people are encouraged to speak up? Do you believe that diverse, inclusive teams drive performance and innovation? At Ericsson, we do.

We provide equal employment opportunities without regard to race, color, gender, sexual orientation, transgender status, gender identity and/or expression, marital status, pregnancy, parental status, religion, political opinion, nationality, ethnic background, social origin, social status, indigenous status, disability, age, union membership or employee representation and any other characteristic protected by local law or Ericsson’s Code of Business Ethics.",3.9,CareerXperts Consulting,Bengaluru,"Stockholm, Sweden",10000+ employees,1876,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Huawei Technologies, IBM, Cisco Systems"
Clinical Data Analyst,-1,"Category: Executive

Location: Chennai and Bangalore

Job Type:
Full Time

Education: Any Degree / Graduate / Post Graduate

Job Description:
Understanding of the clinical development process combined with knowledge of real world medicine which allows overcoming the challenges of collecting quality data in a highly stringent regulatory environment. Complete all mandatory training necessary for the job function.
Should be familiar with CDISC SDTM and ADaM standards.
Provide primary support for study standardization to the CDISC SDTM by creating the SDTM design specifications, including the Annotated CRF and the specification documents.
Should be able to create data definition files and Case Report Forms annotated to the CDISC SDTM standard.
Should be able to train new resources in data standardization processes.
Ability to work on multiple projects simultaneously and meet last minute and scheduled deadlines.

Preferred Skills:
Should be familiar with CDISC SDTM and ADaM standards.

If you would like to apply for this position, or would like a discussion about this, or any other role, please send your contact details, together with your curriculum vitae to:
recruitment.india@navitaslifesciences.com",3.6,"Navitas Life Sciences
3.6",Bengaluru,"Princeton, NJ",501 to 1000 employees,-1,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
Data Engineer with Python,-1,Data Engineer who is highly 5+ years experienced in python and working with relational/nonrelational datastores,3.7,"Covalense Technologies
3.7",Hyderabad,"Hyderabad, India",201 to 500 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Research Scientist,-1,"Manpower Requisition No MPR#17052GFM Department Business Sustainability
Designation Research Scientist Department/Section Process Intensification / Process Intensification Laboratory
Reports To Sr.Research Scientist Reportee NIL
Eperience 4-6 years Salary Range As per Industry Standard
Location NOIDA, UP, India Position Start Date ASAP
No. of openings 2 Work Type Full Time
Percent Travel 25-35% Contact HR Manager

SUMMARY OF FUNCTIONS:
The candidate will be responsible for conducting bench-scale and pilot-scale studies for process development, materials development, process demonstrations and materials failure analysis for membrane based, adsorption based, distillation, liquid etraction and other mass transfer unit operations.

MAJOR ACCOUNTABILITIES:
PRIMARY ROLES & RESPONSIBILITIES:
Perform onsite and off-site bench scale and pilot scale studies
Process Development- Feasibility/proof of concept, parametric studies, Endurance Studies
Material Development – Application envelope determination, Accelerated Life Cycle Determination, Predictive Contamination Determination Studies
Demonstrations – Treatability Studies for eisting applications
Customer Service – Premature Failure Cause Analysis
Assistance in planning
Compilation and interpretation of eperimental data and drafting of technical reports.
Interacting with analytical chemists for method development.
Assistance in design, construction, trouble-shooting and maintenance of application test units and other eperimental hardware.
Participation in process scale-up, technology commercialization, process licensing efforts and key corporate strategic decisions; increasing awareness of Company’s process technologies

ADDITIONAL RESPONSIBILITIES:
Assistance in Department Management
Identifying and implementing solutions, tools for improving the department productivity – quick costing, templatized proposals and contracts etc.
Planning and tracking of department budget including in-house and outsourced manpower, CAPE, OPE and CSR
R&D projects progress monitoring
Identify collaboration partners
Assist in stock management and asset management of the laboratory
Identify and track issues and risks for smooth (productive, safe and information security incident free) functioning of department and related functions
Assistance / Coordination with HR for resource acquisition and assistance in resource selection and handling department personnel issues
Assistance in Cost Accounting of all department activities
Department Procedures and Quality
Assistance in preparing and updating department processes and SOPs
Capturing & Management of Department Knowledge – lessons learnt, best practices etc.
Assistance in keeping department databases updated and generate MIS reports as required
Support Department Compliance & Audits

ACADEMIC QUALIFICATION:
B.Tech./B.S./B.Sc. in Chemical Engineering, Industrial Chemistry, Chemical Technology, Chemistry or Biotechnology from academic institute of repute, candidates in top 5-10% of graduating class preferred
Master’s degree preferred

WORK EPERIENCE:
Eperience preferably in PROCESS R&D in Specialty & Fine-Chemical, Pharma, Biofuels (Distillery, Bio-diesel), Refining or Petrochemical Industry.
Eperience with Membrane separations, adsorption and mass transfer operations
Eperience with any Laboratory Information Management System (LIMS) Preferred
Knowledge of SEM, GC, UV Absorbance and Karl Fischer fundamentals big plus

CERTIFICATIONS/LICENSES/TRAININGS:
Laboratory Safety Training
CHEMCAD, Advanced Ecel, Microsoft Visio

KNOWLEDGE, SKILLS & COMPETENCIES:
Ecellent oral, written (technical writing skills) and coordination skills
Proficiency in MS Office (Word, Ecel, Visio)
Knowledge of using Steady State Process Simulator Preferred
Some hands-on eperimental capabilities and mechanical aptitude along.
Ability to effectively eecute eperimental tasks
Quality, Safety Consciousness
Information Security Awareness
Ability to perform under pressure",2.3,"i3nanotec
2.3",Noida,"Emeryville, CA",201 to 500 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Job Title:
Data Engineer
Job Code:
SWTIND250118_24

Job Description / Responsibilities
Build workflows to ensure data extraction quality and storage into our backend data store
Architect, build and train ML/AI models that can predict outcomes and report on anomalies.
Design data pipelines to perform ETL on content/data from multiple types of source systems.
Create data analytics views using RDBMS/Key-Value stores, on private and public/cloud
Create software that is well tested, maintainable, extensible and scales out with large data
Minimum Qualifications:

2+ years of software development with Python
2+ years of SQL (MySQL/Postgres) and Key-Value databases
1+ years of experience with scikit
2+ years of experience in data extraction, data transformation using custom Python/Java
Experience working with MapReduce/Hadoop/kafka/Elastic stack
Experience with Node backend and React/Redux
Experience working with git/mercurial, Amazon/Google cloud, Linux/LAMP stack
Experience in testing or test driven development
Experience with Data science and Machine Learning algorithm development
Location:

Hyderabad/Bangalore
Package:

Highly competitive to match experience and capability",3.8,"T&VS
3.8",Hyderabad,"Bristol, United Kingdom",51 to 200 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
"Data Engineer-Python,SQL",-1,"We are looking for a talented Data Engineer/BI Developer who will play an integral role in the technical development of critical tools and business workflow leveraging data for decision making. This role involves driving team productivity through creating future state best practices for business analytics.
Responsible for defining, designing, and implementing AWS/BI technologies and services to enable the analysis of data to support strategic initiatives and ongoing business requirements. You will be responsible for creating analytical reports and developing BI layers with resulting action-oriented conclusions.

Responsibilities:
Develop and implement data mining solutions to fit business problems
Hands-on involvement in the design, development and implementation of optimal, scalable AWS services/BI solutions
Understand, implement and automate ETL pipelines with better industry standards
Identify, design and implement internal process improvements: automating manual processes, optimizing data delivery, design infrastructure for greater scalability, etc.
Developing, integrating, testing, and maintaining existing and new applications
Good working knowledge on Python & SQL
Solid understanding of how to design robust data workflows including optimization and user experience
Extract complex data from multiple sources into usable and meaningful reports and analysis
Demonstrated experience in data modeling, scripting, reporting and effective user interface design is highly preferred
Creativity to go beyond current tools to deliver the best solution to the problem
Develop reports and dashboards using R,Tableau, Microstrategy
Work with cross functional team to understand the data extracted from different applications
Independent problem-solving skills and statistical analysis techniques required

Minimum Qualifications:


BS or MS in Computer Science , Engineering
4-7 years experience in BI profile
Advanced working SQL knowledge and experience working with relational Databases (SQL/ORACLE/MySQL etc.,)
Experience with AWS services (EC2, RDS, S3, Data pipeline/Glue, Lambda, DynamoDB etc.,)
Good to have experience in HTML, JavaScript but Python and SQL is must
Experience using data analysis tools like R,Tableau, Micro-strategy or any BI Tools
Data analysis skills in Excel
Strong verbal and written communication skills",3.6,"OLX Group
3.6",Gurgaon,"Amsterdam, Netherlands",5001 to 10000 employees,2006,Company - Private,Internet,Information Technology,₹50 to ₹100 billion (INR),"Amazon, OYO, Quikr India"
Research Scientist for Audio & Video analysis,-1,"Sony Corporation of America , located in New York, NY , is the U.S. headquarters of Sony Corporation, based in Tokyo, Japan. Sony's principal U.S. businesses include Sony Electronics Inc., Sony Mobile Communications (USA) Inc., Sony Interactive Entertainment LLC., Sony Pictures Entertainment Inc., Sony Music Entertainment, and Sony/ATV Music Publishing LLC. With some 900 million Sony devices in hands and homes worldwide today, a vast array of Sony movies, television shows and music, and the PlayStation Network, Sony creates and delivers more entertainment experiences to more people than anyone else on earth. To learn more: www.sony.com .

Sony is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy), gender, national origin, citizenship, ancestry, age, physical or mental disability, military status, status as a veteran or disabled veteran, sexual orientation, gender identity or expression, marital or family status, genetic information, medical condition, or any other basis protected by applicable federal, state, or local law, ordinance, or regulation.

Disability Accommodation for Applicants to Sony Corporation of America

Sony Corporation of America provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. For reasonable accommodation requests, please contact us by email at careers@sonyusa.com or by mail to: Sony Corporation of America, Human Resources Department, 25 Madison Avenue, New York, NY 10010. Please indicate the position you are applying for.",3.8,"Sony Corporation of America
3.8",Mumbai,"Tokyo, Japan",10000+ employees,1946,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),-1
Big Data Engineer,-1,"Description
BizViz provides a 360 degree view of a business's data, serving any vertical and meeting the demanding needs of all business executives. With a 50+ strong team building the BizViz platform over several years, it is targeted at creating technological solutions that will give our customers the edge they need to succeed.

We strongly believe that our success lies in the success of our customers. We aim to build applications the way they envisioned, keeping each business' unique ideas and requirements in mind. We offer businesses a better alternative to using standard cookie-cutter ERP templates.

Job Summary
As a Big Data Engineer, you will be a member of a small, agile team of data engineers responsible for developing an innovative big data platform as a service for enterprises that need to manage mission critical data and diverse application stakeholders at scale. The platform manages data ingestion, warehousing, and governance, and enables developers to quickly create complex queries. The platform provides automatic scaling and elasticity to enable efficient use of resources, and provides services such as security, logging, and data provenance so that third party developers can focus their energy on algorithms rather than administration. We're looking for engineers who want a technical challenge. Help us improve the platform for our current customers and develop new capabilities for our future customers.

Responsibilities
Senior Big Data Engineer is an integral part of the Data Science Innovation team that works closely with Internal/External customer in all phases of the development.
Work with key stakeholders and understand their needs to develop new or improve existing solutions around data and analytics.
Work in a cross-functional, matrix organization, at times under ambiguous circumstances.
Partner in development of scalable solutions using large datasets with other data scientists on the team
Research innovative data solutions to solve real market problems.
Conceptualize, analyze and develop actionable recommendations for strategic challenges facing the organization.
Manage data analysis to develop fact-based recommendations for innovation projects.
Mine Big Data and other unstructured data to tap untouched data sources and deliver insight into new and emerging solutions.
Work with cross-functional teams to develop ideas and execute business plans.
Remain current on new developments in data analytics, Big Data, predictive analytics, and technology.
Education, Experience, Skills and Abilities Required for Consideration as a Candidate:
BTech/MCA degree or higher.
Minimum 5 year experience.
Candidates must be proficient in -
Java, Scala, Python
Apache Spark, Hadoop, Hive, Spark SQL, Spark Streaming, Apache Kafka
Well versed in various Predictive Algorithms, Mllib
Cassandra, RDMS (MYSQL, MS SQL, etc.), NOSQL, Columnar Databases, Big table.
Demonstrate a deep understanding of search engine technology. Ability to configure, index and maintain enterprise scale search applications. Proficient in writing custom handlers for Elasticsearch/Solr.
Agile development including Scrum and other lean techniques.
Excellent problem solving skills with the ability to design algorithms, which may include data cleaning, data mining, data clustering and pattern recognition methodologies
Ability to work cross-functionally in a highly matrix driven organization, at times under ambiguous circumstances
Personal qualities desired: creativity, tenacity, curiosity, and passion for deep technical excellence.
Location
Bangalore & Hyderabad.",3.0,"BDB
3.0",Bengaluru,"London, United Kingdom",51 to 200 employees,1993,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Applied Scientist,-1,"A MS or PhD in Computer Science or Machine learning or Operational research or Statistics or in a highly quantitative field
7+ years of hands-on experience in applied Machine Learning and Big data.
Strong grasp of machine learning, data mining and data analytics techniques
Strong Problem solving ability
Comfortable using Java or C++/C.
Good knowledge of scientific programming in scripting languages like R/Python/Matlab
Sr. Applied Scientist, Retail Systems, Amazon Bangalore

Impact

As a member of Amazon's Global Retail Systems Development team, you'll play a key role in the evolution of our Competitive Monitoring team to solve the world's most complex technical challenges in Natural Language Processing, Optimization, Classification and Prediction.

Innovation

Are you seeking an environment where you can drive innovation? Do you want to apply state-of-the-art computer science and advanced machine learning to solve real world problems of competitive data analysis? Does the challenge of building real time, highly scalable solutions for the most complex online business using innovative technology excite you?

Opportunity

To meet these challenges, the Amazon.com Retail Systems team is looking for passionate, talented and innovative applied scientists for a new team that will be based in Bangalore focused on building and deploying advanced algorithmic systems that help optimize millions of transactions every day. This team will also coordinate with teams in Chennai, India and Seattle, US.
You will be involved in analyzing and modeling terabytes of data to solve real world problems, will own end-to-end business problems/metrics that directly impact the profitability of the company.
PHD in any of the following disciplines - Computer Science, Machine Learning, Data Mining, Statistics, Operational Research
Experience with distributed algorithms
Experience with Hadoop, Hive, Pig, Spark
Superior verbal and written communication skills, ability to convey rigorous mathematical concepts and considerations to non-experts.",-1,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Position Purpose & Summary

The Data Engineer within the regional delivery portfolio will work closely with business partners, Global IT, CBS and 3rd party partners to enable the delivery of process, data, and technology solutions. You will work with the entire Global IT delivery eco-system to understand data, business requirements, create designs, and test solutions to ensure they meet business needs.

As a skilled professional in data and reporting, systems & process design, you will provide solid data and reporting design, system designs, and quality solutions to solve various business requirements. You will expertly manage low to medium rigor projects or work streams throughout the entire project lifecycle and use strong communication skills to deliver effective presentations of the solution detailing data, process, and system design to audiences of all sizes.

To be successful you will leverage common solutions and processes by following Global IT design to deliver solutions and gain knowledge of the solution(s) and business processes for an assigned Regional Delivery Portfolio of either:
Trading
ERP
Operations Supply Chain (OSC)
Functions / Customer Facing
You will have the ability to design solutions by mapping customer business problems and data to reusable end-to-end business application solutions, engage in business decision discussions related to agility, business value, data, and business processes.

You are an individual who is resourceful, confident under pressure, has demonstrated competence in expectation management, and a passion for the business through professionalism and striving for excellence in all aspects of the business experience.

This position is expected follow the Cargill Project Delivery Process and Requirements Analysis and Solution Design process framework.

Principal Accountabilities

50% Analysis & Requirements Gathering
Elicit requirements using interviews, document analysis, requirements workshops, surveys, site visits, business process descriptions, use cases, scenarios, business analysis, task and workflow analysis.
Elicit functional and non-functional (performance, availability, security, accessibility, cross-browser compliance, data) requirements using a methodology most appropriate for the context of each project, such as Joint Requirements Planning (JRP), Joint Application Development (JAD).
Proactively communicate and collaborate with external and internal stakeholders to analyze information needs and functional requirements and deliver the following artifacts as needed: Business Requirements Document, Use Cases, data requirements, Screen, and Interface Designs.
Facilitate requirements discussions with key stakeholders
Communicate and clarify the requirements to the design and development resources. Assist in translating business requirements into functional design specifications
Clarify and improve the business processes and data impacted by the technology changes that are part of assigned projects.
Participate in the evaluation of system changes for downstream system and/or organizational impacts
Plan for acceptance of solution (change management, communication, training needs)
Provide subject matter expertise in assigned business process areas
20% Solution Design
Create solution designs across process, data, and technology that meet business requirements and adhere to relevant standards and principles, leverage common tools and processes, and meet cost/delivery objectives.
Consider in the design, the business implications of the application of technology to the current and future business environment.
Perform reviews with key stakeholders throughout the design lifecycle to ensure alignment on solution designs and requirements. This may include but is not limited to the following activities: design reviews, testing execution, data validation, deployment verifications, customer satisfaction reviews, etc.
Create supporting solution design documentation to ensure sustainment of the solution and business capability, support solution implementation as necessary.
Develop requirements specifications according to standard templates, using natural language.
Participate with developers and subject matter experts to establish the technical vision and analyze trade-offs between usability and performance needs.
Be the liaison between the business, technology teams and support teams.
Actively participate in discussions on solution options and business partner decision making to minimize the amount of project investment divergence from target architecture
15% Business Partnership
Work with businesses to identify and confirm connections between business goals, strategies,process, data, and technology investments required to achieve them.
Engage with and influence business units on their assumptions of how they will successfully execute their plans
Create and maintain strong working relationships with technology teams, functional counterparts, vendors and business partners.
Effectively engage stakeholders in change management activities
15% Project Delivery Responsibilities
Manage workload and priorities to deliver agreed upon project milestones
Provides input to staffing plans at the project-level to identify key / required skills
Ensure traceability from business requirements through application testing and work with offshore development and QA teams clarifying requirements.
Deliver presentations and training of solutions to stakeholders and end users
Holds project team resources accountable to their deliverables and ensures project execution.
Prepare high and detailed level estimations of effort in order to achieve a preferred solution.
Provide guidance and oversight during requirements, design, build, and test phases.
Education, Experience, Skills

Minimum Required Qualifications
Bachelor’s degree in Business Administration, Computer Science or Management Information Systems; OR equivalent experience
3 years experience in diverse operational, development and/or business roles
3 years experience collaborating with project teams to define business requirements and deliver solutions that meet business goals
3 years experience in developing integrated solutions involving process, data, and technology
1 – 3 years experience with GitHub, TSVS, AzureDepOps and other repository systems
1 – 3 years working experience with Hadoop or other Big Data platform and building solutions that deliver value through leveraging data as an asset
1 years experience with Agile methodology.
Ability to travel up to 20%
Preferred Qualifications
3 years experience across various businesses and project types (including custom software development, COTS and SAAS implementation, O&M support).
2 years experience in Use Case diagramming, Business Process Modeling (BPM) and User Stories development
Experience working in a business role including mergers and acquisitions
Experience with in-house developed and package implementations.
Knowledge of and experience with Change Management, industry certification (e.g ITIL, six sigma etc)
Knowledge of data access framework, data processing pipeline tools , and or other ETL knowledge.
Applied Experience with numerical algorithms, data structures and statistics
Applied Experience with Visualisation tools like Power BI, Tableau etc.
Applied Experience with Cloud platform including AWS and/or Azure.
Other relevant information to the position
Success Attributes
Strong analytical skills required, including a thorough understanding of how to interpret customer business needs and translate them into application and operational requirements.
Ability to influence peers and leadership stakeholders
Strong written and verbal communication skills, ability to communicate technical and business information effectively to both technical and non-technical people.
Strong project management, planning and organizational skills
Ability to quickly comprehend the functions and capabilities of new technologies
Demonstrated ability in identifying and developing strategies to address change management issues
Business fluency in English",4.0,"Cargill
4.0",India,"Wayzata, MN",10000+ employees,1865,Company - Private,Food Production,Agriculture & Forestry,₹500+ billion (INR),-1
Senior Data Engineer,-1,"About JLL Technologies

JLL is a leading professional services firm that specializes in real estate and investment management. Our vision is to reimagine the world of real estate, creating rewarding opportunities and amazing spaces where people can achieve their ambitions. In doing so, we will build a better tomorrow for our clients, our people and our communities.

JLL Technologies is a specialized group within JLL. At JLL Technologies, our mission is to bring technology innovation to commercial real estate. We deliver unparalleled digital advisory, implementation, and services solutions to organizations globally. Our goal is to leverage technology to increase the value and liquidity of the world's buildings, while enhancing the productivity and the happiness of those that occupy them.

What this job involves:

We are looking for a Senior Data Engineer who is self-starter to work in a diverse and fast-paced environment that can join our global Data Engineering team. This is an individual contributor role that is responsible for the designing and developing of data solutions that are strategic for the business and built on the latest technologies and patterns. This a global role that requires partnering with both the regional IT teams as well as the other global engineering teams.
Contribute to the design of information infrastructure, and data management processes to move the organization to a more sophisticated, agile and robust target state data architecture
Develop systems that ingest, cleanse and normalize diverse datasets, develop data pipelines from various internal and external sources and build structure for previously unstructured data
Interfaces with internal colleagues and external professionals to determine requirements, anticipate future needs, and identify areas of opportunity to drive data development
Develop good understanding of how data will flow & stored through an organization across multiple applications such as CRM, Broker & Sales, Finance, HR, MDM, ODS, Data Lake, & EDW
Develop data solutions that enable non-technical staff to make data-driven decisions
Design & develop data management and data persistence solutions for application use cases leveraging relational, non-relational databases and enhancing our data processing capabilities
Develop POCs to influence platform architects, product managers and software engineers to validate solution proposals and migrate
Develop data lake solutions to store structured and unstructured data from internal and external sources and provide technical guidance to help migrate colleagues to modern technology platform
Sound like you? Before you apply it’s worth knowing what we are looking for:

Required Qualifications, Skills & Experience
Bachelor’s degree in Information Science, Computer Science, Mathematics, Statistics or a quantitative discipline in science, business, or social science.
Hands-on engineering lead who is curious about technology, should be able to quickly adopt to change and one who understands the technologies supporting areas such as Cloud Computing (AWS, Azure(preferred), etc.), Micro Services, Streaming Technologies, Network, Security, etc.
3 to 5 years of experience as a data developer using Python-spark, Kafka, Spark Streaming, Azure SQL Server, Cosmos DB/Mongo DB, Azure Event Hubs, Azure Data Lake Storage, Azure Search etc.
Hands-on Experience of building Data Pipelines in Cloud and well versed with CICD and DevOps process.
Experience of handling un-structured data, working in a data lake environment, leveraging data streaming and developing data pipelines driven by events/queues
Experience building and maintaining a data warehouse/ data lake in a production environment with efficient ETL design, implementation, and maintenance
Team player, Reliable, self-motivated, and self-disciplined individual capable of executing on multiple projects simultaneously within a fast-paced environment working with cross functional teams
What you can expect from us:

We’re an entrepreneurial, inclusive culture. We succeed together—across the desk and around the globe. We believe the best inspire the best, so we invest in supporting each other, learning together and celebrating our success.

Our Total Rewards program reflects our commitment to helping you achieve your ambitions in career, recognition, well-being, benefits and pay. We’ll offer you a competitive salary and benefits package.

With us, you’ll develop your strengths and enjoy a career full of varied experiences. We can’t wait to see where your ambitions take you at JLL.

Apply today!

JLL Privacy Notice

Jones Lang LaSalle (JLL), together with its subsidiaries and affiliates, is a leading global provider of real estate and investment management services. We take our responsibility to protect the personal information provided to us seriously. Generally the personal information we collect from you are for the purposes of processing in connection with JLL’s recruitment process. We endeavour to keep your personal information secure with appropriate level of security and keep for as long as we need it for legitimate business or legal reasons. We will then delete it safely and securely.

For more information about how JLL processes your personal data, please view our Candidate Privacy Statement.

For additional details please see our career site pages for each country.

For employees in the United States, please see a fully copy of our Equal Employment Opportunity and Affirmative Action policy here.

Jones Lang LaSalle (“JLL”) is an Equal Opportunity Employer and is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process – including the online application and/or overall selection process – you may email us at Accommodation.Reques@am.jll.com. This email is only to request an accommodation. Please direct any other general recruiting inquiries to our Contact Us page > I want to work for JLL.",4.1,"JLL
4.1",Bengaluru,"Chicago, IL",10000+ employees,-1,Company - Public,Real Estate,Real Estate,₹500+ billion (INR),"CBRE, Cushman & Wakefield"
Data Analyst,-1,"Experience : 3-8 years
Job Type : Permanent
Work Location : Whitefield,Bangalore.

Notice Period : IMMEDIATE ONLY
.
Skills : Big Data,Python development,REST API,Data Visualisation.

Mail ID : hr10@cadmaxx.com
Contact Number : 9739866653
00-8.00 Years",3.4,"Cadmaxx Solutions Private Limited
3.4",Bengaluru,"BENGALURU, India",201 to 500 employees,-1,Contract,-1,-1,Unknown / Non-Applicable,-1
Corporate and Investment Banking - Quantitative Research Credit Bond - Vice President,-1,"Key responsibilities could include:
Developing models for the pricing and risk management of corporate bonds and corporate bond derivatives (e.g. bond options, total return swaps, asset swaps), including investigating improvements to existing models
Writing model documentation compliant with internal and regulatory standards
Working with model control teams to facilitate timely and efficient review and approval of models
Liaising with business functions as well as other quantitative research and control teams
Explaining model behaviour, carrying out scenario analyses, developing and delivering quantitative tools, and supporting analytics
Requirements:

The role requires the combination of very strong software development skills, a very structured mathematical approach to problem solving, business overview, and the ability to work in a dynamic environment. Prior knowledge of quantitative modeling and risk neutral pricing is a plus, but not an absolute requirement. Excellent oral communication skills are required in our interaction with trading, technology, and control functions. Excellent written communication skills are also required for meeting the high standards of the model documentation. A strong interest in good software design principles is a requirement as well. A Ph.D. in a numerate subject from a top academic institution is a plus, but not an absolute requirement.

Essential skills :
An advanced degree in math, statistics, physics, financial engineering, computer science or other quantitative fields
Exceptional analytical, quantitative and problem-solving skills
Excellent written and oral communication and interpersonal skills
Knowledge of fixed income markets, in particular credit products and models, is a plus, but is not a strict requirement.
Strong software design and development skills, preferably with some C++ and Python knowledge and experience
Pro-active attitude. Should have a natural interest to learn about our business, models, and infrastructure.
Ability to work in a high-pressure environment
Attention to detail and focus on quality of deliverables .
Ideal candidates for these positions would be a graduate/post-graduate from a premier college or institute. A computer science or mathematics background will be most suitable.

J.P. Morgan's Global Quants Group provides a challenging work environment and excellent opportunities to learn and grow both at the Quants Group and in the Firm's global network.

We recognize that our people are our strength and the diverse talents they bring to our global workforce is directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, or disability, or any other basis protected under applicable local law. In accordance with applicable local law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.",3.9,"J.P. Morgan
3.9",Mumbai,"New York, NY",10000+ employees,1799,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Data Engineer,-1,"Job Description

If you love the challenges that come with big data then this role is for you. We are looking for Data Engineers who can handle of events a day, manage petabyte scale data on Redshift and S3, and develop data pipelines using Spark/Scala EMR, SQL based ETL, and Java services.

This role requires you to live at the cross section of data and engineering. You have a deep understanding of data, analytical techniques, and how to connect insights to the business, and you have practical experience in insisting on highest standards on operations in ETL and big data pipelines..

We deal in AWS technologies like Redshift, S3, EMR, EC2, DynamoDB, Kinesis Firehose, and Lambda. You'll build our data portfolio and partner with Product, Marketing, BI, and ML teams to build new behavioural events, pipelines, datasets, models, and reporting to support their initiatives. You'll also continue to develop our offline analytics capabilities in Tableau and build out our real time dashboarding capabilities.

Come innovate with the Coda Data & Analytics Team!

Basic Qualifications

Bachelor’s degree in computer science, mathematics, statistics or a similar quantitative field
Experience with Redshift or another columnar store DW
Experience with cloud solutions / AWS / Azure / Google cloud
Experience building reports and/or data visualization
Experience with Hadoop/MapReduce/AWS/EMR
Experience with Spark/Scala/PySpark/ Apache Kafka / Kinesis Streams / AWS Glue
Experience building or administering reporting/analytics platforms
Experience building flexible data APIs that consumers use to power other parts of the business Preferred Qualifications
3 to 5 years of experience as a data/software developer/scientist or related technical job
Experience working with predictive analytics/decision models/data mining libraries as well as the tools for developing it
Experience in algorithm design and problem solving
Experience leading small teams of engineers
Experience with Agile Development
Experience with Machine Learning (Classification, Collaborative Filtering)
Love for Data",4.4,"Coda Global
4.4",Tamil Nadu,"Southlake, TX",51 to 200 employees,-1,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1
Data Analyst,-1,"We have a wide variety of career opportunities around the world come find yours.

Overview

Extract data and use statistical modeling and data analysis to drive incremental value. You will focus on leveraging existing technology capability to drive revenue growth in current year. You will also be supporting the team's strategic goals of defining the technology and data infrastructure roadmap to enhance performance of existing products and/or create new revenue streams, in partnership with the internal stakeholders. You will be collaborating with a number of internal and external teams to accomplish these goals.

It is essential that you are quantitatively orientated, results focused and of a test-and-learn mindset. Airline experience is not required for this position. People with retail experience and mentality will be successful in this role. This role requires business intuition and a working knowledge of analytical tools.

Responsibilities
Execute solutions to business problems using data analysis, data mining, optimization tools, statistical modeling and machine learning techniques
Develop and validate evaluation metrics and models to analyze business performance and areas of opportunity
Act independently to identify opportunities for improved analysis or improved efficiency through better use of statistical tools
Identify practical approach to test and learn key hypotheses to extend analytic insight
Leverage new data and/or experimental results to extend analytical frameworks/algorithms
Design experiments and analyze results to determine effectiveness of programs, policies and strategies
Collaborate with internal and external teams, help business owners make faster, smarter decisions
Socialize key initiatives with stakeholders
Create and deliver presentations as required
This position is offered on local terms and conditions. Expatriate assignments and sponsorship for employment visas, even on a time-limited visa status, will not be awarded.

Knowledge/Skills
Must have a proven, strong background in statistical concepts and working knowledge of statistical software (i.e. SAS, STATA, R etc.)
Ability to communicate complex quantitative analysis and algorithms in a clear, precise and actionable manner required
Excellent written and oral communication skills required
Must be fluent in English (written and spoken)
Experience using database querying tools and ability to write complex queries using Teradata SQL and/or Microsoft TSQL required
Familiarity with SQL Server Reporting Services required
Ability to learn new technologies required
Experience
Demonstrated experience in empirical research and for answering hard questions with data required
Experience in data mining and experimental design and analysis required
Demonstrated experience in manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources to highlight patterns and relationships required
Other
About 4-6 weeks of travel to US in a year required
Must be legally authorized to work in India for any employer without sponsorship
Successful completion of interview required to meet job qualification
Reliable, punctual attendance is an essential function of the position


Equal Opportunity Employer – Minorities/Women/Veterans/Disabled/LGBT",4.1,"United Airlines
4.1",Gurgaon,"Chicago, IL",10000+ employees,1926,Company - Public,Airlines,Travel & Tourism,₹500+ billion (INR),"American Airlines, Delta Air Lines, Southwest Airlines"
Artificial Intelligence Scientists,-1,"Experience 2- 4 Years
Salary 4 LPA - 6 LPA
Job Location Chennai

Industry:
IT-Software / Software Services

Keywords:
Artificial Intelligence

About Job:
Must have Excellent knowledge in AI / Machine learning (Mandatory).
Machine learning frameworks like keras, tensor flow etc.
And also other big data tools like Hadoop etc, Must know R and python.
Good understanding in SDLC & Business cycle.",4.1,"Careerera
4.1",Chennai,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
Data Engineer,-1,"Tech9 is a fast growing custom software development company. We work to represent an ideal in software development delivery. We strive to make each client love us by providing a skilled team, engaging design, solid architecture, and quality implementation. We tackle big challenges with enthusiasm and gusto.


Tech9 India is looking for junior and senior Data Engineers. This is a great opportunity to work with a company that has a primary focus of making our customers happy by delivering value, without all the burdensome policies and rules that have become typical for outsourced software development companies.

If you are looking for a change this is what we can promise you:
You will have challenging problems to solve
You will have flexibility and autonomy to solve problems and deliver solutions
We will provide a highly collaborative environment with skilled and super friendly teammates
We will fully support you in developing software the right way
We won't burden you with useless policies and procedures
We will provide you the tools you need to do your job right
If that sounds attractive please apply! We'd love to talk to you.

Job Overview


We are looking for savvy Data Engineers to join our growing team. This person will be responsible for expanding and optimizing data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder who enjoys optimizing data systems and building them from the ground up. This Data Engineer will support our software developers on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.

Responsibilities for Data Engineer
Create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Python, SQL and AWS
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications for Data Engineer
Working knowledge of SQL
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment
Experience with relational SQL databases
Knowledge of Object Oriented Development
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience developing in Python required
Experience with data pipeline and workflow management tools like Azkaban, Luigi, Airflow, etc preferred
Experience with Flask is preferred
Powered by JazzHR",4.3,"Tech9
4.3",Pune,"Draper, UT",51 to 200 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Sr. Analyst- Data Science,-1,"Company Description

About Merkle

Merkle is a global data-driven, technology-enabled performance marketing agency. For over 30 years, Fortune 1,000 companies and leading nonprofit organizations have partnered with us to build and maximize the value of their customer portfolios. We work with world-class brands like Dell, T-Mobile, Samsung, GEICO, Regions, Kimberly-Clark, AARP, Lilly, Sanofi, NBC Universal, DIRECTV, American Cancer Society, Habitat for Humanity, and many others to build and execute customer-centric business strategies. With more than 9,000 smart, dedicated people in more than 50 offices around the world, we are still growing at a rate that outpaces the market, with 2018 net revenue of $846million.

About Dentsu

Dentsu is the world’s largest advertising agency brand, a company with a history of 118 years of innovation, the Dentsu Group provides a comprehensive range of client centric brand, integrated communications, media and digital services through its ten global network brands—Carat, Dentsu, dentsu X, iProspect, Isobar, McGarry Bowen, Merkle, MKTG, Posterscope and Vizeum—as well as through its specialist/multi-market brands. The Dentsu Group has a strong presence in over 145 countries and regions across five continents and employs more than 62,000 dedicated professionals. Dentsu Aegis Network Ltd., its international business headquarters in London, oversees Dentsu’s agency operations outside of Japan. The Group is also active in the production and marketing of sports and entertainment content on a global scale.

Job Description

Merkle | Sokrati, a leader in Digital Marketing and Analytics, managing Digital Marketing campaigns for several large brand clients in India. We are currently a 750+ people team; and growing extremely fast to gain more market share and roll out even cooler technology solutions in Digital Advertising space.

In pursuit of this, we seek to hire an Analyst / Sr. Analyst – Data Science in ourteam.

What you’ll do at Merkle|Sokrati?
Use statistical methods to analyze data and generate useful business reports
Analyze client data using EDA and provide actionable insights to improve processes and present them successfully to management using a reporting tool.
Use data to create AI&ML models to solve complex business problems
Provide support for ad hoc requests from the Business Users
Provide support for Analytics Processes monitoring and troubleshooting.
Identify, evaluate and implement external services and tools to support data validation and cleansing
Liaise with internal and external clients to fully understand data content
Gather, understand and document detailed business requirements using appropriate tools and techniques
Support in creating PowerPoints, reports, dashboards and models
Independently determine the appropriate approach for new assignments
Complete a variety of atypical assignments
Solve a range of straight forward problems
Builds knowledge of the organization, processes and customers
What’s on Offer:
An opportunity to work with one of India’s most promising companies in a genuine growth hacking role
Unparalleled learning opportunities in the company of ridiculously smart folks with very high levels of expertise in their respective functions
Fantastically transparent, vibrant and positive work culture
Qualifications

What we are looking for?
Someone who is inquisitive and has great problem-solving skills.
1-3 years core data science/analytics experience
Hands-on experience of building statistical models like regression, decision tree, random forests and other AI/ML models is a must
Experience using R, Python, SAS is mandatory.
Ability to write SQL queries, doing cohort analysis, comparative analysis etc.
Ability to lead own projects and work independently once given a direction.
Experience working directly with business users to build reports, dashboards and solving business questions with data.
Experience of working on visualization tools (Tableau/Power BI etc.)
Understanding about GA360/Adobe/Datorama/CDP/DMP etc.",3.6,"Merkle
3.6",Pune,"Columbia, MD",1001 to 5000 employees,1971,Company - Private,Advertising & Marketing,Business Services,₹50 to ₹100 billion (INR),"Accenture, Deloitte"
Big Data Analyst,-1,"TEG Analytics is committed to deliver on the promise of BIG DATA technologies and Machine Learning algorithms to solve complex business problems for our clients. The business problems range from BIG data problems to BIG-DATA problems. E.g. we are developing recommendation engines that offer the right medical plan for the right individual using vast amounts of publicly available healthcare data. We are also analyzing telematics data from thousands of tractors operating in various conditions throughout the US to predict exactly which part in which tractor is likely to fail in the next 72 hours
To meet the demands of Insights @ Speed of Business, we are in the process of re-engineering our entire Technology stack using open source which sometimes feels like a wild wild west.",3.1,"TEG Analytics
3.1",Bengaluru,"Bengaluru, India",51 to 200 employees,2008,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Data Analysts,-1,"JOB INFORMATION

Very good programming skills, preferably in ‘R’ language
Strong Experience in MySQL
Ability to grasp nuances of business quickly
Experience in business requirements gathering
Use statistical methods to analyse data and generate useful business reports
Ability to solve problem and break down complex problem into solvable pieces
Ability to deliver quick and accurate results for each analysis/task",4.8,"Zoxima
4.8",Noida,"Noida, India",51 to 200 employees,-1,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Advanced Multiscale Process Modeling Engineer,-1,"Relocation Level: Domestic

Hiring Manager: Sumeet Pandey

Recruiter: RAGHUNATH RAO PASUPULATY

Micron Technology’s vision is to transform how the world uses information to enrich life and our commitment to people, innovation, tenacity, collaboration, and customer focus allows us to fulfill our mission to be a global leader in memory and storage solutions. This means conducting business with integrity, accountability, and professionalism while supporting our global community.

As an Advanced Modeling Engineer in the Technology Development Group at Micron Technology, Inc., you will be responsible for developing first-principles physical, chemical, thermal, mechanical, materials, and statistical/ML/AI models for unit processes (such as, Plasma etch, Wet etch, ALE, CVD/ALD/Diffusion, PVD, CMP, etc. that enables manufacturing of next generation memory chips). You will model the unit process at multiple length scales, calibrate against process data, and train the models to provide for predictive unit-process modeling capability. You will contribute and develop modeling workflows, platforms, and applications working with other members of the TDE modeling team.

Responsibilities include but are not limited to:
Development of unit-process models and its cross-interactions in a process flow
Perform process space exploration, and statistical studies to derive margin and sensitivity
Perform process simulations, validation, optimization, and devise predictive control strategies
Build unit-process models to better predict memory scaling roadmap
Estimate impact of process on structural stability, electrical performance, yield, and reliability
Model and simulate processes at reactor-, wafer-, die-, and feature-scale
Modeling of plasma in reactor/equipment, plasma-surface/materials interactions, and feature profile evolution
Process simulations using various methods: MC, MD, phase-field, cellular-automata, level-set, computational fluid dynamics (NS and LBM), reactive multiphase flows, micro-/nano-fluidics, immersed boundary, mesh-free, and various finite-differences, finite-elements, and finite volume simulations of mass, heat, and fluid transport
Perform mesh generation, structure conversions, algorithms and software development, large-scale visualization, and parallel programming
Development of advanced numerical methods, meshing algorithms, multi-scale modeling and coupling schemes, and stand-alone applications
Work with process teams and equipment suppliers to deliver process-equipment models to process teams
Develop stress/strain models that captures process-induced deformation and failures using finite element structural mechanics, thermo-mechanical, and fluid-structure simulations
Apply and implement ML/AI techniques for process analytics
Design, develop, test, deploy and maintain applications/software
Qualifications:
3+ years of experience in the use of process modeling tools
3+ years of experience in multi-scale multi-physics modeling/simulations
2+ years of experience in statistical, machine learning, and AI techniques
2+ years of experience with stress/strain modeling
Strong background in thermodynamics and kinetics
Strong background in semiconductor processes and fabrication
Strong background in machine learning algorithms and image processing
Strong knowledge of solid mechanics
Experience with application development is strongly desired
Excellent verbal and written communication skills with the ability to operate across large teams in a fast-paced dynamic environment
Education:
A MS/M.Tech or PhD in Chemical Engineering, Electrical Engineering, Computer Science, Materials Science, Physics, Chemistry, Mechanical Engineering, or related discipline.
About Us

As the leader in innovative memory solutions, Micron is helping the world make sense of data by delivering technology that is transforming how the world uses information. Through our global brands - Micron, Crucial and Ballistix - we offer the industry's broadest portfolio. We are the only company manufacturing today's major memory and storage technologies: DRAM, NAND, NOR and 3D XPoint™ memory. Our solutions are purpose built to leverage the value of data to unlock financial insights, accelerate scientific break throughs and enhance communication around the world.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

Keywords: Hyderabad || Andhra Pradesh (IN-AP) || India (IN) || Technology Development || Experienced || Regular || Engineering || #LI-RR1 || Tier 4 ||",3.5,"Micron
3.5",Hyderabad,"Boise, ID",10000+ employees,1978,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Samsung Electronics, SK hynix, Toshiba"
Financial Data Analyst,-1,"- Analyzing operational cost
Should be excellent in creating multiple reports
Improve financial status by analyzing results; monitoring variances; identifying trends; recommending actions to management.
Should have hands-on experience with Tally, Advance Excel, Dashboard, Analysis.
4-5 Years of experience

Job Type: Full-time

Work Remotely:
No",5.0,"CO-OFFIZ
5.0",New Delhi,"New Delhi, India",1 to 50 employees,2015,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
AI/Machine Learning Engineer (Premium Institute only),-1,"Share this job

Description

Requirements

We are looking for applicants with a strong background in Analytics and Data mining (Web, Social and Big data), Machine Learning and Pattern Recognition, Natural Language Processing and Computational Linguistics, Statistical Modelling and Inferencing, Information Retrieval, Large Scale Distributed Systems and Cloud Computing, Econometrics and Quantitative Marketing, Applied Game Theory and Mechanism Design, Operations Research and Optimization, Human Computer Interaction and Information Visualization. Applicants with a background in other quantitative areas are also encouraged to apply.

We are looking for someone who can create and implement AI solutions. If you have built a product like IBM WATSON in the past and not just used WATSON to build applications, this could be the perfect role for you.

All successful candidates are expected to dive deep into problem areas of Zycus’ interest and invent technology solutions to not only advance the current products, but also to generate new product options that can strategically advantage the organization.

Skills:
Experience in predictive modelling and predictive software development
Skilled in Java, C++, Perl/Python (or similar scripting language)
Experience in using R, Matlab, or any other statistical software
Experience in mentoring junior team members, and guiding them on machine learning and data modelling applications
Strong communication and data presentation skills
Classification (svm, decision tree, random forest, neural network)
Regression (linear, polynomial, logistic, etc)
Classical Optimization(gradient descent, newton raphson, etc)
Graph theory (network analytics)
Heuristic optimisation (genetic algorithm, swarm theory)
Deep learning (lstm, convolutional nn, recurrent nn)

Must Have:
Experience: 3-9 years
The ideal candidate must have proven expertise in Artificial Intelligence (including deep learning algorithms), Machine Learning and/or NLP
The candidate must also have expertise in programming traditional machine learning algorithms, algorithm design & usage
Preferred experience with large data sets & distributed computing in Hadoop ecosystem
Fluency with databases
Benefits",3.3,"Zycus
3.3",Mumbai,"Princeton, NJ",501 to 1000 employees,1998,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),"SAP Ariba, GEP, Coupa Software Inc"
Lead Data Engineer,-1,"Lead Data Engineer (Full-Time)

Vahan was founded with a mission to unlock the potential of the blue collar workforce. We’re building an AI-driven assistant on WhatsApp to bring jobs to the next billion internet users globally. With 96% of smartphone users already using WhatsApp, there is no need for them to download anything else to use Vahan’s job assistant.

Data is at the heart of everything we do. We are looking for a Lead Data Engineer. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. This role will also work with Machine learning team to help them with Productionizing ML models. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. This role will support our software developers, database architects, data analysts and ML scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Responsibilities

Design, build, test, and maintain machine learning infrastructure and services.
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Deploy ML models.
Monitor ML APIs and provide 99.99% uptime, reliability and availability.
Bring best practices to bridges between ML and Backend

We can promise:
Our co-workers are a close-knit, intelligent, and motivated team
We care about you. We offer competitive health insurance for employees and their dependents.
Unlimited PTO so you can take the time you need to rejuvenate
You’ll love where you work. We have a bright and modern collaborative office space located in the heart of Indiranagar, Bangalore’s most happening neighborhood!

Compensation will be commensurate with experience (Cash + Bonus + Equity)

Qualifications

BTech/MTech in Computer Science
4+ years of relevant experience is must.
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Cross-cultural background and experience.
Passion for creating positive social impact
Collaborative, organized, and detail-oriented
Comfortable working in a fast-paced startup environment
Strong interpersonal and communication skills",5.0,"Vahan
5.0",Bengaluru,"Bengaluru, India",1 to 50 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Business Analyst - Data Analyst - Capital Market/Investment Banking,-1,"5-8 year of experience as Business Analyst – Data Analyst.
Should have Strong Domain knowledge in Banking and Financial Services in Capital Market/Investment Banking area
Strong knowledge of complete Trade lifecycle of 2-3 common asset classes (Securities, Derivatives, OTC etc.)
Strong Analytical Skills & problem-solving skills o Fundamental analytical and conceptual thinking skills.
Experience creating detailed reports and giving presentations
Excellent planning, organizational, and time management skills
Strong experience in SQL queries for data extraction & data analysis
Should be well versed with BA role and responsibilities, like understanding BRD, FRD writing and Managing E2E implementation.
Strong Communication (written & verbal) and excellent Stakeholder management Skills.
Flexible to work in UK shift
External BA certification (AAC/CCBA/CBAP/CSPO) would be an added advantage",3.5,"Larsen & Toubro Infotech Limited
3.5",Pune,"Mumbai, India",10000+ employees,1997,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,"Infosys, Accenture, Capgemini"
Job Opening for Data Science Lead,-1,"Job Description: - An opportunity in a leading IT Company

Position - Data Science Lead
Location - Mumbai
Work Experience - 7 to 14 years
Notice Period - Immediate candidates preferred

Interested Candidates may apply with updated / latest Resume, Total Experience, Current CTC, Expected CTC, Notice Period.

Email - jobs@teamacehr.com / Email Subject - Job Opening for Data Science Lead

WhatsApp - +91-8657418510
00-14.00 Years",-1,Team Ace HR LLP,Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are seeking a hands-on senior data engineer to help us build out and manage our data infrastructure, which will need to operate reliably at scale using a high degree of automation in setup and maintenance. The role will involve both setting up and managing the data infrastructure, as well as building and optimizing key ETL pipelines on both batch and streaming data. The ability to work with the teams from product, engineering, BI/analytics and data science is essential. Ownership needs to be taken of data model design and data quality. Automation and the use of data science to manage and improve data quality would be valued. The individual will also play active roles in ensuring data governance policies and tooling are implemented and adhered to.

The individual will also need to be able to manage multiple stakeholders at an executive level and make well informed architectural choices when required. A high degree of empathy is required for the needs of the downstream consumers of the data artefacts produced by the data engineering team, i.e. the software engineers, data scientists, business intelligence analysts, etc and the individual needs to be able to produce transparent and easily navigable data pipelines. Value should be assigned to consistently producing high quality metadata to support discoverability and consistency of calculation and interpretation.

Candidates should have a wide set of experience across the following systems and languages:
Apache Kafka
Apache Flink
Apache Airflow
Cloud data warehouses such as Redshift or BigQuery
Python and Java",4.5,"DKatalis Labs
4.5",Pune,"Jakarta, Indonesia",201 to 500 employees,2018,Unknown,IT Services,Information Technology,₹500+ billion (INR),-1
Data Engineer/Python Spark Developer,-1,"The Applications Development Intermediate Programmer Analyst is an intermediate level position responsible for participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to contribute to applications systems analysis and programming activities. Responsibilities: Utilize knowledge of applications development procedures and concepts, and basic knowledge of other technical areas to identify and define necessary system enhancements, including using script tools and analyzing/interpreting code Consult with users, clients, and other technology groups on issues, and recommend programming solutions, install, and support customer exposure systems Apply fundamental knowledge of programming languages for design specifications. Analyze applications to identify vulnerabilities and security issues, as well as conduct testing and debugging Serve as advisor or coach to new or lower level analysts Identify problems, analyze information, and make evaluative judgements to recommend and implement solutions Resolve issues by identifying and selecting solutions through the applications of acquired technical experience and guided by precedents Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. Qualifications: 2-5 years of relevant experience in the Financial Service industry Intermediate level experience in Applications Development role Consistently demonstrates clear and concise written and verbal communication Demonstrated problem-solving and decision-making skills Ability to work under pressure and manage deadlines or unexpected changes in expectations or requirements Education: Bachelors degree/University degree or equivalent experience This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN ------------------------------------------------------ Time Type :Full time ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.8,"Citibank
3.8",Pune,"Irving, TX",1001 to 5000 employees,-1,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
Corporate and Investment Banking - Quantitative Research - Wholesale Credit - Analyst,-1,"Responsibilities
Excellent data analysis and statistical modeling experience.
This includes:
Theoretical and practical aspects of statistical inference
Generalized linear models, time series analysis, clustering, decision tress, logistic regression
Hypothesis testing and model selection
Ability to handle large amount of financial data, and data cleaning/filtering in Python or R
Strong background in programming and significant experience on large data projects
Strong programming in Python with experience on relational databases
Knowledge and experience in big data platform
(SPARK/Hadoop/Impala/Kinetica) is preferred.
Experience working in a shared computing environment (Linux) and with version control
Strong analytic, quantitative and problem solving skills
Motivation to take initiative and solve problems independent
Good knowledge of financial instruments and financial risk management principles is preferred.
Prior experience in writing model documents is strongly preferred but not mandatory
Required Qualifications:
PhD/Master's or Bachelor's Degree in a quantitative discipline such as Statistics, Computer Science, Econometrics, Engineering, Physics etc. and related fields from a premier institute.
3-7 years of relevant modelling experience or application development experience as a data scientist/big data engineer
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.",3.9,"J.P. Morgan
3.9",Mumbai,"New York, NY",10000+ employees,1799,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Research Scientist,-1,"• Design, develop and optimize PCR assays, from initial screening through validation on clinical samples
• Execute research and development activities through all phases of product development
• Perform research related to improving and expanding core technology capabilities
• Analyze experimental results and provide written reports and oral presentations to executives
• To identify, design, implement, and manage molecular diagnostics experiments.
• To prepare reports and presentations for internal and external use in a suitable and professional manner. Expectation of minimal review for technical content and R&D standards.
• Hands-on involvement in molecular assay development, verification and validation
• Own and drive technical sub-projects as needed to guarantee overall project success
• Actively contribute to technical root cause activities to identify and alleviate roadblocks internally and with customers
• With guidance, create documentation for R&D deliverables according to SHPL Design Control Process for IVD or RUO products (feasibility plan/report, reagent/software requirements, verification & validation plan/report)
• Ensure timely completion of all relevant deliverable. Plan own work in alignment with overall timelines of the R&D projects and support other team members.

Education and Experience:
• Ph.D. degree in relevant science field, such as biology, molecular biology, or cell biology and 3-5 years of industry experience, in similar Field.
• 5+ years’ experience in molecular diagnostic assay development (Could be in LDT, CE-IVD or IVD space)
• Expert and hands-on experience in diagnostic molecular methods with expertise in technologies including qPCR, Sanger sequencing and fragment analysis.
• Experience in the process of product development and demonstrated track record for product development .

Organization: Siemens Healthineers

Company: Siemens Healthcare Private Limited

Experience Level: Experienced Professional

Job Type: Full-time",4.0,"Siemens Healthineers
4.0",Vadodara,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche"
Senior Data Engineer - ETL,-1,"A professional at this position, works with the business users, technologists, analyzes systems, and gathers how data is used in them. Determines methods and procedures to analyze source data, extract - transform - load (ETL) the data into downstream environment, improve data quality, and make the data usable for consumption. Researches, designs, develops, configures, integrates, tests and maintains existing and new data and analytical solutions including databases through integration of technical and business requirements. Data and analytical solutions include ERP systems, open source software, custom home-grown systems, and 3rd party software. Provides required documentation and participates in architecture reviews to ensure that the solutions comply with standards and use approved technologies. Typical customers are HP Enterprise's end users and various functional areas such as Supply Chain, Research and Development, Marketing, Finance, a business, or the company.

Responsibilities:
Participates as a senior member of data development team or cross functional teams; and may lead a project/ program development team; Performs analysis of functional and business requirements.
Completes data analysis, ETL, batch and real-time intergtation codes to implement solutions.
Develops data integration and exploratory data analysis codes independently; participates in code reviews and may lead code reviews.
Works with business and system teams to design, prepare and automate test cases.
Applies in-depth or broad technical knowledge to maintain data engineering. Performs solution design. Applies the company, open source, and 3rd party technologies to highly complex infrastructure and software solutions.
Education and Experience Required:
Typically a technical Bachelor's degree or equivalent experience and a minimum of 6 years related experience or a Master's degree and a minimum of 4 years of experience.
Knowledge and Skills:
3 or more years of experience in exploratory data analysis and integration
3 or more years of experience writing SQL and ETL code(such as Informatica/ IBM; and databases like SqlServer/ Oracle; and data quality tools.
Knowledge of open source software development tools such as Kafka and Python.
Experience of multiple full release cycles.
Understanding of Software Test methodologies, and testing tools.
General Project Management.
Customer/ Vendor Management
#GlobalITIN

1066622",4.1,"Hewlett Packard Enterprise
4.1",Bengaluru,"Palo Alto, CA",10000+ employees,2015,Company - Public,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Oracle, Accenture"
Senior Research Scientist or Research Scientist,-1,"Analog Devices (NASDAQ: ADI) designs and manufactures semiconductor products and solutions. We enable our customers to interpret the world around us by intelligently bridging the physical and digital worlds with unmatched technologies that sense, measure and connect.

Job Title: Research Scientist or Senior Research Scientist

Analog Devices defines innovation and excellence in signal processing. ADI's analog, mixed-signal, and digital signal processing integrated circuits play a fundamental role in converting, conditioning, and processing real-world phenomena such as light, sound, temperature, motion, and pressure into electrical signals to be used in a wide array of electronic equipment.

The Analog Garage Research Lab in Boston, MA researches innovative and groundbreaking technologies for Analog Devices. The Algorithmic Systems Group within Analog Garage creates advanced algorithms in the fields of signal processing, machine learning, computer vision, artificial intelligence, communication systems, and other areas of electrical engineering and computer science, and implements those algorithms in practical and efficient hardware. We are looking for a Research Scientist or Senior Research Scientist to work within the Algorithmic Systems Group.

Research Scientists are expected to advance the scientific and technological state of the art. They will work in a collaborative and hands-on environment to solve challenging problems that arise from ADI’s diverse portfolio of applications.

Responsibilities:

- Create novel algorithms specialized for applications relevant to Analog Devices.

- Develop software simulations and analyze performance of algorithms.

- Lead or contribute to hardware prototyping efforts and integrated circuit designs.

- Work with other researchers and engineers, inside and outside the Algorithmic Systems Group, to connect our work with the goals of business units throughout Analog Devices.

- Stay abreast of state-of-the-art algorithms, and research advances beyond the state of the art in areas relevant to Analog Devices.

Qualifications: Assumes PhD degree or equivalent experience. Candidates should have a strong background in two or more of the following areas: signal processing, computer vision, machine learning and AI, communications systems, algorithm development, ASIC circuit design, FPGA prototyping, or software development. This search is open to new Ph.D.’s as well as more experienced candidates. More senior candidates should have experience in organizing and leading technical projects.

For positions requiring access to technical data, Analog Devices, Inc. may have to obtain export licensing approval from the U.S. Department of Commerce - Bureau of Industry and Security and/or the U.S. Department of State - Directorate of Defense Trade Controls. As such, applicants for this position – except US Citizens, US Permanent Residents, and protected individuals as defined by 8 U.S.C. 1324b(a)(3) – may have to go through an export licensing review process.

Analog Devices, Inc. is an Equal Opportunity Employer Minorities/Females/Vet/Disability

EEO is the Law: Notice of Applicant Rights Under the Law

Education Level: Doctorate Degree
Travel Required: Yes, 10% of the Time",3.9,"Analog Devices
3.9",Karnataka,"Norwood, MA",10000+ employees,1965,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),"Texas Instruments, Qualcomm"
HIVE Data Engineer- Pune,-1,"Description

6sense is a Predictive Intelligence Engine that is reimagining how B2B companies do sales and marketing. It works with big data at scale, advanced machine learning and predictive modeling to find buyers and predict what they will purchase, when and how much.

6sense helps B2B marketing and sales organizations fully understand the complex ABM buyer journey. By combining intent signals from every channel with the industry's most advanced AI predictive capabilities, it is finally possible to predict account demand and optimize demand generation in an ABM world. Equipped with the power of AI and the 6sense Demand Platform™, marketing and sales professionals can uncover, prioritize and engage buyers to drive more revenue.

6sense is seeking a Data Engineer to become part of a team designing, developing, and deploying its customer centric applications.

A Data Engineer at 6sense will have the opportunity to
Create, validate and maintain optimal data pipelines, assemble large, complex data sets that meet functional / non-functional business requirements.
Improving our current data pipelines i.e. improve their performance, remove redundancy, and figure out a way to test before v/s after to roll out.
Debug any issues that arise from data pipelines especially performance issues.
Experiment with new tools and new versions of hive/presto etc. etc.
Required qualifications and must have skills
BE/BTech/BS or equivalent
Excellent analytical and problem-solving skills
6+ years work experience showing growth as a Data Engineer.
Strong hands-on experience with Big Data Platforms like Hadoop / Hive / Spark / Presto
Experience with writing Hive / Presto UDFs in Java
String experience in writing complex, optimized SQL queries across large data sets
Experience with optimizing queries and underlying storage
Comfortable with Unix / Linux command line
Nice to have Skills
Used Key Value stores or noSQL databases
Good understanding of docker and container platforms like Mesos and Kubernetes
Security-first architecture approach
Application benchmarking and optimization
Interpersonal Attributes
You can work independently as well as part of a team
You take ownership of projects and drive them to conclusion
You're a good communicator and are capable of not just doing the work, but teaching others and explaining the ""why"" behind complicated technical decisions
You aren't afraid to roll up your sleeves: This role will evolve over time, and we'll want you to evolve with it!",5.0,"6sense
5.0",Pune,"San Francisco, CA",51 to 200 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"Data Analyst Jobs In Votiko Solutions Private Limited Posted On 20th July 2020Company Name: Votiko Solutions Private limited Designation: Data Analyst Education : Any Graduate,Any Post Graduate Location: Experience: Fresher - 1 years Salary: Rs.10000 - Rs.12000 (per annum) JOB PROFILE: Internet research expert Job in Surat @ Votiko Job description Job Summary Qualification : Graduate in B.E or B.tech ( in Computer / IT / Communication) Experience : Experiences & Freshers with Good Knowledge of Internet and Research are also welcome. Responsibilities and Duties Preparing Market research reports using certain Web tools/domains like LinkedIn, Jigsaw, Hoovers, Zoom info etc. Sourcing relevant contacts as per provided research brief. Internet Research.

Data Mining, Data Processing, Sourcing. Searching contacts as per client requirement criteria on LinkedIn, Company website and Google and handling excel document. Internet Research, Data Processing. Contact s Email building and verifying.

Required Experience, Skills and Qualifications Should have hands on experience on Internet Browsing which is Mandatory. Understanding of using appropriate keywords for efficient web results Should have through understanding on using relevant keywords on LinkedIn and Sales Navigator Should be familiar with various tools used for automation of web research Good Knowledge of MS-Office Experience in Secondary Research/Web Research is a must. Multi-Tasker with Go-Getter Learning Attitude. Good Inter-Personal Skills and Ability to work in changing environmentEducation: Graduate in B.E or B.tech (in Computer / IT / Communication) Salary: 10,000 to - 12,000.00 /monthWebsite: - www.votiko.comIf the above requirements suit your interest, please call us on +91 8511539085 or send your resume to hr@votiko.comFull Time",-1,Votiko Solutions Private limited,Gujarat,-1,-1,-1,-1,-1,-1,-1,-1
Junior Healthcare Data Analyst / Healthcare Data Analyst,-1,"Department: Analytics

Experience: 2+ Years

Location: Chennai

Job Description
Trend data to identify potential opportunities (e.g., variances, significant outliers, percentile ranked groups) for quality improvement or focused investigations
Access data, construct and manipulate large datasets to support planned analyzes, using SAS and SQL.
Develop, test and deploy predictive models
Assessment of data quality using advanced statistical testing and validation techniques
Data management and reporting
Analytical skills to provide insights from the data and create report
Good Communication – able to collaborate with onshore SMEs
Aptitude to learn and multitask
Good team player & collaborative in approach
Certified Base and/or Advanced SAS programmer
Knowledge in “R programming language”
Moderate/ Expert working knowledge of and programming experience with SAS - able to create queries.
Knowledge of statistical techniques such as Logistic Regression, Segmentation, Clustering, etc.
Little or moderate Experience with different database systems such as MS SQL Server, Oracle, DB2, etc. 85
Understanding of health care data / databases.
Conduct all job functions and responsibilities in accordance with all company Compliance, Information Security and Regulatory policies, procedures and programs.",3.1,"SCIO Health Analytics
3.1",Chennai,"West Hartford, CT",501 to 1000 employees,2007,Company - Private,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),-1
Machine Learning Engineer,-1,"Job Location
Mountain View, California or Pune, India

Role and Responsibilities
Engineering core machine learning capabilities in our IoT platform by building tools and high-performance infrastructure for running ML models at the edge.
Creating supervised and semi-supervised ML models for the platform.
Core Qualifications
Candidates must meet ALL of the following qualifications.

Experience in Agile software development with strong programming experience in C++ or Python.
Experience in building and using high-speed data processing infrastructure and tools.
Have used or developed high performance C++ packages (e.g. LAPACK, BLAS, YOLO etc.)
Some experience with real-time stream processing data systems.
Training in data mining or statistics, enough to understand the context of developing software to be used by data scientists.
Algorithm experience in the families of predictive algorithms (regression, neural nets, decision trees) and clustering algorithms (k-means or other).
Bonus Qualifications
Any of the following extra qualifications will make a candidate more competitive.

Strong experience with C++ development and high-performance computing.
Cython programming or written python wrapper for C++.
Experience developing Machine Learning software infrastructure, algorithms and libraries.
Training or experience in Deep Learning, such as Keras, TensorFlow, convolutional neural networks (CNN) or Long Short Term Memory (LSTM) neural network.
Experience with PMML or PFA or TFR is of interest (see www.DMG.org).
How To Apply
To apply, submit resume and cover letter to HR at jobs@foghorn.io.
Indicate how you meet core and bonus qualifications including two to four detailed paragraphs of three data mining projects you have deployed.",4.1,"Foghorn Systems
4.1",Pune,"Sunnyvale, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"Require a full-time Data Analyst for immediate joining & with the following requirements-

Responsibilities-
The Data Analyst will be responsible for collecting and analyzing data sets using various tools such as Microsoft Excel, Access, SQL etc. and presenting them in easy-to-understand formats.
The Data Analyst will be expected to retrieve data from the daily reports of construction contracts in the USA & develop spreadsheets and excel macros to filter, analyze, generate reports and draw conclusions from that data. It will be important to focus on the primary metrics while understanding the business requirements.
Interpret the data using statistical techniques and provide ongoing reports.
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.
Technical Skills-
MS Office products including strong grasp of Excel (Charting, Formulae, Pivots) Advance Excel, MS Access
Added advantage - Knowledge of SQL, Python
Qualifications & Experience-
Graduation/Masters in statistics,
Self-motivated having Minimum Work experience of 1 to 3 years
Office Location & Timings-
Siddharth Tower, Kothrud, Pune
9.30 AM to 6.30 PM
Job Type: Full-time

Salary: ₹24,000.00 - ₹38,000.00 per month",-1,MAK'S CONSTRUCTION DATA ANALYSIS LLP,Pune,-1,-1,-1,-1,-1,-1,-1,-1
Quantitative Researcher,-1,"NK Securities is a leading financial firm that leverages cutting edge technology and sophisticated algorithms to trade in the Indian markets. Founded in 2011, we have gained invaluable experience in the field of Algorithmic and High Frequency Trading across different asset classes.

Responsibilities:
We are seeking to recruit a Quantitative Trader to work out of our Gurgaon office. As a Quantitative Trader your responsibilities would include:

Develop and improve trading models using in-house platform

Analyse large financial data sets to identify trading opportunities

Provide analytical support to experienced traders

Develop models to predict market movements

Qualifications:Qualifications:
The ideal requirements for our candidates are:
A bachelor's, master's, or PhD degree from a top college or university

Strong analytical skills

Hard working and strong work ethic

Programming experience in C++ or C

Proficiency in using Python, R, or Matlab for statistical/data analysis of HFT tick data

Any of the following is a plus:
Prior experience in start-up

Knowledge of any other developing language including. Java, Python and shell scripts.

Experience in HFT industry

Benefits:
NK Securities offers compensation above industry standards for deserving candidates. We are a fast-growing organisation where there is no ceiling on the career trajectory of an individual. The startup style governance of the firm enables the newest employees to work with industry veterans. Outstanding performers are entitled to ESOPs. Our focus is on a premium quality of life and we encourage everyone in the firm to thrive in all aspects of their lives.

Interested candidates are invited to send their updated resumes to contact@nksecurities.com

You can also reach us at +91-7760628951 for more details.",-1,NK Securities,Gurgaon,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Engineer,-1,"In this role, the individual will be part of the engineering team in Enterprise data lake group and will be responsible for.
Participating and collaborating with cross functional teams in the organization to understand the business requirements and to deliver solutions that can scale.
Planning the execution of the project in an effective and efficient manner.
Proactively anticipating problems and appropriately communicating to the team and management in a timely manner.
Being flexible and being able to support all functions of product life cycle when required.
Ability to work in a fast-paced environment
Ability to deliver from coarse grained requirements
Be a Mentor for the junior members in the organization.
Job Requirements

Required Skills:
8+ years of experience in the IT industry, experience in Data Technology space is preferred.
Advanced Shell or Perl scripting experience or proficiency in any programming language like C, C++ or CORE Java
Working experience in any MPP systems, should have strong SQL programming skills
Knowledge of data warehousing concepts
Working knowledge on any ETL tool (ie. Informatica/ Ab Initio) is preferable.
Knowledge of Scheduling Tools is a plus
Excellent written and oral communication skills
Strong analytical skills including the ability to define problems, collect data, establish facts, and draw valid conclusions
Expertise in database programming and performance tuning techniques
Familiar with data movement techniques and best practices to handle large volumes of data
Experience with data warehousing architecture and data modeling best practices
Experience with File Systems, server architectures, and distributed systems
Strong communication skills and willingness to take initiative to contribute beyond basic responsibilities
Working experience in an Agile methodology is highly preferred
Knowledge of Hadoop, HBase and Hive is highly preferred",3.7,"PayPal
3.7",Chennai,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Data Analyst,-1,"Good Knowledge of Adobe Analytics/Omniture/Sitecatalyst Implementation
Good Knowledge of using Analysis Workspace, Adhoc Analysis, Segmentation and other features of Adobe Analytics.
Have some exposure to SQL and Databases
Exposure to Python will be a plus.
00-5.00 Years",4.1,"Collabera Technologies Private Limited
4.1",Bengaluru,"Basking Ridge, NJ",10000+ employees,1991,Company - Private,IT Services,Information Technology,₹50 to ₹100 billion (INR),"Kforce, Insight Global, Volt Consulting Group"
Data Analyst AssociateZobello,-1,"Zobello is looking for a Data Analyst Associate who will be responsible for presenting data to derive actionable results.

What we are looking out for:
Graduate with 1-2 years of experience in data analysis, data mining/modeling.
Proficient with reporting and statistical tools like Microsoft Excel, SPSS, Adobe etc.
Ability to work in a team.
Good Analytical skills
Experience in E-commerce industry is a must.

What we would like you to do:
Responsible for analysing data on a constant basis.
Gathering information from various sources in order to better understand the data.
Communicating findings of data to relevant departments in the form of presentation, graphs etc.
Provide recommendations and actionable strategies based on the data.

If you are interested in applying for this position, please send your, CV, with your portfolio, a covering letter and a photo as soon as possible to careers@zobello.com",-1,Zobello,New Delhi,"New Delhi, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"We are looking for a passionate Data Analyst to turn data into information, information into insight and insight into business decisions. You will conduct full lifecycle activities to include requirements analysis and design, develop analysis and reporting capabilities, and continuously monitor performance and quality control plans to identify improvements.
Responsibilities
Inspect, clean, transform and model data with the goal of discovering useful information
Interpret data, analyze results using statistical techniques and provide valuable insights in the form of reports.
Identify, analyze, and interpret trends or patterns in complex data sets.
Develop and implement data collection systems and other strategies that optimize statistical efficiency and data quality. Acquire and maintain databases/data systems
Work closely with management to prioritize business and information needs.
Locate and define new process improvement opportunities.
Skills and Qualifications
Minimum 5 years of working experience as a data analyst.
Degree in Mathematics, Economics, Information Management or Statistics.
Technical expertise regarding data models, database design development, data mining and segmentation techniques.
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks).
Knowledge of statistics and experience using statistical packages for analyzing large datasets (Excel, SPSS, SAS etc).
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
Adept at queries, report writing and presenting findings.
To apply, please submit a cover letter, resume and portfolio to jobs@voice-over.co Submissions without a cover letter & resume or portfolio will not be considered.",-1,Voiceover,Gurgaon,"New York, NY",Unknown,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Your consulting projects will include integrating data in a virtual manner for operational and/or informational purposes - Integration of 100+ data sources for a Customer Service Multichannel IT Infrastructure; implementation of Logical Data Warehouses and Virtual Datamarts to enable modern Business Intelligence solutions, Integration Layers for Hadoop-based Data Lakes, and support for Agile Operational Reporting on a diverse Big Data infrastructure are just a few flavours of your future projects. Be part of an elite team in a rapidly growing international software product company. Your career with us will combine cutting edge technology, exposure to worldwide clients across all industries (Financial Services, Automotive, Insurance, Pharma, etc.), exciting growth path for technical, product and customer-facing roles, direct mentorship, and access to senior management as part of a global team. Your mission is to help our clients and prospects in the East Asia region to realize their full potential through support services, accelerated adoption and productive use of Denodo's data virtualization capability in many solutions.
Salary Negotiable
Industry IT Software
SubIndustry Software Development
Functional Area IT Software Development
Specialization IT/Technical Content Developer
Role Executive / Officer Level
Keyskills
Troubleshootingproduct managementCustomer Service
Desired Candidate Profile
Please refer on JD
Education
Highest Qualification
Graduation B.E/B.Tech",5.0,"Fine Jobs
5.0",Chennai,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Software Engineer - Data Science,-1,"About the Department

Data Science

Summary of the Role

Software Engineer will be working as part of Data Science team to build and maintain scalable web crawlers to fetch data from multiple online sources.

Job Responsibilities

· As a Python Developer, your role is to apply your knowledge set to fetch data from multiple online sources, cleanse it and build APIs on top of it

· Develop a deep understanding of our vast data sources on the web and know exactly how, when, and which data to scrap, parse and store this data

· Develop frameworks for automating and maintaining constant flow of data from multiple sources

Job Requirements

· Strong coding experience in Python (knowledge of Java, Javascripts is a plus)

· Experience with SQL and NoSQL databases

· Experience with micro services, multi-threading and AWS/Azure

· Strong knowledge of scraping frameworks such as Scrapy, Selenium,Portia etc.

· Experience with web crawling is a must.

· Experience with web technology, such as HTTP, JSON, HTML, XPath or JavaScript.

· Experience with ELK(Elasticsearch, Logstash, Kibana) is plus.

Particulars Requirement

Experience 2-6 years

Education BE/B.Tech

Role Python Developer- Web Crawling/Software Engineer

Functional Area Software Development

Reporting to Rahul Kulhari

LOB Data Science

Group Software Engineer

Location Bangalore

Employment Type Full Time
---Data EngineerBig Data EngineerData Scientist – AnalyticsData Scientist (Interns)Python DeveloperBack End DeveloperUI DeveloperFront End DeveloperDeep Learning ScientistProgram Manager - Delivery & WFM Process AutomationData ScientistAutomation Test LeadProject ManagerEnterprise Account SalesInside SalesDevops EngineerFull Stack DeveloperMachine Learning Engineer",3.7,"EdGe Networks
3.7",Bengaluru,"Bangalore, India",51 to 200 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"As a Data Engineer at TEAL, you'll be taking the plunge into a rich data lake that includes everything from satellite data to legal court orders. You'll be hustling and getting your hands dirty with every part of the data pipeline always having an implicit appreciation for how all of this data will ultimately power a revolutionary real estate risk platform.

Your day-to-day will include either all or some of the following:

Constantly scoping out new data sources to complement existing ones
Creating and maintaining distributed web scrapers using Python, RabbitMQ and other technologies
Architecting and managing data pipelines where data flows into multiple end-points including, but not limited to, Postgres, MongoDB and Apache Solr
Documenting workflows and constantly iterating to create better data infrastructure

We'd love it if you:
Are proficient in Python or any other object-oriented language
Have worked with large (millions to hundreds of millions of rows in a SQL database) interdisciplinary datasets
Have scraped difficult websites and have some experience working with various data APIs
Are patient and methodical with unstructured and messy data
Are always hungry to learn newer and better technologies to make the data ecosystem faster, smoother and less silo-ed

Extra brownie points if you:
Have some experience working with large-scale search indexing
Have performed geospatial analyses in some capacity
Have created and managed data lakes in the cloud",4.7,"Terra Economics & Analytics Lab (TEAL)
4.7",New Delhi,"Bengaluru, India",1 to 50 employees,2018,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Risk - Corporate and Investment Banking - Quantitative Research - Market Risk_Model Performance - Vice President,-1,"Responsibilities:
Lead the Mumbai team for Model Performance and Time Series Management.
Build, maintain and enhance a robust framework covering
VaR model backtesting
P&L Attribution test (including the recently introduced FRTB requirements)
Understanding FRTB Rules
Knowledgeable in derivatives, VAR, SVaR, expected short fall
Good understanding of financial derivatives including Greeks
Time Series Management
New time series onboarding
Review of time-series, anomaly detection and resolution
Build tools for performing effective review of time-series across asset class
Work closely with Data Quality model team to enhance
Participate in Backbone selection analysis
Procedures and Governance relating to Sox & Audit
Identifying spurious data and correcting these data points; liaising with Market Risk Coverage/MRQR product specialist for remedial action.
Prepare periodic report on the time series management, model performance analysis.
Provide robust and comprehensive documented analysis/explanatory and present the results to MRQR, Market risk Group senior management
Participate in regulatory submission related to model performance output.
Performed model enhancements as required under model performance analysis. This will require close coordination with Model development team within Market Risk QR as well as Markets (Front office) QR.
Basic understanding of product knowledge across a range of asset classes - Credit, Rates, Equities, Commodities & SPG
Working with stakeholders such as Market Risk Coverage, Model Review and Governance, MRQR product specialist & Technology teams
Overall, the candidate will need to work closely with teams in Asia-Pacific and/or London and/or New York and will need to be proactive to improve the Market Risk analytics and strategic platform, access and learn J. P. Morgan's highly sophisticated solutionsJPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.",3.9,"J.P. Morgan
3.9",Mumbai,"New York, NY",10000+ employees,1799,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Data Engineer,-1,"Senior Data Engineer
IDC (Hyderabad, India)

This position reports to: Manager, Product Usage and Data Engineering

ServiceNow is changing the way people work. With a service-orientation toward the activities, tasks and processes that make up day-to-day work life, we help the modern enterprise operate faster and be more scalable than ever before.

As a member of the Product Operations Analytics team, youll focus on driving operational awareness to our Executive Team while partnering with leaders throughout ServiceNow to fundamentally improve how we run our business. With a combination of exceptional analytical skills, an insatiable curiosity, and an entrepreneurial get stuff done mindset, youll help us better understand our customers, partners, and products, and drive important changes that will shape the future of ServiceNow.

What you get to do in this role:

We are looking for a Rock Star with a winning track record in Big Data, Data Warehousing, Visualization and Data Web Services. The Senior Data Engineer will be a core technical contributor to the team with deep expertise in manipulating and structuring large, complex datasets that feed central data warehouses. S/he will be responsible for helping stand up and maintaining daily data transfer jobs, database structures, identifying data integrity issues, and developing documentation on data assets. The Senior Data Engineer will also work closely with ServiceNow data analysts and data scientists to help prep data for models and dashboards.

The ideal candidate should have a background in Engineering, Statistics, Mathematics, Computer Science, equivalent quantitative field or related practical experience with an obsession on data quality. S/he should have an outstanding ability to foster relationships with staff across departments and be motivated to continuously achieve positive results. Extensive understanding to the needs of data visualization is a must for this role. S/he should also be able to effectively handle ad hoc requests and multitask with ease and little guidance.

Examples Of Day-to-Day Responsibilities
Enforcing company data policies and procedures to ensure data quality and reduce discrepancies
Securing approvals for data access based on business needs
Developing scalable automated ETL/ELT jobs and maintain them
Identify any data integrity issues and deep dive to find root cause
Using PL/SQL queries, Python and API calls to stand up master data sets and merge datasets across disparate systems
Training analysts and data scientists alike on available data sources
Ensuring very large databases and compute clusters operate optimally
Implementing and maintaining database structures and governance
Developing / maintaining documentation on databases and production tables
Collaborating across the companys multiple data teams to meet analytics deliverables
In order to be successful in this role, we need someone who has:
Bachelors degree in Engineering, Computer Science, Statistics, Mathematics, a related quantitative field, or equivalent practical experience.
5 years of experience in consulting, business intelligence, analytics, or an equivalent analyst position with experience in PL/SQL and an additional object-oriented programming language (e.g., Python, Java, JavaScript)
Effective problem solving and analytical skills. Ability to manage multiple projects and report simultaneously across different stakeholders
Structured thinking with ability to easily break down ambiguous problems and propose impactful data modeling designs
Passion for analyzing large and complex data sets and converting them into the information which drive business decisions
Attention to detail, organization and effective verbal/written communication skills
Experience in big data instances: Cloudera, Azure, Snowflake, and the like.
Proven track record in rolling out self-service analytics solutions (e.g. Tableau Server Ask Data, etc)
Solid decision making, negotiation, and persuasion skills, often in ambiguous situations
Must be able to work in fast paced environment and be able to adapt to changing requirements.
Understanding of technology development projects and the full technology development lifecycle
We provide competitive compensation, generous benefits and a professional atmosphere. This is a very collaborative and inclusive work environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers through working with some of the most advanced technology and talented developers in the business.",3.8,"ServiceNow
3.8",Hyderabad,"Santa Clara, CA",10000+ employees,2004,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 billion (INR),"BMC Software, CA Technologies, Salesforce"
Data Analyst,-1,"Join Our Team

Data Analyst {Hyderabad, India}
Job Description


Kline, a global management consulting and market research firm, is looking for a Data Analyst. This data science professional will help interpret and visualize information hidden in vast amounts of data, both internal and external, to make more meaningful and insightful decisions that will enable the delivery of better products and services. This technologist should have a minimum of two (2) years of experience working as a subject matter expert in Data Visualization and Business Intelligence development.

The ideal candidate will come from a services firm engaged in Business Intelligence/Market Research or Business/Management Consulting with a focus on Data Management, Knowledge Services, and Business Analytics.

This individual is expected to: use modern technology and state-of-the-art data mining & analysis techniques to conduct statistical and quantitative analyses and build high-quality dashboards and business intelligence reports integrated with Kline’s product and service portfolio.

A candidate must have excellent English verbal and written communication skills.

Job Responsibilities
Enhancing data collection procedures to include relevant information for analytic solutions
Processing, cleansing, and verifying the integrity of data used for analyses
Interacting with and utilizing Azure cloud databases and on-prem Microsoft databases
Conducting statistical analysis and presenting results using modern data visualization techniques
Developing insightful and interactive business intelligence reports and dashboards
Skills and Qualifications
Expertise in analyzing data and creating innovative dashboards & visualizations using industry-proven best practices using tools like Power BI or Tableau
Expertise in performing in-depth data analysis using Microsoft Excel and its advanced functions
Experience in data acquisition, performing data transformations, data aggregations using SQL, PL/SQL
Experience providing ad-hoc reports to answer specific business questions from business leaders
Experience conducting and delivering experiments and proofs of concept to validate business ideas and their potential value
Knowledge of the Python (or R) programming language
Familiarity with Microsoft Azure services and tools is a plus
Degree in Computer Science, Mathematics, Statistics, or other related technical fields with equivalent practical experience.
Strong communications skills
Kline & Company offers: a world-class international work environment located in Hyderabad, India; a dynamic, multi-cultural team and collegial work atmosphere; every day, practical use of English and valuable work experience with a well-established consulting and market research firm; and, a competitive compensation and benefits package in a supportive work environment.

Interested and qualified candidates should apply by submitting their resume via our website.

Equal Opportunity Employer, M/F/D/V.",2.9,"Kline & Company
2.9",Hyderabad,"Parsippany, NJ",51 to 200 employees,1959,Company - Private,Consulting,Business Services,₹1 to ₹5 billion (INR),"McKinsey & Company, Euromonitor, Frost & Sullivan"
Machine Learning Engineer,-1,"OakNorth is the next-generation credit and monitoring platform that provides banks and lending institutions with the insight and foresight needed to create a better borrowing experience for the Missing Middle – the growth business who are the backbones of communities and economies globally but who have been in banking’s blind spot for decades.
The business was founded in 2015 by Rishi Khosla and Joel Perlman, who previously co-founded Copal Amba and grew it to 3,000 employees over 12 years, before selling it to Moody’s (NYSE: MCO) in 2014, returning 125 times capital to seed investors.
Since its inception, OakNorth has secured over $1bn from several investors, including: Clermont Group, Coltrane, EDBI of Singapore, GIC, Indiabulls, NIBC, Toscafund, and SoftBank’s Vision Fund.
The Platform has been deployed at various banks across North America, Europe, and Asia, and in the UK where OakNorth lends off of its own balance sheet via OakNorth Bank. The platform has helped OakNorth Bank become the fastest-growing business in Europe according to the Financial Times FT 1000 (2020), profitably lending over £4bn to date. In terms of the impact this has had on the economy, OakNorth Bank’s loans have directly helped with the creation of 13,000 new homes and 17,000 new jobs in the UK, as well as adding several billion pounds to the economy.
With offices in London, New York, Manchester, Singapore, Hong Kong, Shanghai, Istanbul, Gurgaon and Bangalore, the global team across the OakNorth Holdings group is over 800 people.

SME are crucial in global economy. Although they account for 99% of business in the UK/US, their financing need is increasingly difficult to be met by major banks, due to higher risk of default and heterogeneity of different sectors in SME.
To solve these challenges, OakNorth is building a platform to improve productivity of SME lenders. From credit appraisal, to loan monitoring, the OakNorth Machine Learning team has identified multiple key areas that can be optimised by recent advances in Machine Learning (ML), Natural Language Processing (NLP), Computer Vision (CV), and Information Retrieval (IR).
We are looking for a passionate machine learning and/or software engineer who will be joining the fastest growing and profitable fintech in Bangalore. You enjoy solving challenging tasks, creating and maintaining impactful and data-driven products with innovative techniques.
We expect you to
1. have experience in ML, CV, NLP, IR, or related fields
2. have a master (or PhD) degree with 3 years' experience in industry
3. able to learn new technologies and comprehend academic literatures independently.
We would love to see
1. Experience with modern deep learning frameworks (e.g. PyTorch, Tensorflow, Jax)
2. Experience working on distributed software system (e.g. Spark, Hadoop, ElasticSearch)
3. Publications in related academic venues (e.g. ACL, CVPR, EMNLP, ICML, KDD, NeurIPS)
You will
1. Convert research findings into production-level software systems and maintain them.
2. Research and evaluate techniques that can improve/solve a concrete business workflow/problem.
3. Work with domain experts to shape the future of our platform.
Thank you very much for your interest in OakNorth. We are happy to consider you for roles within our group of companies. If we can identify a match between your skill set and our immediate recruiting needs, please expect to hear from us very soon. If we are unable to identify a fit in the near term, please note that we intend to retain the data you send to us so we may contact you in the future.

For more information regarding our Privacy Policy and practices, please visit: https://www.oaknorth.com/privacy-notice/employees/",3.7,"OakNorth
3.7",Bengaluru,"London, United Kingdom",51 to 200 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Business Intelligence Analyst,-1,"At Franklin Templeton Investments, we are dedicated to delivering strong results and exceptional service to clients, team members and business partners. Over 9,000 employees working in 60 offices around the world are dedicated to servicing investment solutions for our clients in more than 150 countries. For over 65 years, our success has been a direct result of the talent, skills and persistence of our people, and we are looking for qualified candidates to join our team.

What is the Business Intelligence Analyst – Client Analytics group responsible for?
The candidate will have experience in the financial services industry and the ability to quickly learn and apply concepts within this industry. Provide on demand and regularly scheduled reports using a variety of technology tools; including, but not limited to, Tableau, SAS, SQL, Excel; Access; Word and PowerPoint and Siebel. Answer any questions with respect to those reports as well as general business knowledge to internal and external customers. Demonstrate a solid knowledge of ongoing reports as well as additional ad hoc requests. Ability to partner with USAS Sales Management, Client Analytics and Consultant Relations Group while building a relationship to help meet the sales mission. Display the ability to create processes and reports related to projects assigned. Excellent communication skills, written and verbal, are required
What are the ongoing responsibilities of a Business Intelligence Analyst?
Subject Matter Expertise:
Develop and produce routine and non-routine dashboards of intermediate to complex scope using multiple systems and technology tools like Power BI, Tableau
Ability to answer any questions with respect to underlying data, as well as general business knowledge to internal customers
Interpret data, providing analytical commentary and recommendations for change
Provide subject matter expertise on assigned systems or areas
Assume the role of technical expert responsible for developing and guiding more junior team members
Act as business unit liaison with other business units
Technology Expertise and Process Improvement:
Assume the role of technical expert responsible for developing and guiding other team members
Display the ability to create and streamline processes and reports related to projects assigned and respond to ad hoc requests
Be an active member of the various data management projects
Research, Recommend and Implement Workflow Efficiencies:
Research and document business issues involving workflow procedures and processes
Gather comprehensive information to be used in problem identification and resolution
Analyze data and work with management to develop creative solutions
Develop user test plans and testing to validate system enhancements and other business requirement documents and specifications
Develop new procedure documentation in support of new process, products or system enhancements
Coordinate recommended process changes and enhancements including test plans to ensure successful implementation
Discuss proposed system enhancements and modifications with information technology staff
Provide post-implementation support for all approved deliverables
What ideal qualifications, skills & experience would help someone to be Successful?

Knowledge:
Have a solid understanding of the reporting, data management process and able to recommend and implement workflow
Develop and produce routine and non-routine dashboards intermediate to complex scope
Provide subject matter expertise on assigned systems or focuses
Tests plans to validate system enhancements for other business unit requirements
Support new procedures while documenting new process, products or system enhancements that affect the team
Demonstrates an intermediate ability to perform mathematical calculations and analysis
Have knowledge and aptitude of working on Tableau, SQL
Ability to communicate, written and verbal, to internal customers and business partners.
Education and Experience:
Bachelor’s Degree in Business Administration or related field, or equivalent combination of education and experience
Minimum 3 years of related experience
Expertise in Power BI, SQL
Additional Desirable Qualifications:
Financial Services experience, preferred
Strong use of databases/technology skills
Skills and Abilities:
Ability to operate a personal computer and related software
Microsoft Office skills:
Advanced: Excel, Word, Access
Intermediate: PowerPoint, SQL, VB Macros
Basic: Visio,
Note: level of skill will vary by specific department/assignment
Ability to communicate effectively both orally and in writing and to establish and maintain cooperative working relationships with persons contacted in the course of performing assigned duties
Strong attention to detail
Ability to maintain updated knowledge of procedures, products and activities of assigned area
Ability to adhere/respond to established time frames and schedules
Ability to perform mathematical calculations and analyses
Ability to work independently
Ability to exercise independent judgment consistent with department guidelines
Problem Solving And Decision Making:

Work is performed under very general direction; participates in determining objectives of assignment; work is reviewed for adequacy in meeting objectives.
Develops solutions to a variety of problems; ensures solutions are consistent with organization objectives.
Physical Requirements:
Ability to hear and speak to employees and customers on the phone and in person.
Ability to sit for long hours at a time.
Ability to see the letters and numbers on a personal computer screen and on memos, reports and other documents (near vision).
Requires moderate right- and left-hand coordination for the use of a personal computer

What makes Franklin Templeton Investments unique?
In addition to the dynamic and professional environment at Franklin Templeton, we strive to ensure that our employees have access to a competitive and valuable set of Total Rewards—the mix of both monetary and non-monetary rewards provided to you in recognition for your time, talents, efforts, and results.

Highlights of our benefits include:

Professional development growth opportunities through in-house classes and over 150 Web-based training courses
An educational assistance program to financially help employees seeking continuing education
Medical, Life, and Personal Accident Insurance benefit for employees. Medical insurance also covers employee’s dependents (spouses, children and dependent parents)
Life Insurance for protection of employees families
Personal accident insurance for protection of employees and their families
Personal loan assistance
Employee Stock Investment Plan (ESIP)
Onsite fitness center, recreation center, and cafeteria
Cricket grounds and gymnasium
Library
Health Center with doctor availability
Tuition Assistance Program
HDFC ATM on the campus
Franklin Templeton Investments is an Equal Opportunity Employer. We invite you to visit us at http://www.franklintempletoncareers.com/ to learn more about our company and our career opportunities.",3.8,"Franklin Templeton Investments
3.8",Hyderabad,"San Mateo, CA",5001 to 10000 employees,1947,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Fidelity Investments, Vanguard"
Senior Data Engineer (2 Positions),-1,"Company Description

WhizAI is the first and only purpose-built cognitive insights platform for life sciences, empowering users to get answers to their business questions by simply asking via voice or text on web and mobile. WhizAI is pre-trained on life sciences data and business terminologies, enabling it to answer even the most complex questions from billions of records in seconds. Fast, easy, and scalable, WhizAI is the trusted partner of choice at the top global life sciences companies. Asked. Answered. Instantly.

We are on a mission to make enterprise analytics as easy and delightful as using your favorite app. The days of tedious dashboards, long training hours, and complex analytics software are over. Our platform is disrupting the $190B+ analytics market industry by making it 100X faster and easier for all business users to simply talk to their data and get insights, based on the innovations in NLP, AI, ML and enterprise software. We are the future of business intelligence and if you too want to put innovation and user experience for business users above all else, this role is for you.

Job Description

As Data Specialist at an AI Startup you will:
IntegratingWhiz., Data Warehouses, AnalyticalStores, HadoopandERP/CRM systems
pipeline/workflow libraries

Qualifications

Technical

At least 5+years programming experience working with data Integration and tools on Linux platform
Excellent knowledge of SQL, Schemas, Data Warehouse
Excellent knowledge of Python Programming and processing JSON, XML,CSV files
Shell Scripting and good knowledge of Linux commands

Non-Technical

Good communication & analytical skills
Self-driven with a strong sense of ownership & urgency

Preferred Qualifications

Familiarity with Python Pandas and other data processing utilities,Scikit learn
Good to have knowledge of Analytical/OLAP/Columnar, Hadoop and NoSQL databases
Apache Spark, R programming, Virtual Machines, AWS

Additional Information

Compensation:
Competitive and commensurate with experience. WhizAI offers a base salary, a bonus plan, and equity.

Benefits:
Health care and paid time off.",-1,whiz.ai,Pune,-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"Looking for Data Scientists with Python/R Programming skills.
Specific experience in AI areas like Statistical Machine learning / Deep learning / Natural Language Processing (NLP)/ Operations Research (Optimization) will be an advantage.Individual in this role is expected to work with multiple stakeholders and teams

Qualifications and Requirements:-
Previous working experience as a Machine Learning/ Data Scientist for 2 years
MA in Computer Science or similar relevant field
Hands on experience with MALLET
In depth knowledge of Apache Tomcat/Open Source
Excellent project and time management skills
Attention to detail
Outstanding problem solving and analytical skills",-1,Tekolutions.ai,India,"Mumbai, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Analyst,-1,"About OnlineTyari:
OnlineTyari (OT) is India's largest multi-lingual platform for test preparation founded by IIT and IIM alumni. We are backed by marquee investors like Michael & Susan Dell Foundation, Contrarian Fund, Mohandas Pai, Tracxn Labs, 500Startups, etc.

OnlineTyari is first of its kind online marketplace for exam preparation for SSC, IAS, IBPS and many other competitive exams. We have become the preferred destination for both content providers and students.

Within one year of inception, we are already the biggest education app in India by a huge margin. With 5 million+ app downloads and 4 lakh+ people using our platform every single day, our app usage is increasing exponentially month on month. More than 1 billion questions have been attempted by students on the OT platform. OnlineTyari is poised for a massive growth as mobile internet revolution is providing a gateway to millions of Indians to fulfill their aspirations.

With a strong management team of IIT and IIM alumni and backing of marquee investors, we are scaling new heights every day and disrupting the traditional education sector with smart technologies.

To know more about us, please visit:
website: www.onlinetyari.com and android app: https://goo.gl/G3AuwD

Office Location –Gurgaon- https://goo.gl/maps/ 6fNjp5Dd3ro

Position Summary

OnlineTyari is a faced paced startup disrupting the education sector rapidly and helping millions of Indians build a better career! We are looking for a passionate Product Designer who will take ownership of the complete Design cycle and create an amazing user interface on our app and website! You will play a critical role in providing a great and seamless user experience to our users. You would also work closely with the founders in building a distinct and attractive OnlineTyari brand connecting with millions of our users!

Responsibilities:
Lead all aspects of design cycle to translate the Company’s product vision into seamless user interface and intuitive user experience
Create comprehensive style guide and unify the design language across all products and marketing channels to create a seamless and distinct Brand experience.
Map the user flow and product journey and understand the impact of each touch point
Collaborate with the product and engineering team to deliver highly creative designs, wireframes, user stories, user journeys, and mock ups
Create beautiful and attractive User Interface, graphic designs, icons, etc. as per Company’s brand and design guidelines
Regularly meet and interact with users to understand their personas and requirements
Improve conversions through design tweaks and create new features based on user feedback and usability analytics

Requirements:
Atleast 4 years of UI/UX design experience for high traffic web and app products
A great design portfolio that demonstrates creative design thinking and a deep understanding of latest UI/UX trends and practices
Extensive experience developing software interfaces using Adobe Suite tools (e.g.,
Photoshop, Illustrator) HTML5, CSS3, and JavaScript skills are a plus
Strong visual design skills with proven ability to create beautiful responsive designs
Solid experience in UX research and usability testing
Willing to take ownership and result oriented
Quick learner and ability to solve problem using data driven approach

What we offer:
Be part of the fastest growing edtech company
Your contributions will have a potential to create an immediate positive impact on 6 million+ Indians!
Get full freedom to dream big and chase your passion
Flexible, fun and modern work culture with a highly motivated and energetic team
Work with top talent",3.4,"Onlinetyari
3.4",Gurgaon,"Gurgaon, India",1 to 50 employees,2014,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"We are looking for a Machine Learning (ML) Engineer to help us create artificial intelligence products. Machine Learning Engineer's responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we’d like to meet you. Your ultimate goal will be to shape and build efficient self-learning applications.

Let's pre-pay machine learning debt: https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf

Responsibilities

Study and transform data science prototypes
Design machine learning systems
Design and Develop data repositories
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Select appropriate datasets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Train and retrain systems when necessary
Extend existing ML libraries and frameworks
Keep abreast of developments in the field

Requirements

5+ years of industry experience
Proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling, and software architecture
Ability to write robust code in Python, Java, SQL, BigData Technologies
Familiarity with GCP/AWS technologies
Familiarity with Python libraries (Pandas, Celery, MultiProcessing)
Familiarity with Linux shell scripting
Familiarity with machine learning frameworks (like H2O, scikit-learn)
Excellent communication skills
Ability to work in a team
Outstanding analytical and problem-solving skills
BSc in Computer Science, Mathematics or similar field; Master’s degree is a plus",-1,hudsondata.com,Gurgaon,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer I / Data Engineer II,-1,"Relocation Assistance Offered Within Country
# 84506 - Mumbai, Maharashtra, India

Scope of Responsibility

This role will involve working with business analysts to understand needs and then developing the solution which entails planning, design, development and maintenance of our data repositories, pipeline and analytical solutions. The ideal candidate is self driven and looking to build high quality tools to provide actionable insights to our business partners to facilitate data-driven decision making. The candidate needs to be a self-starter - eager to learn new technologies, extract insights and value from data and how to leverage technology to deliver those insights. The candidate should also have an interest in analytics, focus on customer experience and design and intuitive visualization to ensure business users are getting the most from delivered tools.

Specific Responsibilities

Major position responsibilities include but are not limited to the following:
You are excited at the prospect of leveraging technology to solve complex data problems
Build data applications on SAP BI/BW, HANA & Google cloud platform
Design, develop, and maintain a world class data warehouse and analytics architecture to meet business analysis, reporting needs, and data science initiatives
Work directly with supply chain business users and data scientists to assist in project analysis
Participate in the development and maintenance of ETL jobs and data pipelines to aggregate data from various on premise, cloud platforms & external data sources
Design and develop data marts for consumption by analytics tools and end users
Develop code standards, guidelines to manage and ensure data quality and integrity
Optimize and scale data warehouse and data processing infrastructure
Evaluate new technologies and constantly work towards continuous improvements in data engineering, our platform, and the organization
Basic Qualifications
Bachelor’s degree required, Graduate degree in Computer Science, Statistics, Informatics, Information
Systems or another quantitative field is preferred
At east 4 year of experience as Data Engineer role.
At least 1 year of experience in SAP data warehousing & analytical tools like Tableau etc.
Demonstrates ability in data modeling, ETL development, and Data warehousing
Knowledge of data management fundamentals and data storage principles
Experience with Python/Javascript or similar programming languages
Working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Preferred Qualifications
Experience building and optimizing""big data"" data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with data warehousing platforms/storage platforms such as SAP BW/HANA
Experience with SAP data extractors, SAP Integration tools like SLT, SDI & understanding of Supply chain processes is preferred
Experience with cloud data warehousing/Big data environments like Snowflakes, Bigquery, Google cloud storage etc is a plus
Experience with object-oriented/object function scripting languages: Python, Java, etc.
Experience with data pipelines and streaming frameworks such as Pubsub, Spark, Airflow, Kafka etc
Experience with RDBMS; NoSQL experience also encouraged
Ability to embrace, learn, and apply new technologies and tools
Familiarity with agile software development methodology
Ability to communicate well with both technical and non-technical teams
Equal Opportunity Employer
Colgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, veteran status (United States positions), or any other characteristic protected by law.

Are you interested in working for Colgate-Palmolive? You can apply online and attach all relevant documents such as a cover letter and resume or CV. Applications received by e-mail are not considered in the selection process. Become part of our team. We look forward to your application.

Colgate-Palmolive is a leading global consumer products company, tightly focused on Oral Care, Personal Care, Home Care and Pet Nutrition. Colgate sells its products in over 200 countries and territories around the world under such internationally recognized brand names as Colgate, Palmolive, elmex, Tom’s of Maine, Sorriso, Speed Stick, Lady Speed Stick, Softsoap, Irish Spring, Protex, Sanex, Elta MD, PCA Skin, Ajax, Axion, Fabuloso, Soupline and Suavitel, as well as Hill’s Science Diet and Hill’s Prescription Diet.

For more information about Colgate’s global business, visit the Company’s web site at http://www.colgatepalmolive.com. To learn more about Colgate Bright Smiles, Bright Futures® oral health education program, please visit http://www.colgatebsbf.com. To learn more about Hill's and the Hill’s Food, Shelter & Love program please visit http://www.hillspet.com. To learn more about Tom’s of Maine please visit http://www.tomsofmaine.com.

Reasonable accommodation during the application process is available for persons with disabilities. Please contact Application_Accommodation@colpal.com with the subject ""Accommodation Request"" should you require accommodation.",4.0,"Colgate-Palmolive
4.0",Mumbai,"New York, NY",10000+ employees,1806,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),-1
Data Analyst,-1,"Duties and Responsibilities
Research and verify the accuracy of the data from source documents within the time limits.
Verify the accuracy and the credibility of the information.
Prepare documents, files and reports utilizing various computer (Microsoft Office) programs.
Enter data into prescribed computer database, files and forms.
Review data for deficiencies or errors, correct any incompatibilities if possible.
Keep information confidential.
Requirements
Any graduate, higher preferred.
Good verbal and written communication skills.
Problem analysis and problem solving.
Proficient in relevant computer skills such as MS Office.
Typing speed and accuracy.
Eager to learn and cooperate with the time.",3.4,"Edunuts
3.4",New Delhi,"Connaught Place, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
APAC Resources Consulting - Reliability Analytics Manager - 7,-1,"Job Description

About Accenture:
Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries - powered by the world's largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com

About Accenture
Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions — underpinned by the world’s largest delivery network — Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With 492,000 people serving clients in more than 120 countries, Accenture drives innovation to improve the way the world works and lives. Visit us at www.accenture.com

Key responsibilities of the role:
To bring industry knowledge, world class capabilities, innovation and cutting-edge technology to our clients in the Resources industry to deliver business value.
To work with leading Resources clients, major customers and suppliers to develop and execute maintenance & reliability strategies.
To harness extensive knowledge combined with an integrated suite of methods, people and assets to deliver sustainable long term solutions.
Experience:
8-12 years of experience in Upstream O&G, Downstream Refining & Petrochemicals, Power Generation Utilities, Mining, Chemical plants
Hands on experience in Reliability centered maintenance (RCM), Asset Life Cycle, Asset Criticality analysis, Risk Management framework, , Maintenance Best Practices and Strategies
Hands on experience in tools such as SAP PM / Maximo / infor, APM tools as – GE Meridium / Bentley asset wise / Aveva, NRX Asset Hub, Asset Answers

Qualification:
Engineering Degree (Tier-1 institutes)
MBA / PGDM (preferred though not mandatory)
Qualifications
Qualification: • Engineering Degree (Tier-1 institutes) MBA / PGDM (preferred though not mandatory)",3.9,"Accenture
3.9",Gurgaon,"Dublin, Ireland",10000+ employees,1989,Company - Public,Consulting,Business Services,₹500+ billion (INR),"Cognizant Technology Solutions, EY, McKinsey & Company"
Senior Lead Data Scientist,-1,"Job Description
:

Looking for talented individuals to join the Analytics department based out of the Headquarters in Pune – to join colleagues with passion towards data alongside focus on execution through mathematical intuition, curiosity and a positive outlook

Depending on immediate skillsets and role, one will be an essential part of the Analytics team working on
Scorecard Development and Statistical Analysis
Development and deployment of end to end ML/DL/AI driven products and solutions
Machine Learning based data Products development
One will be involved in many industry first data solutions working in a start-up mode. We’re all about creative, self-starting talent who are excited by the very thought of changing an entire industry for the better

We’re all about creative, self-starters who are excited by the very thought of changing an entire insurance industry by caring for our citizens in the best possible and granular way leveraging data and analytics. We continue to accelerate our progress in creation of an Machine Learning driven advanced Analytics function that will integrate ML, Deep Learning, Bayesian or Behavioural Science into software applications to drive operational efficiencies and create business value while delivering a best-in-class experience with all stakeholders and customers.

Working with business stakeholders to understand their most complex business challenges and develop precise and fine-grained problem statements.
Developing high-level solution architectures and working with our team of data engineers and decision science analysts to build, test and assess models that predict and optimize business outcomes based on client’s success criteria.
Develop sophisticated yet simple interpretations and communicate insights to business stakeholders that lead to quantifiable business impact.
Building deep relationship with business stakeholders by understanding their stated but more importantly, latent needs

Department
:

HO

Open Positions
:

1

Skills Required
:

Proficiency of 8+ (in a scale of 10) in al-least one of Python, R or Java

Role
:

Developing high-level solution architectures and working data engineers and decision science analysts to build, test and assess models that predict and optimize business outcomes based on business success criteria.
Work unsupervised with internal and external teams to respond to business requirements.
End-to-end responsibility for model development, including data exploration, training data, feature extraction and model development, validation and scoring.
Convincingly communicate with our stakeholders at all levels, including pairing with other Data Scientists.
An experienced data scientist and math nerd with a passion for ML/AI.
People who love innovation, playing with AI/DL/ML, and challenging the status quo.
One will be responsible for exciting innovations around Vision, Sound, NLP or data-based solutions or product development on Risk, Fraud, NLP, ML and prediction problems.
Comfortable writing own library
End to End project management experience developing, implementating and integration of ML based models with system applications- Experience working on high-scale, production-grade projects.
AWS/Azure experience is must.
Working knowledge of data engineering – building ML pipelines.
Statistics, Computer Science or Mathematics degree and is fluent in Python, R, and has knowledge of relational and NoSQL databases.

Additional details:
Experience in TensorFlow, Keras, Pytorch, NLTK etc.
Be a go- to resource for key complex systems and services, working closely with engineers to deliver high quality software on time.
Define long term design and build reliable, scalable fast- performance consumer- grade geo- related services and solutions, end- to- end. Fully understand non- functional requirements, system interdependencies and limitations
Strong background in at least one specific machine learning area*

Deep learning, re-enforcement learning, CNN, RNN, LSTM, Natural language processing: sequence segmentation, labeling and parsing, language modeling, machine translation, question answering and dialog systems, knowledge extraction, representation and reasoning, Graph DB, Computer vision: large scale image classification, detection, face recognition, scene understanding, metric learning, image search, etc.

Location
:

HO

Education/Qualification
:

B.Tech/M.Tech/ M.S. in Statistics, Computer Science or Mathematics or equivalent technical degree with strong programming skills

Years Of Exp
:

7 to 14 Years

Posted On
:
13-Jul-2020
Designation
:

Senior Lead Data Scientist",3.8,"Bajaj Allianz General Insurance Company
3.8",India,"Pune, India",1001 to 5000 employees,2001,Company - Private,Insurance Operators,Insurance,₹500+ billion (INR),-1
BI Data Analyst,-1,"Department: AIDT - BUSINESS, INFO & DATA ANALYSIS

Job Location: Mumbai

About Us
Morgan Stanley is a leading global financial services firm providing a wide range of investment banking, securities, investment management and wealth management services. We advise, originate, trade, manage and distribute capital for governments, institutions and individuals. As a market leader, the talent and passion of our people is critical to our success. Together, we share a common set of values rooted in integrity, excellence and strong team ethic. We provide you a superior foundation for building a professional career where you can learn, achieve and grow.

Technology/Role/Department at Morgan Stanley
AIDT (Analytics, Intelligence and Data Technology) is looking for Data Analyst for its Mumbai MSAS office.
Successful candidate will be responsible for conducting full lifecycle analysis to include requirements, activities and design. He will assist in developing analysis and reporting capabilities. He will also be responsible to assist in monitoring performance and quality control plans to identify improvements

Department Profile:
Wealth Management Technology (WMT) is responsible for the design, development, delivery, and support of the technical platform behind the products and services used by the Business.
Morgan Stanley Wealth Management (WM) is a product of the acquisition of Smith Barney from Citigroup, which was completed in June ‘13. Its core client base is individual investors, small- to medium-size businesses and institutions, and high net worth families and individuals. In the second half of ‘14, WM reached a milestone, with its business having surpassed $2 trillion in total client assets.

Position Overview:
Interpret data, analyze results using statistical techniques and provide ongoing reports
Extensive coordination and collaboration for gathering requirements and technical details with key stakeholder across different teams (development, architecture, QA and SMEs)
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Participate in design discussions and partner with key stakeholders in documenting and developing potential solutions to the business problems
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities

The Right Candidate
7 years of experience working as Data Analyst with extensive experience of working on complex Data driven applications
Knowledge of BFSI domain and Wealth Management business – new account opening, KYC and client onboarding
Proven working experience as a Data Analyst or Business Data Analyst
Critical thinking ability, Strong problem-solving capacity
Advanced written and verbal communication skills.
Project management skills
Ability to work under pressure with different moving parts and deliver to tight deadlines
Effective listener, speaker, reader and writer - able to bridge business and technical domains, promote best practices, and enforce good governance within challenging timelines
Bachelors or Masters in Computer Science, Information Management or other relevant field
Required Experience:

Skill Set:

Primary skills
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong Knowledge of SQL is a must
Strong knowledge of and experience with reporting packages (Tableau, Business Objects etc.), databases (SQL etc.) and ETL frameworks (Informatica etc.)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Understand business objectives. Working with users to formulate business & system requirements.
Adept at queries, report writing and presenting findings
Comfortable in manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources
Strong knowledge of Data warehousing concepts and knowledge of formal database architecture and design. Good SQL experience (preferably Teradata).
Ability to challenge status-quo through identification of key business requirements and addressing through innovative data-driven solutions.
Ability to work in fast paced and dynamic environment.
Experience in agile, for planning, leading, organizing, and motivating agile project teams. Achieve a high level of performance and quality and deliver agile projects that provide exceptional business value to users. Good in user story writing and grouping
Excellent Communication and presentation skills
Strong ability to take ownership and run stakeholder meetings
Be excellent at time management
Good documentation and writing skills
Stakeholder management

Good to have skills
Experience working with BFSI domain
Expertise in handling large data volumes MPP databases like Teradata/Greenplum
Knowledge of Hadoop will be a plus",3.8,"Morgan Stanley
3.8",Mumbai,"New York, NY",10000+ employees,1935,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Senior Scientist I,-1,"M. Sc. in chemistry or PhD in chemistry with 6 or 2 years of experience in the
chemical or pharmaceutical industry.

Expansive knowledge in Synthetic Organic Chemistry. Devising suitable synthetic plans including detailed literature procedures.
Setting up of the reactions, monitoring and analyzing progress, workup and isolation of products and interpretation of the spectral data.
In addition to depth of knowledge in synthetic chemistry, good communication skills are a must, as are good report writing skills.
General lab maintenance, maintenance of the instruments, glass wares and apparatus and overall cleanliness.
Knowledge of safety aspects in the lab and hazardous nature of chemicals, incorporation of safety practices in day to day work.
Use of chemistry databases such as SCIFINDER and BIELSTEIN.",-1,Kemxtree,Mumbai,-1,-1,-1,-1,-1,-1,-1,-1
Research Scientist - R&D,-1,"candidate should have experience in R&d -Formulation.the person should have experience on working on doe software.
Salary Negotiable
Industry Pharmaceuticals / Healthcare
SubIndustry Formulation
Functional Area R&D / Design
Specialization Formulation Development - Regulated Market
Role Entry level / Trainee Level
Keyskills
R&DF&
Desired Candidate Profile
candidate should have experience in R&d -Formulation.the person should have experience on working on doe software.
Education
Highest Qualification M.Pharm
Graduation B.Pham",5.0,"Fine Jobs
5.0",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Development Scientist II,-1,"Summary of responsibilities:

Assists in the evaluation and implementation of new technologies. The incumbent performs experiments, analyzes data and plans next series of experiments, takes ownership for the assigned work participates in planning studies for the development, evolution and optimization of assay(s);

Prepares study plans and reports, maintains well organized laboratory notebooks in compliance with relevant procedures; and supports post-launch to resolve performance and/or quality issues.

Boundary Conditions/Authority Levels:

Normally receives no instruction on routine work; general instructions on new assignments. Adheres to policies and procedures

Essential Duties and Responsibilities: include the following. Other duties may be assigned.
Participates in the analysis, design and development of system applications.
Follows standard practices and procedures in analyzing situations or data from which answers can be readily obtained.
Reports status of experiments to supervisor/Technical lead.
Applies analytical skills to interpret data and uses independent judgment and discretion in developing solutions to a variety of work problems of moderate scope and complexity
Able to troubleshoot issues, identify root cause and strive towards solutions for identified problems
Responsible for creating technical presentations and updating relevant functions on the same
Responsible for generating high quality technical documents and reports
Responsible for strict adherence to quality standards and regulatory guidelines
Responsible for communicating business related issues or opportunities to next management level.
Responsible for ensuring personal and company compliance with all Federal, State, local and company regulations, policies and procedures for Health, Safety and Environmental compliance.
Performs other related duties as required.
Education and/or Experience:

PhD in Life Sciences/Microbiology/ Biochemistry/Biotechnology or relevant fields with 2+ years of experience ; Masters degree in Microbiology/ Biochemistry/Biotechnology or relevant fields with 5+ years of relevant experience in industry

Industrial experience in the field of assay development of Flow cytometry reagents, ELISAs or other Immunological techniques is desirable but not mandatory.

Danaher Corporation and all Danaher Companies are equal opportunity employers that evaluate qualified applicants without regard to race, color, national origin, religion, sex, age, marital status, disability, veteran status, sexual orientation, gender identity, or other characteristics protected by law. The EEO is the Law poster is available here.",3.4,"Beckman Coulter Life Sciences
3.4",Bengaluru,"Brea, CA",10000+ employees,1935,Subsidiary or Business Segment,Healthcare Product Manufacturing,Manufacturing,₹100 to ₹500 billion (INR),"Abbott, Roche, Thermo Fisher Scientific"
Senior Data Engineer,-1,"Employment Type
Permanent
Closing Date
11 Aug 2020 11:59pm
Job Title
Senior Data Engineer
Job Description


Telstra is Australia’s leading telecommunications and technology company, with operations in more than 20 countries, including in India where we’ve launched our new Innovation and Capability Centre (ICC) in Bangalore.

We’re combining innovation, automation and technology to solve the world’s biggest technological challenges in areas such as Internet of Things (IoT), 5G, Artificial Intelligence (AI), Machine Learning, and more. Join us on this exciting journey, and together, we’ll reimagine the future.

Our Software Engineering teams are building a new platform to support Microservice APIs, developed by our teams of developers spread across the globe. We're using industry leading technologies and design principles to encourage best practice application design / development and operation, such as automation and CI/CD.

As a Senior Data Engineer, you will develop, maintain, test and evaluate big data solutions within organisations and would also be involved in the design of big data solutions. You will plan, coordinate, and execute all activities related to the requirements interpretation, design and implementation of data analytics applications.

In this role, your key responsibilities are…
Design and develop data analytics applications.
Review vendor designs and recommended solutions based on industry best practises.
Provide technical governance across data analytics solutions at Telstra.
Assess and improve the efficiency and effectiveness of the data analytics application solutions to ensure user requirements and business objectives are met in a timely and cost-effective manner.
Understand overall business landscape and develops innovative solutions to help improve productivity.
Coordinate with technical resource within and outside of Feature team.
Monitor process of software configuration/development/testing to assure quality deliverable.
Ensure standards of QA are being met.
Review deliverables to verify that they meet client and contract expectations; Implement and enforce high standards for quality deliverables.
Analyses performance and capacity issues of the highest complexity.
Assists leadership with development and management of new application capabilities to improve productivity.
Provide training and educate other team members around core capabilities and helps them deliver high quality solutions and deliverables/documentation.
Design/develop user requirements, test and deploy the changes into production.
To be successful in the role, you must have…
Degree level IT qualifications in Software or Systems Engineering.
Minimum 8 years of experience in IT space and minimum 8 years of Big Data platform experience, consulting or technical lead / team lead role, with 3 years of team/project leadership experience as a solution lead, or similar roles implementing projects.
Extensive experience using Hortonworks Data Platform.
Experience in Apache Hive, Spark, Zeppelin and Ambari.
Proven expertise of working on Azure Cloud using Databricks, Azure Event hub Flume/Kafka/Spark streaming, Azure Data Factory.
Experience of using Informatica for ETL use cases.
Experience of working in Azure DevOps and ARM.
Experience of using Control-m to schedule data engineering workflows.
Experience in designing solutions for multiple large data warehouses with a good understanding of cluster and parallel architecture as well as high-scale or distributed RDBMS and/or knowledge on NoSQL platforms.
Experience in translating, loading and presenting disparate datasets in multiple formats/sources including JSON, XML etc.
Good knowledge of NoSQL Databases/ HBase/ MongoDB.
Experience in Programming: Java Spring Boot/ Scala/ Python / SQL and Multi-tenant databases.
Experience in Scaled Agile Framework.
Ability to identify and rationalise issues and provide leadership in progressing to a beneficial outcome.
Strong problem solving and analytical skills.
Demonstrated high level of written and oral communication skills.
Proven high level of initiative, drive and enthusiasm with excellent time management and an ability to work under pressure.
Desirable to have experience on:
Automation using PowerShell
Rabbit MQ
Jenkins
Power BI
REST API
Salesforce
Our people in India will be at the forefront of technological change as they work collaboratively with, and learn from, world-class experts and have access to the latest training programs and insights for their field.

Alongside your work on leading edge projects, working with us means you'll have access to company perks and benefits that'll reward you for the great work you do.

We’re growing, fast, and for you that means many exciting opportunities to develop your career with us at Telstra.

Interested?

If you're excited about the opportunity to be part of a team, committed to delivering amazing experiences for our customers – your next step is to apply!

We’re committed to building a diverse and inclusive workforce. To enable everyone to participate, we’ve developed an ‘All Roles Flex’ policy to consider flexible ways of working for every role. To learn more, visit our Telstra Careers Website: tel.st/allrolesflex

We’re committed to building a diverse and inclusive workforce. To enable everyone to participate, we’ve developed an ‘All Roles Flex’ policy to consider flexible ways of working for every role. To learn more, visit http://tel.st/allrolesflex. We welcome applications from Indigenous Australians, people from diverse cultural and linguistic backgrounds and people living with a disability. We encourage you to talk to us about how we can support you through the recruitment process.",3.6,"Telstra
3.6",Bengaluru,"Melbourne, Australia",10000+ employees,1901,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Optus, Vodafone, Macquarie Telecom Group"
Data Analyst,-1,"Requirement
B.Tech. / B.E in any Engineering Stream/ MCA / Bachelor’s degree in any science stream.
0-2 years’ experience - Fresher’s are welcome to apply.
Added advantage if you have basic knowledge about Mechanical/Electrical appliances, FMCG products
Added advantage if you have experience of working with API’s used to extract web data - dimensional data from databases and web is an added advantage. Basic programming skills to program custom scrapping tools
Should have excellent computer knowledge - MS Office – Excel, MS Word, etc.
Engineering Product / Data Mining understanding – Product information like Manufacturer / Part Number / Product Description / Energy rating / Energy consumption etc.
Good Analytical & Communication skills (Ability to communicate with clients)
Data management capabilities, attention to detail.
Demonstrates interpersonal skills and team work
Quick learner and flexible to perform multiple jobs
What you've got
If you have the ability to look down at the meaning of data with good analysis and identify trends and patterns of information clubbed with excellent computer skills, then this role is what you are looking for. Expertise in streamlining of data management projects and end to end process flow, ensuring deliverables are prepared to exceed customer expectations, status reporting, developing, documenting, and maintaining data quality goals and standards.",-1,Outsource Bigdata,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1
Data Analyst,-1,"Work Experience
Candidate with 1-3 Years of work experience of Charges/ Payment Posting in US Healthcare with RCM Company.",-1,Nath Outsourcing Solutions,Nagar,-1,-1,-1,-1,-1,-1,-1,-1
Data Analyst,-1,"Experience
2 Years
Location
Vijayawada
Role
Data Analyst
Your Skills
Tableau / Microsoft Power Bi (Model development using statistical methods ,Analyze data and generate insight - result interpretation and presentation, analyze data using statistical techniques and provide adhoc and ongoing reports)
Job Description
Product development Envisage the product features as per requirement, plan and execute.
Maintaining heigh coding standards and practices and exercisequality control on all aspect of web developement
Breaking new ground, researching and implementing innovative web technologies and features .
problem-solving in all areas of web development
Industry Type
IT Software, Software services
Functional Area
IT Software-Application Programming, Maintainance",-1,Entrolabs It solutions,Vijayawada,-1,-1,-1,-1,-1,-1,-1,-1
Data Analyst,-1,"Technical Skills Required :

1. Proficient in SQL Oracle (must) ,Hive ,Macro and any programming language ( Good to Have) and able to learn new analytical software to support finance (like Power BI, Qlik View ).

2. Have worked as SQL developer with more than 3-5 Years of experience with End to End development projects.

Responsibilities : You will be part of automation team for Finance department , who will be taking care of End to End development of Projects for them which includes automation of their daily reporting process which they do via excel or qlik view for this you will have to automate their reporting from source till there dash boarding. You need to be self Driven and have to handle project end to end on their own and complete the project within timelines.

Job Types: Full-time, Contract

Salary: ₹20,000.00 - ₹25,000.00 per month

Experience:
work: 3 years (Required)
total work: 3 years (Required)
Education:
Bachelor's (Required)
Work Remotely:
No",-1,GUTURI Infotech Pvt Ltd,Karnataka,-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Engineer - Data Quality,-1,"The role:

Taking part in the Data Quality team, this position will require you to have excellent engineering skills, be creative and a self starter. You will be responsible for implementing and evolving data quality tools and methodologies, acting as a key driver to resolution and prevention of issues, improving and standardising the way all data producers implement data quality checks so that the data products meet the established standards of quality including reliability, usability and performance.

The Senior DQ Engineer will also contribute to inspire the Data Quality culture and mindset across the company: communicating, providing guidelines and processes to the teams, supporting the Data Strategy and one of Farfetch's strategic pillars: Fashion Meets Data.
What you will do
Work on data engineering challenges that arise from Farfetch's scale and data growth.
You will be accountable for implementing and evolving the Data Quality Tool (Great Expectation) to identify issues and possible anomalies, and implement dashboards to measure KPIs and performs data validation.
You will evolve data models & schema design of our data warehouse to support the engagement of all teams on Data Quality and create reports to leverage the DQ SLO’s commitment between all the teams in the company.
You will be a keen advocate of quality and continuous improvement.
Build great relationships with analysts to and other engineering teams - acting as a partner on analysing issues and bringing automated solutions for them.
Contribute to the creation of quality assurance standards, policies and procedures to influence the DQ mindset across the company.
Work in an agile fashion, and deliver on time and accurately.

Who you are
Minimum 5 years of experience working with Data Engineering.
You have experience in building and maintaining data pipelines.
You can productionise your code, but also know that something done is better than something perfect, and iterate over time to improve it.
You have experience in creating and evolving dimensional data models & schema designs to improve accessibility of data and provide intuitive analytics.
You have Experience with BI and data visualisation tools (e.g., Looker, Tableau, etc.) is preferred.
You can write SQL in your sleep!
You have experience in a cloud environment
You have experience in continuous delivery principles: version control, unit and automated tests;
You have skills in programming languages, preferably Python.
You have good analytical and problem solving skills, the ability to work in a fast moving operational environment and you are enthusiastic and with a positive attitude.
An individual that can change directions quickly to respond to new information and changing circumstances.
Fluent in English

It would be a plus:
Knowledge of tools, concepts and methodologies of QA
Previous experience implementing Data Quality tools, for instance: Informatica, Talend, Dequu, Great Expectations etc.
Experience with QA in the Data world: Quality inspection, auditing and testing
Certifications in one of these areas would be a plus: Quality Auditor, Quality Engineer, Quality Improvement Associate, Six Sigma
We are looking for a Senior Data Quality Engineer who will implement and improve the Data Quality tools, so that we support the company to meet higher standards of quality including reliability, usability and performance and empower Farfetch on making data driven decisions.",3.9,"Farfetch
3.9",New Delhi,"London, United Kingdom",1001 to 5000 employees,2008,Company - Public,Internet,Information Technology,Unknown / Non-Applicable,Neiman Marcus
Lead Data Engineer,-1,"About Us

upGrad is an online education platform building the careers of tomorrow by offering the most industry-relevant programs in an immersive learning experience. Our mission is to create a new digital-first learning experience to deliver tangible career impact to individuals at scale. upGrad currently offers programs in Data Science, Machine Learning, Product Management, Digital Marketing, and Entrepreneurship, etc.

upGrad is looking for people passionate about management and education to help design learning programs for working professionals to stay sharp and stay relevant and help build the careers of tomorrow.
upGrad was awarded the Best Tech for Education by IAMAI for 2018-19
upGrad was also ranked as one of the LinkedIn Top Startups 2018: The 25 most sought-after startups in India
upGrad was earlier selected as one of the top ten most innovative companies in India by FastCompany.
We were also covered by the Financial Times along with other disruptors in Ed-Tech
upGrad is the official education partner for Government of India - Startup India program
Our program with IIIT B has been ranked #1 program in the country in the domain of Artificial Intelligence and Machine Learning
About the Role

A seasoned technical contributor who has experience in proposing and implementing Data Engineering projects and bringing them to production to solve complex engineering/business problems. Passionate about storage, retrieval and analysis of data to build data driven solutions and aid in the decision making process.

Role and Responsibilities
Lead the effort of setting up a strong framework for collection, storage and analysis of data at scale.
Own and develop the data pipelines that form the base of upGrads applications and services and leverage the use of cutting edge techniques for both real time and non-real time ETL and data pipelines.
Provide timelines and own end to end delivery of data engineering projects.
Prioritize to manage ad-hoc requests in parallel with ongoing projects.
Take decisions on real time and non-real time based collection and analysis strategies which suit the need of the engineering and product teams.
Standardize the tools that are used by backend and frontend developers to collect events data. Collaborate with multiple teams and identify problem statement and propose and implement solutions.
Find ways to optimize the huge amount of data being stored and queried with different tools and follow best practices of setting up and delivering data driven solutions and APIs.
Skills/Experience
A highly talented and technical developer with 8+ years of hands-on experience in building and deploying data engineering solutions. Experience in building APIs and dashboards using data.
6+ years of industry experience with at least 4+ years experience with ETL, Data Modeling and working with large-scale datasets.
8+ years experience with an object-oriented programming language such as Python, Scala or Java
Extremely proficient in writing performant SQL working with large data volumes
Experience with designing, scaling and optimizing cloud based data warehouses (like AWS Redshift) and data lakes
Strong knowledge and experience in 1 or more tools/frameworks from each category:
Query/Data Processing engines: Spark, Hive, Athena/ Presto
Data Warehouses: Redshift, Druid, Snowflake
AWS : S3, Glue, EMR, RDS
Stream-processing: Spark-Streaming, Faust, Flink etc.
Message queuing: Apache Kafka, AWS Kinesis
Orchestration: Luigi, Airflow, Azkaban etc.
Basic knowledge of software architecture design, docker, and microservices concepts. Kubernetes knowledge is a bonus.
Strong knowledge of cloud computing and AWS services.
Qualification – B.Tech/M.Tech/MCA(IT/Computer Science)

Years of Exp – 8-10+",3.3,"upGrad Education Private Limited
3.3",Bengaluru,"Mumbai, India",501 to 1000 employees,2015,Company - Private,Education Training Services,Education,₹1 to ₹5 billion (INR),"Udacity, General Assembly, Springboard"
"Analyst, Data Science",-1,"Analytics

Analyst, Data Science

Pune, Maharashtra, India
APPLY

WhatYou’llBe Doing:
Research, conceptualize, and implement analytical approaches and predictive modeling to evaluate scenarios, predict utilization and clinical outcomes, and recommend actions to impact results.
Manage and execute on the entire model development process, including scope definition, hypothesis formation, data cleaning and preparation, feature selection, model implementation, validation and iteration, using multiple data sources.
Provide guidance on necessary data and software infrastructure capabilities to deliver a scalable solution across partners and support the implementation of the team’s algorithms and models into Evolent’s product offerings.
Contribute to the development and publication of white papers showcasing Evolent’s leadership in healthcare data science.
Collaborate with stakeholders from clinical, operations, and product teams to identify advanced analytics opportunities to add value to Evolent’s solution offerings.
Leverage clinical and administrative data to support other business needs related to clinical program improvement, networks optimization, and other strategic initiatives.
The Experience You’ll Need (Required):
Master’s Degree with a quantitative focus (e.g. data science program, software engineering, statistics, mathematics, computer science, health services research).
3-6 years of professional experience in an analytical field related to health service analytics, predictive modeling in health care, or other health care-related experience.
Strong technical abilities with advanced data and analytics tools and programming languages, including Python or R, and at least one database language such as SQL or Mongodb.
Foundational understanding of core concepts in applying machine learning algorithms: data cleaning, feature selection, and parameter tuning.
Strong communication skills, including both communicating with other stakeholders to fully evaluate project requirements and context, as well as communicating project results, findings, and applicability.
Ability to work independently with little technical guidance day-to-day, in a fast-paced environment.
Finishing Touches (Preferred):
Experience in SAS, SAS/CONNECT, and disparate programming language integration techniques
Proficiency in most areas of mathematical analysis methods, statistical analyses, predictive modeling, and/or machine learning (such as neural networks, random forests, gradient boosting, etc), and in-depth specialization in some areas.
Working knowledge of analyzing administrative medical claims, pharmacy claims, and/or EMR data and clinical data.
Proficiency with git or other version-control software, especially in collaboration with others.
Proficiency working at the command line / shell.
Experience in reporting and visualization tools such as R’sggplot, Python’s bokeh, Tableau, MSTR, or geo-mapping tools.
Experience building and/or using APIs.

APPLY",2.9,"Evolent Health
2.9",Pune,"Arlington, VA",1001 to 5000 employees,2011,Company - Public,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),-1
Data Science & Analytic,-1,"Location : Delhi, NCR.

Experience :
1 to 2 years developing and implementing data analytics methodologies with good interpersonal with excellent communication skills

Technical Skills Required :
Python, Machine learning, Deep Learning, Data wrangling, Integration with Big Data Hadoop, Scoop, Impala, Hive, Pig & Spark R with Statistics, Data Wrangling, Models, Data mining, and Algorithms. Time series and forecasting, SQL, queries, Tableau Data Visualization.
Good Understanding with Hadoop, HBase, Hive, Pig, and Mapreduce, Python, R, Java, Apache spark, Impala, Hive, Pig, Machine Learning, Algorithms, Time series and forecasting, SQL, queries, Tableau Data Visualization.
Develop BigData/ Hadoop Technologies training content for Students, Working Professionals and Corporates.
Conduct online and classroom training sessions by providing practical use cases and assignments.
Design quality self-faced recorded training sessions on all latest BigData/ Hadoop development technologies for students, working professionals and corporates.
Continuously improve on teaching methodology to suite online model to lead to high student.
Work in small teams where each team member has a lot of ownership and each individual can make a big impact.
Design and make the trainees develop mini or major real time projects for practical exposure.
Work as a consultant or architect in development and training of real time BigData/ Hadoop Applications for corporates on part time or fulltime basis.

Hands on Knowledge on Tools :
Anaconda Navigator
Jupyter Notebook
Hadoop
Hive
Pig
Mapreduce
Mapreduce
Apache
Spark
Impala
SQL
Tableau",3.9,"Evolent Health
2.9",New Delhi,"New Delhi, India",1 to 50 employees,2011,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"WE ARE A TRANSFORMATIONAL PARTNER


Cognizant Softvision is a fast growing global digital development company. We help global companies in the areas of enterprise application development and integration, automation and machine learning, agile transformation, big data and analytics, full stack web, mobile, IoT, design and UX, QA and testing, infrastructure, and digital commerce.

We are looking for an exceptional QA Automation Engineer to work with our cross-functional team, and join our world-class community of talented experts.

For this position you should be able to check the following:
QA automation with development skills - ability to write from scratch automation scripts.
+2 years of experience Automating test cases in any top programming language (Javascript/Java/PHP/Python/Ruby).
Knowledge of OOP
Experience with Automation tools (at least one): Selenium (IDE/RC/Web Driver), Jmeter, Cucumber, QTP, SoapUI, Sikuli.
Knowledge of version control tools, especially Git.
Good understanding of data formats is a must.
Experience in creating tests for API's and automate them.
Experience with continuous integrations and continuous deployment (Jenkins is a plus).
Experience working in Agile Projects.
A problem solver with a keen eye for details and a strong desire to learn.
Self-directed, independent and comfortable in a fast paced, ambiguous and often multi-directional work environments.
A day in the life of a QA Automation Engineer:
Defines test objectives, creates test plans and develops automated test cases/procedures.
Performs testing against highly detailed specifications.
Provides test results to management and customers that are clear and concise.
Innovates and helps build new features in the current tools or design and builds new and improved automation tools.
Leads and delivers cutting edge test automation solutions that have a direct impact on increasing the quality of the products, while decreasing the time it takes to test them.
Responsible for recognizing and creating awareness of process or quality problems.
Researches and develops an understanding of the marketing and/or industry requirements for the product feature being tested, including how the users use the feature and their performance requirements for the features.
Identifies & proposes QA process improvements.",4.1,"Cognizant Softvision
4.1",Mysore,"New York, NY",1001 to 5000 employees,1994,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Accenture, NTT DATA, Endava"
Machine Learning Engineer,-1,"Job Description

Position : Data Science Architect

Location : Pune

We are looking for an exceptional Data Scientist who is passionate about data and motivated to build large scale machine learning solutions to shine our data products.
This person will be contributing to the analytics of data for insight discovery and development of machine learning pipeline to support modeling of terabytes of daily data for various use cases
Looking for people who are part of a product development company, especially cater to the Machine Learning and Big data domain.
Typical persona : Data Science Manager / Architect

Experience: 8+ years programming / engineering experience (with at least last 4 years in big data, Data science)

Must :
a. Hands-on Python: pandas,scikit-learn

b. Working knowledge of Kafka

c. Able to carry out own tasks and help the team in resolving problems - logical or technical (25% of job)

d. Good on analytical & debugging skills

e. Strong communication skills

Desired (in order of priorities) :
a. Go (Strong advantage)

b. Airflow (Strong advantage)

c. Familiarity & working experience on more than one type of database: relational, object, columnar, graph and other unstructured databases

d. Data structures, Algorithms

e. Experience with multi-threaded and thread sync concepts

f. AWS Sagemaker

g. Keras

Education : Computer Science Graduate from a premium University / Engineering college

Salary: Not Disclosed by Recruiter

Industry:IT-Software / Software Services

Functional Area:IT Software - Application Programming, Maintenance

Role Category:System Design/Implementation/ERP/CRM

Role:Solution Architect / Enterprise Architect

Keyskills
AirflowJavaSolutions ArchitectHadoopBig DataKafkaGoMachine LearningScikit - LearnData ScienceData ScientistData ArchitectPandasBig Data EngineerKerasMachine Learning EngineerScikitPython
Desired Candidate Profile
Please refer to the Job description above

Education-

UG:B.Tech/B.E. - Electronics/Telecommunication, Computers

PG:MS/M.Sc(Science) - Computers, M.Tech - Computers, Other",4.6,"Cognizant Softvision
4.1",Mysore,"Pune, India",1 to 50 employees,-1,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Germplasm Enhancement Scientist,-1,"Job Description

PURPOSE:
Develop and implement germplasm strategy aligned across regions thru haplotype based germplasm diversity and innovation to develop diverse lines with breeding value to deliver the seed & trait product pipelines across APAC for Corn, Rice, Cotton, Pearl Millet and Mustard crops valued at $300M annual sales

Develop a strong multifunctional team collaboration to implement disruptive germplasm enhancement program thru strong collaborative relationships to leverage diverse germplasm in line with the breeding requirements to drive strategic business initiatives aligned with Corn, Rice, Cotton Pearl Millet and Mustard hybrid crop strategy

WHAT YOU DO:
Partner with global team to develop a digital tool to monitor the genetic diversity across APAC pipelines and develop a detailed plan for diversification of pipeline
Collaborate to explore and resource new and diverse germplasm available in public program
Develop a germplasm scientist program matrix to achieve the desired goal in timely manner
Work with genetic discovery scientist and breeding team to understand diversity at genomic level and develop plans to utilize the diverse germplasm
Supports the breeding programs to deliver genetic gain in the short and long term with focus on germplasm management
Designs and deliver technical innovations to support breeding by leveraging genomic insights, data science, analytics and developing rapid breeding schemes
Develop a strong collaborative relationship to leverage internal germplasm and procure public germplasm in line with the breeding requirements
Supports the Health Safety & Environment, Compliance, Business Conduct and Human Rights policies and culture in the site.
Independently identifies research opportunities in assigned areas. Identifies opportunities for technical innovation. Aligns core competencies with business objectives. Currently conducts multiple complex scientific projects. Effectively communicates study findings internally and externally.
Identifies and implements new technologies to continuously improve processes. Demonstrates an expanded sphere of technical influence. Aligns activities to broad business objectives

Required Candidate profile

PhD degree in Plant Breeding & Genetics or other relevant agricultural science with minimum of 5+ years of relevant experience or MS degree with 8+

years of experience in handling germplasm development projects.

Experience in analysis of large biological data sets, quantitative genetics, statistical genetics, as well as coding experience in R, Python or similar

software.

Strong ability in building cross-functional and external partnerships and influence others to drive results and innovation focused in solving business

problems.

Customer-centricity, with proven record of identifying customer needs, prioritizing resources, and bring timely and sustainable solutions

Results orientation with demonstrated ability to manage multiple projects/priorities simultaneously

Salary: Not Disclosed by Recruiter

Industry:Agriculture / Dairy

Functional Area:Other

Keyskills
digital breeding
python
haplotype
R programing
data analytics
germplasm
statistical genetics
plant breeding
biological data sets
quantitative genetics
genetics
genetic discovery scientist
agriculture science
breeding
Desired Candidate Profile
Please refer to the Job description above

Education-

UG:B.Sc - Agriculture

PG:MS/M.Sc(Science) - Other, Agriculture, Data Informatics, Biotechnology

Doctorate:Ph.D - Agriculture, Genetics, Other, Biotechnology

Company Profile

Bayer Group

Bayer CropScience Ltd.",3.5,"Bayer Group
3.5",Bengaluru,"Las Vegas, NV",201 to 500 employees,-1,Company - Public,Vehicle Dealers,Retail,₹5 to ₹10 billion (INR),-1
Senior Scientist – Fermentation Development,-1,"Position: Senior Scientist – Fermentation Development

Location: Bangalore, India

Contact: Please email Subbiane@stringbio.com

No of Openings: 1

The Senior Scientist will be responsible for scaling up and optimization of fermentation processes. The candidate will have a strong command of fermentation development, scale up and plant operations.

POSITION RESPONSIBILITIES:
Design, execute, and analyze scientific experiments for production of small molecules using fermentation and other techniques.
Optimize the fermentation processes for maximizing production of value added products. Optimize product yield and minimize production cost.
Evaluate production processes, check its compatibility/configuration with respect to design and conduct follow-up experiments.
Develop statistical models of fermentation production for developing simulations of biochemical production.
Analyze and record process flow configurations, instrument specifications, instrumentation and piping diagrams required for systems design.
Utilize pilot process data for developing operational narratives.
Develop and execute scalable bioreactor control strategies.
Conduct detailed analysis, compile and report fermentation data.
Scale the fermentation process from demo through commercial scale.
Conduct routine maintenance of fermentation laboratory equipment.
Analyze batch records and monitor consistency of operations by using appropriate database and statistical tools.
Participate in techno-commercial evaluation of the projects to allow proper prioritization.
Lead trouble shooting in the plant for process and quality issues.
Serve as expert technical support to develop, implement and drive improvement in process safety.
Develop, review, update and implement process safety-related Standard Operating Procedures (SOPs) and guidelines as needed.
Track and report process safety indicators, key process safety metrics, action plans, and priority recommendations.
Assist in training of plant personnel.
Participate in identifying and implementing best practices for plant operations
Reliable execution and management of fermentation runs as per company SOPs.
Seek and qualify new technologies that are enabling for accomplishing project objectives.
Maintain accurate and timely records of laboratory work. Evaluate data, prepare technical reports and make scientific presentations.
Be a conscientious laboratory citizen, adhere to EH&S standards, and use knowledge of laboratory procedures to advance projects.

CANDIDATE PROFILE EDUCATION AND EXPERIENCE

PhD or MSc in Chemical Engineering, Biotechnology, Molecular Biology or a related field.
5-10 years’ work experience in in bio-industrial, pharma, life sciences or ethanol industry.
Experience with handling and managing fermentation equipment.
Experience with fermentation plant management is a plus.
Proficiency with MS Office suite.

PERSONAL QUALITIES

Creative, out of the box thinker with strong analytical and problem-solving capabilities.
Ability to work independently and deliver on project objectives.
Capacity to be proactive and take initiatives.
Good organizational skills.
Ability to adapt to changing drivers.
Effective interpersonal skills and a team player.
Good communication skills.
Good observation skills for paying attention to details.
Integrity, dependability, and persistence towards task accomplishment.
Innovation, cooperation and willingness to take on new responsibilities.
Strong leadership skills.",4.7,"String Bio
4.7",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Job Description

Smart, collaborative person passionate about technology and is driver to get things done.
Varied experience of using various data mining techniques and data intensive applications
Hands-on experience using Big Data components (Hadoop, Spark) & programming languages.
Experience in using, or migrating to cloud databases
Proficient in relational database design and development
Proficiency and hands-on experience with Big Data technologies

Duties & Responsibilities:
Support the design, and implement data engineering solutions
Design, construct, test and optimize solutions
Work independently as well as in teams to deliver transformative solutions to clients
Manipulate data from database tables (Oracle, Redshift etc.)
Develop ETL modules using ETL tools as well as custom developed applications.

Technical skills:
Strong Experience in Cloud (AWS/Azure/Google Cloud)
Expertise in Distributed Data (Hadoop/Spark/Kafka etc.)
Expertise in Legacy Enterprise Tools (Informatica/ Talend/SSIS)
Expertise in Programming Skills (Python/Java/R/Scala etc.)
Experienced in 2 or more packages, implementing across multiple customers(Oracle/Microsoft SQL Server/IBM DB2/ Postgres/ MySQL/ AWS Redshift/ MongoDB/ CouchDB)
Good to have experience in Data Visualization (Microsoft Power BI/Tableau/Qlik)

Soft Skills:
Excellent English language communication skills, verbal and written
Ability to build strong working relationships.
Ability to facilitate change management with teams.
Experience in the full project delivery life cycles
Good team player",4.2,"Experion
4.2",Thiruvananthapuram,"Trivandrum, India",201 to 500 employees,2006,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
"MTS 2, Data Engineer",-1,"In this role, the individual will be responsible for.
Participating and collaborating with Product Owner/ Cross functional teams in the organization to understand the business requirements and to deliver solutions that can scale.
Creativity and out of the box thinking is required.
Proactively anticipating problems and keeping the team and management informed in a timely manner.
Being flexible and being able to support all functions of product life cycle when required.
Will be acting as tech lead and produce quality deliverable.
Job Requirements

Required Skills:
12+ years of experience in the IT industry, experience in data engineering is Mandatory.
Experience in building enterprise application & platforms for E-commerce biz (offline batch, Near-Real-time streaming and real time sync solutions especially for Big Data Technologies such as Apache Spark, Kafka, Hive, HBase is highly preferred)
Shell/ Perl scripting experience or proficiency in any programming language like Java/C/ C++
Hands on in Java programming
Proficient in Frameworks Spring, Maven, Hibernate
Knowledge Of Real time Analytics
Strong fundamentals of object oriented design, data structures, algorithms and design patterns
Expert in software engineering tools and best practices
Expert in design/implementation for reliability, availability, scalability and performance
Should have strong SQL programming skills
Knowledge of data warehousing concepts
Excellent written and oral communication skills
Desired Skills:
Knowledge in MPP Databases/ Distributed systems
Knowledge on Data Encryption Standards is a huge plus
Exposure to Data Quality and Profiling tools is a plus.
Exposure BI tools desired, but not required (Micro strategy, Business Objects).",3.7,"PayPal
3.7",Chennai,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple"
Lead - Data Scientist,-1,"Job Description
Manage a team of data scientists and big data specialists Lead data mining and collection procedures Ensure data quality and integrity Interpret and analyze data problems Conceive, plan and prioritize data projects Visualize data and create reports

Required Candidate profile

Proven experience as a Data Scientist or similar role. Solid understanding of machine learning A knack for statistical analysis Candidates with notice period of 30 or less than 30days can apply

Perks and Benefits

we can go higher for right fit

Salary: INR 15,00,000 - 30,00,000 PA.

Industry:Medical / Healthcare / Hospitals

Functional Area:IT Software - Application Programming, Maintenance

Role Category:Programming & Design

Role:Software Developer

Desired Candidate Profile
Please refer to the Job description above

Education-

PG:Other

Doctorate:Other Doctorate",3.7,"Consult In India
3.7",Kota,"Stockholm, Sweden",10000+ employees,-1,Company - Public,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Science Trainer,-1,"Should have a strong knowledge on Machine Learning, Deep Learning, R Programming; Python,Statistics,Hadoop etc
Understanding and assessing individual (or) group training requirements.
Execute workshops to create awareness of the latest technologies.
Up to date knowledge of IT skills and software packages.
Designing the Course modules appropriate to the skills needed.
Helping IT Professionals in updating their skills with latest technologies.
Evaluating each and every Individual progress and outcomes.

Job Types: Full-time, Part-time

Salary: ₹300,000.00 - ₹500,000.00 per year

Experience:
total work: 5 years (Preferred)
training: 5 years (Preferred)
Education:
Bachelor's (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.1,"Nacre Software Services Pvt. Ltd
4.1",Telangana,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"What it’s like to work with the world’s fastest-growing Healthcare Technology Company


At Innovaccer, we go beyond the normal. We believe in doing things differently. So don’t expect - old-school cubicles, slow pace, and anything remotely dull.

What you can expect is plenty of support and guidance from your colleagues, freedom to take risks, and opportunities to learn from each other.

The healthcare industry is witnessing a transformational shift and we are committed to helping healthcare work as one. Taking on new challenges head-on and building something that can create a huge impact is a part of our culture.

We love organized chaos. So, if you are looking for a typical 9 to 5 job where you are told what to do, this may not be for you. When you work with Innovaccer, you are your own boss.

Your Role


We are looking for a Senior Data Analyst to help our customers explore their healthcare data, understand how to improve the health of the population and bring down the cost of healthcare

A Day in the Life
Play with and transform data
Work towards creating easy-to-digest analytical reports for US healthcare customers
Design and build interfaces that facilitate workflows between Data Activation Platform and client third party systems as scoped while complying with respective standards and industry best practices
Define and document best practices along with thorough message specifications
Monitor and tune the configuration of interfaces for high availability once deployed in production environments
Understand Innovaccer data warehousing concepts and implement best practices
Work on creating in-house predictive models to forecast medical events

What You Need
3+ years in an analytics role in data services/product firm
Data modeling ability - knowledge of different data modeling concepts
Hands on experience in creating statistical models; Understanding of when to use which model to better fit the data
Strong knowledge of SQL, scripting languages (Groovy/JavaScript/Python)
Exposure to Python Libraries - Numpy, Scipy, Scikit-Learn
Hands on experience with BI tools such as Tableau/Sisense
Self-starter, curious, accountable, enjoys a healthy level of autonomy, strong work ethic, able to succeed in a fast-paced, high-intensity startup environment
Extensive experience relaying technical and non-technical information in a clear and concise manner
Demonstrated expert problem solving and analytical skills
Excellent oral and written communication skills
Excellence in multitasking and managing multiple high-priority customer engagements at once
Ability to assess complex client environments and workflows and arrive at integration solutions that will satisfy seamless experience between our platform and theirs
Ability to mentor junior team members and introduce industry expertise and best practices across integration development
Bachelor’s degree in Engineering, Computer Science. Advanced degree in any of the areas above would be a plus

Preferred Skills
Knowledge of Elasticsearch NoSQL, Tableau/Sisense
Experience in US Healthcare

What We Offer
Industry-focused Certifications: We want you to be a subject matter expert in what you do. So, whether it’s our product or our domain, you will dive straight in and be certified by the best in the world.
Quarterly Rewards and Recognition Programs: We foster learning and encourage people to take moonshots. When you achieve your goals, we recognize and reward your hard work.
Health Benefits: We cover health insurance for you and your loved ones.
Sabbatical Policy: We encourage people to take time off and rejuvenate, upskill and pursue their interests so that they can generate new ideas for innovating at Innovaccer.
Pet-friendly office and open floor plan. No mundane cubicles.


Apply Here


Job Title

Senior Data Analyst


Department

Customer Engineering


Employment Type

Full-time


Location

Noida",3.6,"InnovAccer
3.6",Noida,"San Francisco, CA",501 to 1000 employees,2014,Company - Private,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),Health Catalyst
Research Scientist,-1,"Role Purpose:

To perform the formulation/AI
product chemistry studies and work, as discussed with the Team Leader
T&E, to agreed timelines.
Ensure HSEQ as per site policy
and local Regulation requirements
Maintain Laboratory and
equipment as per GLP requirements.
Support the Study
Director to GLP studies and documentation
Update GLP data in team space
Accountabilities:

Excellent experimental skills i.e., perform and
document analytical and product chemistry work as per GLP
Minimum of 2-4 years’ experience with good technical
knowledge of LC and/or GC, preferably both, in an industrial setup.
Knowledge of method development/Validation of
Chromatographic methods
Good hands on experience on spectroscopic techniques
viz. LCMS, GCMS, NMR etc. with at least 3 years practical experience.
Able to plan and organize his/her work to achieve a
high level of productivity and to meet important deadlines
Maintain Laboratories and assigned Equipment used for
GLP studies and document as per the GLP requirements
Contribute to a product chemistry group and conduct,
under the direction of a study director, studies that fully meet world-wide
regulatory requirements to facilitate registration.
Characterize analytical references and certified
substances to meet development and production schedule requirements
Good understanding of GLP, SOPs and knowledge of
formulation/A.I. Product Chemistry
Ensure HSE and waste disposal as per the site policy
Communicate results and
programs effectively with staff, peers, and customers
Ensure compliance with all company HS&E policies
and GLP. Train junior scientist to enable safe and competent performance.
Knowledge, Skills and
Experience:
PhD degree in Chemistry preferable in analytical or
allied Science, area from the reputed Universities with strong academic records
and good communication skills and sound in instrumentations. with >2 years
of industrial experience preferable worked in GLP facility
Or
Master degree in Chemistry preferable analytical or
allied Science, area from the reputed Universities with strong academic records
and good communication skills with >3 years of industrial experience.
Experience Analytical Chemist with sound GLP experience is
desirable,
Excellent experimental skills
Able to plan and organize work to achieve a high level
of productivity and to meet important deadlines.
IT literate relevant to work
Sound understanding of GLP and knowledge of
formulation/AI Product Chemistry
Good knowledge of written English
Team player, flexible and with people skill
Behaviors:

Team-Oriented
Demonstrates
personal commitment to the team
Values
and uses individual differences and talents
Results-Oriented
Works
tenaciously to deliver agreed goals
Self-disciplined
to achieve results through effective prioritisation and timely delivery
Communicative
Ensures
structure and clarity in both verbal and written messages
Provides
timely communications and feedback to stakeholders",4.0,"Syngenta
4.0",India,"Basel, Switzerland",10000+ employees,2000,Company - Public,Chemical Manufacturing,Manufacturing,₹500+ billion (INR),-1
Data Engineer/Python Spark Developer,-1,"The Applications Development Intermediate Programmer Analyst is an intermediate level position responsible for participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to contribute to applications systems analysis and programming activities. Responsibilities: Utilize knowledge of applications development procedures and concepts, and basic knowledge of other technical areas to identify and define necessary system enhancements, including using script tools and analyzing/interpreting code Consult with users, clients, and other technology groups on issues, and recommend programming solutions, install, and support customer exposure systems Apply fundamental knowledge of programming languages for design specifications. Analyze applications to identify vulnerabilities and security issues, as well as conduct testing and debugging Serve as advisor or coach to new or lower level analysts Identify problems, analyze information, and make evaluative judgements to recommend and implement solutions Resolve issues by identifying and selecting solutions through the applications of acquired technical experience and guided by precedents Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. Qualifications: 2-5 years of relevant experience in the Financial Service industry Intermediate level experience in Applications Development role Consistently demonstrates clear and concise written and verbal communication Demonstrated problem-solving and decision-making skills Ability to work under pressure and manage deadlines or unexpected changes in expectations or requirements Education: Bachelors degree/University degree or equivalent experience This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN ------------------------------------------------------ Time Type :Full time ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.7,"Citi
3.7",Pune,"New York, NY",10000+ employees,1812,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Python for Data Science-Developer,-1,"Pune, India
BE / BTech
1405960
Job Description
Key skills required for the job are: n Python for Data Science-L2, (Mandatory) .As a Senior Developer, you are responsible for development, support, maintenance and implementation of a complex project module. You should have good experience in application of standard software development principles. You should be able to work as an independent team member, capable of applying judgment to plan and execute your tasks. You should have in-depth knowledge of at least one development technology/ programming language. You should be able to respond to technical queries / requests from team members and customers. You should be able to coach, guide and mentor junior members in the team. Minimum work experience: 3 - 5 YEARS

Roles and Responsibilities
Mandatory Skills: Python for Data Science-L2
Experience Range: 3-5 YEARS
We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law. Any complaints or concerns regarding the recruitment, application or hiring process should be directed to our Ombuds group www.wiproombuds.com. Any US applicant can also call our hotline at 1-866-921-6714. Applicants outside the US can request the applicable hotline number via email via the Ombuds group.

Wipro does not charge any fee at any stage of the recruitment process and has not authorized agencies/partners to collect any fee for recruitment. If you encounter any suspicious mail, advertisements or persons who offer jobs at Wipro, please do let us know by contacting us on helpdesk.recruitment@wipro.com",3.6,"Wipro LTD
3.6",Pune,"Bengaluru, India",10000+ employees,1945,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Cognizant Technology Solutions, Tata Consultancy Services, Accenture"
Data Engineering,-1,"Data Engineer

Job Purpose :
Analyzing, designing, developing and managing the infrastructure and the data that feeds Data Science models.
The Data Engineer is expected to be in charge of the whole lifecycle of the datasets, including updates, backups,
synchronization, and policy access.

Job Responsibilities :
Managing the lifecycle (from data collection to archive) of ML/DL datasets and ensure their
usability for Nielsen’s Data Scientists.
Design, build and integrate data from various sources.
Design ETL pipelines with scripted components.
Optimize data workflows, choosing the most cost-efficient approach.
Automate the management of recurrent task in the pipeline.
Perform feasibility studies/analysis with a critical point of view.
Support and maintain (troubleshoot issues with data and applications).
Develop technical documentation for applications, including diagrams and manuals.
Work on many different software challenges always ensuring a combination of simplicity and
maintainability within the code.
Contribute to architectural designs of large complexity and size, potentially involving several distinct
software components.
Working closely with data scientists and a variety of end-users (across different cultures) to ensure
technical compatibility and user satisfaction.
Work as a member of a team, encouraging team building, motivation and cultivate effective team
relations.

Role Requirements :
E=essential, P=preferred.

E - Bachelor's degree in computer engineering.
P - Master’s degree in data engineering or related.
E - Demonstrated experience and knowledge in Big Data and NoSQL databases.
E - Demonstrated experience and knowledge in Object-Oriented Programming.
E - Demonstrated experience and knowledge in distributed systems.
E - Proficient in programming languages: Python.
E - Experience designing and implementing data warehouses.
E - Experience developing ETL pipelines.
E - Experience working with distributed storage systems in the cloud (Azure, GCP or AWS).
P - Experience managing deep learning datasets.
P - Experience managing Cassandra.
P - Experience working with Spark.
P - Experience implementing CICD pipelines for automation.
E - Experience in the use of collaborative developing tools such as Git, Confluence, Jira, etc.
E - Problem-solving capabilities.
E - Strong ability to analyze and synthesize. (Good analytical and logical thinking capability)
E - Proactive attitude, resolutive, used to work in a team and manage deadlines.
E - Ability to learn quickly.
E - Agile methodologies development (SCRUM/KANBAN).
E - Ability to keep fluid communication written and oral in English, both written and spoken.
Experience level: Minimal work experience of 3-4 years with evidence.

To apply for this job please send your resume to connect@blackstraw.ai

Location :
Blackstraw.ai , Chennai, 4th floor, Tower C, Ratha Tek Meadows Rd, Elcot Sez, Sholinganallur, Chennai, Tamil Nadu 600119, India",4.6,"Blackstraw
4.6",Chennai,"Tampa, FL",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Big Data Engineer - Cloudera/ Hortonworks,-1,"Location : Visakhapatnam

Experience : 5-6 years

Notice Period : 30 days

Roles and Responsibilities :
Design & implement new components and various emerging technologies in Hadoop Eco System, and successful execution of various projects.
Integrate external data sources and create data lake/data mart.
Integrate machine learning models on real-time input data stream.
Collaborate with various cross-functional teams: infrastructure, network, database.
Work with various teams to set up new Hadoop users, security and platform governance which should be pci-dss complaint.
Create and executive capacity planning strategy process for the Hadoop platform.
Monitor job performances, file system/disk-space management, cluster & database connectivity, log files, management of backup/security and troubleshooting various user issues.
Design, implement, test and document performance benchmarking strategy for the platform as well for each use cases.
Drive customer communication during critical events and participate/lead various operational improvement initiatives.
Responsible for setup, administration, and monitoring, tuning, optimizing, governing Large Scale
Hadoop Cluster and Hadoop components: On-Premise/Cloud to meet high availability/uptime requirements.? - 2-4 years relevant experience in BIG DATA.
Exposure to Cloudera/Hortonworks production implementations.
Knowledge of Linux and shell scripting is a must.
Sound knowledge on Python or Scala.
Sound knowledge on Spark, HDFS/HIVE/HBASE
Thorough understanding of Hadoop, Spark, and ecosystem components.
Must be proficient with data ingestion tools like sqoop, flume, talend, and Kafka.
Candidates having knowledge on Machine Learning using Spark will be given preference.
Knowledge of Spark & Hadoop is a must.
Knowledge of AWS and Google Cloud Platform and their various components is preferable.",4.7,"innData Analytics
4.7",Visakhapatnam,"Visakhapatnam, India",1 to 50 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"3+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, data warehousing, and building ETL pipelines
Experience in SQL
- 5+ years of experience with and detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures.
- 4+ years of Big data(Hadoop) experience including one programming language JAVA/PYTHON/SCALA
3+ years of experience in architecting data warehouse solutions and integrating technical components
4+ years of experience with relational and star schema data modeling concepts
Experience in MPP systems such as Redshift, Netezza or Teradata.
-Experience in any big data technologies - Hadoop Eco Systems, EMR
3+ years of working with very large data warehousing environment
Demonstrated knowledge and experience in capacity planning for hardware and storage needs
The Finance Automation team at Amazon is looking for a Data Engineer to play a key role in building their industry leading Financial Data Warehouses. If you have experience in building and maintaining very large data warehouses with high transaction volumes then we need you!!!

The Data Engineer should be an expert familiar with all of the new age data engineering technologies (e.g. Distributed computing, MPP systems, Cloud, NoSQL databases, Data Models and atleast one programming language-JAVA/PYTHON/SCALA). The ideal candidate will be responsible for developing overall architecture and high level design. The candidate must have extensive experience with Star Schemas, Dimensional Models, Datamarts in Traditional Data Warehouses as well as in Big Data / Advanced Analytics domains. The individual is expected to bring a methodology and lead the framework development for the next generation data warehouse by designing an efficient, flexible, extensible, and scalable design and mappings and also will be working extensively on building big data environment.

Excellent written and verbal communication skills are required as the candidate will work very closely with a diverse team. The candidate will also lead a small technical teams or participate in close customer interactions while having an influencing role, and be accountable for deliverable's. Ability to create and manage work plans, timelines and accommodate multiple priorities is required.

Job Responsibilities
Tableau Skill is mandatory.
Applies broad knowledge of technology options, technology platforms, design techniques and approaches across the data warehouse life cycle phases to design an integrated, quality solution to address the business requirements
Meets and collaborates with business users on requirements, objectives and measures.
Designs the technology infrastructure across all technical environments
Ensures completeness and compatibility of the technical infrastructure to support system performance, availability and architecture requirements
Designs and plans for the integration for all data engineering components
Supervises the technical implementation of the data warehouse and oversees hardware/ software configuration
Provides input and recommendations on technical issues to the project manager
Reviews technical work of other team members
Reviews and participate in testing of the data design, tool design, data extracts/transforms, networks and hardware selections
Develops the implementation and operation support plans
Experience in PYTHON, BIG DATA and AWS.
Knowledge of Reporting tools such as OBIEE is preferred
Excellent communication skills, both written and verbal
Strong ability to interact, communicate, present and influence within multiple levels of the organization",-1,ADCI HYD 13 SEZ,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
Data Management - Digital Expert,-1,"A candidate for this position must have had at least 3 years of working experience working with business analysis/informatics and business outcomes research within a fast-paced and complex business setting, preferably working as support data scientist junior support personnel.

The candidate will also have experience working in probability and statistics, time-series analysis, or econometrics as well as experience in the use of machine learning methods, for example, linear regression, correlation, statistical significance, and so forth. A candidate for this position will also require strong programming skills and experience working with tools such as SAS, R Programming, Open Source, visualizations, and so forth.

A suitable candidate will also have had experience as well as in-depth knowledge of the Python programming language, SAS Enterprise Miner and substantial knowledge of big data platforms such as Aster and Hadoop.

Communication skills for the Data Scientist, both in written and verbal form are a must have. The Data Scientist will be required to explain advanced statistical content to senior data scientists and relevant stakeholders.

Therefore, he must have the ability to translate and tailor this technical content into business applicable material with clear recommendations and insights relevant to the audience at hand.

These reports and presentations will not only be translations of technical analyses into business applicable material, the reports have to be simple, concise, understandable and convincing, which will require exceptionally good communication skills on the Data Scientist’s part.

A candidate for this position must be technologically adept, demonstrate exceptionally good computer skills, and demonstrate a passion for research, statistics, and data analysis as well as a demonstrated ability and passion for designing and implementing successful data analysis solutions within a business.

The candidate must have a strong understanding of data-mining techniques and an ability to apply these techniques in practical real-world business issues. The Data Scientist will demonstrate an ability to consider data, identify patterns, issues, or data analysis needs for the business. The candidate must also have skills in the workings of SQL and scripting languages such as Python and Perl as well as familiarity with statistical analysis, data visualization, and data cleansing tools and techniques.

about you

Excellent customer service skills
Good leadership skills
Ability to build relationships with peers ,stakeholders and the management
Excellent interpersonal skills
Good time management, organizational and communication skills
Ability to work under pressure and deal with multiple tasks concurrently
Proactive, self-motivated
Problem solving skills
Matrix Management
Excellent knowledge of Service Management tools / processes

additional information

Degree / Diploma Holders with good Telecom / and IT infrastructure (Sever / Cloud / Security etc)
CCNA / ITIL Preferred
Excellent verbal & written communication skills in English
5 – 7 years of work experience, at least 3 years in telecom domain
At least 3 years of hands on experience in Data Science
Hands on experience on Power BI or Tableu Application

department

Customer Services & Operations

contract

Regular",3.9,"Orange
3.9",Mumbai,"Paris, France",10000+ employees,1988,Company - Private,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Vodafone, Deutsche Telekom, Telefónica"
CSII - Item and inventory - Senior Data Scientist,-1,"Our Company

We help people around the world save money and live better -- anytime and anywhere -- in retail stores, online and through their mobile devices. Each week, more than 220 million customers and members visit our 11,096 stores under 69 banners in 27 countries and e-commerce websites in 10 countries. With last fiscal revenues of approximately $486 billion, Walmart employs 2.2 million employees worldwide.

@ Walmart Labs in Chennai, we use technology for the charter of building brand new platforms and services on the latest technology stack to support both our stores and e-commerce businesses worldwide.

Our Team:

CSII Team is responsible for building data driven highly optimized supply chain suite of products to manage entire gamut of supply chain lifecycle for our retail and ecommerce lines of business. With our rapidly increasing footfalls in stores and exponential growth in online orders; this all has to be done to scale millions of owned and marketplace SKUs complete inbound and outbound fulfilment lifecycles.

Teams mission - Enable customers to receive their orders when and where they want in an innovative and cost effective way for Walmart derives from Walmarts mission statement - Save Money. Live Better complementing our organizations philosophy to deliver low prices every day, on everything.

How we achieve this, comes down to the team of smartest technologists from India focused on the entire suite of supply chain management products for the Walmart Supply Chain at a massive scale. From forecasting & replenishing inventory for millions of items worth billions of dollars, sourcing of millions of orders, to route optimization & last mile delivery to Warehouse Management Systems to most advanced grocery & order management systems; technology is the backbone behind the entire platform enabling the massive cloud-scale supply chain from India.

With over 4,000 associates in Silicon Valley, San Diego, Portland, Brazil, United Kingdom and India, were bringing together some of the best professionals from around the world. If youre inspired by the opportunity to solve complex problems at scale and make a difference for our customers and members, join us.

Your Opportunity

Data Science

This position Data Science , will be on the Walmart Labs Supply Chain team, focused on building Walmart's best in class Supply Chain. At Walmart Labs, you will Work with small teams of talented analyst to build a best-in-class supply chain at Walmart. Be given the freedom to try new things and prove the value of your own ideas and innovations and own them all the way to production Identify and facilitate the removal of team impediments and escalate as appropriate Foster a motivating culture of openness, collaboration, and continuous improvement Ensure business needs are being met using Data Science best practices Participate in internal hackathons and innovation challenges!.

Your Responsibility

· Develop interactive statistical models using the latest frameworks.

· Develop Machine learning modelling leveraging existing frameworks and customizing to problem.

· Find workable solution in case of data inconsistency and inconclusive data

· Drive projects with minimal guidance. Provide thought leadership by researching best practices and conducting experiments

· Evaluate various analytical/statistical methods and procedures and provide recommendation of relevance, applicability, efficiency of those to Walmart Catalog teams

· Work with cross functional group consisting of Engineering, Product, Program managers to drive data based decisions

Your Qualifications

· Bachelors degree in computer science or related discipline with 8+ years experience (5+ Relevant)

· Practical experience with SAS, ETL, data processing, database programming and data analytics

· Proficient is Sql and no-sql languages, R, Python

· Worked on gathering data from Cassandra, Kafka, MongoDBs. Work with big data on GCP and Azure.

· Advanced statistical modelling skills

· Handled multi-million records of data. Troubleshooting and fixing data issue

· Data Visualization in any BI tools like Tableau, PowerBI, etc.,

· Collected, analyzed, and reported data to meet customer needs.

· Understanding and application of statistical concepts to solve business problems",3.3,"Walmart
3.3",Chennai,"Bentonville, AR",1001 to 5000 employees,1962,Company - Public,"Department, Clothing, & Shoe Shops",Retail,₹500+ billion (INR),"Target, Costco Wholesale, Amazon"
Data Analyst,-1,"Netomi is a Y-Combinator and VC-backed Artificial Intelligence company that sits at the intersection of two rapidly developing fields: AI and messaging. We do not sell an abstract, futuristic technology - we sell a solution that a large number of Fortune 500 companies are using today to drive engagement and sales across the entire customer journey. By leveraging deep reinforcement learning and our continuously learning neural network, our customers are able to successfully meet their objectives of generating social engagement, driving commerce and providing customer service. We're building the future of how technology and people work together to create frictionless experiences for customers.

Want to have a direct impact in solving the top challenges businesses face today? Join us!

Job Description:

We are looking for a Data Analyst who can help us dig into raw data, analyse it and draw conclusions that help in making business decisions.
Responsibilities
Business Analysis to understand the client's business and work with Data Analysts to define the Deep Learning (DL) model
Quality Assurance of Deep Learning models
Analyze the conversation quality in chatbots
Leverage multiple crowdsourcing strategies to collect training and test data for DL models and help with cleansing, filtering and massaging those data
Providing a high level of data quality awareness across multiple teams
Evaluate and identify where enhancements of data to maintained higher quality data
Detailed testing feedback preparation to help the team to improve the models.
Monitor and improve the Data Quality Assurance process that can meet/exceed the current standards and procedures
Learn and/or leverage the required software tools and technology

Requirements
0-1 years experience in related field
Bachelors degree from a Tier I/Tier II college
Knowledge of any one foreign language - French, Spanish or Russian
Excellent written and verbal communication skills
An eye for detail and accuracy",4.8,"Netomi
4.8",Gurgaon,"San Francisco, CA",51 to 200 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"HP is the world’s leading personal systems and printing company, we create technology that makes life better for everyone, everywhere. Our innovation springs from a team of individuals, each collaborating and contributing their own perspectives, knowledge, and experience to advance the way the world works and lives.

We are looking for visionaries, like you, who are ready to make a purposeful impact on the way the world works.

At HP, the future is yours to create!

We are Pricing Analytics Team; our main objective is to help the business to decide optimal price for the HP products in a scientific way through statistical and predictive analysis.

If you are our Data Engineer in India, you will get an opportunity to work on below.

Designs and establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data pipelines, repositories or models for structured data.
Analyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.
Writes and executes complete pipeline plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs and creates solutions for issues with data sources and integration into data system architecture.
Collaborates and communicates with project team regarding project progress and issue resolution. Represents the data engineering team for all phases of larger and more-complex development projects. Provides guidance and mentoring to less experienced staff members.

Are you a high-performer? We are looking for an individual with.

Well versed knowledge on SQL servers and database solutions.
Python programming language to create efficient data flow
Various operating systems like Linux, windows, Unix which will enable data interconnection Data warehousing and ETL tools Good to have.
Knowledge on R and visualization tools such as Power BI / Tableau/ R Shiny Data architecture skills to create effective data flow Team player to interact and understand the data based on data scientists and analysts
#LI-Post",3.3,"HP
3.3",Bengaluru,"Houston, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"The Role: Senior Data Analyst

The Location: Mumbai

The Grade: 11

The Team: The Global Data Management team within the Global Index Management & Production Group.

The Impact: The Senior Data Analyst is responsible for the acquisition, management and quality of a variety of data items used for the production and maintenance of S&P Dow Jones-branded indices.

The successful candidate will be expected to set the standard in carrying out tasks associated with the management of data used for the production and maintenance of indices, setting an example for more junior analysts to follow.

Additionally, the Senior Data Analyst is responsible for a wide range of data points across global markets and may be required to make presentations to Index Committees on matters impacting the maintenance and particularly the rebalancing of S&P DJI global indices, making in-depth knowledge of their product line essential.

Whats in it for you: As a Senior Data Analyst, you will work collaboratively with a wide range of data points, indices and other products across global markets. You must be able to analyze and implement complex data processes and calculation methodology and solve non-routine problems on an on-going basis.

Responsibilities:

The Senior Data Analyst will be a subject matter expert, an example and escalation point for more junior team members and will support the team leader.

In addition, the Senior Data Analyst will be required to:
Demonstrate organizational skills by ensuring that processes for the capture, quality screen and presentation of data sets are completed in time for their delivery to end clients or use in the further calculation or rebalancing of indices
Preparing and calculating fundamental ratios for S&P and Dow Jones branded indices, ensuring timely and accurate delivery of index data to clients and end users
Develop a detailed understanding of the way each data set is used in the production and maintenance of S&P Dow Jones Indices, ensuring the Senior Data Analyst is able to identify and resolve issues and ensure the data is fit for purpose
Serve on index committees and make presentations of original, non-routine analysis to committee in support of the data items for which the Senior Data Analyst is responsible. Decisions reached by committee determine index composition and drive asset allocations.
Take responsibility for the management of high profile data sets, acting as an industry expert and displaying in-depth knowledge of our product lines.
Provide timely and accurate responses to enquiries from internal groups and external clients, through our client services team
Manage and maintain key relationships with other groups within the department and across other departments, particularly Product Management, Client Coverage, Index Services and IT Support
Work in close coordination with the technology group and production support group to further enhance our system capabilities
Qualifications:
A demonstrable, deep understanding of global financial markets and financial data, particularly company fundamentals
Familiarity with Environmental, Social and Governance (ESG) themes in finance and particularly ESG data providers would be considered an advantage
Must be able to work independently on multiple projects with minimal direction or supervision.
Ability to assume responsibility, work with others and manage projects
Bachelors Degree. Advanced degree in business, math, economics, or finance strongly preferred
Minimum of 4 years of professional experience working with financial indices.
Strong understanding of how indices are used, the impact of different methodologies, corporate event events on both indices and financial portfolios.
Superior computer skills in Excel, Word and related applications. Access, VBA, SQL and/or Python would be an advantage.
Ability to learn S&Ps proprietary index calculation systems and requirements
Excellent analytical and numerical capabilities to aid in solving non-routine problems in a timely fashion
About us:

At S&P Dow Jones Indices, our role can be described in one word: essential. Were the largest global resource for index-based concepts, data and research, and home to iconic financial market indicators, such as the S&P 500® and the Dow Jones Industrial Average®. More assets are invested in products based upon our indices than any other index provider in the world; with over 1,000,000 indices, S&P Dow Jones Indices defines the way people measure and trade the markets. We provide essential intelligence that helps investors identify and capitalize on global opportunities.

S&P Dow Jones Indices is a division of S&P Global (NYSE: SPGI), which provides essential intelligence for individuals, companies and governments to make decisions with confidence. For more information, visit www.spdji.com.",3.7,"S&P DOW JONES INDICES
3.7",Mumbai,"New York, NY",201 to 500 employees,-1,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,-1
Data Analyst,-1,"Have Accounting background.
Data analysis of the records
Good Communication
Excellent Excel Knowledge
Job Type: Full-time
Salary: ₹240,000.00 - ₹480,000.00 per year
Experience:
work: 3 years (Preferred)
total work: 3 years (Preferred)
Education:
Master's (Preferred)
Work Remotely:
No",3.3,"Express Roadways Pvt Ltd
3.3",Hisar,"Mumbai, India",5001 to 10000 employees,-1,Company - Public,Transportation Management,Transportation & Logistics,Unknown / Non-Applicable,-1
Sr. Data Analyst,-1,"1. Hands-on professional with in-depth knowledge and High level of Proficiency in Qlikview scripting.
2. Use of complex QlikView functions, advance Qlikview expressions.
Knowledge of Qlikview scripting features such as Resident Tables,loops and other advanced scripting fuctions.
3.Hands on experience with complex data models.
4.Understanding of BI/data warehouse concepts, Star schema/snowflake models, SCDs, fact and dimension tables, SQL etc.
5. Good Knowledge of Python especially in packages Pandas and numpy.
5.Must have written SQL queries for extracting data for varied complex scenarios with an exposure to big data environment.
6.Have practical experience using the windowing and analytic functions in SQl.
7.Good knowledge of Excel functions including index,match,array and other advanced functions in excel.
8. Candidate must have strong problem solving, logical and analytical skills.

What You Need for this Position

You should have knowledge of:
QlikView functions
advance Qlikview expressions
BI/data warehouse concepts
Star schema/snowflake models
SCDs
fact
SQL
Aditional
No. of Positions
Education level
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
HIVE Data Engineer- Bangalore,-1,"Description

6sense is a Predictive Intelligence Engine that is reimagining how B2B companies do sales and marketing. It works with big data at scale, advanced machine learning and predictive modeling to find buyers and predict what they will purchase, when and how much.

6sense helps B2B marketing and sales organizations fully understand the complex ABM buyer journey. By combining intent signals from every channel with the industry's most advanced AI predictive capabilities, it is finally possible to predict account demand and optimize demand generation in an ABM world. Equipped with the power of AI and the 6sense Demand Platform™, marketing and sales professionals can uncover, prioritize and engage buyers to drive more revenue.

6sense is seeking a Data Engineer to become part of a team designing, developing, and deploying its customer centric applications.

A Data Engineer at 6sense will have the opportunity to
Create, validate and maintain optimal data pipelines, assemble large, complex data sets that meet functional / non-functional business requirements.
Improving our current data pipelines i.e. improve their performance, remove redundancy, and figure out a way to test before v/s after to roll out.
Debug any issues that arise from data pipelines especially performance issues.
Experiment with new tools and new versions of hive/presto etc. etc.
Required qualifications and must have skills
BE/BTech/BS or equivalent
Excellent analytical and problem-solving skills
6+ years work experience showing growth as a Data Engineer.
Strong hands-on experience with Big Data Platforms like Hadoop / Hive / Spark / Presto
Experience with writing Hive / Presto UDFs in Java
String experience in writing complex, optimized SQL queries across large data sets
Experience with optimizing queries and underlying storage
Comfortable with Unix / Linux command line
Nice to have Skills
Used Key Value stores or noSQL databases
Good understanding of docker and container platforms like Mesos and Kubernetes
Security-first architecture approach
Application benchmarking and optimization
Interpersonal Attributes
You can work independently as well as part of a team
You take ownership of projects and drive them to conclusion
You're a good communicator and are capable of not just doing the work, but teaching others and explaining the ""why"" behind complicated technical decisions
You aren't afraid to roll up your sleeves: This role will evolve over time, and we'll want you to evolve with it!",5.0,"6sense
5.0",Bengaluru,"San Francisco, CA",51 to 200 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Science Online Trainer,-1,"Job Id : PTPL/HR/8

Anywhere in India

1+ year experience in Data Science. Must have worked on minimum 2 Data Science Projects and must have at least 50 hours experience in online training on Data Science topics.",3.5,"Prognoz
3.5",India,"Perm, Russia",1001 to 5000 employees,-1,Company - Private,Research & Development,Business Services,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Company Description

Cermati is a financial technology (fintech) startup based in Indonesia. Cermati simplifies the process of finding and applying for financial product by bringing everything online so people can shop around for financial products online and can apply online without having to physically visit a bank.

Our team hailed from Silicon Valley Tech companies such as Google, Microsoft, LinkedIn and Sofi as well as Indonesian startups such as Doku, Touchten. We have graduates from well known universities such as Universitas Indonesia, ITB, Stanford, University of Washington, Cornell and many others. We are building a company with the same culture of openness, transparency, drive and meritocracy as Silicon Valley companies. Join us in our cause to build a world class fintech company in Indonesia.

Job Description

The candidate should be able to design high performance, maintainable, extensible software architectures to solve abstract business problems. Here are some example business problems:
""We want to reduce the time for productionizing experimental machine learning features to 1 day""

""We want to completely automate the credit approval process while maintaining an accuracy of >90% when compared with manual approval""

They should be able to translate the high level design into a series of tasks that can be executed by other software engineers working in parallel

The high level designs are usually design documents consisting of relevant block diagrams, UML diagrams meant to be consumed by other engineering leaders and software engineers

They must be able to work with international teams effectively. They will be required to communicate with:
- Clients who may not necessarily be software engineers (marketing teams, business development team etc)
- Software engineers and tech leads to communicate the design in a simple yet accurate language without compromising details.
They would be leading a team of talented but possibly inexperienced engineers who will look to you for mentorship. In a typical day, candidates would be spending
10% of the time project management, 20% of the time doing code review and mentorship, 20% of the time coding (evaluating technologies, doing PoC, etc) 50% of the time requirement gathering, high level design, low level design, roadmap etc

The following technical skills would be useful:
Candidates must be able to understand the tradeoff between performance, simplicity, maintainability and timeline constraints when developing software solutions
Strong hands on experience in java, python is required. Must have shipped multiple projects with a major hands on contribution to each project.
Experience in Big data technologies: hadoop ecosystem (mapreduce, spark, kafka)
Experience in different storage technologies: OLTP like postgres, OLAP like redshift, Google bigquery, NoSQl like redis, hbase, kafka
Familiarity with machine learning algorithms and concepts (gradient descent, logistic regression) and software libraries like pandas, tensorflow, etc
Qualifications

The following technical skills would be useful:
Candidates must be able to understand the tradeoff between performance, simplicity, maintainability and timeline constraints when developing software solutions
Strong hands on experience in java, python is required. Must have shipped multiple projects with a major hands on contribution to each project.
Experience in Big data technologies: hadoop ecosystem (mapreduce, spark, kafka)
Experience in different storage technologies: OLTP like postgres, OLAP like redshift, Google bigquery, NoSQl like redis, hbase, kafka
Familiarity with machine learning algorithms and concepts (gradient descent, logistic regression) and software libraries like pandas, tensorflow, etc
Additional Information

Impressive Benefits and flexible work culture.",4.2,"Cermati.com
4.2",Bengaluru,"Jakarta, Indonesia",1 to 50 employees,-1,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
CIEL/SEL/13651: Data Scientist,-1,"Job Description
Key points about the position are as below;
Hadoop - working knowledge

PL SQL
Python or R
Inferential Statistics
ML - must have implemented at least one algorithm
Visualisation - Tableau preferred, BI, Spotfire
Service Delivery, communication skills
Statistical education background
Production model experience using ML with any algorithm. Worked on real time projects

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
Data Engineer,-1,"Job Type: Full time Experience: 2+ years Hyderabad

Job Description:
We are looking for a savvy Data Engineer to join our growing team. We work with fortune 500 companies to build their data infrastructure and help them with their data journey. The Data Engineer will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing the data flow. The Data Engineer will help generate data pipelines and subsequently with DataOps. He/ She must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.

Qualifications:
2+ years of experience in building data pipelines.
Experience building data pipelines using StreamSets or Azure Data Factory.
Understanding of stream processing with knowledge on Kafka.
Experience with scripting languages i.e. Python, Perl, etc.
Experience with SQL (RDBMS), NoSQL (MongoDB), and PostgreSQL.
Understanding of data flows, data architecture, ETL and processing of structured and unstructured data.
Current experience developing and deploying applications to a public cloud (AWS, GCE).
Experience with DevOps tools (GitHub, Jira) and methodologies (Lean, Agile, Scrum).
Experience with ETL, Data Modeling, and working with large-scale datasets. Extremely proficient in writing performant SQL working with large data volumes.
Experience on Azure DevOps is a plus.
Ability to manage competing priorities simultaneously and drive projects to completion.

Desired Candidate Profile:
Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Engineering).
Excellent written and verbal communication skills in English.
Experience in working in agile (SCRUM) methodology.",4.0,"Modak Analytics
4.0",Hyderabad,"Hyderabad, India",201 to 500 employees,2010,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst (NLP),-1,"Department: Analytics

Experience: 3-5 Years

Location: Chennai

Job Description
Should have experience in developing efficient code in R / Python
Sound have understanding of statistical concepts behind data modelling
Experience in training and deploying models based on Stanford Core NLP.
Experience with machine learning, preferably one or more among Tensorflow, Theano, Deeplearning4J, Torch
Experience developing backend systems involving NoSQL databases and Graph Databases
Experience and familiarity with the concepts of threading, concurrent execution methodologies including monads
Familiarity with text-to-speech
Familiarity with modern speech recognition engine technology. LVCSR, HMMs, DNNs.
Familiarity and experience with open-source/commercial NLP toolkits such as Stanford NLP, NLTK, Tensorflow, Apache Lucene/Solr, GATE
Knowledge of techniques for critical problem/application areas in NLP such as Named Entity Extraction, PoS tagging, parsing, semantic analysis, ambiguity resolution, pronoun resolution, sentiment analysis, summarization
Sound understanding behind machine learning algorithms like SVM, KNN, Decision tree etc.
NLP analyst to work with Clients and Senior analyst / SME to bring insights using AI/ML/NLS techniques.
Conduct all job functions and responsibilities in accordance with all company Compliance, Information Security and Regulatory policies, procedures and programs.",3.1,"SCIO Health Analytics
3.1",Chennai,"West Hartford, CT",501 to 1000 employees,2007,Company - Private,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),-1
Computer Vision - Data Scientist,-1,"Arya.ai is looking for ambitious and talented computer vision researchers with strong skills in software development to join our research team. If you get excited by the prospect of analyzing and modelling terabytes of data and creating state-of-the-art algorithms to solve real-world problems and by owning business problems/metrics, then we have the perfect role for you. Here you will have the ability to thrive in a dynamic environment combining conceptual and applied research, systems building and collaborative work. You will work together with similar minds in a unique development team where your skills and expertise will be put to the test.

*
Major responsibilities:
*
Research, design, implement and evaluate novel computer vision algorithms

- Work on large-scale datasets, focusing on creating scalable and accurate computer vision systems in versatile application fields

- Collaborate closely with team members on developing systems from prototyping to production level

- Able to derive model’s risk towards business and communicate with corresponding business managers

- Track general business activity and provide clear, compelling management reports on a regular basis
*
Qualifications Required:
*
Hands-on experience in Computer Vision and Deep Learning

- Broad knowledge of fundamentals and state-of-the-art in computer vision

- High proficiency in C/C++ or Python

- Ability to develop large-scale systems working with image/video data

- Strong working knowledge of software architecture and data structure

- Excellent problem-solving ability

- Minimum of 2-year experience in Deep Learning(CNNs, RNNs, Attention-based Networks, etc)

- Minimum of 2-year experience in Computer Vision (Image/Video Processing)
Job Type: Full-time",3.5,"Arya.ai
3.5",Mumbai,"Mumbai, India",1 to 50 employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"Start : Immediate
Must Have Technical expertise
Strong Experience with SQL, T-SQL
Strong Experience with Power BI
Experience with data extraction, cleansing and loading into a database using integration tools such as Talend or using Microsoft tools or Python data wrangling libraries
Ability to understand a problem and produce technical solutions
Good to Have Technical experience
Azure Cosmos DB NoSQL
Azure Synapse Analytics
Python Data Science Libraries
Good to Have Functional experience
Supply Chain or Manufacturing
Finance
Experience: 4+ years, 6+ years
Job Type: Full-time
Experience:
Power BI: 4 years (Preferred)
Talend: 3 years (Preferred)
SQL, T-SQL: 4 years (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Work Remotely:
Yes",2.0,"Aavid Software
2.0",Pune,"Pune, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Hands on experience working with Cloud Platform - Preferred AWS
Good experience working with ETL Tools - Cloud based (AWS) + Others (Talend)
AWS Services - S3, Redshift, Athena, Glue, DMS, Lambda. Good to have knowledge about AWS Infra
Hands on working with any RDBMS & NoSQL DBs.
Good understanding of DB Concepts & SQL Queries. PL/SQL, Stored Procedures, Optimization & Performance Tuning
Experienced in Data Migration
Experience working with Spark, Hadoop, HDFS, Scala
Good To have big data knowledge
Knowledge of Data Visualization Tools (like Tableau)
Knowledge working with Data-warehouses (Cloud based)
Good understanding & working experience in any programming language
Good to have experience working in Python
00-5.00 Years",3.5,"Unitforce Technologies Consulting Pvt Ltd
3.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
"Data Engineer Oracle, ETL for NFRM IT",-1,"Job Description:


Position Overview

Role Description:

The Oracle developer will be responsible for developing, enhancing and maintaining applications in the Non Financial Risk (NFR) domain. The activities shall be performed in accordance with the defined tools/technologies of the project , shall adhere to the standards and processes followed in the organization & project. Additionally, the developer will be a partner to the development and Level 2 support organizations and shall work on any issues in the production environment for which the Development’s team help is required.

Tasks |Responsibilities:
Develop a good understanding of the activities required to execute the development/bug fix activity.
Actively participate and contribute in Agile ceremonies including Daily Stand up’s, Sprint Planning, Sprint review, Sprint retrospective meetings
Take part in software and architectural design activities
Perform analysis, development, testing and debugging/defect fixing for the assigned stories/bug fixes
Develop the required functionalities using the appropriate database technologies
Write unit tests for the developed code.
Recommend changes to improve established application processes.
Integration of changes with other user stories developed by team members
Deployment in Development/integration/UAT environments
Create required documentation for the project.
Meet the SLA’s for any assigned defects.
Development and delivery KPI’s shall be met.
Shall be ready to learn new technologies as per the project requirements.
Experience | Knowledge
10+ years combined experience as software developer. Well aware of the Agile methodology.
Hands on experience in SQL and relational databases, preferably Oracle 10G and higher
Experience with database migration, database upgrade activities
Experience with performance tuning, indexing, partitioning
Experience using the Git version control system, Jenkins, Nexus and Sonar.
Proficient in Linux/Unix system.
Experience working with high availability and high performance systems.
Should be aware of the release/deployment and application support processes (Incident/problem/change management etc.)
Basic knowledge of Oracle database management system
Experience using atleast one ETL tool
Experience in datawarehousing
Good to have experience with BI tools like SAP Buiness Objects or Cognos reporting
Good to have experience with big data technologies
Education | Certification

Bachelor degree from an accredited college or university with a concentration in an IT related discipline

Our values define the working environment we strive to create – diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer.

We promote good working relationships and encourage high standards of conduct and work performance. We welcome applications from talented people from all cultures, countries, races, genders, sexual orientations, disabilities, beliefs and generations and are committed to providing a working environment free from harassment, discrimination and retaliation.

Click here to find out more about our diversity and inclusion policy and initiatives.",3.5,"Deutsche Bank
3.5",Pune,"Frankfurt am Main, Germany",10000+ employees,1870,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),-1
Data Science Engineer - Start Up Software Company Baner,-1,"Responsibilities:
Design and build highly scalable nlp pipelines
Design and write custom algorithms to solve domain specific problems
Build POCs using open-source libraries for independent modules
Create AI solutions for automated dialogue (chat bots); natural texting for knowledge & expertise recommendations.
Build & train NLP platform from user generated textual data (email, IM, search logs) on daily basis
Code ML models primarily using python, No-Sql & AWS
Collaborate with other team members and stakeholders.

Requirements:
5+ years experience in web-app development, with minimum 2+ years of NLP experience .
Proficiency in Data Structures & Algorithms .
Experience with open-source NLP libraries such as spacy, NLTK
Experience with MySQL, Mongo-DB & Neo4j
Experience with Word2Vec, Glove, RNN, LSTM
Experience with Data Pipeline Frameworks such as AWS Data Pipeline
00-7.00 Years
Masters in Technology (M.Tech/M.E/M.Sc), Master in Computer Application (M.C.A), Bachelor Of Technology (B.Tech/B.E)",5.0,"Seventh Contact Hiring Solutions
5.0",Pune,"Pune, India",1 to 50 employees,-1,Private Practice / Firm,-1,-1,Unknown / Non-Applicable,-1
ANALYST-DATA SCIENCE-PYTHON,-1,"Apply machine learning techniques to deliver actionable insights from large-scale, multi-structured datasets. Work with internal and external teams to develop models (ranging from data exploration to feature engineering and model development to validation and scoring.) and put them into production This is an individual contributor profile wherein the candidate is required to work in collaboration with the AMs and DMs Machine Learning techniques (recommendation engines, ensemble models such as random forests, bagging and boosting, support vector machines, dynamic optimization etc.) Design and build systems that mine massive datasets and structure/ engineer it to be usable for machine learning models
Salary Negotiable
Industry IT Software
SubIndustry Software Development
Functional Area IT Software Development
Specialization IT/Technical Content Developer
Role Manager / Sr. Manager Level
Keyskills
NLPText MiningMachine Learning
Desired Candidate Profile
Please refer on JD
Education
Highest Qualification
Graduation Any Graduate",5.0,"Fine Jobs
5.0",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Digital - Associate Program Manager - Analytics Consultant,-1,"SKILLS REQUIRED:
Advanced Analytics, Predictive Analytics",3.4,"eClerx
3.4",Mumbai,"Mumbai, India",5001 to 10000 employees,2000,Company - Public,Consulting,Business Services,₹10 to ₹50 billion (INR),"Genpact, WNS, Convergys"
"ES Tech, Data Engineer",-1,"Do you love data as much as we do? Do you want to influence at Amazon? We have the career for you!

Amazon's Employee Services Technology (ES Tech) team is seeking an outstanding ETL/Data Engineer to join our BI team to build out the BI platform with all of the data ingestion mechanisms required for the initiative. Our platform delivers business intelligence to a diverse, global community of internal customers from one of the worlds largest and most complex financial data sets. Amazon has culture of data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable.

You will be responsible for designing and implementing solutions using third-party technology and Amazon cloud technologies. A successful candidate knows and loves working with business intelligence ETL tools, is comfortable accessing and working with big data from multiple sources, and passionately partners with the business to identify strategic opportunities and deliver results. You should have an internal drive to answer why? questions, excellent analytical abilities, strong technical skills, as well as superior written and verbal communication skills. S/he would be a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail), and enjoy working in a fast-paced dynamic environment.

Responsibilities include:
· Drive the collection of new data and the refinement of existing data sources to continually improve data quality
· Support data analysts and product managers by turning business requirements into functional specifications and then executing ETL delivery
· Lead the technical lifecycle of data presentation from data sourcing to transforming into user-facing metrics





Basic Qualifications

· Bachelors or Masters Degree in Computer Science, Systems Analysis, or related field
· 3+ years experience in data modeling, ETL development, and Data Warehousing
· 1+ years experience with BI/DW/ETL projects.
· Knowledge of AWS product suite including S3, Redshift, Dynamo DB and RDS.
· Experience in scripts like Python, Java, javascript etc.
· Technical guru; SQL expert.
· Experience with Linux, UNIX, UNIX tools
· Experience writing software to automate manual workflows
· Good instincts; you know what it means to be a subject matter expert and how to be a team player



Preferred Qualifications


Strong background in data relationships, modeling, and mining.
Mulesoft experience a plus.




Amazon is an Equal Opportunity Employer",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Analyst,-1,"Responsibilites :
Backgrounds in technology, information management, relational database design and development, business intelligence, data mining or statistics.
Solid understand of data analysis techniques or processes will help reduce the need for you to learn every data analysis tool in the market
Experinece in importing, cleaning, transforming, validating or modeling data with the purpose of understanding or making conclusions from the data for decision making purposes.
Experinece in Performing audit on data and resolve business related issues for customer base
Experinece in Performing data analysis and facilitate in delivery to all end users.
Explorering sift through mountains of data to discover the data you actually need

Send us the Resume at info@zettamine.com",3.8,"ZettaMine
3.8",Hyderabad,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Big Data Engineer,-1,"Data Engineer

About Print Analytics

As part of the HP Inc. R&D Centre, Print Analytics Team work closely with Print GBU of HP Inc. across multiple domains. We deploy data products and analytics assets, provide data-driven actionable insights to influence business decisions.

Within Print Analytics, Supplies Analytics Team seeks to deploy data products through designing table structures and data flows, automating repetitive data tasks, building and maintaining data dictionaries, finding/resolving data anomalies and data errors. This would, in turn, result in delivering complex analysis and improving intelligence.

Business Environment

Supplies Analytics Team strategically partners with Big Data Business Transformation organization to deploy data products and deliver analytics to help them discover new opportunities and solve their business challenges in a data driven manner.

Role Description:

In order to deploy data products, we are looking for a high caliber and detail-oriented Data Engineer who can work in collaboration with cross-functional, cross-regional teams to establish and improve data pipelines. She / He will also be responsible for designing table structures and data flows, automating repetitive data tasks, building and maintaining data dictionaries, finding/resolving data anomalies and data errors. This would, in turn, enable downstream data analyses and AI/ML models.

The analyst would act as an informed team member who can help bridge technical data requirements.

Responsibilities:
Establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data platform, repositories or models for structured/unstructured data.
Analyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.
Writes and executes complete testing plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs, and creates solutions for issues with code and integration into data system architecture.
Collaborates and communicates with project team regarding project progress and issue resolution.
Works with the data engineering team for all phases of larger and more-complex development projects and engages with external users on business and technical requirements.
Collaborates with peers, engineers, data scientists and project team.
Typically interacts with high-level Individual Contributors, Managers and Program Teams on a daily/weekly basis.
Defines and leads portions of project requirements for data exchanges and business requirements with externals and internal teams
Creates plans, data collection and analysis procedures and works with data insight visualization teams for assigned projects.
Collaborates with internal and external partners to perform experiments and validations in accordance with overall plan.
Collaborates with SMEs to develop procedures for collecting, recording, analyzing, and communicating data for review and feedback.
Education and Experience Required:
Bachelor's or Master's degree in Computer Science, Information Systems, Engineering or equivalent.
4-6 years experience in a data analyst or data engineering type role.
Knowledge & Skills:
Using data engineering tools, languages, frameworks to mine, cleanse and explore data.
Fluent in relational based systems and writing complex SQL.
Fluent in programming and automating repetitive tasks preferably using VBA and Python
Fluent in complex, distributed and massively parallel systems.
Strong analytical and problem-solving skills with ability to represent complex algorithms in software.
Designing data systems/solutions to manage complex data.
Strong understanding of database technologies and management systems.
Strong understanding of cloud-based systems/services, including the AWS environment.
Database architecture testing methodology, including execution of test plans, debugging, and testing scripts and tools.
Ability to effectively communicate product architectures, design proposals and negotiate options at management levels.
Using scientific design and data collection methodologies, tools and analysis packages to collect, validate, and analyze research data.
Excellent written and verbal communication skills
Strong interpersonal skills and ability to work in a collaborative environment",4.1,"HP Inc.
4.1",Bengaluru,"Palo Alto, CA",10000+ employees,1939,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Science Trainer,-1,"Should have a strong knowledge on Machine Learning, Deep Learning, R Programming; Python,Statistics,Hadoop etc
Understanding and assessing individual (or) group training requirements.
Execute workshops to create awareness of the latest technologies.
Up to date knowledge of IT skills and software packages.
Designing the Course modules appropriate to the skills needed.
Helping IT Professionals in updating their skills with latest technologies.
Evaluating each and every Individual progress and outcomes.

Job Types: Full-time, Part-time

Salary: ₹300,000.00 - ₹500,000.00 per year

Experience:
total work: 5 years (Preferred)
Training: 5 years (Preferred)
Education:
Bachelor's (Preferred)
Location:
Ameerpet, Hyderabad, Telangana (Preferred)
Work Remotely:
Temporarily due to COVID-19",3.7,"Naresh I Technologies
3.7",Telangana,"Hyderābād, India",51 to 200 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Research Scientist,-1,"Role Purpose:

To perform the formulation/AI
product chemistry studies and work, as discussed with the Team Leader
T&E, to agreed timelines.
Ensure HSEQ as per site policy
and local Regulation requirements
Maintain Laboratory and
equipment as per GLP requirements.
Support the Study
Director to GLP studies and documentation
Update GLP data in team space
Accountabilities:

Excellent experimental skills i.e., perform and
document analytical and product chemistry work as per GLP
Minimum of 2-4 years’ experience with good technical
knowledge of LC and/or GC, preferably both, in an industrial setup.
Knowledge of method development/Validation of
Chromatographic methods
Good hands on experience on spectroscopic techniques
viz. LCMS, GCMS, NMR etc. with at least 3 years practical experience.
Able to plan and organize his/her work to achieve a
high level of productivity and to meet important deadlines
Maintain Laboratories and assigned Equipment used for
GLP studies and document as per the GLP requirements
Contribute to a product chemistry group and conduct,
under the direction of a study director, studies that fully meet world-wide
regulatory requirements to facilitate registration.
Characterize analytical references and certified
substances to meet development and production schedule requirements
Good understanding of GLP, SOPs and knowledge of
formulation/A.I. Product Chemistry
Ensure HSE and waste disposal as per the site policy
Communicate results and
programs effectively with staff, peers, and customers
Ensure compliance with all company HS&E policies
and GLP. Train junior scientist to enable safe and competent performance.
Knowledge, Skills and
Experience:
PhD degree in Chemistry preferable in analytical or
allied Science, area from the reputed Universities with strong academic records
and good communication skills and sound in instrumentations. with >2 years
of industrial experience preferable worked in GLP facility
Or
Master degree in Chemistry preferable analytical or
allied Science, area from the reputed Universities with strong academic records
and good communication skills with >3 years of industrial experience.
Experience Analytical Chemist with sound GLP experience is
desirable,
Excellent experimental skills
Able to plan and organize work to achieve a high level
of productivity and to meet important deadlines.
IT literate relevant to work
Sound understanding of GLP and knowledge of
formulation/AI Product Chemistry
Good knowledge of written English
Team player, flexible and with people skill
Behaviors:

Team-Oriented
Demonstrates
personal commitment to the team
Values
and uses individual differences and talents
Results-Oriented
Works
tenaciously to deliver agreed goals
Self-disciplined
to achieve results through effective prioritisation and timely delivery
Communicative
Ensures
structure and clarity in both verbal and written messages
Provides
timely communications and feedback to stakeholders",4.0,"Syngenta
4.0",India,"Basel, Switzerland",10000+ employees,2000,Company - Public,Chemical Manufacturing,Manufacturing,₹500+ billion (INR),-1
Data Engineer/Python Spark Developer,-1,"The Applications Development Intermediate Programmer Analyst is an intermediate level position responsible for participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to contribute to applications systems analysis and programming activities. Responsibilities: Utilize knowledge of applications development procedures and concepts, and basic knowledge of other technical areas to identify and define necessary system enhancements, including using script tools and analyzing/interpreting code Consult with users, clients, and other technology groups on issues, and recommend programming solutions, install, and support customer exposure systems Apply fundamental knowledge of programming languages for design specifications. Analyze applications to identify vulnerabilities and security issues, as well as conduct testing and debugging Serve as advisor or coach to new or lower level analysts Identify problems, analyze information, and make evaluative judgements to recommend and implement solutions Resolve issues by identifying and selecting solutions through the applications of acquired technical experience and guided by precedents Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. Qualifications: 2-5 years of relevant experience in the Financial Service industry Intermediate level experience in Applications Development role Consistently demonstrates clear and concise written and verbal communication Demonstrated problem-solving and decision-making skills Ability to work under pressure and manage deadlines or unexpected changes in expectations or requirements Education: Bachelors degree/University degree or equivalent experience This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN ------------------------------------------------------ Time Type :Full time ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.7,"Citi
3.7",Pune,"New York, NY",10000+ employees,1812,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Python for Data Science-Developer,-1,"Pune, India
BE / BTech
1405960
Job Description
Key skills required for the job are: n Python for Data Science-L2, (Mandatory) .As a Senior Developer, you are responsible for development, support, maintenance and implementation of a complex project module. You should have good experience in application of standard software development principles. You should be able to work as an independent team member, capable of applying judgment to plan and execute your tasks. You should have in-depth knowledge of at least one development technology/ programming language. You should be able to respond to technical queries / requests from team members and customers. You should be able to coach, guide and mentor junior members in the team. Minimum work experience: 3 - 5 YEARS

Roles and Responsibilities
Mandatory Skills: Python for Data Science-L2
Experience Range: 3-5 YEARS
We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law. Any complaints or concerns regarding the recruitment, application or hiring process should be directed to our Ombuds group www.wiproombuds.com. Any US applicant can also call our hotline at 1-866-921-6714. Applicants outside the US can request the applicable hotline number via email via the Ombuds group.

Wipro does not charge any fee at any stage of the recruitment process and has not authorized agencies/partners to collect any fee for recruitment. If you encounter any suspicious mail, advertisements or persons who offer jobs at Wipro, please do let us know by contacting us on helpdesk.recruitment@wipro.com",3.6,"Wipro LTD
3.6",Pune,"Bengaluru, India",10000+ employees,1945,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Cognizant Technology Solutions, Tata Consultancy Services, Accenture"
Data Engineering,-1,"Data Engineer

Job Purpose :
Analyzing, designing, developing and managing the infrastructure and the data that feeds Data Science models.
The Data Engineer is expected to be in charge of the whole lifecycle of the datasets, including updates, backups,
synchronization, and policy access.

Job Responsibilities :
Managing the lifecycle (from data collection to archive) of ML/DL datasets and ensure their
usability for Nielsen’s Data Scientists.
Design, build and integrate data from various sources.
Design ETL pipelines with scripted components.
Optimize data workflows, choosing the most cost-efficient approach.
Automate the management of recurrent task in the pipeline.
Perform feasibility studies/analysis with a critical point of view.
Support and maintain (troubleshoot issues with data and applications).
Develop technical documentation for applications, including diagrams and manuals.
Work on many different software challenges always ensuring a combination of simplicity and
maintainability within the code.
Contribute to architectural designs of large complexity and size, potentially involving several distinct
software components.
Working closely with data scientists and a variety of end-users (across different cultures) to ensure
technical compatibility and user satisfaction.
Work as a member of a team, encouraging team building, motivation and cultivate effective team
relations.

Role Requirements :
E=essential, P=preferred.

E - Bachelor's degree in computer engineering.
P - Master’s degree in data engineering or related.
E - Demonstrated experience and knowledge in Big Data and NoSQL databases.
E - Demonstrated experience and knowledge in Object-Oriented Programming.
E - Demonstrated experience and knowledge in distributed systems.
E - Proficient in programming languages: Python.
E - Experience designing and implementing data warehouses.
E - Experience developing ETL pipelines.
E - Experience working with distributed storage systems in the cloud (Azure, GCP or AWS).
P - Experience managing deep learning datasets.
P - Experience managing Cassandra.
P - Experience working with Spark.
P - Experience implementing CICD pipelines for automation.
E - Experience in the use of collaborative developing tools such as Git, Confluence, Jira, etc.
E - Problem-solving capabilities.
E - Strong ability to analyze and synthesize. (Good analytical and logical thinking capability)
E - Proactive attitude, resolutive, used to work in a team and manage deadlines.
E - Ability to learn quickly.
E - Agile methodologies development (SCRUM/KANBAN).
E - Ability to keep fluid communication written and oral in English, both written and spoken.
Experience level: Minimal work experience of 3-4 years with evidence.

To apply for this job please send your resume to connect@blackstraw.ai

Location :
Blackstraw.ai , Chennai, 4th floor, Tower C, Ratha Tek Meadows Rd, Elcot Sez, Sholinganallur, Chennai, Tamil Nadu 600119, India",4.6,"Blackstraw
4.6",Chennai,"Tampa, FL",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Big Data Engineer - Cloudera/ Hortonworks,-1,"Location : Visakhapatnam

Experience : 5-6 years

Notice Period : 30 days

Roles and Responsibilities :
Design & implement new components and various emerging technologies in Hadoop Eco System, and successful execution of various projects.
Integrate external data sources and create data lake/data mart.
Integrate machine learning models on real-time input data stream.
Collaborate with various cross-functional teams: infrastructure, network, database.
Work with various teams to set up new Hadoop users, security and platform governance which should be pci-dss complaint.
Create and executive capacity planning strategy process for the Hadoop platform.
Monitor job performances, file system/disk-space management, cluster & database connectivity, log files, management of backup/security and troubleshooting various user issues.
Design, implement, test and document performance benchmarking strategy for the platform as well for each use cases.
Drive customer communication during critical events and participate/lead various operational improvement initiatives.
Responsible for setup, administration, and monitoring, tuning, optimizing, governing Large Scale
Hadoop Cluster and Hadoop components: On-Premise/Cloud to meet high availability/uptime requirements.? - 2-4 years relevant experience in BIG DATA.
Exposure to Cloudera/Hortonworks production implementations.
Knowledge of Linux and shell scripting is a must.
Sound knowledge on Python or Scala.
Sound knowledge on Spark, HDFS/HIVE/HBASE
Thorough understanding of Hadoop, Spark, and ecosystem components.
Must be proficient with data ingestion tools like sqoop, flume, talend, and Kafka.
Candidates having knowledge on Machine Learning using Spark will be given preference.
Knowledge of Spark & Hadoop is a must.
Knowledge of AWS and Google Cloud Platform and their various components is preferable.",4.7,"innData Analytics
4.7",Visakhapatnam,"Visakhapatnam, India",1 to 50 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"3+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, data warehousing, and building ETL pipelines
Experience in SQL
- 5+ years of experience with and detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures.
- 4+ years of Big data(Hadoop) experience including one programming language JAVA/PYTHON/SCALA
3+ years of experience in architecting data warehouse solutions and integrating technical components
4+ years of experience with relational and star schema data modeling concepts
Experience in MPP systems such as Redshift, Netezza or Teradata.
-Experience in any big data technologies - Hadoop Eco Systems, EMR
3+ years of working with very large data warehousing environment
Demonstrated knowledge and experience in capacity planning for hardware and storage needs
The Finance Automation team at Amazon is looking for a Data Engineer to play a key role in building their industry leading Financial Data Warehouses. If you have experience in building and maintaining very large data warehouses with high transaction volumes then we need you!!!

The Data Engineer should be an expert familiar with all of the new age data engineering technologies (e.g. Distributed computing, MPP systems, Cloud, NoSQL databases, Data Models and atleast one programming language-JAVA/PYTHON/SCALA). The ideal candidate will be responsible for developing overall architecture and high level design. The candidate must have extensive experience with Star Schemas, Dimensional Models, Datamarts in Traditional Data Warehouses as well as in Big Data / Advanced Analytics domains. The individual is expected to bring a methodology and lead the framework development for the next generation data warehouse by designing an efficient, flexible, extensible, and scalable design and mappings and also will be working extensively on building big data environment.

Excellent written and verbal communication skills are required as the candidate will work very closely with a diverse team. The candidate will also lead a small technical teams or participate in close customer interactions while having an influencing role, and be accountable for deliverable's. Ability to create and manage work plans, timelines and accommodate multiple priorities is required.

Job Responsibilities
Tableau Skill is mandatory.
Applies broad knowledge of technology options, technology platforms, design techniques and approaches across the data warehouse life cycle phases to design an integrated, quality solution to address the business requirements
Meets and collaborates with business users on requirements, objectives and measures.
Designs the technology infrastructure across all technical environments
Ensures completeness and compatibility of the technical infrastructure to support system performance, availability and architecture requirements
Designs and plans for the integration for all data engineering components
Supervises the technical implementation of the data warehouse and oversees hardware/ software configuration
Provides input and recommendations on technical issues to the project manager
Reviews technical work of other team members
Reviews and participate in testing of the data design, tool design, data extracts/transforms, networks and hardware selections
Develops the implementation and operation support plans
Experience in PYTHON, BIG DATA and AWS.
Knowledge of Reporting tools such as OBIEE is preferred
Excellent communication skills, both written and verbal
Strong ability to interact, communicate, present and influence within multiple levels of the organization",-1,ADCI HYD 13 SEZ,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
Data Management - Digital Expert,-1,"A candidate for this position must have had at least 3 years of working experience working with business analysis/informatics and business outcomes research within a fast-paced and complex business setting, preferably working as support data scientist junior support personnel.

The candidate will also have experience working in probability and statistics, time-series analysis, or econometrics as well as experience in the use of machine learning methods, for example, linear regression, correlation, statistical significance, and so forth. A candidate for this position will also require strong programming skills and experience working with tools such as SAS, R Programming, Open Source, visualizations, and so forth.

A suitable candidate will also have had experience as well as in-depth knowledge of the Python programming language, SAS Enterprise Miner and substantial knowledge of big data platforms such as Aster and Hadoop.

Communication skills for the Data Scientist, both in written and verbal form are a must have. The Data Scientist will be required to explain advanced statistical content to senior data scientists and relevant stakeholders.

Therefore, he must have the ability to translate and tailor this technical content into business applicable material with clear recommendations and insights relevant to the audience at hand.

These reports and presentations will not only be translations of technical analyses into business applicable material, the reports have to be simple, concise, understandable and convincing, which will require exceptionally good communication skills on the Data Scientist’s part.

A candidate for this position must be technologically adept, demonstrate exceptionally good computer skills, and demonstrate a passion for research, statistics, and data analysis as well as a demonstrated ability and passion for designing and implementing successful data analysis solutions within a business.

The candidate must have a strong understanding of data-mining techniques and an ability to apply these techniques in practical real-world business issues. The Data Scientist will demonstrate an ability to consider data, identify patterns, issues, or data analysis needs for the business. The candidate must also have skills in the workings of SQL and scripting languages such as Python and Perl as well as familiarity with statistical analysis, data visualization, and data cleansing tools and techniques.

about you

Excellent customer service skills
Good leadership skills
Ability to build relationships with peers ,stakeholders and the management
Excellent interpersonal skills
Good time management, organizational and communication skills
Ability to work under pressure and deal with multiple tasks concurrently
Proactive, self-motivated
Problem solving skills
Matrix Management
Excellent knowledge of Service Management tools / processes

additional information

Degree / Diploma Holders with good Telecom / and IT infrastructure (Sever / Cloud / Security etc)
CCNA / ITIL Preferred
Excellent verbal & written communication skills in English
5 – 7 years of work experience, at least 3 years in telecom domain
At least 3 years of hands on experience in Data Science
Hands on experience on Power BI or Tableu Application

department

Customer Services & Operations

contract

Regular",3.9,"Orange
3.9",Mumbai,"Paris, France",10000+ employees,1988,Company - Private,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Vodafone, Deutsche Telekom, Telefónica"
CSII - Item and inventory - Senior Data Scientist,-1,"Our Company

We help people around the world save money and live better -- anytime and anywhere -- in retail stores, online and through their mobile devices. Each week, more than 220 million customers and members visit our 11,096 stores under 69 banners in 27 countries and e-commerce websites in 10 countries. With last fiscal revenues of approximately $486 billion, Walmart employs 2.2 million employees worldwide.

@ Walmart Labs in Chennai, we use technology for the charter of building brand new platforms and services on the latest technology stack to support both our stores and e-commerce businesses worldwide.

Our Team:

CSII Team is responsible for building data driven highly optimized supply chain suite of products to manage entire gamut of supply chain lifecycle for our retail and ecommerce lines of business. With our rapidly increasing footfalls in stores and exponential growth in online orders; this all has to be done to scale millions of owned and marketplace SKUs complete inbound and outbound fulfilment lifecycles.

Teams mission - Enable customers to receive their orders when and where they want in an innovative and cost effective way for Walmart derives from Walmarts mission statement - Save Money. Live Better complementing our organizations philosophy to deliver low prices every day, on everything.

How we achieve this, comes down to the team of smartest technologists from India focused on the entire suite of supply chain management products for the Walmart Supply Chain at a massive scale. From forecasting & replenishing inventory for millions of items worth billions of dollars, sourcing of millions of orders, to route optimization & last mile delivery to Warehouse Management Systems to most advanced grocery & order management systems; technology is the backbone behind the entire platform enabling the massive cloud-scale supply chain from India.

With over 4,000 associates in Silicon Valley, San Diego, Portland, Brazil, United Kingdom and India, were bringing together some of the best professionals from around the world. If youre inspired by the opportunity to solve complex problems at scale and make a difference for our customers and members, join us.

Your Opportunity

Data Science

This position Data Science , will be on the Walmart Labs Supply Chain team, focused on building Walmart's best in class Supply Chain. At Walmart Labs, you will Work with small teams of talented analyst to build a best-in-class supply chain at Walmart. Be given the freedom to try new things and prove the value of your own ideas and innovations and own them all the way to production Identify and facilitate the removal of team impediments and escalate as appropriate Foster a motivating culture of openness, collaboration, and continuous improvement Ensure business needs are being met using Data Science best practices Participate in internal hackathons and innovation challenges!.

Your Responsibility

· Develop interactive statistical models using the latest frameworks.

· Develop Machine learning modelling leveraging existing frameworks and customizing to problem.

· Find workable solution in case of data inconsistency and inconclusive data

· Drive projects with minimal guidance. Provide thought leadership by researching best practices and conducting experiments

· Evaluate various analytical/statistical methods and procedures and provide recommendation of relevance, applicability, efficiency of those to Walmart Catalog teams

· Work with cross functional group consisting of Engineering, Product, Program managers to drive data based decisions

Your Qualifications

· Bachelors degree in computer science or related discipline with 8+ years experience (5+ Relevant)

· Practical experience with SAS, ETL, data processing, database programming and data analytics

· Proficient is Sql and no-sql languages, R, Python

· Worked on gathering data from Cassandra, Kafka, MongoDBs. Work with big data on GCP and Azure.

· Advanced statistical modelling skills

· Handled multi-million records of data. Troubleshooting and fixing data issue

· Data Visualization in any BI tools like Tableau, PowerBI, etc.,

· Collected, analyzed, and reported data to meet customer needs.

· Understanding and application of statistical concepts to solve business problems",3.3,"Walmart
3.3",Chennai,"Bentonville, AR",1001 to 5000 employees,1962,Company - Public,"Department, Clothing, & Shoe Shops",Retail,₹500+ billion (INR),"Target, Costco Wholesale, Amazon"
Data Analyst,-1,"Netomi is a Y-Combinator and VC-backed Artificial Intelligence company that sits at the intersection of two rapidly developing fields: AI and messaging. We do not sell an abstract, futuristic technology - we sell a solution that a large number of Fortune 500 companies are using today to drive engagement and sales across the entire customer journey. By leveraging deep reinforcement learning and our continuously learning neural network, our customers are able to successfully meet their objectives of generating social engagement, driving commerce and providing customer service. We're building the future of how technology and people work together to create frictionless experiences for customers.

Want to have a direct impact in solving the top challenges businesses face today? Join us!

Job Description:

We are looking for a Data Analyst who can help us dig into raw data, analyse it and draw conclusions that help in making business decisions.
Responsibilities
Business Analysis to understand the client's business and work with Data Analysts to define the Deep Learning (DL) model
Quality Assurance of Deep Learning models
Analyze the conversation quality in chatbots
Leverage multiple crowdsourcing strategies to collect training and test data for DL models and help with cleansing, filtering and massaging those data
Providing a high level of data quality awareness across multiple teams
Evaluate and identify where enhancements of data to maintained higher quality data
Detailed testing feedback preparation to help the team to improve the models.
Monitor and improve the Data Quality Assurance process that can meet/exceed the current standards and procedures
Learn and/or leverage the required software tools and technology

Requirements
0-1 years experience in related field
Bachelors degree from a Tier I/Tier II college
Knowledge of any one foreign language - French, Spanish or Russian
Excellent written and verbal communication skills
An eye for detail and accuracy",4.8,"Netomi
4.8",Gurgaon,"San Francisco, CA",51 to 200 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"HP is the world’s leading personal systems and printing company, we create technology that makes life better for everyone, everywhere. Our innovation springs from a team of individuals, each collaborating and contributing their own perspectives, knowledge, and experience to advance the way the world works and lives.

We are looking for visionaries, like you, who are ready to make a purposeful impact on the way the world works.

At HP, the future is yours to create!

We are Pricing Analytics Team; our main objective is to help the business to decide optimal price for the HP products in a scientific way through statistical and predictive analysis.

If you are our Data Engineer in India, you will get an opportunity to work on below.

Designs and establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data pipelines, repositories or models for structured data.
Analyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.
Writes and executes complete pipeline plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs and creates solutions for issues with data sources and integration into data system architecture.
Collaborates and communicates with project team regarding project progress and issue resolution. Represents the data engineering team for all phases of larger and more-complex development projects. Provides guidance and mentoring to less experienced staff members.

Are you a high-performer? We are looking for an individual with.

Well versed knowledge on SQL servers and database solutions.
Python programming language to create efficient data flow
Various operating systems like Linux, windows, Unix which will enable data interconnection Data warehousing and ETL tools Good to have.
Knowledge on R and visualization tools such as Power BI / Tableau/ R Shiny Data architecture skills to create effective data flow Team player to interact and understand the data based on data scientists and analysts
#LI-Post",3.3,"HP
3.3",Bengaluru,"Houston, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"The Role: Senior Data Analyst

The Location: Mumbai

The Grade: 11

The Team: The Global Data Management team within the Global Index Management & Production Group.

The Impact: The Senior Data Analyst is responsible for the acquisition, management and quality of a variety of data items used for the production and maintenance of S&P Dow Jones-branded indices.

The successful candidate will be expected to set the standard in carrying out tasks associated with the management of data used for the production and maintenance of indices, setting an example for more junior analysts to follow.

Additionally, the Senior Data Analyst is responsible for a wide range of data points across global markets and may be required to make presentations to Index Committees on matters impacting the maintenance and particularly the rebalancing of S&P DJI global indices, making in-depth knowledge of their product line essential.

Whats in it for you: As a Senior Data Analyst, you will work collaboratively with a wide range of data points, indices and other products across global markets. You must be able to analyze and implement complex data processes and calculation methodology and solve non-routine problems on an on-going basis.

Responsibilities:

The Senior Data Analyst will be a subject matter expert, an example and escalation point for more junior team members and will support the team leader.

In addition, the Senior Data Analyst will be required to:
Demonstrate organizational skills by ensuring that processes for the capture, quality screen and presentation of data sets are completed in time for their delivery to end clients or use in the further calculation or rebalancing of indices
Preparing and calculating fundamental ratios for S&P and Dow Jones branded indices, ensuring timely and accurate delivery of index data to clients and end users
Develop a detailed understanding of the way each data set is used in the production and maintenance of S&P Dow Jones Indices, ensuring the Senior Data Analyst is able to identify and resolve issues and ensure the data is fit for purpose
Serve on index committees and make presentations of original, non-routine analysis to committee in support of the data items for which the Senior Data Analyst is responsible. Decisions reached by committee determine index composition and drive asset allocations.
Take responsibility for the management of high profile data sets, acting as an industry expert and displaying in-depth knowledge of our product lines.
Provide timely and accurate responses to enquiries from internal groups and external clients, through our client services team
Manage and maintain key relationships with other groups within the department and across other departments, particularly Product Management, Client Coverage, Index Services and IT Support
Work in close coordination with the technology group and production support group to further enhance our system capabilities
Qualifications:
A demonstrable, deep understanding of global financial markets and financial data, particularly company fundamentals
Familiarity with Environmental, Social and Governance (ESG) themes in finance and particularly ESG data providers would be considered an advantage
Must be able to work independently on multiple projects with minimal direction or supervision.
Ability to assume responsibility, work with others and manage projects
Bachelors Degree. Advanced degree in business, math, economics, or finance strongly preferred
Minimum of 4 years of professional experience working with financial indices.
Strong understanding of how indices are used, the impact of different methodologies, corporate event events on both indices and financial portfolios.
Superior computer skills in Excel, Word and related applications. Access, VBA, SQL and/or Python would be an advantage.
Ability to learn S&Ps proprietary index calculation systems and requirements
Excellent analytical and numerical capabilities to aid in solving non-routine problems in a timely fashion
About us:

At S&P Dow Jones Indices, our role can be described in one word: essential. Were the largest global resource for index-based concepts, data and research, and home to iconic financial market indicators, such as the S&P 500® and the Dow Jones Industrial Average®. More assets are invested in products based upon our indices than any other index provider in the world; with over 1,000,000 indices, S&P Dow Jones Indices defines the way people measure and trade the markets. We provide essential intelligence that helps investors identify and capitalize on global opportunities.

S&P Dow Jones Indices is a division of S&P Global (NYSE: SPGI), which provides essential intelligence for individuals, companies and governments to make decisions with confidence. For more information, visit www.spdji.com.",3.7,"S&P DOW JONES INDICES
3.7",Mumbai,"New York, NY",201 to 500 employees,-1,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,-1
Data Analyst,-1,"Have Accounting background.
Data analysis of the records
Good Communication
Excellent Excel Knowledge
Job Type: Full-time
Salary: ₹240,000.00 - ₹480,000.00 per year
Experience:
work: 3 years (Preferred)
total work: 3 years (Preferred)
Education:
Master's (Preferred)
Work Remotely:
No",3.3,"Express Roadways Pvt Ltd
3.3",Hisar,"Mumbai, India",5001 to 10000 employees,-1,Company - Public,Transportation Management,Transportation & Logistics,Unknown / Non-Applicable,-1
Sr. Data Analyst,-1,"1. Hands-on professional with in-depth knowledge and High level of Proficiency in Qlikview scripting.
2. Use of complex QlikView functions, advance Qlikview expressions.
Knowledge of Qlikview scripting features such as Resident Tables,loops and other advanced scripting fuctions.
3.Hands on experience with complex data models.
4.Understanding of BI/data warehouse concepts, Star schema/snowflake models, SCDs, fact and dimension tables, SQL etc.
5. Good Knowledge of Python especially in packages Pandas and numpy.
5.Must have written SQL queries for extracting data for varied complex scenarios with an exposure to big data environment.
6.Have practical experience using the windowing and analytic functions in SQl.
7.Good knowledge of Excel functions including index,match,array and other advanced functions in excel.
8. Candidate must have strong problem solving, logical and analytical skills.

What You Need for this Position

You should have knowledge of:
QlikView functions
advance Qlikview expressions
BI/data warehouse concepts
Star schema/snowflake models
SCDs
fact
SQL
Aditional
No. of Positions
Education level
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
HIVE Data Engineer- Bangalore,-1,"Description

6sense is a Predictive Intelligence Engine that is reimagining how B2B companies do sales and marketing. It works with big data at scale, advanced machine learning and predictive modeling to find buyers and predict what they will purchase, when and how much.

6sense helps B2B marketing and sales organizations fully understand the complex ABM buyer journey. By combining intent signals from every channel with the industry's most advanced AI predictive capabilities, it is finally possible to predict account demand and optimize demand generation in an ABM world. Equipped with the power of AI and the 6sense Demand Platform™, marketing and sales professionals can uncover, prioritize and engage buyers to drive more revenue.

6sense is seeking a Data Engineer to become part of a team designing, developing, and deploying its customer centric applications.

A Data Engineer at 6sense will have the opportunity to
Create, validate and maintain optimal data pipelines, assemble large, complex data sets that meet functional / non-functional business requirements.
Improving our current data pipelines i.e. improve their performance, remove redundancy, and figure out a way to test before v/s after to roll out.
Debug any issues that arise from data pipelines especially performance issues.
Experiment with new tools and new versions of hive/presto etc. etc.
Required qualifications and must have skills
BE/BTech/BS or equivalent
Excellent analytical and problem-solving skills
6+ years work experience showing growth as a Data Engineer.
Strong hands-on experience with Big Data Platforms like Hadoop / Hive / Spark / Presto
Experience with writing Hive / Presto UDFs in Java
String experience in writing complex, optimized SQL queries across large data sets
Experience with optimizing queries and underlying storage
Comfortable with Unix / Linux command line
Nice to have Skills
Used Key Value stores or noSQL databases
Good understanding of docker and container platforms like Mesos and Kubernetes
Security-first architecture approach
Application benchmarking and optimization
Interpersonal Attributes
You can work independently as well as part of a team
You take ownership of projects and drive them to conclusion
You're a good communicator and are capable of not just doing the work, but teaching others and explaining the ""why"" behind complicated technical decisions
You aren't afraid to roll up your sleeves: This role will evolve over time, and we'll want you to evolve with it!",5.0,"6sense
5.0",Bengaluru,"San Francisco, CA",51 to 200 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Science Online Trainer,-1,"Job Id : PTPL/HR/8

Anywhere in India

1+ year experience in Data Science. Must have worked on minimum 2 Data Science Projects and must have at least 50 hours experience in online training on Data Science topics.",3.5,"Prognoz
3.5",India,"Perm, Russia",1001 to 5000 employees,-1,Company - Private,Research & Development,Business Services,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Company Description

Cermati is a financial technology (fintech) startup based in Indonesia. Cermati simplifies the process of finding and applying for financial product by bringing everything online so people can shop around for financial products online and can apply online without having to physically visit a bank.

Our team hailed from Silicon Valley Tech companies such as Google, Microsoft, LinkedIn and Sofi as well as Indonesian startups such as Doku, Touchten. We have graduates from well known universities such as Universitas Indonesia, ITB, Stanford, University of Washington, Cornell and many others. We are building a company with the same culture of openness, transparency, drive and meritocracy as Silicon Valley companies. Join us in our cause to build a world class fintech company in Indonesia.

Job Description

The candidate should be able to design high performance, maintainable, extensible software architectures to solve abstract business problems. Here are some example business problems:
""We want to reduce the time for productionizing experimental machine learning features to 1 day""

""We want to completely automate the credit approval process while maintaining an accuracy of >90% when compared with manual approval""

They should be able to translate the high level design into a series of tasks that can be executed by other software engineers working in parallel

The high level designs are usually design documents consisting of relevant block diagrams, UML diagrams meant to be consumed by other engineering leaders and software engineers

They must be able to work with international teams effectively. They will be required to communicate with:
- Clients who may not necessarily be software engineers (marketing teams, business development team etc)
- Software engineers and tech leads to communicate the design in a simple yet accurate language without compromising details.
They would be leading a team of talented but possibly inexperienced engineers who will look to you for mentorship. In a typical day, candidates would be spending
10% of the time project management, 20% of the time doing code review and mentorship, 20% of the time coding (evaluating technologies, doing PoC, etc) 50% of the time requirement gathering, high level design, low level design, roadmap etc

The following technical skills would be useful:
Candidates must be able to understand the tradeoff between performance, simplicity, maintainability and timeline constraints when developing software solutions
Strong hands on experience in java, python is required. Must have shipped multiple projects with a major hands on contribution to each project.
Experience in Big data technologies: hadoop ecosystem (mapreduce, spark, kafka)
Experience in different storage technologies: OLTP like postgres, OLAP like redshift, Google bigquery, NoSQl like redis, hbase, kafka
Familiarity with machine learning algorithms and concepts (gradient descent, logistic regression) and software libraries like pandas, tensorflow, etc
Qualifications

The following technical skills would be useful:
Candidates must be able to understand the tradeoff between performance, simplicity, maintainability and timeline constraints when developing software solutions
Strong hands on experience in java, python is required. Must have shipped multiple projects with a major hands on contribution to each project.
Experience in Big data technologies: hadoop ecosystem (mapreduce, spark, kafka)
Experience in different storage technologies: OLTP like postgres, OLAP like redshift, Google bigquery, NoSQl like redis, hbase, kafka
Familiarity with machine learning algorithms and concepts (gradient descent, logistic regression) and software libraries like pandas, tensorflow, etc
Additional Information

Impressive Benefits and flexible work culture.",4.2,"Cermati.com
4.2",Bengaluru,"Jakarta, Indonesia",1 to 50 employees,-1,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
CIEL/SEL/13651: Data Scientist,-1,"Job Description
Key points about the position are as below;
Hadoop - working knowledge

PL SQL
Python or R
Inferential Statistics
ML - must have implemented at least one algorithm
Visualisation - Tableau preferred, BI, Spotfire
Service Delivery, communication skills
Statistical education background
Production model experience using ML with any algorithm. Worked on real time projects

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
Data Engineer,-1,"Job Type: Full time Experience: 2+ years Hyderabad

Job Description:
We are looking for a savvy Data Engineer to join our growing team. We work with fortune 500 companies to build their data infrastructure and help them with their data journey. The Data Engineer will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing the data flow. The Data Engineer will help generate data pipelines and subsequently with DataOps. He/ She must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.

Qualifications:
2+ years of experience in building data pipelines.
Experience building data pipelines using StreamSets or Azure Data Factory.
Understanding of stream processing with knowledge on Kafka.
Experience with scripting languages i.e. Python, Perl, etc.
Experience with SQL (RDBMS), NoSQL (MongoDB), and PostgreSQL.
Understanding of data flows, data architecture, ETL and processing of structured and unstructured data.
Current experience developing and deploying applications to a public cloud (AWS, GCE).
Experience with DevOps tools (GitHub, Jira) and methodologies (Lean, Agile, Scrum).
Experience with ETL, Data Modeling, and working with large-scale datasets. Extremely proficient in writing performant SQL working with large data volumes.
Experience on Azure DevOps is a plus.
Ability to manage competing priorities simultaneously and drive projects to completion.

Desired Candidate Profile:
Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Engineering).
Excellent written and verbal communication skills in English.
Experience in working in agile (SCRUM) methodology.",4.0,"Modak Analytics
4.0",Hyderabad,"Hyderabad, India",201 to 500 employees,2010,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst (NLP),-1,"Department: Analytics

Experience: 3-5 Years

Location: Chennai

Job Description
Should have experience in developing efficient code in R / Python
Sound have understanding of statistical concepts behind data modelling
Experience in training and deploying models based on Stanford Core NLP.
Experience with machine learning, preferably one or more among Tensorflow, Theano, Deeplearning4J, Torch
Experience developing backend systems involving NoSQL databases and Graph Databases
Experience and familiarity with the concepts of threading, concurrent execution methodologies including monads
Familiarity with text-to-speech
Familiarity with modern speech recognition engine technology. LVCSR, HMMs, DNNs.
Familiarity and experience with open-source/commercial NLP toolkits such as Stanford NLP, NLTK, Tensorflow, Apache Lucene/Solr, GATE
Knowledge of techniques for critical problem/application areas in NLP such as Named Entity Extraction, PoS tagging, parsing, semantic analysis, ambiguity resolution, pronoun resolution, sentiment analysis, summarization
Sound understanding behind machine learning algorithms like SVM, KNN, Decision tree etc.
NLP analyst to work with Clients and Senior analyst / SME to bring insights using AI/ML/NLS techniques.
Conduct all job functions and responsibilities in accordance with all company Compliance, Information Security and Regulatory policies, procedures and programs.",3.1,"SCIO Health Analytics
3.1",Chennai,"West Hartford, CT",501 to 1000 employees,2007,Company - Private,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),-1
Computer Vision - Data Scientist,-1,"Arya.ai is looking for ambitious and talented computer vision researchers with strong skills in software development to join our research team. If you get excited by the prospect of analyzing and modelling terabytes of data and creating state-of-the-art algorithms to solve real-world problems and by owning business problems/metrics, then we have the perfect role for you. Here you will have the ability to thrive in a dynamic environment combining conceptual and applied research, systems building and collaborative work. You will work together with similar minds in a unique development team where your skills and expertise will be put to the test.

*
Major responsibilities:
*
Research, design, implement and evaluate novel computer vision algorithms

- Work on large-scale datasets, focusing on creating scalable and accurate computer vision systems in versatile application fields

- Collaborate closely with team members on developing systems from prototyping to production level

- Able to derive model’s risk towards business and communicate with corresponding business managers

- Track general business activity and provide clear, compelling management reports on a regular basis
*
Qualifications Required:
*
Hands-on experience in Computer Vision and Deep Learning

- Broad knowledge of fundamentals and state-of-the-art in computer vision

- High proficiency in C/C++ or Python

- Ability to develop large-scale systems working with image/video data

- Strong working knowledge of software architecture and data structure

- Excellent problem-solving ability

- Minimum of 2-year experience in Deep Learning(CNNs, RNNs, Attention-based Networks, etc)

- Minimum of 2-year experience in Computer Vision (Image/Video Processing)
Job Type: Full-time",3.5,"Arya.ai
3.5",Mumbai,"Mumbai, India",1 to 50 employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"Start : Immediate
Must Have Technical expertise
Strong Experience with SQL, T-SQL
Strong Experience with Power BI
Experience with data extraction, cleansing and loading into a database using integration tools such as Talend or using Microsoft tools or Python data wrangling libraries
Ability to understand a problem and produce technical solutions
Good to Have Technical experience
Azure Cosmos DB NoSQL
Azure Synapse Analytics
Python Data Science Libraries
Good to Have Functional experience
Supply Chain or Manufacturing
Finance
Experience: 4+ years, 6+ years
Job Type: Full-time
Experience:
Power BI: 4 years (Preferred)
Talend: 3 years (Preferred)
SQL, T-SQL: 4 years (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Work Remotely:
Yes",2.0,"Aavid Software
2.0",Pune,"Pune, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Hands on experience working with Cloud Platform - Preferred AWS
Good experience working with ETL Tools - Cloud based (AWS) + Others (Talend)
AWS Services - S3, Redshift, Athena, Glue, DMS, Lambda. Good to have knowledge about AWS Infra
Hands on working with any RDBMS & NoSQL DBs.
Good understanding of DB Concepts & SQL Queries. PL/SQL, Stored Procedures, Optimization & Performance Tuning
Experienced in Data Migration
Experience working with Spark, Hadoop, HDFS, Scala
Good To have big data knowledge
Knowledge of Data Visualization Tools (like Tableau)
Knowledge working with Data-warehouses (Cloud based)
Good understanding & working experience in any programming language
Good to have experience working in Python
00-5.00 Years",3.5,"Unitforce Technologies Consulting Pvt Ltd
3.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
"Data Engineer Oracle, ETL for NFRM IT",-1,"Job Description:


Position Overview

Role Description:

The Oracle developer will be responsible for developing, enhancing and maintaining applications in the Non Financial Risk (NFR) domain. The activities shall be performed in accordance with the defined tools/technologies of the project , shall adhere to the standards and processes followed in the organization & project. Additionally, the developer will be a partner to the development and Level 2 support organizations and shall work on any issues in the production environment for which the Development’s team help is required.

Tasks |Responsibilities:
Develop a good understanding of the activities required to execute the development/bug fix activity.
Actively participate and contribute in Agile ceremonies including Daily Stand up’s, Sprint Planning, Sprint review, Sprint retrospective meetings
Take part in software and architectural design activities
Perform analysis, development, testing and debugging/defect fixing for the assigned stories/bug fixes
Develop the required functionalities using the appropriate database technologies
Write unit tests for the developed code.
Recommend changes to improve established application processes.
Integration of changes with other user stories developed by team members
Deployment in Development/integration/UAT environments
Create required documentation for the project.
Meet the SLA’s for any assigned defects.
Development and delivery KPI’s shall be met.
Shall be ready to learn new technologies as per the project requirements.
Experience | Knowledge
10+ years combined experience as software developer. Well aware of the Agile methodology.
Hands on experience in SQL and relational databases, preferably Oracle 10G and higher
Experience with database migration, database upgrade activities
Experience with performance tuning, indexing, partitioning
Experience using the Git version control system, Jenkins, Nexus and Sonar.
Proficient in Linux/Unix system.
Experience working with high availability and high performance systems.
Should be aware of the release/deployment and application support processes (Incident/problem/change management etc.)
Basic knowledge of Oracle database management system
Experience using atleast one ETL tool
Experience in datawarehousing
Good to have experience with BI tools like SAP Buiness Objects or Cognos reporting
Good to have experience with big data technologies
Education | Certification

Bachelor degree from an accredited college or university with a concentration in an IT related discipline

Our values define the working environment we strive to create – diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer.

We promote good working relationships and encourage high standards of conduct and work performance. We welcome applications from talented people from all cultures, countries, races, genders, sexual orientations, disabilities, beliefs and generations and are committed to providing a working environment free from harassment, discrimination and retaliation.

Click here to find out more about our diversity and inclusion policy and initiatives.",3.5,"Deutsche Bank
3.5",Pune,"Frankfurt am Main, Germany",10000+ employees,1870,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),-1
Data Science Engineer - Start Up Software Company Baner,-1,"Responsibilities:
Design and build highly scalable nlp pipelines
Design and write custom algorithms to solve domain specific problems
Build POCs using open-source libraries for independent modules
Create AI solutions for automated dialogue (chat bots); natural texting for knowledge & expertise recommendations.
Build & train NLP platform from user generated textual data (email, IM, search logs) on daily basis
Code ML models primarily using python, No-Sql & AWS
Collaborate with other team members and stakeholders.

Requirements:
5+ years experience in web-app development, with minimum 2+ years of NLP experience .
Proficiency in Data Structures & Algorithms .
Experience with open-source NLP libraries such as spacy, NLTK
Experience with MySQL, Mongo-DB & Neo4j
Experience with Word2Vec, Glove, RNN, LSTM
Experience with Data Pipeline Frameworks such as AWS Data Pipeline
00-7.00 Years
Masters in Technology (M.Tech/M.E/M.Sc), Master in Computer Application (M.C.A), Bachelor Of Technology (B.Tech/B.E)",5.0,"Seventh Contact Hiring Solutions
5.0",Pune,"Pune, India",1 to 50 employees,-1,Private Practice / Firm,-1,-1,Unknown / Non-Applicable,-1
ANALYST-DATA SCIENCE-PYTHON,-1,"Apply machine learning techniques to deliver actionable insights from large-scale, multi-structured datasets. Work with internal and external teams to develop models (ranging from data exploration to feature engineering and model development to validation and scoring.) and put them into production This is an individual contributor profile wherein the candidate is required to work in collaboration with the AMs and DMs Machine Learning techniques (recommendation engines, ensemble models such as random forests, bagging and boosting, support vector machines, dynamic optimization etc.) Design and build systems that mine massive datasets and structure/ engineer it to be usable for machine learning models
Salary Negotiable
Industry IT Software
SubIndustry Software Development
Functional Area IT Software Development
Specialization IT/Technical Content Developer
Role Manager / Sr. Manager Level
Keyskills
NLPText MiningMachine Learning
Desired Candidate Profile
Please refer on JD
Education
Highest Qualification
Graduation Any Graduate",5.0,"Fine Jobs
5.0",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Digital - Associate Program Manager - Analytics Consultant,-1,"SKILLS REQUIRED:
Advanced Analytics, Predictive Analytics",3.4,"eClerx
3.4",Mumbai,"Mumbai, India",5001 to 10000 employees,2000,Company - Public,Consulting,Business Services,₹10 to ₹50 billion (INR),"Genpact, WNS, Convergys"
"ES Tech, Data Engineer",-1,"Do you love data as much as we do? Do you want to influence at Amazon? We have the career for you!

Amazon's Employee Services Technology (ES Tech) team is seeking an outstanding ETL/Data Engineer to join our BI team to build out the BI platform with all of the data ingestion mechanisms required for the initiative. Our platform delivers business intelligence to a diverse, global community of internal customers from one of the worlds largest and most complex financial data sets. Amazon has culture of data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable.

You will be responsible for designing and implementing solutions using third-party technology and Amazon cloud technologies. A successful candidate knows and loves working with business intelligence ETL tools, is comfortable accessing and working with big data from multiple sources, and passionately partners with the business to identify strategic opportunities and deliver results. You should have an internal drive to answer why? questions, excellent analytical abilities, strong technical skills, as well as superior written and verbal communication skills. S/he would be a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail), and enjoy working in a fast-paced dynamic environment.

Responsibilities include:
· Drive the collection of new data and the refinement of existing data sources to continually improve data quality
· Support data analysts and product managers by turning business requirements into functional specifications and then executing ETL delivery
· Lead the technical lifecycle of data presentation from data sourcing to transforming into user-facing metrics





Basic Qualifications

· Bachelors or Masters Degree in Computer Science, Systems Analysis, or related field
· 3+ years experience in data modeling, ETL development, and Data Warehousing
· 1+ years experience with BI/DW/ETL projects.
· Knowledge of AWS product suite including S3, Redshift, Dynamo DB and RDS.
· Experience in scripts like Python, Java, javascript etc.
· Technical guru; SQL expert.
· Experience with Linux, UNIX, UNIX tools
· Experience writing software to automate manual workflows
· Good instincts; you know what it means to be a subject matter expert and how to be a team player



Preferred Qualifications


Strong background in data relationships, modeling, and mining.
Mulesoft experience a plus.




Amazon is an Equal Opportunity Employer",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Analyst,-1,"Responsibilites :
Backgrounds in technology, information management, relational database design and development, business intelligence, data mining or statistics.
Solid understand of data analysis techniques or processes will help reduce the need for you to learn every data analysis tool in the market
Experinece in importing, cleaning, transforming, validating or modeling data with the purpose of understanding or making conclusions from the data for decision making purposes.
Experinece in Performing audit on data and resolve business related issues for customer base
Experinece in Performing data analysis and facilitate in delivery to all end users.
Explorering sift through mountains of data to discover the data you actually need

Send us the Resume at info@zettamine.com",3.8,"ZettaMine
3.8",Hyderabad,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Big Data Engineer,-1,"Data Engineer

About Print Analytics

As part of the HP Inc. R&D Centre, Print Analytics Team work closely with Print GBU of HP Inc. across multiple domains. We deploy data products and analytics assets, provide data-driven actionable insights to influence business decisions.

Within Print Analytics, Supplies Analytics Team seeks to deploy data products through designing table structures and data flows, automating repetitive data tasks, building and maintaining data dictionaries, finding/resolving data anomalies and data errors. This would, in turn, result in delivering complex analysis and improving intelligence.

Business Environment

Supplies Analytics Team strategically partners with Big Data Business Transformation organization to deploy data products and deliver analytics to help them discover new opportunities and solve their business challenges in a data driven manner.

Role Description:

In order to deploy data products, we are looking for a high caliber and detail-oriented Data Engineer who can work in collaboration with cross-functional, cross-regional teams to establish and improve data pipelines. She / He will also be responsible for designing table structures and data flows, automating repetitive data tasks, building and maintaining data dictionaries, finding/resolving data anomalies and data errors. This would, in turn, enable downstream data analyses and AI/ML models.

The analyst would act as an informed team member who can help bridge technical data requirements.

Responsibilities:
Establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data platform, repositories or models for structured/unstructured data.
Analyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.
Writes and executes complete testing plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs, and creates solutions for issues with code and integration into data system architecture.
Collaborates and communicates with project team regarding project progress and issue resolution.
Works with the data engineering team for all phases of larger and more-complex development projects and engages with external users on business and technical requirements.
Collaborates with peers, engineers, data scientists and project team.
Typically interacts with high-level Individual Contributors, Managers and Program Teams on a daily/weekly basis.
Defines and leads portions of project requirements for data exchanges and business requirements with externals and internal teams
Creates plans, data collection and analysis procedures and works with data insight visualization teams for assigned projects.
Collaborates with internal and external partners to perform experiments and validations in accordance with overall plan.
Collaborates with SMEs to develop procedures for collecting, recording, analyzing, and communicating data for review and feedback.
Education and Experience Required:
Bachelor's or Master's degree in Computer Science, Information Systems, Engineering or equivalent.
4-6 years experience in a data analyst or data engineering type role.
Knowledge & Skills:
Using data engineering tools, languages, frameworks to mine, cleanse and explore data.
Fluent in relational based systems and writing complex SQL.
Fluent in programming and automating repetitive tasks preferably using VBA and Python
Fluent in complex, distributed and massively parallel systems.
Strong analytical and problem-solving skills with ability to represent complex algorithms in software.
Designing data systems/solutions to manage complex data.
Strong understanding of database technologies and management systems.
Strong understanding of cloud-based systems/services, including the AWS environment.
Database architecture testing methodology, including execution of test plans, debugging, and testing scripts and tools.
Ability to effectively communicate product architectures, design proposals and negotiate options at management levels.
Using scientific design and data collection methodologies, tools and analysis packages to collect, validate, and analyze research data.
Excellent written and verbal communication skills
Strong interpersonal skills and ability to work in a collaborative environment",4.1,"HP Inc.
4.1",Bengaluru,"Palo Alto, CA",10000+ employees,1939,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Science Trainer,-1,"Should have a strong knowledge on Machine Learning, Deep Learning, R Programming; Python,Statistics,Hadoop etc
Understanding and assessing individual (or) group training requirements.
Execute workshops to create awareness of the latest technologies.
Up to date knowledge of IT skills and software packages.
Designing the Course modules appropriate to the skills needed.
Helping IT Professionals in updating their skills with latest technologies.
Evaluating each and every Individual progress and outcomes.

Job Types: Full-time, Part-time

Salary: ₹300,000.00 - ₹500,000.00 per year

Experience:
total work: 5 years (Preferred)
Training: 5 years (Preferred)
Education:
Bachelor's (Preferred)
Location:
Ameerpet, Hyderabad, Telangana (Preferred)
Work Remotely:
Temporarily due to COVID-19",3.7,"Naresh I Technologies
3.7",Telangana,"Hyderābād, India",51 to 200 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Research Scientist,-1,"Role Purpose:

To perform the formulation/AI
product chemistry studies and work, as discussed with the Team Leader
T&E, to agreed timelines.
Ensure HSEQ as per site policy
and local Regulation requirements
Maintain Laboratory and
equipment as per GLP requirements.
Support the Study
Director to GLP studies and documentation
Update GLP data in team space
Accountabilities:

Excellent experimental skills i.e., perform and
document analytical and product chemistry work as per GLP
Minimum of 2-4 years’ experience with good technical
knowledge of LC and/or GC, preferably both, in an industrial setup.
Knowledge of method development/Validation of
Chromatographic methods
Good hands on experience on spectroscopic techniques
viz. LCMS, GCMS, NMR etc. with at least 3 years practical experience.
Able to plan and organize his/her work to achieve a
high level of productivity and to meet important deadlines
Maintain Laboratories and assigned Equipment used for
GLP studies and document as per the GLP requirements
Contribute to a product chemistry group and conduct,
under the direction of a study director, studies that fully meet world-wide
regulatory requirements to facilitate registration.
Characterize analytical references and certified
substances to meet development and production schedule requirements
Good understanding of GLP, SOPs and knowledge of
formulation/A.I. Product Chemistry
Ensure HSE and waste disposal as per the site policy
Communicate results and
programs effectively with staff, peers, and customers
Ensure compliance with all company HS&E policies
and GLP. Train junior scientist to enable safe and competent performance.
Knowledge, Skills and
Experience:
PhD degree in Chemistry preferable in analytical or
allied Science, area from the reputed Universities with strong academic records
and good communication skills and sound in instrumentations. with >2 years
of industrial experience preferable worked in GLP facility
Or
Master degree in Chemistry preferable analytical or
allied Science, area from the reputed Universities with strong academic records
and good communication skills with >3 years of industrial experience.
Experience Analytical Chemist with sound GLP experience is
desirable,
Excellent experimental skills
Able to plan and organize work to achieve a high level
of productivity and to meet important deadlines.
IT literate relevant to work
Sound understanding of GLP and knowledge of
formulation/AI Product Chemistry
Good knowledge of written English
Team player, flexible and with people skill
Behaviors:

Team-Oriented
Demonstrates
personal commitment to the team
Values
and uses individual differences and talents
Results-Oriented
Works
tenaciously to deliver agreed goals
Self-disciplined
to achieve results through effective prioritisation and timely delivery
Communicative
Ensures
structure and clarity in both verbal and written messages
Provides
timely communications and feedback to stakeholders",4.0,"Syngenta
4.0",India,"Basel, Switzerland",10000+ employees,2000,Company - Public,Chemical Manufacturing,Manufacturing,₹500+ billion (INR),-1
Data Engineer/Python Spark Developer,-1,"The Applications Development Intermediate Programmer Analyst is an intermediate level position responsible for participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to contribute to applications systems analysis and programming activities. Responsibilities: Utilize knowledge of applications development procedures and concepts, and basic knowledge of other technical areas to identify and define necessary system enhancements, including using script tools and analyzing/interpreting code Consult with users, clients, and other technology groups on issues, and recommend programming solutions, install, and support customer exposure systems Apply fundamental knowledge of programming languages for design specifications. Analyze applications to identify vulnerabilities and security issues, as well as conduct testing and debugging Serve as advisor or coach to new or lower level analysts Identify problems, analyze information, and make evaluative judgements to recommend and implement solutions Resolve issues by identifying and selecting solutions through the applications of acquired technical experience and guided by precedents Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. Qualifications: 2-5 years of relevant experience in the Financial Service industry Intermediate level experience in Applications Development role Consistently demonstrates clear and concise written and verbal communication Demonstrated problem-solving and decision-making skills Ability to work under pressure and manage deadlines or unexpected changes in expectations or requirements Education: Bachelors degree/University degree or equivalent experience This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN ------------------------------------------------------ Time Type :Full time ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.7,"Citi
3.7",Pune,"New York, NY",10000+ employees,1812,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Python for Data Science-Developer,-1,"Pune, India
BE / BTech
1405960
Job Description
Key skills required for the job are: n Python for Data Science-L2, (Mandatory) .As a Senior Developer, you are responsible for development, support, maintenance and implementation of a complex project module. You should have good experience in application of standard software development principles. You should be able to work as an independent team member, capable of applying judgment to plan and execute your tasks. You should have in-depth knowledge of at least one development technology/ programming language. You should be able to respond to technical queries / requests from team members and customers. You should be able to coach, guide and mentor junior members in the team. Minimum work experience: 3 - 5 YEARS

Roles and Responsibilities
Mandatory Skills: Python for Data Science-L2
Experience Range: 3-5 YEARS
We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law. Any complaints or concerns regarding the recruitment, application or hiring process should be directed to our Ombuds group www.wiproombuds.com. Any US applicant can also call our hotline at 1-866-921-6714. Applicants outside the US can request the applicable hotline number via email via the Ombuds group.

Wipro does not charge any fee at any stage of the recruitment process and has not authorized agencies/partners to collect any fee for recruitment. If you encounter any suspicious mail, advertisements or persons who offer jobs at Wipro, please do let us know by contacting us on helpdesk.recruitment@wipro.com",3.6,"Wipro LTD
3.6",Pune,"Bengaluru, India",10000+ employees,1945,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Cognizant Technology Solutions, Tata Consultancy Services, Accenture"
Data Engineering,-1,"Data Engineer

Job Purpose :
Analyzing, designing, developing and managing the infrastructure and the data that feeds Data Science models.
The Data Engineer is expected to be in charge of the whole lifecycle of the datasets, including updates, backups,
synchronization, and policy access.

Job Responsibilities :
Managing the lifecycle (from data collection to archive) of ML/DL datasets and ensure their
usability for Nielsen’s Data Scientists.
Design, build and integrate data from various sources.
Design ETL pipelines with scripted components.
Optimize data workflows, choosing the most cost-efficient approach.
Automate the management of recurrent task in the pipeline.
Perform feasibility studies/analysis with a critical point of view.
Support and maintain (troubleshoot issues with data and applications).
Develop technical documentation for applications, including diagrams and manuals.
Work on many different software challenges always ensuring a combination of simplicity and
maintainability within the code.
Contribute to architectural designs of large complexity and size, potentially involving several distinct
software components.
Working closely with data scientists and a variety of end-users (across different cultures) to ensure
technical compatibility and user satisfaction.
Work as a member of a team, encouraging team building, motivation and cultivate effective team
relations.

Role Requirements :
E=essential, P=preferred.

E - Bachelor's degree in computer engineering.
P - Master’s degree in data engineering or related.
E - Demonstrated experience and knowledge in Big Data and NoSQL databases.
E - Demonstrated experience and knowledge in Object-Oriented Programming.
E - Demonstrated experience and knowledge in distributed systems.
E - Proficient in programming languages: Python.
E - Experience designing and implementing data warehouses.
E - Experience developing ETL pipelines.
E - Experience working with distributed storage systems in the cloud (Azure, GCP or AWS).
P - Experience managing deep learning datasets.
P - Experience managing Cassandra.
P - Experience working with Spark.
P - Experience implementing CICD pipelines for automation.
E - Experience in the use of collaborative developing tools such as Git, Confluence, Jira, etc.
E - Problem-solving capabilities.
E - Strong ability to analyze and synthesize. (Good analytical and logical thinking capability)
E - Proactive attitude, resolutive, used to work in a team and manage deadlines.
E - Ability to learn quickly.
E - Agile methodologies development (SCRUM/KANBAN).
E - Ability to keep fluid communication written and oral in English, both written and spoken.
Experience level: Minimal work experience of 3-4 years with evidence.

To apply for this job please send your resume to connect@blackstraw.ai

Location :
Blackstraw.ai , Chennai, 4th floor, Tower C, Ratha Tek Meadows Rd, Elcot Sez, Sholinganallur, Chennai, Tamil Nadu 600119, India",4.6,"Blackstraw
4.6",Chennai,"Tampa, FL",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Big Data Engineer - Cloudera/ Hortonworks,-1,"Location : Visakhapatnam

Experience : 5-6 years

Notice Period : 30 days

Roles and Responsibilities :
Design & implement new components and various emerging technologies in Hadoop Eco System, and successful execution of various projects.
Integrate external data sources and create data lake/data mart.
Integrate machine learning models on real-time input data stream.
Collaborate with various cross-functional teams: infrastructure, network, database.
Work with various teams to set up new Hadoop users, security and platform governance which should be pci-dss complaint.
Create and executive capacity planning strategy process for the Hadoop platform.
Monitor job performances, file system/disk-space management, cluster & database connectivity, log files, management of backup/security and troubleshooting various user issues.
Design, implement, test and document performance benchmarking strategy for the platform as well for each use cases.
Drive customer communication during critical events and participate/lead various operational improvement initiatives.
Responsible for setup, administration, and monitoring, tuning, optimizing, governing Large Scale
Hadoop Cluster and Hadoop components: On-Premise/Cloud to meet high availability/uptime requirements.? - 2-4 years relevant experience in BIG DATA.
Exposure to Cloudera/Hortonworks production implementations.
Knowledge of Linux and shell scripting is a must.
Sound knowledge on Python or Scala.
Sound knowledge on Spark, HDFS/HIVE/HBASE
Thorough understanding of Hadoop, Spark, and ecosystem components.
Must be proficient with data ingestion tools like sqoop, flume, talend, and Kafka.
Candidates having knowledge on Machine Learning using Spark will be given preference.
Knowledge of Spark & Hadoop is a must.
Knowledge of AWS and Google Cloud Platform and their various components is preferable.",4.7,"innData Analytics
4.7",Visakhapatnam,"Visakhapatnam, India",1 to 50 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"3+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, data warehousing, and building ETL pipelines
Experience in SQL
- 5+ years of experience with and detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures.
- 4+ years of Big data(Hadoop) experience including one programming language JAVA/PYTHON/SCALA
3+ years of experience in architecting data warehouse solutions and integrating technical components
4+ years of experience with relational and star schema data modeling concepts
Experience in MPP systems such as Redshift, Netezza or Teradata.
-Experience in any big data technologies - Hadoop Eco Systems, EMR
3+ years of working with very large data warehousing environment
Demonstrated knowledge and experience in capacity planning for hardware and storage needs
The Finance Automation team at Amazon is looking for a Data Engineer to play a key role in building their industry leading Financial Data Warehouses. If you have experience in building and maintaining very large data warehouses with high transaction volumes then we need you!!!

The Data Engineer should be an expert familiar with all of the new age data engineering technologies (e.g. Distributed computing, MPP systems, Cloud, NoSQL databases, Data Models and atleast one programming language-JAVA/PYTHON/SCALA). The ideal candidate will be responsible for developing overall architecture and high level design. The candidate must have extensive experience with Star Schemas, Dimensional Models, Datamarts in Traditional Data Warehouses as well as in Big Data / Advanced Analytics domains. The individual is expected to bring a methodology and lead the framework development for the next generation data warehouse by designing an efficient, flexible, extensible, and scalable design and mappings and also will be working extensively on building big data environment.

Excellent written and verbal communication skills are required as the candidate will work very closely with a diverse team. The candidate will also lead a small technical teams or participate in close customer interactions while having an influencing role, and be accountable for deliverable's. Ability to create and manage work plans, timelines and accommodate multiple priorities is required.

Job Responsibilities
Tableau Skill is mandatory.
Applies broad knowledge of technology options, technology platforms, design techniques and approaches across the data warehouse life cycle phases to design an integrated, quality solution to address the business requirements
Meets and collaborates with business users on requirements, objectives and measures.
Designs the technology infrastructure across all technical environments
Ensures completeness and compatibility of the technical infrastructure to support system performance, availability and architecture requirements
Designs and plans for the integration for all data engineering components
Supervises the technical implementation of the data warehouse and oversees hardware/ software configuration
Provides input and recommendations on technical issues to the project manager
Reviews technical work of other team members
Reviews and participate in testing of the data design, tool design, data extracts/transforms, networks and hardware selections
Develops the implementation and operation support plans
Experience in PYTHON, BIG DATA and AWS.
Knowledge of Reporting tools such as OBIEE is preferred
Excellent communication skills, both written and verbal
Strong ability to interact, communicate, present and influence within multiple levels of the organization",-1,ADCI HYD 13 SEZ,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
Data Management - Digital Expert,-1,"A candidate for this position must have had at least 3 years of working experience working with business analysis/informatics and business outcomes research within a fast-paced and complex business setting, preferably working as support data scientist junior support personnel.

The candidate will also have experience working in probability and statistics, time-series analysis, or econometrics as well as experience in the use of machine learning methods, for example, linear regression, correlation, statistical significance, and so forth. A candidate for this position will also require strong programming skills and experience working with tools such as SAS, R Programming, Open Source, visualizations, and so forth.

A suitable candidate will also have had experience as well as in-depth knowledge of the Python programming language, SAS Enterprise Miner and substantial knowledge of big data platforms such as Aster and Hadoop.

Communication skills for the Data Scientist, both in written and verbal form are a must have. The Data Scientist will be required to explain advanced statistical content to senior data scientists and relevant stakeholders.

Therefore, he must have the ability to translate and tailor this technical content into business applicable material with clear recommendations and insights relevant to the audience at hand.

These reports and presentations will not only be translations of technical analyses into business applicable material, the reports have to be simple, concise, understandable and convincing, which will require exceptionally good communication skills on the Data Scientist’s part.

A candidate for this position must be technologically adept, demonstrate exceptionally good computer skills, and demonstrate a passion for research, statistics, and data analysis as well as a demonstrated ability and passion for designing and implementing successful data analysis solutions within a business.

The candidate must have a strong understanding of data-mining techniques and an ability to apply these techniques in practical real-world business issues. The Data Scientist will demonstrate an ability to consider data, identify patterns, issues, or data analysis needs for the business. The candidate must also have skills in the workings of SQL and scripting languages such as Python and Perl as well as familiarity with statistical analysis, data visualization, and data cleansing tools and techniques.

about you

Excellent customer service skills
Good leadership skills
Ability to build relationships with peers ,stakeholders and the management
Excellent interpersonal skills
Good time management, organizational and communication skills
Ability to work under pressure and deal with multiple tasks concurrently
Proactive, self-motivated
Problem solving skills
Matrix Management
Excellent knowledge of Service Management tools / processes

additional information

Degree / Diploma Holders with good Telecom / and IT infrastructure (Sever / Cloud / Security etc)
CCNA / ITIL Preferred
Excellent verbal & written communication skills in English
5 – 7 years of work experience, at least 3 years in telecom domain
At least 3 years of hands on experience in Data Science
Hands on experience on Power BI or Tableu Application

department

Customer Services & Operations

contract

Regular",3.9,"Orange
3.9",Mumbai,"Paris, France",10000+ employees,1988,Company - Private,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Vodafone, Deutsche Telekom, Telefónica"
CSII - Item and inventory - Senior Data Scientist,-1,"Our Company

We help people around the world save money and live better -- anytime and anywhere -- in retail stores, online and through their mobile devices. Each week, more than 220 million customers and members visit our 11,096 stores under 69 banners in 27 countries and e-commerce websites in 10 countries. With last fiscal revenues of approximately $486 billion, Walmart employs 2.2 million employees worldwide.

@ Walmart Labs in Chennai, we use technology for the charter of building brand new platforms and services on the latest technology stack to support both our stores and e-commerce businesses worldwide.

Our Team:

CSII Team is responsible for building data driven highly optimized supply chain suite of products to manage entire gamut of supply chain lifecycle for our retail and ecommerce lines of business. With our rapidly increasing footfalls in stores and exponential growth in online orders; this all has to be done to scale millions of owned and marketplace SKUs complete inbound and outbound fulfilment lifecycles.

Teams mission - Enable customers to receive their orders when and where they want in an innovative and cost effective way for Walmart derives from Walmarts mission statement - Save Money. Live Better complementing our organizations philosophy to deliver low prices every day, on everything.

How we achieve this, comes down to the team of smartest technologists from India focused on the entire suite of supply chain management products for the Walmart Supply Chain at a massive scale. From forecasting & replenishing inventory for millions of items worth billions of dollars, sourcing of millions of orders, to route optimization & last mile delivery to Warehouse Management Systems to most advanced grocery & order management systems; technology is the backbone behind the entire platform enabling the massive cloud-scale supply chain from India.

With over 4,000 associates in Silicon Valley, San Diego, Portland, Brazil, United Kingdom and India, were bringing together some of the best professionals from around the world. If youre inspired by the opportunity to solve complex problems at scale and make a difference for our customers and members, join us.

Your Opportunity

Data Science

This position Data Science , will be on the Walmart Labs Supply Chain team, focused on building Walmart's best in class Supply Chain. At Walmart Labs, you will Work with small teams of talented analyst to build a best-in-class supply chain at Walmart. Be given the freedom to try new things and prove the value of your own ideas and innovations and own them all the way to production Identify and facilitate the removal of team impediments and escalate as appropriate Foster a motivating culture of openness, collaboration, and continuous improvement Ensure business needs are being met using Data Science best practices Participate in internal hackathons and innovation challenges!.

Your Responsibility

· Develop interactive statistical models using the latest frameworks.

· Develop Machine learning modelling leveraging existing frameworks and customizing to problem.

· Find workable solution in case of data inconsistency and inconclusive data

· Drive projects with minimal guidance. Provide thought leadership by researching best practices and conducting experiments

· Evaluate various analytical/statistical methods and procedures and provide recommendation of relevance, applicability, efficiency of those to Walmart Catalog teams

· Work with cross functional group consisting of Engineering, Product, Program managers to drive data based decisions

Your Qualifications

· Bachelors degree in computer science or related discipline with 8+ years experience (5+ Relevant)

· Practical experience with SAS, ETL, data processing, database programming and data analytics

· Proficient is Sql and no-sql languages, R, Python

· Worked on gathering data from Cassandra, Kafka, MongoDBs. Work with big data on GCP and Azure.

· Advanced statistical modelling skills

· Handled multi-million records of data. Troubleshooting and fixing data issue

· Data Visualization in any BI tools like Tableau, PowerBI, etc.,

· Collected, analyzed, and reported data to meet customer needs.

· Understanding and application of statistical concepts to solve business problems",3.3,"Walmart
3.3",Chennai,"Bentonville, AR",1001 to 5000 employees,1962,Company - Public,"Department, Clothing, & Shoe Shops",Retail,₹500+ billion (INR),"Target, Costco Wholesale, Amazon"
Data Analyst,-1,"Netomi is a Y-Combinator and VC-backed Artificial Intelligence company that sits at the intersection of two rapidly developing fields: AI and messaging. We do not sell an abstract, futuristic technology - we sell a solution that a large number of Fortune 500 companies are using today to drive engagement and sales across the entire customer journey. By leveraging deep reinforcement learning and our continuously learning neural network, our customers are able to successfully meet their objectives of generating social engagement, driving commerce and providing customer service. We're building the future of how technology and people work together to create frictionless experiences for customers.

Want to have a direct impact in solving the top challenges businesses face today? Join us!

Job Description:

We are looking for a Data Analyst who can help us dig into raw data, analyse it and draw conclusions that help in making business decisions.
Responsibilities
Business Analysis to understand the client's business and work with Data Analysts to define the Deep Learning (DL) model
Quality Assurance of Deep Learning models
Analyze the conversation quality in chatbots
Leverage multiple crowdsourcing strategies to collect training and test data for DL models and help with cleansing, filtering and massaging those data
Providing a high level of data quality awareness across multiple teams
Evaluate and identify where enhancements of data to maintained higher quality data
Detailed testing feedback preparation to help the team to improve the models.
Monitor and improve the Data Quality Assurance process that can meet/exceed the current standards and procedures
Learn and/or leverage the required software tools and technology

Requirements
0-1 years experience in related field
Bachelors degree from a Tier I/Tier II college
Knowledge of any one foreign language - French, Spanish or Russian
Excellent written and verbal communication skills
An eye for detail and accuracy",4.8,"Netomi
4.8",Gurgaon,"San Francisco, CA",51 to 200 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"HP is the world’s leading personal systems and printing company, we create technology that makes life better for everyone, everywhere. Our innovation springs from a team of individuals, each collaborating and contributing their own perspectives, knowledge, and experience to advance the way the world works and lives.

We are looking for visionaries, like you, who are ready to make a purposeful impact on the way the world works.

At HP, the future is yours to create!

We are Pricing Analytics Team; our main objective is to help the business to decide optimal price for the HP products in a scientific way through statistical and predictive analysis.

If you are our Data Engineer in India, you will get an opportunity to work on below.

Designs and establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data pipelines, repositories or models for structured data.
Analyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.
Writes and executes complete pipeline plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs and creates solutions for issues with data sources and integration into data system architecture.
Collaborates and communicates with project team regarding project progress and issue resolution. Represents the data engineering team for all phases of larger and more-complex development projects. Provides guidance and mentoring to less experienced staff members.

Are you a high-performer? We are looking for an individual with.

Well versed knowledge on SQL servers and database solutions.
Python programming language to create efficient data flow
Various operating systems like Linux, windows, Unix which will enable data interconnection Data warehousing and ETL tools Good to have.
Knowledge on R and visualization tools such as Power BI / Tableau/ R Shiny Data architecture skills to create effective data flow Team player to interact and understand the data based on data scientists and analysts
#LI-Post",3.3,"HP
3.3",Bengaluru,"Houston, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"The Role: Senior Data Analyst

The Location: Mumbai

The Grade: 11

The Team: The Global Data Management team within the Global Index Management & Production Group.

The Impact: The Senior Data Analyst is responsible for the acquisition, management and quality of a variety of data items used for the production and maintenance of S&P Dow Jones-branded indices.

The successful candidate will be expected to set the standard in carrying out tasks associated with the management of data used for the production and maintenance of indices, setting an example for more junior analysts to follow.

Additionally, the Senior Data Analyst is responsible for a wide range of data points across global markets and may be required to make presentations to Index Committees on matters impacting the maintenance and particularly the rebalancing of S&P DJI global indices, making in-depth knowledge of their product line essential.

Whats in it for you: As a Senior Data Analyst, you will work collaboratively with a wide range of data points, indices and other products across global markets. You must be able to analyze and implement complex data processes and calculation methodology and solve non-routine problems on an on-going basis.

Responsibilities:

The Senior Data Analyst will be a subject matter expert, an example and escalation point for more junior team members and will support the team leader.

In addition, the Senior Data Analyst will be required to:
Demonstrate organizational skills by ensuring that processes for the capture, quality screen and presentation of data sets are completed in time for their delivery to end clients or use in the further calculation or rebalancing of indices
Preparing and calculating fundamental ratios for S&P and Dow Jones branded indices, ensuring timely and accurate delivery of index data to clients and end users
Develop a detailed understanding of the way each data set is used in the production and maintenance of S&P Dow Jones Indices, ensuring the Senior Data Analyst is able to identify and resolve issues and ensure the data is fit for purpose
Serve on index committees and make presentations of original, non-routine analysis to committee in support of the data items for which the Senior Data Analyst is responsible. Decisions reached by committee determine index composition and drive asset allocations.
Take responsibility for the management of high profile data sets, acting as an industry expert and displaying in-depth knowledge of our product lines.
Provide timely and accurate responses to enquiries from internal groups and external clients, through our client services team
Manage and maintain key relationships with other groups within the department and across other departments, particularly Product Management, Client Coverage, Index Services and IT Support
Work in close coordination with the technology group and production support group to further enhance our system capabilities
Qualifications:
A demonstrable, deep understanding of global financial markets and financial data, particularly company fundamentals
Familiarity with Environmental, Social and Governance (ESG) themes in finance and particularly ESG data providers would be considered an advantage
Must be able to work independently on multiple projects with minimal direction or supervision.
Ability to assume responsibility, work with others and manage projects
Bachelors Degree. Advanced degree in business, math, economics, or finance strongly preferred
Minimum of 4 years of professional experience working with financial indices.
Strong understanding of how indices are used, the impact of different methodologies, corporate event events on both indices and financial portfolios.
Superior computer skills in Excel, Word and related applications. Access, VBA, SQL and/or Python would be an advantage.
Ability to learn S&Ps proprietary index calculation systems and requirements
Excellent analytical and numerical capabilities to aid in solving non-routine problems in a timely fashion
About us:

At S&P Dow Jones Indices, our role can be described in one word: essential. Were the largest global resource for index-based concepts, data and research, and home to iconic financial market indicators, such as the S&P 500® and the Dow Jones Industrial Average®. More assets are invested in products based upon our indices than any other index provider in the world; with over 1,000,000 indices, S&P Dow Jones Indices defines the way people measure and trade the markets. We provide essential intelligence that helps investors identify and capitalize on global opportunities.

S&P Dow Jones Indices is a division of S&P Global (NYSE: SPGI), which provides essential intelligence for individuals, companies and governments to make decisions with confidence. For more information, visit www.spdji.com.",3.7,"S&P DOW JONES INDICES
3.7",Mumbai,"New York, NY",201 to 500 employees,-1,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,-1
Data Analyst,-1,"Have Accounting background.
Data analysis of the records
Good Communication
Excellent Excel Knowledge
Job Type: Full-time
Salary: ₹240,000.00 - ₹480,000.00 per year
Experience:
work: 3 years (Preferred)
total work: 3 years (Preferred)
Education:
Master's (Preferred)
Work Remotely:
No",3.3,"Express Roadways Pvt Ltd
3.3",Hisar,"Mumbai, India",5001 to 10000 employees,-1,Company - Public,Transportation Management,Transportation & Logistics,Unknown / Non-Applicable,-1
Sr. Data Analyst,-1,"1. Hands-on professional with in-depth knowledge and High level of Proficiency in Qlikview scripting.
2. Use of complex QlikView functions, advance Qlikview expressions.
Knowledge of Qlikview scripting features such as Resident Tables,loops and other advanced scripting fuctions.
3.Hands on experience with complex data models.
4.Understanding of BI/data warehouse concepts, Star schema/snowflake models, SCDs, fact and dimension tables, SQL etc.
5. Good Knowledge of Python especially in packages Pandas and numpy.
5.Must have written SQL queries for extracting data for varied complex scenarios with an exposure to big data environment.
6.Have practical experience using the windowing and analytic functions in SQl.
7.Good knowledge of Excel functions including index,match,array and other advanced functions in excel.
8. Candidate must have strong problem solving, logical and analytical skills.

What You Need for this Position

You should have knowledge of:
QlikView functions
advance Qlikview expressions
BI/data warehouse concepts
Star schema/snowflake models
SCDs
fact
SQL
Aditional
No. of Positions
Education level
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
HIVE Data Engineer- Bangalore,-1,"Description

6sense is a Predictive Intelligence Engine that is reimagining how B2B companies do sales and marketing. It works with big data at scale, advanced machine learning and predictive modeling to find buyers and predict what they will purchase, when and how much.

6sense helps B2B marketing and sales organizations fully understand the complex ABM buyer journey. By combining intent signals from every channel with the industry's most advanced AI predictive capabilities, it is finally possible to predict account demand and optimize demand generation in an ABM world. Equipped with the power of AI and the 6sense Demand Platform™, marketing and sales professionals can uncover, prioritize and engage buyers to drive more revenue.

6sense is seeking a Data Engineer to become part of a team designing, developing, and deploying its customer centric applications.

A Data Engineer at 6sense will have the opportunity to
Create, validate and maintain optimal data pipelines, assemble large, complex data sets that meet functional / non-functional business requirements.
Improving our current data pipelines i.e. improve their performance, remove redundancy, and figure out a way to test before v/s after to roll out.
Debug any issues that arise from data pipelines especially performance issues.
Experiment with new tools and new versions of hive/presto etc. etc.
Required qualifications and must have skills
BE/BTech/BS or equivalent
Excellent analytical and problem-solving skills
6+ years work experience showing growth as a Data Engineer.
Strong hands-on experience with Big Data Platforms like Hadoop / Hive / Spark / Presto
Experience with writing Hive / Presto UDFs in Java
String experience in writing complex, optimized SQL queries across large data sets
Experience with optimizing queries and underlying storage
Comfortable with Unix / Linux command line
Nice to have Skills
Used Key Value stores or noSQL databases
Good understanding of docker and container platforms like Mesos and Kubernetes
Security-first architecture approach
Application benchmarking and optimization
Interpersonal Attributes
You can work independently as well as part of a team
You take ownership of projects and drive them to conclusion
You're a good communicator and are capable of not just doing the work, but teaching others and explaining the ""why"" behind complicated technical decisions
You aren't afraid to roll up your sleeves: This role will evolve over time, and we'll want you to evolve with it!",5.0,"6sense
5.0",Bengaluru,"San Francisco, CA",51 to 200 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Science Online Trainer,-1,"Job Id : PTPL/HR/8

Anywhere in India

1+ year experience in Data Science. Must have worked on minimum 2 Data Science Projects and must have at least 50 hours experience in online training on Data Science topics.",3.5,"Prognoz
3.5",India,"Perm, Russia",1001 to 5000 employees,-1,Company - Private,Research & Development,Business Services,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Company Description

Cermati is a financial technology (fintech) startup based in Indonesia. Cermati simplifies the process of finding and applying for financial product by bringing everything online so people can shop around for financial products online and can apply online without having to physically visit a bank.

Our team hailed from Silicon Valley Tech companies such as Google, Microsoft, LinkedIn and Sofi as well as Indonesian startups such as Doku, Touchten. We have graduates from well known universities such as Universitas Indonesia, ITB, Stanford, University of Washington, Cornell and many others. We are building a company with the same culture of openness, transparency, drive and meritocracy as Silicon Valley companies. Join us in our cause to build a world class fintech company in Indonesia.

Job Description

The candidate should be able to design high performance, maintainable, extensible software architectures to solve abstract business problems. Here are some example business problems:
""We want to reduce the time for productionizing experimental machine learning features to 1 day""

""We want to completely automate the credit approval process while maintaining an accuracy of >90% when compared with manual approval""

They should be able to translate the high level design into a series of tasks that can be executed by other software engineers working in parallel

The high level designs are usually design documents consisting of relevant block diagrams, UML diagrams meant to be consumed by other engineering leaders and software engineers

They must be able to work with international teams effectively. They will be required to communicate with:
- Clients who may not necessarily be software engineers (marketing teams, business development team etc)
- Software engineers and tech leads to communicate the design in a simple yet accurate language without compromising details.
They would be leading a team of talented but possibly inexperienced engineers who will look to you for mentorship. In a typical day, candidates would be spending
10% of the time project management, 20% of the time doing code review and mentorship, 20% of the time coding (evaluating technologies, doing PoC, etc) 50% of the time requirement gathering, high level design, low level design, roadmap etc

The following technical skills would be useful:
Candidates must be able to understand the tradeoff between performance, simplicity, maintainability and timeline constraints when developing software solutions
Strong hands on experience in java, python is required. Must have shipped multiple projects with a major hands on contribution to each project.
Experience in Big data technologies: hadoop ecosystem (mapreduce, spark, kafka)
Experience in different storage technologies: OLTP like postgres, OLAP like redshift, Google bigquery, NoSQl like redis, hbase, kafka
Familiarity with machine learning algorithms and concepts (gradient descent, logistic regression) and software libraries like pandas, tensorflow, etc
Qualifications

The following technical skills would be useful:
Candidates must be able to understand the tradeoff between performance, simplicity, maintainability and timeline constraints when developing software solutions
Strong hands on experience in java, python is required. Must have shipped multiple projects with a major hands on contribution to each project.
Experience in Big data technologies: hadoop ecosystem (mapreduce, spark, kafka)
Experience in different storage technologies: OLTP like postgres, OLAP like redshift, Google bigquery, NoSQl like redis, hbase, kafka
Familiarity with machine learning algorithms and concepts (gradient descent, logistic regression) and software libraries like pandas, tensorflow, etc
Additional Information

Impressive Benefits and flexible work culture.",4.2,"Cermati.com
4.2",Bengaluru,"Jakarta, Indonesia",1 to 50 employees,-1,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
CIEL/SEL/13651: Data Scientist,-1,"Job Description
Key points about the position are as below;
Hadoop - working knowledge

PL SQL
Python or R
Inferential Statistics
ML - must have implemented at least one algorithm
Visualisation - Tableau preferred, BI, Spotfire
Service Delivery, communication skills
Statistical education background
Production model experience using ML with any algorithm. Worked on real time projects

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
Data Engineer,-1,"Job Type: Full time Experience: 2+ years Hyderabad

Job Description:
We are looking for a savvy Data Engineer to join our growing team. We work with fortune 500 companies to build their data infrastructure and help them with their data journey. The Data Engineer will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing the data flow. The Data Engineer will help generate data pipelines and subsequently with DataOps. He/ She must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.

Qualifications:
2+ years of experience in building data pipelines.
Experience building data pipelines using StreamSets or Azure Data Factory.
Understanding of stream processing with knowledge on Kafka.
Experience with scripting languages i.e. Python, Perl, etc.
Experience with SQL (RDBMS), NoSQL (MongoDB), and PostgreSQL.
Understanding of data flows, data architecture, ETL and processing of structured and unstructured data.
Current experience developing and deploying applications to a public cloud (AWS, GCE).
Experience with DevOps tools (GitHub, Jira) and methodologies (Lean, Agile, Scrum).
Experience with ETL, Data Modeling, and working with large-scale datasets. Extremely proficient in writing performant SQL working with large data volumes.
Experience on Azure DevOps is a plus.
Ability to manage competing priorities simultaneously and drive projects to completion.

Desired Candidate Profile:
Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Engineering).
Excellent written and verbal communication skills in English.
Experience in working in agile (SCRUM) methodology.",4.0,"Modak Analytics
4.0",Hyderabad,"Hyderabad, India",201 to 500 employees,2010,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst (NLP),-1,"Department: Analytics

Experience: 3-5 Years

Location: Chennai

Job Description
Should have experience in developing efficient code in R / Python
Sound have understanding of statistical concepts behind data modelling
Experience in training and deploying models based on Stanford Core NLP.
Experience with machine learning, preferably one or more among Tensorflow, Theano, Deeplearning4J, Torch
Experience developing backend systems involving NoSQL databases and Graph Databases
Experience and familiarity with the concepts of threading, concurrent execution methodologies including monads
Familiarity with text-to-speech
Familiarity with modern speech recognition engine technology. LVCSR, HMMs, DNNs.
Familiarity and experience with open-source/commercial NLP toolkits such as Stanford NLP, NLTK, Tensorflow, Apache Lucene/Solr, GATE
Knowledge of techniques for critical problem/application areas in NLP such as Named Entity Extraction, PoS tagging, parsing, semantic analysis, ambiguity resolution, pronoun resolution, sentiment analysis, summarization
Sound understanding behind machine learning algorithms like SVM, KNN, Decision tree etc.
NLP analyst to work with Clients and Senior analyst / SME to bring insights using AI/ML/NLS techniques.
Conduct all job functions and responsibilities in accordance with all company Compliance, Information Security and Regulatory policies, procedures and programs.",3.1,"SCIO Health Analytics
3.1",Chennai,"West Hartford, CT",501 to 1000 employees,2007,Company - Private,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),-1
Computer Vision - Data Scientist,-1,"Arya.ai is looking for ambitious and talented computer vision researchers with strong skills in software development to join our research team. If you get excited by the prospect of analyzing and modelling terabytes of data and creating state-of-the-art algorithms to solve real-world problems and by owning business problems/metrics, then we have the perfect role for you. Here you will have the ability to thrive in a dynamic environment combining conceptual and applied research, systems building and collaborative work. You will work together with similar minds in a unique development team where your skills and expertise will be put to the test.

*
Major responsibilities:
*
Research, design, implement and evaluate novel computer vision algorithms

- Work on large-scale datasets, focusing on creating scalable and accurate computer vision systems in versatile application fields

- Collaborate closely with team members on developing systems from prototyping to production level

- Able to derive model’s risk towards business and communicate with corresponding business managers

- Track general business activity and provide clear, compelling management reports on a regular basis
*
Qualifications Required:
*
Hands-on experience in Computer Vision and Deep Learning

- Broad knowledge of fundamentals and state-of-the-art in computer vision

- High proficiency in C/C++ or Python

- Ability to develop large-scale systems working with image/video data

- Strong working knowledge of software architecture and data structure

- Excellent problem-solving ability

- Minimum of 2-year experience in Deep Learning(CNNs, RNNs, Attention-based Networks, etc)

- Minimum of 2-year experience in Computer Vision (Image/Video Processing)
Job Type: Full-time",3.5,"Arya.ai
3.5",Mumbai,"Mumbai, India",1 to 50 employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"Start : Immediate
Must Have Technical expertise
Strong Experience with SQL, T-SQL
Strong Experience with Power BI
Experience with data extraction, cleansing and loading into a database using integration tools such as Talend or using Microsoft tools or Python data wrangling libraries
Ability to understand a problem and produce technical solutions
Good to Have Technical experience
Azure Cosmos DB NoSQL
Azure Synapse Analytics
Python Data Science Libraries
Good to Have Functional experience
Supply Chain or Manufacturing
Finance
Experience: 4+ years, 6+ years
Job Type: Full-time
Experience:
Power BI: 4 years (Preferred)
Talend: 3 years (Preferred)
SQL, T-SQL: 4 years (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Work Remotely:
Yes",2.0,"Aavid Software
2.0",Pune,"Pune, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Hands on experience working with Cloud Platform - Preferred AWS
Good experience working with ETL Tools - Cloud based (AWS) + Others (Talend)
AWS Services - S3, Redshift, Athena, Glue, DMS, Lambda. Good to have knowledge about AWS Infra
Hands on working with any RDBMS & NoSQL DBs.
Good understanding of DB Concepts & SQL Queries. PL/SQL, Stored Procedures, Optimization & Performance Tuning
Experienced in Data Migration
Experience working with Spark, Hadoop, HDFS, Scala
Good To have big data knowledge
Knowledge of Data Visualization Tools (like Tableau)
Knowledge working with Data-warehouses (Cloud based)
Good understanding & working experience in any programming language
Good to have experience working in Python
00-5.00 Years",3.5,"Unitforce Technologies Consulting Pvt Ltd
3.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
"Data Engineer Oracle, ETL for NFRM IT",-1,"Job Description:


Position Overview

Role Description:

The Oracle developer will be responsible for developing, enhancing and maintaining applications in the Non Financial Risk (NFR) domain. The activities shall be performed in accordance with the defined tools/technologies of the project , shall adhere to the standards and processes followed in the organization & project. Additionally, the developer will be a partner to the development and Level 2 support organizations and shall work on any issues in the production environment for which the Development’s team help is required.

Tasks |Responsibilities:
Develop a good understanding of the activities required to execute the development/bug fix activity.
Actively participate and contribute in Agile ceremonies including Daily Stand up’s, Sprint Planning, Sprint review, Sprint retrospective meetings
Take part in software and architectural design activities
Perform analysis, development, testing and debugging/defect fixing for the assigned stories/bug fixes
Develop the required functionalities using the appropriate database technologies
Write unit tests for the developed code.
Recommend changes to improve established application processes.
Integration of changes with other user stories developed by team members
Deployment in Development/integration/UAT environments
Create required documentation for the project.
Meet the SLA’s for any assigned defects.
Development and delivery KPI’s shall be met.
Shall be ready to learn new technologies as per the project requirements.
Experience | Knowledge
10+ years combined experience as software developer. Well aware of the Agile methodology.
Hands on experience in SQL and relational databases, preferably Oracle 10G and higher
Experience with database migration, database upgrade activities
Experience with performance tuning, indexing, partitioning
Experience using the Git version control system, Jenkins, Nexus and Sonar.
Proficient in Linux/Unix system.
Experience working with high availability and high performance systems.
Should be aware of the release/deployment and application support processes (Incident/problem/change management etc.)
Basic knowledge of Oracle database management system
Experience using atleast one ETL tool
Experience in datawarehousing
Good to have experience with BI tools like SAP Buiness Objects or Cognos reporting
Good to have experience with big data technologies
Education | Certification

Bachelor degree from an accredited college or university with a concentration in an IT related discipline

Our values define the working environment we strive to create – diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer.

We promote good working relationships and encourage high standards of conduct and work performance. We welcome applications from talented people from all cultures, countries, races, genders, sexual orientations, disabilities, beliefs and generations and are committed to providing a working environment free from harassment, discrimination and retaliation.

Click here to find out more about our diversity and inclusion policy and initiatives.",3.5,"Deutsche Bank
3.5",Pune,"Frankfurt am Main, Germany",10000+ employees,1870,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),-1
Data Science Engineer - Start Up Software Company Baner,-1,"Responsibilities:
Design and build highly scalable nlp pipelines
Design and write custom algorithms to solve domain specific problems
Build POCs using open-source libraries for independent modules
Create AI solutions for automated dialogue (chat bots); natural texting for knowledge & expertise recommendations.
Build & train NLP platform from user generated textual data (email, IM, search logs) on daily basis
Code ML models primarily using python, No-Sql & AWS
Collaborate with other team members and stakeholders.

Requirements:
5+ years experience in web-app development, with minimum 2+ years of NLP experience .
Proficiency in Data Structures & Algorithms .
Experience with open-source NLP libraries such as spacy, NLTK
Experience with MySQL, Mongo-DB & Neo4j
Experience with Word2Vec, Glove, RNN, LSTM
Experience with Data Pipeline Frameworks such as AWS Data Pipeline
00-7.00 Years
Masters in Technology (M.Tech/M.E/M.Sc), Master in Computer Application (M.C.A), Bachelor Of Technology (B.Tech/B.E)",5.0,"Seventh Contact Hiring Solutions
5.0",Pune,"Pune, India",1 to 50 employees,-1,Private Practice / Firm,-1,-1,Unknown / Non-Applicable,-1
ANALYST-DATA SCIENCE-PYTHON,-1,"Apply machine learning techniques to deliver actionable insights from large-scale, multi-structured datasets. Work with internal and external teams to develop models (ranging from data exploration to feature engineering and model development to validation and scoring.) and put them into production This is an individual contributor profile wherein the candidate is required to work in collaboration with the AMs and DMs Machine Learning techniques (recommendation engines, ensemble models such as random forests, bagging and boosting, support vector machines, dynamic optimization etc.) Design and build systems that mine massive datasets and structure/ engineer it to be usable for machine learning models
Salary Negotiable
Industry IT Software
SubIndustry Software Development
Functional Area IT Software Development
Specialization IT/Technical Content Developer
Role Manager / Sr. Manager Level
Keyskills
NLPText MiningMachine Learning
Desired Candidate Profile
Please refer on JD
Education
Highest Qualification
Graduation Any Graduate",5.0,"Fine Jobs
5.0",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Digital - Associate Program Manager - Analytics Consultant,-1,"SKILLS REQUIRED:
Advanced Analytics, Predictive Analytics",3.4,"eClerx
3.4",Mumbai,"Mumbai, India",5001 to 10000 employees,2000,Company - Public,Consulting,Business Services,₹10 to ₹50 billion (INR),"Genpact, WNS, Convergys"
"ES Tech, Data Engineer",-1,"Do you love data as much as we do? Do you want to influence at Amazon? We have the career for you!

Amazon's Employee Services Technology (ES Tech) team is seeking an outstanding ETL/Data Engineer to join our BI team to build out the BI platform with all of the data ingestion mechanisms required for the initiative. Our platform delivers business intelligence to a diverse, global community of internal customers from one of the worlds largest and most complex financial data sets. Amazon has culture of data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable.

You will be responsible for designing and implementing solutions using third-party technology and Amazon cloud technologies. A successful candidate knows and loves working with business intelligence ETL tools, is comfortable accessing and working with big data from multiple sources, and passionately partners with the business to identify strategic opportunities and deliver results. You should have an internal drive to answer why? questions, excellent analytical abilities, strong technical skills, as well as superior written and verbal communication skills. S/he would be a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail), and enjoy working in a fast-paced dynamic environment.

Responsibilities include:
· Drive the collection of new data and the refinement of existing data sources to continually improve data quality
· Support data analysts and product managers by turning business requirements into functional specifications and then executing ETL delivery
· Lead the technical lifecycle of data presentation from data sourcing to transforming into user-facing metrics





Basic Qualifications

· Bachelors or Masters Degree in Computer Science, Systems Analysis, or related field
· 3+ years experience in data modeling, ETL development, and Data Warehousing
· 1+ years experience with BI/DW/ETL projects.
· Knowledge of AWS product suite including S3, Redshift, Dynamo DB and RDS.
· Experience in scripts like Python, Java, javascript etc.
· Technical guru; SQL expert.
· Experience with Linux, UNIX, UNIX tools
· Experience writing software to automate manual workflows
· Good instincts; you know what it means to be a subject matter expert and how to be a team player



Preferred Qualifications


Strong background in data relationships, modeling, and mining.
Mulesoft experience a plus.




Amazon is an Equal Opportunity Employer",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Analyst,-1,"Responsibilites :
Backgrounds in technology, information management, relational database design and development, business intelligence, data mining or statistics.
Solid understand of data analysis techniques or processes will help reduce the need for you to learn every data analysis tool in the market
Experinece in importing, cleaning, transforming, validating or modeling data with the purpose of understanding or making conclusions from the data for decision making purposes.
Experinece in Performing audit on data and resolve business related issues for customer base
Experinece in Performing data analysis and facilitate in delivery to all end users.
Explorering sift through mountains of data to discover the data you actually need

Send us the Resume at info@zettamine.com",3.8,"ZettaMine
3.8",Hyderabad,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Big Data Engineer,-1,"Data Engineer

About Print Analytics

As part of the HP Inc. R&D Centre, Print Analytics Team work closely with Print GBU of HP Inc. across multiple domains. We deploy data products and analytics assets, provide data-driven actionable insights to influence business decisions.

Within Print Analytics, Supplies Analytics Team seeks to deploy data products through designing table structures and data flows, automating repetitive data tasks, building and maintaining data dictionaries, finding/resolving data anomalies and data errors. This would, in turn, result in delivering complex analysis and improving intelligence.

Business Environment

Supplies Analytics Team strategically partners with Big Data Business Transformation organization to deploy data products and deliver analytics to help them discover new opportunities and solve their business challenges in a data driven manner.

Role Description:

In order to deploy data products, we are looking for a high caliber and detail-oriented Data Engineer who can work in collaboration with cross-functional, cross-regional teams to establish and improve data pipelines. She / He will also be responsible for designing table structures and data flows, automating repetitive data tasks, building and maintaining data dictionaries, finding/resolving data anomalies and data errors. This would, in turn, enable downstream data analyses and AI/ML models.

The analyst would act as an informed team member who can help bridge technical data requirements.

Responsibilities:
Establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data platform, repositories or models for structured/unstructured data.
Analyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.
Writes and executes complete testing plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs, and creates solutions for issues with code and integration into data system architecture.
Collaborates and communicates with project team regarding project progress and issue resolution.
Works with the data engineering team for all phases of larger and more-complex development projects and engages with external users on business and technical requirements.
Collaborates with peers, engineers, data scientists and project team.
Typically interacts with high-level Individual Contributors, Managers and Program Teams on a daily/weekly basis.
Defines and leads portions of project requirements for data exchanges and business requirements with externals and internal teams
Creates plans, data collection and analysis procedures and works with data insight visualization teams for assigned projects.
Collaborates with internal and external partners to perform experiments and validations in accordance with overall plan.
Collaborates with SMEs to develop procedures for collecting, recording, analyzing, and communicating data for review and feedback.
Education and Experience Required:
Bachelor's or Master's degree in Computer Science, Information Systems, Engineering or equivalent.
4-6 years experience in a data analyst or data engineering type role.
Knowledge & Skills:
Using data engineering tools, languages, frameworks to mine, cleanse and explore data.
Fluent in relational based systems and writing complex SQL.
Fluent in programming and automating repetitive tasks preferably using VBA and Python
Fluent in complex, distributed and massively parallel systems.
Strong analytical and problem-solving skills with ability to represent complex algorithms in software.
Designing data systems/solutions to manage complex data.
Strong understanding of database technologies and management systems.
Strong understanding of cloud-based systems/services, including the AWS environment.
Database architecture testing methodology, including execution of test plans, debugging, and testing scripts and tools.
Ability to effectively communicate product architectures, design proposals and negotiate options at management levels.
Using scientific design and data collection methodologies, tools and analysis packages to collect, validate, and analyze research data.
Excellent written and verbal communication skills
Strong interpersonal skills and ability to work in a collaborative environment",4.1,"HP Inc.
4.1",Bengaluru,"Palo Alto, CA",10000+ employees,1939,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Science Trainer,-1,"Should have a strong knowledge on Machine Learning, Deep Learning, R Programming; Python,Statistics,Hadoop etc
Understanding and assessing individual (or) group training requirements.
Execute workshops to create awareness of the latest technologies.
Up to date knowledge of IT skills and software packages.
Designing the Course modules appropriate to the skills needed.
Helping IT Professionals in updating their skills with latest technologies.
Evaluating each and every Individual progress and outcomes.

Job Types: Full-time, Part-time

Salary: ₹300,000.00 - ₹500,000.00 per year

Experience:
total work: 5 years (Preferred)
Training: 5 years (Preferred)
Education:
Bachelor's (Preferred)
Location:
Ameerpet, Hyderabad, Telangana (Preferred)
Work Remotely:
Temporarily due to COVID-19",3.7,"Naresh I Technologies
3.7",Telangana,"Hyderābād, India",51 to 200 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Research Scientist,-1,"Role Purpose:

To perform the formulation/AI
product chemistry studies and work, as discussed with the Team Leader
T&E, to agreed timelines.
Ensure HSEQ as per site policy
and local Regulation requirements
Maintain Laboratory and
equipment as per GLP requirements.
Support the Study
Director to GLP studies and documentation
Update GLP data in team space
Accountabilities:

Excellent experimental skills i.e., perform and
document analytical and product chemistry work as per GLP
Minimum of 2-4 years’ experience with good technical
knowledge of LC and/or GC, preferably both, in an industrial setup.
Knowledge of method development/Validation of
Chromatographic methods
Good hands on experience on spectroscopic techniques
viz. LCMS, GCMS, NMR etc. with at least 3 years practical experience.
Able to plan and organize his/her work to achieve a
high level of productivity and to meet important deadlines
Maintain Laboratories and assigned Equipment used for
GLP studies and document as per the GLP requirements
Contribute to a product chemistry group and conduct,
under the direction of a study director, studies that fully meet world-wide
regulatory requirements to facilitate registration.
Characterize analytical references and certified
substances to meet development and production schedule requirements
Good understanding of GLP, SOPs and knowledge of
formulation/A.I. Product Chemistry
Ensure HSE and waste disposal as per the site policy
Communicate results and
programs effectively with staff, peers, and customers
Ensure compliance with all company HS&E policies
and GLP. Train junior scientist to enable safe and competent performance.
Knowledge, Skills and
Experience:
PhD degree in Chemistry preferable in analytical or
allied Science, area from the reputed Universities with strong academic records
and good communication skills and sound in instrumentations. with >2 years
of industrial experience preferable worked in GLP facility
Or
Master degree in Chemistry preferable analytical or
allied Science, area from the reputed Universities with strong academic records
and good communication skills with >3 years of industrial experience.
Experience Analytical Chemist with sound GLP experience is
desirable,
Excellent experimental skills
Able to plan and organize work to achieve a high level
of productivity and to meet important deadlines.
IT literate relevant to work
Sound understanding of GLP and knowledge of
formulation/AI Product Chemistry
Good knowledge of written English
Team player, flexible and with people skill
Behaviors:

Team-Oriented
Demonstrates
personal commitment to the team
Values
and uses individual differences and talents
Results-Oriented
Works
tenaciously to deliver agreed goals
Self-disciplined
to achieve results through effective prioritisation and timely delivery
Communicative
Ensures
structure and clarity in both verbal and written messages
Provides
timely communications and feedback to stakeholders",4.0,"Syngenta
4.0",India,"Basel, Switzerland",10000+ employees,2000,Company - Public,Chemical Manufacturing,Manufacturing,₹500+ billion (INR),-1
Data Engineer/Python Spark Developer,-1,"The Applications Development Intermediate Programmer Analyst is an intermediate level position responsible for participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to contribute to applications systems analysis and programming activities. Responsibilities: Utilize knowledge of applications development procedures and concepts, and basic knowledge of other technical areas to identify and define necessary system enhancements, including using script tools and analyzing/interpreting code Consult with users, clients, and other technology groups on issues, and recommend programming solutions, install, and support customer exposure systems Apply fundamental knowledge of programming languages for design specifications. Analyze applications to identify vulnerabilities and security issues, as well as conduct testing and debugging Serve as advisor or coach to new or lower level analysts Identify problems, analyze information, and make evaluative judgements to recommend and implement solutions Resolve issues by identifying and selecting solutions through the applications of acquired technical experience and guided by precedents Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. Qualifications: 2-5 years of relevant experience in the Financial Service industry Intermediate level experience in Applications Development role Consistently demonstrates clear and concise written and verbal communication Demonstrated problem-solving and decision-making skills Ability to work under pressure and manage deadlines or unexpected changes in expectations or requirements Education: Bachelors degree/University degree or equivalent experience This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN ------------------------------------------------------ Time Type :Full time ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.7,"Citi
3.7",Pune,"New York, NY",10000+ employees,1812,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Python for Data Science-Developer,-1,"Pune, India
BE / BTech
1405960
Job Description
Key skills required for the job are: n Python for Data Science-L2, (Mandatory) .As a Senior Developer, you are responsible for development, support, maintenance and implementation of a complex project module. You should have good experience in application of standard software development principles. You should be able to work as an independent team member, capable of applying judgment to plan and execute your tasks. You should have in-depth knowledge of at least one development technology/ programming language. You should be able to respond to technical queries / requests from team members and customers. You should be able to coach, guide and mentor junior members in the team. Minimum work experience: 3 - 5 YEARS

Roles and Responsibilities
Mandatory Skills: Python for Data Science-L2
Experience Range: 3-5 YEARS
We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law. Any complaints or concerns regarding the recruitment, application or hiring process should be directed to our Ombuds group www.wiproombuds.com. Any US applicant can also call our hotline at 1-866-921-6714. Applicants outside the US can request the applicable hotline number via email via the Ombuds group.

Wipro does not charge any fee at any stage of the recruitment process and has not authorized agencies/partners to collect any fee for recruitment. If you encounter any suspicious mail, advertisements or persons who offer jobs at Wipro, please do let us know by contacting us on helpdesk.recruitment@wipro.com",3.6,"Wipro LTD
3.6",Pune,"Bengaluru, India",10000+ employees,1945,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Cognizant Technology Solutions, Tata Consultancy Services, Accenture"
Data Engineering,-1,"Data Engineer

Job Purpose :
Analyzing, designing, developing and managing the infrastructure and the data that feeds Data Science models.
The Data Engineer is expected to be in charge of the whole lifecycle of the datasets, including updates, backups,
synchronization, and policy access.

Job Responsibilities :
Managing the lifecycle (from data collection to archive) of ML/DL datasets and ensure their
usability for Nielsen’s Data Scientists.
Design, build and integrate data from various sources.
Design ETL pipelines with scripted components.
Optimize data workflows, choosing the most cost-efficient approach.
Automate the management of recurrent task in the pipeline.
Perform feasibility studies/analysis with a critical point of view.
Support and maintain (troubleshoot issues with data and applications).
Develop technical documentation for applications, including diagrams and manuals.
Work on many different software challenges always ensuring a combination of simplicity and
maintainability within the code.
Contribute to architectural designs of large complexity and size, potentially involving several distinct
software components.
Working closely with data scientists and a variety of end-users (across different cultures) to ensure
technical compatibility and user satisfaction.
Work as a member of a team, encouraging team building, motivation and cultivate effective team
relations.

Role Requirements :
E=essential, P=preferred.

E - Bachelor's degree in computer engineering.
P - Master’s degree in data engineering or related.
E - Demonstrated experience and knowledge in Big Data and NoSQL databases.
E - Demonstrated experience and knowledge in Object-Oriented Programming.
E - Demonstrated experience and knowledge in distributed systems.
E - Proficient in programming languages: Python.
E - Experience designing and implementing data warehouses.
E - Experience developing ETL pipelines.
E - Experience working with distributed storage systems in the cloud (Azure, GCP or AWS).
P - Experience managing deep learning datasets.
P - Experience managing Cassandra.
P - Experience working with Spark.
P - Experience implementing CICD pipelines for automation.
E - Experience in the use of collaborative developing tools such as Git, Confluence, Jira, etc.
E - Problem-solving capabilities.
E - Strong ability to analyze and synthesize. (Good analytical and logical thinking capability)
E - Proactive attitude, resolutive, used to work in a team and manage deadlines.
E - Ability to learn quickly.
E - Agile methodologies development (SCRUM/KANBAN).
E - Ability to keep fluid communication written and oral in English, both written and spoken.
Experience level: Minimal work experience of 3-4 years with evidence.

To apply for this job please send your resume to connect@blackstraw.ai

Location :
Blackstraw.ai , Chennai, 4th floor, Tower C, Ratha Tek Meadows Rd, Elcot Sez, Sholinganallur, Chennai, Tamil Nadu 600119, India",4.6,"Blackstraw
4.6",Chennai,"Tampa, FL",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Big Data Engineer - Cloudera/ Hortonworks,-1,"Location : Visakhapatnam

Experience : 5-6 years

Notice Period : 30 days

Roles and Responsibilities :
Design & implement new components and various emerging technologies in Hadoop Eco System, and successful execution of various projects.
Integrate external data sources and create data lake/data mart.
Integrate machine learning models on real-time input data stream.
Collaborate with various cross-functional teams: infrastructure, network, database.
Work with various teams to set up new Hadoop users, security and platform governance which should be pci-dss complaint.
Create and executive capacity planning strategy process for the Hadoop platform.
Monitor job performances, file system/disk-space management, cluster & database connectivity, log files, management of backup/security and troubleshooting various user issues.
Design, implement, test and document performance benchmarking strategy for the platform as well for each use cases.
Drive customer communication during critical events and participate/lead various operational improvement initiatives.
Responsible for setup, administration, and monitoring, tuning, optimizing, governing Large Scale
Hadoop Cluster and Hadoop components: On-Premise/Cloud to meet high availability/uptime requirements.? - 2-4 years relevant experience in BIG DATA.
Exposure to Cloudera/Hortonworks production implementations.
Knowledge of Linux and shell scripting is a must.
Sound knowledge on Python or Scala.
Sound knowledge on Spark, HDFS/HIVE/HBASE
Thorough understanding of Hadoop, Spark, and ecosystem components.
Must be proficient with data ingestion tools like sqoop, flume, talend, and Kafka.
Candidates having knowledge on Machine Learning using Spark will be given preference.
Knowledge of Spark & Hadoop is a must.
Knowledge of AWS and Google Cloud Platform and their various components is preferable.",4.7,"innData Analytics
4.7",Visakhapatnam,"Visakhapatnam, India",1 to 50 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"3+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, data warehousing, and building ETL pipelines
Experience in SQL
- 5+ years of experience with and detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures.
- 4+ years of Big data(Hadoop) experience including one programming language JAVA/PYTHON/SCALA
3+ years of experience in architecting data warehouse solutions and integrating technical components
4+ years of experience with relational and star schema data modeling concepts
Experience in MPP systems such as Redshift, Netezza or Teradata.
-Experience in any big data technologies - Hadoop Eco Systems, EMR
3+ years of working with very large data warehousing environment
Demonstrated knowledge and experience in capacity planning for hardware and storage needs
The Finance Automation team at Amazon is looking for a Data Engineer to play a key role in building their industry leading Financial Data Warehouses. If you have experience in building and maintaining very large data warehouses with high transaction volumes then we need you!!!

The Data Engineer should be an expert familiar with all of the new age data engineering technologies (e.g. Distributed computing, MPP systems, Cloud, NoSQL databases, Data Models and atleast one programming language-JAVA/PYTHON/SCALA). The ideal candidate will be responsible for developing overall architecture and high level design. The candidate must have extensive experience with Star Schemas, Dimensional Models, Datamarts in Traditional Data Warehouses as well as in Big Data / Advanced Analytics domains. The individual is expected to bring a methodology and lead the framework development for the next generation data warehouse by designing an efficient, flexible, extensible, and scalable design and mappings and also will be working extensively on building big data environment.

Excellent written and verbal communication skills are required as the candidate will work very closely with a diverse team. The candidate will also lead a small technical teams or participate in close customer interactions while having an influencing role, and be accountable for deliverable's. Ability to create and manage work plans, timelines and accommodate multiple priorities is required.

Job Responsibilities
Tableau Skill is mandatory.
Applies broad knowledge of technology options, technology platforms, design techniques and approaches across the data warehouse life cycle phases to design an integrated, quality solution to address the business requirements
Meets and collaborates with business users on requirements, objectives and measures.
Designs the technology infrastructure across all technical environments
Ensures completeness and compatibility of the technical infrastructure to support system performance, availability and architecture requirements
Designs and plans for the integration for all data engineering components
Supervises the technical implementation of the data warehouse and oversees hardware/ software configuration
Provides input and recommendations on technical issues to the project manager
Reviews technical work of other team members
Reviews and participate in testing of the data design, tool design, data extracts/transforms, networks and hardware selections
Develops the implementation and operation support plans
Experience in PYTHON, BIG DATA and AWS.
Knowledge of Reporting tools such as OBIEE is preferred
Excellent communication skills, both written and verbal
Strong ability to interact, communicate, present and influence within multiple levels of the organization",-1,ADCI HYD 13 SEZ,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
Data Management - Digital Expert,-1,"A candidate for this position must have had at least 3 years of working experience working with business analysis/informatics and business outcomes research within a fast-paced and complex business setting, preferably working as support data scientist junior support personnel.

The candidate will also have experience working in probability and statistics, time-series analysis, or econometrics as well as experience in the use of machine learning methods, for example, linear regression, correlation, statistical significance, and so forth. A candidate for this position will also require strong programming skills and experience working with tools such as SAS, R Programming, Open Source, visualizations, and so forth.

A suitable candidate will also have had experience as well as in-depth knowledge of the Python programming language, SAS Enterprise Miner and substantial knowledge of big data platforms such as Aster and Hadoop.

Communication skills for the Data Scientist, both in written and verbal form are a must have. The Data Scientist will be required to explain advanced statistical content to senior data scientists and relevant stakeholders.

Therefore, he must have the ability to translate and tailor this technical content into business applicable material with clear recommendations and insights relevant to the audience at hand.

These reports and presentations will not only be translations of technical analyses into business applicable material, the reports have to be simple, concise, understandable and convincing, which will require exceptionally good communication skills on the Data Scientist’s part.

A candidate for this position must be technologically adept, demonstrate exceptionally good computer skills, and demonstrate a passion for research, statistics, and data analysis as well as a demonstrated ability and passion for designing and implementing successful data analysis solutions within a business.

The candidate must have a strong understanding of data-mining techniques and an ability to apply these techniques in practical real-world business issues. The Data Scientist will demonstrate an ability to consider data, identify patterns, issues, or data analysis needs for the business. The candidate must also have skills in the workings of SQL and scripting languages such as Python and Perl as well as familiarity with statistical analysis, data visualization, and data cleansing tools and techniques.

about you

Excellent customer service skills
Good leadership skills
Ability to build relationships with peers ,stakeholders and the management
Excellent interpersonal skills
Good time management, organizational and communication skills
Ability to work under pressure and deal with multiple tasks concurrently
Proactive, self-motivated
Problem solving skills
Matrix Management
Excellent knowledge of Service Management tools / processes

additional information

Degree / Diploma Holders with good Telecom / and IT infrastructure (Sever / Cloud / Security etc)
CCNA / ITIL Preferred
Excellent verbal & written communication skills in English
5 – 7 years of work experience, at least 3 years in telecom domain
At least 3 years of hands on experience in Data Science
Hands on experience on Power BI or Tableu Application

department

Customer Services & Operations

contract

Regular",3.9,"Orange
3.9",Mumbai,"Paris, France",10000+ employees,1988,Company - Private,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Vodafone, Deutsche Telekom, Telefónica"
CSII - Item and inventory - Senior Data Scientist,-1,"Our Company

We help people around the world save money and live better -- anytime and anywhere -- in retail stores, online and through their mobile devices. Each week, more than 220 million customers and members visit our 11,096 stores under 69 banners in 27 countries and e-commerce websites in 10 countries. With last fiscal revenues of approximately $486 billion, Walmart employs 2.2 million employees worldwide.

@ Walmart Labs in Chennai, we use technology for the charter of building brand new platforms and services on the latest technology stack to support both our stores and e-commerce businesses worldwide.

Our Team:

CSII Team is responsible for building data driven highly optimized supply chain suite of products to manage entire gamut of supply chain lifecycle for our retail and ecommerce lines of business. With our rapidly increasing footfalls in stores and exponential growth in online orders; this all has to be done to scale millions of owned and marketplace SKUs complete inbound and outbound fulfilment lifecycles.

Teams mission - Enable customers to receive their orders when and where they want in an innovative and cost effective way for Walmart derives from Walmarts mission statement - Save Money. Live Better complementing our organizations philosophy to deliver low prices every day, on everything.

How we achieve this, comes down to the team of smartest technologists from India focused on the entire suite of supply chain management products for the Walmart Supply Chain at a massive scale. From forecasting & replenishing inventory for millions of items worth billions of dollars, sourcing of millions of orders, to route optimization & last mile delivery to Warehouse Management Systems to most advanced grocery & order management systems; technology is the backbone behind the entire platform enabling the massive cloud-scale supply chain from India.

With over 4,000 associates in Silicon Valley, San Diego, Portland, Brazil, United Kingdom and India, were bringing together some of the best professionals from around the world. If youre inspired by the opportunity to solve complex problems at scale and make a difference for our customers and members, join us.

Your Opportunity

Data Science

This position Data Science , will be on the Walmart Labs Supply Chain team, focused on building Walmart's best in class Supply Chain. At Walmart Labs, you will Work with small teams of talented analyst to build a best-in-class supply chain at Walmart. Be given the freedom to try new things and prove the value of your own ideas and innovations and own them all the way to production Identify and facilitate the removal of team impediments and escalate as appropriate Foster a motivating culture of openness, collaboration, and continuous improvement Ensure business needs are being met using Data Science best practices Participate in internal hackathons and innovation challenges!.

Your Responsibility

· Develop interactive statistical models using the latest frameworks.

· Develop Machine learning modelling leveraging existing frameworks and customizing to problem.

· Find workable solution in case of data inconsistency and inconclusive data

· Drive projects with minimal guidance. Provide thought leadership by researching best practices and conducting experiments

· Evaluate various analytical/statistical methods and procedures and provide recommendation of relevance, applicability, efficiency of those to Walmart Catalog teams

· Work with cross functional group consisting of Engineering, Product, Program managers to drive data based decisions

Your Qualifications

· Bachelors degree in computer science or related discipline with 8+ years experience (5+ Relevant)

· Practical experience with SAS, ETL, data processing, database programming and data analytics

· Proficient is Sql and no-sql languages, R, Python

· Worked on gathering data from Cassandra, Kafka, MongoDBs. Work with big data on GCP and Azure.

· Advanced statistical modelling skills

· Handled multi-million records of data. Troubleshooting and fixing data issue

· Data Visualization in any BI tools like Tableau, PowerBI, etc.,

· Collected, analyzed, and reported data to meet customer needs.

· Understanding and application of statistical concepts to solve business problems",3.3,"Walmart
3.3",Chennai,"Bentonville, AR",1001 to 5000 employees,1962,Company - Public,"Department, Clothing, & Shoe Shops",Retail,₹500+ billion (INR),"Target, Costco Wholesale, Amazon"
Data Analyst,-1,"Netomi is a Y-Combinator and VC-backed Artificial Intelligence company that sits at the intersection of two rapidly developing fields: AI and messaging. We do not sell an abstract, futuristic technology - we sell a solution that a large number of Fortune 500 companies are using today to drive engagement and sales across the entire customer journey. By leveraging deep reinforcement learning and our continuously learning neural network, our customers are able to successfully meet their objectives of generating social engagement, driving commerce and providing customer service. We're building the future of how technology and people work together to create frictionless experiences for customers.

Want to have a direct impact in solving the top challenges businesses face today? Join us!

Job Description:

We are looking for a Data Analyst who can help us dig into raw data, analyse it and draw conclusions that help in making business decisions.
Responsibilities
Business Analysis to understand the client's business and work with Data Analysts to define the Deep Learning (DL) model
Quality Assurance of Deep Learning models
Analyze the conversation quality in chatbots
Leverage multiple crowdsourcing strategies to collect training and test data for DL models and help with cleansing, filtering and massaging those data
Providing a high level of data quality awareness across multiple teams
Evaluate and identify where enhancements of data to maintained higher quality data
Detailed testing feedback preparation to help the team to improve the models.
Monitor and improve the Data Quality Assurance process that can meet/exceed the current standards and procedures
Learn and/or leverage the required software tools and technology

Requirements
0-1 years experience in related field
Bachelors degree from a Tier I/Tier II college
Knowledge of any one foreign language - French, Spanish or Russian
Excellent written and verbal communication skills
An eye for detail and accuracy",4.8,"Netomi
4.8",Gurgaon,"San Francisco, CA",51 to 200 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"HP is the world’s leading personal systems and printing company, we create technology that makes life better for everyone, everywhere. Our innovation springs from a team of individuals, each collaborating and contributing their own perspectives, knowledge, and experience to advance the way the world works and lives.

We are looking for visionaries, like you, who are ready to make a purposeful impact on the way the world works.

At HP, the future is yours to create!

We are Pricing Analytics Team; our main objective is to help the business to decide optimal price for the HP products in a scientific way through statistical and predictive analysis.

If you are our Data Engineer in India, you will get an opportunity to work on below.

Designs and establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data pipelines, repositories or models for structured data.
Analyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.
Writes and executes complete pipeline plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs and creates solutions for issues with data sources and integration into data system architecture.
Collaborates and communicates with project team regarding project progress and issue resolution. Represents the data engineering team for all phases of larger and more-complex development projects. Provides guidance and mentoring to less experienced staff members.

Are you a high-performer? We are looking for an individual with.

Well versed knowledge on SQL servers and database solutions.
Python programming language to create efficient data flow
Various operating systems like Linux, windows, Unix which will enable data interconnection Data warehousing and ETL tools Good to have.
Knowledge on R and visualization tools such as Power BI / Tableau/ R Shiny Data architecture skills to create effective data flow Team player to interact and understand the data based on data scientists and analysts
#LI-Post",3.3,"HP
3.3",Bengaluru,"Houston, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Senior Data Analyst,-1,"The Role: Senior Data Analyst

The Location: Mumbai

The Grade: 11

The Team: The Global Data Management team within the Global Index Management & Production Group.

The Impact: The Senior Data Analyst is responsible for the acquisition, management and quality of a variety of data items used for the production and maintenance of S&P Dow Jones-branded indices.

The successful candidate will be expected to set the standard in carrying out tasks associated with the management of data used for the production and maintenance of indices, setting an example for more junior analysts to follow.

Additionally, the Senior Data Analyst is responsible for a wide range of data points across global markets and may be required to make presentations to Index Committees on matters impacting the maintenance and particularly the rebalancing of S&P DJI global indices, making in-depth knowledge of their product line essential.

Whats in it for you: As a Senior Data Analyst, you will work collaboratively with a wide range of data points, indices and other products across global markets. You must be able to analyze and implement complex data processes and calculation methodology and solve non-routine problems on an on-going basis.

Responsibilities:

The Senior Data Analyst will be a subject matter expert, an example and escalation point for more junior team members and will support the team leader.

In addition, the Senior Data Analyst will be required to:
Demonstrate organizational skills by ensuring that processes for the capture, quality screen and presentation of data sets are completed in time for their delivery to end clients or use in the further calculation or rebalancing of indices
Preparing and calculating fundamental ratios for S&P and Dow Jones branded indices, ensuring timely and accurate delivery of index data to clients and end users
Develop a detailed understanding of the way each data set is used in the production and maintenance of S&P Dow Jones Indices, ensuring the Senior Data Analyst is able to identify and resolve issues and ensure the data is fit for purpose
Serve on index committees and make presentations of original, non-routine analysis to committee in support of the data items for which the Senior Data Analyst is responsible. Decisions reached by committee determine index composition and drive asset allocations.
Take responsibility for the management of high profile data sets, acting as an industry expert and displaying in-depth knowledge of our product lines.
Provide timely and accurate responses to enquiries from internal groups and external clients, through our client services team
Manage and maintain key relationships with other groups within the department and across other departments, particularly Product Management, Client Coverage, Index Services and IT Support
Work in close coordination with the technology group and production support group to further enhance our system capabilities
Qualifications:
A demonstrable, deep understanding of global financial markets and financial data, particularly company fundamentals
Familiarity with Environmental, Social and Governance (ESG) themes in finance and particularly ESG data providers would be considered an advantage
Must be able to work independently on multiple projects with minimal direction or supervision.
Ability to assume responsibility, work with others and manage projects
Bachelors Degree. Advanced degree in business, math, economics, or finance strongly preferred
Minimum of 4 years of professional experience working with financial indices.
Strong understanding of how indices are used, the impact of different methodologies, corporate event events on both indices and financial portfolios.
Superior computer skills in Excel, Word and related applications. Access, VBA, SQL and/or Python would be an advantage.
Ability to learn S&Ps proprietary index calculation systems and requirements
Excellent analytical and numerical capabilities to aid in solving non-routine problems in a timely fashion
About us:

At S&P Dow Jones Indices, our role can be described in one word: essential. Were the largest global resource for index-based concepts, data and research, and home to iconic financial market indicators, such as the S&P 500® and the Dow Jones Industrial Average®. More assets are invested in products based upon our indices than any other index provider in the world; with over 1,000,000 indices, S&P Dow Jones Indices defines the way people measure and trade the markets. We provide essential intelligence that helps investors identify and capitalize on global opportunities.

S&P Dow Jones Indices is a division of S&P Global (NYSE: SPGI), which provides essential intelligence for individuals, companies and governments to make decisions with confidence. For more information, visit www.spdji.com.",3.7,"S&P DOW JONES INDICES
3.7",Mumbai,"New York, NY",201 to 500 employees,-1,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,-1
Data Analyst,-1,"Have Accounting background.
Data analysis of the records
Good Communication
Excellent Excel Knowledge
Job Type: Full-time
Salary: ₹240,000.00 - ₹480,000.00 per year
Experience:
work: 3 years (Preferred)
total work: 3 years (Preferred)
Education:
Master's (Preferred)
Work Remotely:
No",3.3,"Express Roadways Pvt Ltd
3.3",Hisar,"Mumbai, India",5001 to 10000 employees,-1,Company - Public,Transportation Management,Transportation & Logistics,Unknown / Non-Applicable,-1
Sr. Data Analyst,-1,"1. Hands-on professional with in-depth knowledge and High level of Proficiency in Qlikview scripting.
2. Use of complex QlikView functions, advance Qlikview expressions.
Knowledge of Qlikview scripting features such as Resident Tables,loops and other advanced scripting fuctions.
3.Hands on experience with complex data models.
4.Understanding of BI/data warehouse concepts, Star schema/snowflake models, SCDs, fact and dimension tables, SQL etc.
5. Good Knowledge of Python especially in packages Pandas and numpy.
5.Must have written SQL queries for extracting data for varied complex scenarios with an exposure to big data environment.
6.Have practical experience using the windowing and analytic functions in SQl.
7.Good knowledge of Excel functions including index,match,array and other advanced functions in excel.
8. Candidate must have strong problem solving, logical and analytical skills.

What You Need for this Position

You should have knowledge of:
QlikView functions
advance Qlikview expressions
BI/data warehouse concepts
Star schema/snowflake models
SCDs
fact
SQL
Aditional
No. of Positions
Education level
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1
HIVE Data Engineer- Bangalore,-1,"Description

6sense is a Predictive Intelligence Engine that is reimagining how B2B companies do sales and marketing. It works with big data at scale, advanced machine learning and predictive modeling to find buyers and predict what they will purchase, when and how much.

6sense helps B2B marketing and sales organizations fully understand the complex ABM buyer journey. By combining intent signals from every channel with the industry's most advanced AI predictive capabilities, it is finally possible to predict account demand and optimize demand generation in an ABM world. Equipped with the power of AI and the 6sense Demand Platform™, marketing and sales professionals can uncover, prioritize and engage buyers to drive more revenue.

6sense is seeking a Data Engineer to become part of a team designing, developing, and deploying its customer centric applications.

A Data Engineer at 6sense will have the opportunity to
Create, validate and maintain optimal data pipelines, assemble large, complex data sets that meet functional / non-functional business requirements.
Improving our current data pipelines i.e. improve their performance, remove redundancy, and figure out a way to test before v/s after to roll out.
Debug any issues that arise from data pipelines especially performance issues.
Experiment with new tools and new versions of hive/presto etc. etc.
Required qualifications and must have skills
BE/BTech/BS or equivalent
Excellent analytical and problem-solving skills
6+ years work experience showing growth as a Data Engineer.
Strong hands-on experience with Big Data Platforms like Hadoop / Hive / Spark / Presto
Experience with writing Hive / Presto UDFs in Java
String experience in writing complex, optimized SQL queries across large data sets
Experience with optimizing queries and underlying storage
Comfortable with Unix / Linux command line
Nice to have Skills
Used Key Value stores or noSQL databases
Good understanding of docker and container platforms like Mesos and Kubernetes
Security-first architecture approach
Application benchmarking and optimization
Interpersonal Attributes
You can work independently as well as part of a team
You take ownership of projects and drive them to conclusion
You're a good communicator and are capable of not just doing the work, but teaching others and explaining the ""why"" behind complicated technical decisions
You aren't afraid to roll up your sleeves: This role will evolve over time, and we'll want you to evolve with it!",5.0,"6sense
5.0",Bengaluru,"San Francisco, CA",51 to 200 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Science Online Trainer,-1,"Job Id : PTPL/HR/8

Anywhere in India

1+ year experience in Data Science. Must have worked on minimum 2 Data Science Projects and must have at least 50 hours experience in online training on Data Science topics.",3.5,"Prognoz
3.5",India,"Perm, Russia",1001 to 5000 employees,-1,Company - Private,Research & Development,Business Services,₹100 to ₹500 billion (INR),-1
Data Engineer,-1,"Company Description

Cermati is a financial technology (fintech) startup based in Indonesia. Cermati simplifies the process of finding and applying for financial product by bringing everything online so people can shop around for financial products online and can apply online without having to physically visit a bank.

Our team hailed from Silicon Valley Tech companies such as Google, Microsoft, LinkedIn and Sofi as well as Indonesian startups such as Doku, Touchten. We have graduates from well known universities such as Universitas Indonesia, ITB, Stanford, University of Washington, Cornell and many others. We are building a company with the same culture of openness, transparency, drive and meritocracy as Silicon Valley companies. Join us in our cause to build a world class fintech company in Indonesia.

Job Description

The candidate should be able to design high performance, maintainable, extensible software architectures to solve abstract business problems. Here are some example business problems:
""We want to reduce the time for productionizing experimental machine learning features to 1 day""

""We want to completely automate the credit approval process while maintaining an accuracy of >90% when compared with manual approval""

They should be able to translate the high level design into a series of tasks that can be executed by other software engineers working in parallel

The high level designs are usually design documents consisting of relevant block diagrams, UML diagrams meant to be consumed by other engineering leaders and software engineers

They must be able to work with international teams effectively. They will be required to communicate with:
- Clients who may not necessarily be software engineers (marketing teams, business development team etc)
- Software engineers and tech leads to communicate the design in a simple yet accurate language without compromising details.
They would be leading a team of talented but possibly inexperienced engineers who will look to you for mentorship. In a typical day, candidates would be spending
10% of the time project management, 20% of the time doing code review and mentorship, 20% of the time coding (evaluating technologies, doing PoC, etc) 50% of the time requirement gathering, high level design, low level design, roadmap etc

The following technical skills would be useful:
Candidates must be able to understand the tradeoff between performance, simplicity, maintainability and timeline constraints when developing software solutions
Strong hands on experience in java, python is required. Must have shipped multiple projects with a major hands on contribution to each project.
Experience in Big data technologies: hadoop ecosystem (mapreduce, spark, kafka)
Experience in different storage technologies: OLTP like postgres, OLAP like redshift, Google bigquery, NoSQl like redis, hbase, kafka
Familiarity with machine learning algorithms and concepts (gradient descent, logistic regression) and software libraries like pandas, tensorflow, etc
Qualifications

The following technical skills would be useful:
Candidates must be able to understand the tradeoff between performance, simplicity, maintainability and timeline constraints when developing software solutions
Strong hands on experience in java, python is required. Must have shipped multiple projects with a major hands on contribution to each project.
Experience in Big data technologies: hadoop ecosystem (mapreduce, spark, kafka)
Experience in different storage technologies: OLTP like postgres, OLAP like redshift, Google bigquery, NoSQl like redis, hbase, kafka
Familiarity with machine learning algorithms and concepts (gradient descent, logistic regression) and software libraries like pandas, tensorflow, etc
Additional Information

Impressive Benefits and flexible work culture.",4.2,"Cermati.com
4.2",Bengaluru,"Jakarta, Indonesia",1 to 50 employees,-1,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
CIEL/SEL/13651: Data Scientist,-1,"Job Description
Key points about the position are as below;
Hadoop - working knowledge

PL SQL
Python or R
Inferential Statistics
ML - must have implemented at least one algorithm
Visualisation - Tableau preferred, BI, Spotfire
Service Delivery, communication skills
Statistical education background
Production model experience using ML with any algorithm. Worked on real time projects

Job Responsibilities
Develop novel ways to help business partners achieve objectives through analysis & modelling
Think outside the box to identify & test new sources of information that unlock new business value
Curate and connect external data sets for broad enterprise-wide analytic usage
Be a storyteller to explain the ‘why & how’ of your data driven recommendations to cross-functional teams
Engineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results
Utilize machine learning to create repeatable, dynamic & scalable models
Have passion to advocate and educate on the value and importance of data driven decision making & analytical methods
Identify and develop long-term data science processes, frameworks, tools, and standards
Be a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists
Consultation
Collaborates with technical teams like development and infrastructure.
Able to explore, troubleshoot on niche technologies and provide automation solutions
Specific Job Experience or Skills Needed
Experience in basic statistical analysis, modelling, clustering and data mining techniques to identify trends and insights. Understanding / experience of CPG industry is desiable.
Mathematical or statistical background required
Ability to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)
Understanding of data warehousing & databases is critical
Number sense, ability to identify questionable data, dig in & address it
Experience with Hadoop, Hive, and/or Spark a plus
Bias for action with ability to deliver outstanding results through task prioritization & time management
Exemplary organizational skills with attention to detail & accuracy
Experience with machine learning
Experience with data visualization tools
Experience writing complex SQL queries
Skill Name Mandatory Expert Intermediate Basic Comments
Databases Yes
SQL, Oracle, Any RDBMS Yes Yes Should have working knowledge of atleast one database
Hadoop - Hive, Impala No Only Know how
PL/SQL Yes Yes
Programming Languages
R, Python Yes (Any One) Yes
Inferential Statistics Yes Yes Hypothesis, p-value, R2, RMSE, MAPE etc",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1
Data Engineer,-1,"Job Type: Full time Experience: 2+ years Hyderabad

Job Description:
We are looking for a savvy Data Engineer to join our growing team. We work with fortune 500 companies to build their data infrastructure and help them with their data journey. The Data Engineer will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing the data flow. The Data Engineer will help generate data pipelines and subsequently with DataOps. He/ She must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.

Qualifications:
2+ years of experience in building data pipelines.
Experience building data pipelines using StreamSets or Azure Data Factory.
Understanding of stream processing with knowledge on Kafka.
Experience with scripting languages i.e. Python, Perl, etc.
Experience with SQL (RDBMS), NoSQL (MongoDB), and PostgreSQL.
Understanding of data flows, data architecture, ETL and processing of structured and unstructured data.
Current experience developing and deploying applications to a public cloud (AWS, GCE).
Experience with DevOps tools (GitHub, Jira) and methodologies (Lean, Agile, Scrum).
Experience with ETL, Data Modeling, and working with large-scale datasets. Extremely proficient in writing performant SQL working with large data volumes.
Experience on Azure DevOps is a plus.
Ability to manage competing priorities simultaneously and drive projects to completion.

Desired Candidate Profile:
Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Engineering).
Excellent written and verbal communication skills in English.
Experience in working in agile (SCRUM) methodology.",4.0,"Modak Analytics
4.0",Hyderabad,"Hyderabad, India",201 to 500 employees,2010,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst (NLP),-1,"Department: Analytics

Experience: 3-5 Years

Location: Chennai

Job Description
Should have experience in developing efficient code in R / Python
Sound have understanding of statistical concepts behind data modelling
Experience in training and deploying models based on Stanford Core NLP.
Experience with machine learning, preferably one or more among Tensorflow, Theano, Deeplearning4J, Torch
Experience developing backend systems involving NoSQL databases and Graph Databases
Experience and familiarity with the concepts of threading, concurrent execution methodologies including monads
Familiarity with text-to-speech
Familiarity with modern speech recognition engine technology. LVCSR, HMMs, DNNs.
Familiarity and experience with open-source/commercial NLP toolkits such as Stanford NLP, NLTK, Tensorflow, Apache Lucene/Solr, GATE
Knowledge of techniques for critical problem/application areas in NLP such as Named Entity Extraction, PoS tagging, parsing, semantic analysis, ambiguity resolution, pronoun resolution, sentiment analysis, summarization
Sound understanding behind machine learning algorithms like SVM, KNN, Decision tree etc.
NLP analyst to work with Clients and Senior analyst / SME to bring insights using AI/ML/NLS techniques.
Conduct all job functions and responsibilities in accordance with all company Compliance, Information Security and Regulatory policies, procedures and programs.",3.1,"SCIO Health Analytics
3.1",Chennai,"West Hartford, CT",501 to 1000 employees,2007,Company - Private,Healthcare Services & Hospitals,Healthcare,₹1 to ₹5 billion (INR),-1
Computer Vision - Data Scientist,-1,"Arya.ai is looking for ambitious and talented computer vision researchers with strong skills in software development to join our research team. If you get excited by the prospect of analyzing and modelling terabytes of data and creating state-of-the-art algorithms to solve real-world problems and by owning business problems/metrics, then we have the perfect role for you. Here you will have the ability to thrive in a dynamic environment combining conceptual and applied research, systems building and collaborative work. You will work together with similar minds in a unique development team where your skills and expertise will be put to the test.

*
Major responsibilities:
*
Research, design, implement and evaluate novel computer vision algorithms

- Work on large-scale datasets, focusing on creating scalable and accurate computer vision systems in versatile application fields

- Collaborate closely with team members on developing systems from prototyping to production level

- Able to derive model’s risk towards business and communicate with corresponding business managers

- Track general business activity and provide clear, compelling management reports on a regular basis
*
Qualifications Required:
*
Hands-on experience in Computer Vision and Deep Learning

- Broad knowledge of fundamentals and state-of-the-art in computer vision

- High proficiency in C/C++ or Python

- Ability to develop large-scale systems working with image/video data

- Strong working knowledge of software architecture and data structure

- Excellent problem-solving ability

- Minimum of 2-year experience in Deep Learning(CNNs, RNNs, Attention-based Networks, etc)

- Minimum of 2-year experience in Computer Vision (Image/Video Processing)
Job Type: Full-time",3.5,"Arya.ai
3.5",Mumbai,"Mumbai, India",1 to 50 employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Analyst,-1,"Start : Immediate
Must Have Technical expertise
Strong Experience with SQL, T-SQL
Strong Experience with Power BI
Experience with data extraction, cleansing and loading into a database using integration tools such as Talend or using Microsoft tools or Python data wrangling libraries
Ability to understand a problem and produce technical solutions
Good to Have Technical experience
Azure Cosmos DB NoSQL
Azure Synapse Analytics
Python Data Science Libraries
Good to Have Functional experience
Supply Chain or Manufacturing
Finance
Experience: 4+ years, 6+ years
Job Type: Full-time
Experience:
Power BI: 4 years (Preferred)
Talend: 3 years (Preferred)
SQL, T-SQL: 4 years (Preferred)
Education:
Secondary(10th Pass) (Preferred)
Work Remotely:
Yes",2.0,"Aavid Software
2.0",Pune,"Pune, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Data Engineer,-1,"Hands on experience working with Cloud Platform - Preferred AWS
Good experience working with ETL Tools - Cloud based (AWS) + Others (Talend)
AWS Services - S3, Redshift, Athena, Glue, DMS, Lambda. Good to have knowledge about AWS Infra
Hands on working with any RDBMS & NoSQL DBs.
Good understanding of DB Concepts & SQL Queries. PL/SQL, Stored Procedures, Optimization & Performance Tuning
Experienced in Data Migration
Experience working with Spark, Hadoop, HDFS, Scala
Good To have big data knowledge
Knowledge of Data Visualization Tools (like Tableau)
Knowledge working with Data-warehouses (Cloud based)
Good understanding & working experience in any programming language
Good to have experience working in Python
00-5.00 Years",3.5,"Unitforce Technologies Consulting Pvt Ltd
3.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
"Data Engineer Oracle, ETL for NFRM IT",-1,"Job Description:


Position Overview

Role Description:

The Oracle developer will be responsible for developing, enhancing and maintaining applications in the Non Financial Risk (NFR) domain. The activities shall be performed in accordance with the defined tools/technologies of the project , shall adhere to the standards and processes followed in the organization & project. Additionally, the developer will be a partner to the development and Level 2 support organizations and shall work on any issues in the production environment for which the Development’s team help is required.

Tasks |Responsibilities:
Develop a good understanding of the activities required to execute the development/bug fix activity.
Actively participate and contribute in Agile ceremonies including Daily Stand up’s, Sprint Planning, Sprint review, Sprint retrospective meetings
Take part in software and architectural design activities
Perform analysis, development, testing and debugging/defect fixing for the assigned stories/bug fixes
Develop the required functionalities using the appropriate database technologies
Write unit tests for the developed code.
Recommend changes to improve established application processes.
Integration of changes with other user stories developed by team members
Deployment in Development/integration/UAT environments
Create required documentation for the project.
Meet the SLA’s for any assigned defects.
Development and delivery KPI’s shall be met.
Shall be ready to learn new technologies as per the project requirements.
Experience | Knowledge
10+ years combined experience as software developer. Well aware of the Agile methodology.
Hands on experience in SQL and relational databases, preferably Oracle 10G and higher
Experience with database migration, database upgrade activities
Experience with performance tuning, indexing, partitioning
Experience using the Git version control system, Jenkins, Nexus and Sonar.
Proficient in Linux/Unix system.
Experience working with high availability and high performance systems.
Should be aware of the release/deployment and application support processes (Incident/problem/change management etc.)
Basic knowledge of Oracle database management system
Experience using atleast one ETL tool
Experience in datawarehousing
Good to have experience with BI tools like SAP Buiness Objects or Cognos reporting
Good to have experience with big data technologies
Education | Certification

Bachelor degree from an accredited college or university with a concentration in an IT related discipline

Our values define the working environment we strive to create – diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer.

We promote good working relationships and encourage high standards of conduct and work performance. We welcome applications from talented people from all cultures, countries, races, genders, sexual orientations, disabilities, beliefs and generations and are committed to providing a working environment free from harassment, discrimination and retaliation.

Click here to find out more about our diversity and inclusion policy and initiatives.",3.5,"Deutsche Bank
3.5",Pune,"Frankfurt am Main, Germany",10000+ employees,1870,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),-1
Data Science Engineer - Start Up Software Company Baner,-1,"Responsibilities:
Design and build highly scalable nlp pipelines
Design and write custom algorithms to solve domain specific problems
Build POCs using open-source libraries for independent modules
Create AI solutions for automated dialogue (chat bots); natural texting for knowledge & expertise recommendations.
Build & train NLP platform from user generated textual data (email, IM, search logs) on daily basis
Code ML models primarily using python, No-Sql & AWS
Collaborate with other team members and stakeholders.

Requirements:
5+ years experience in web-app development, with minimum 2+ years of NLP experience .
Proficiency in Data Structures & Algorithms .
Experience with open-source NLP libraries such as spacy, NLTK
Experience with MySQL, Mongo-DB & Neo4j
Experience with Word2Vec, Glove, RNN, LSTM
Experience with Data Pipeline Frameworks such as AWS Data Pipeline
00-7.00 Years
Masters in Technology (M.Tech/M.E/M.Sc), Master in Computer Application (M.C.A), Bachelor Of Technology (B.Tech/B.E)",5.0,"Seventh Contact Hiring Solutions
5.0",Pune,"Pune, India",1 to 50 employees,-1,Private Practice / Firm,-1,-1,Unknown / Non-Applicable,-1
ANALYST-DATA SCIENCE-PYTHON,-1,"Apply machine learning techniques to deliver actionable insights from large-scale, multi-structured datasets. Work with internal and external teams to develop models (ranging from data exploration to feature engineering and model development to validation and scoring.) and put them into production This is an individual contributor profile wherein the candidate is required to work in collaboration with the AMs and DMs Machine Learning techniques (recommendation engines, ensemble models such as random forests, bagging and boosting, support vector machines, dynamic optimization etc.) Design and build systems that mine massive datasets and structure/ engineer it to be usable for machine learning models
Salary Negotiable
Industry IT Software
SubIndustry Software Development
Functional Area IT Software Development
Specialization IT/Technical Content Developer
Role Manager / Sr. Manager Level
Keyskills
NLPText MiningMachine Learning
Desired Candidate Profile
Please refer on JD
Education
Highest Qualification
Graduation Any Graduate",5.0,"Fine Jobs
5.0",Mumbai,"Mumbai, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Digital - Associate Program Manager - Analytics Consultant,-1,"SKILLS REQUIRED:
Advanced Analytics, Predictive Analytics",3.4,"eClerx
3.4",Mumbai,"Mumbai, India",5001 to 10000 employees,2000,Company - Public,Consulting,Business Services,₹10 to ₹50 billion (INR),"Genpact, WNS, Convergys"
"ES Tech, Data Engineer",-1,"Do you love data as much as we do? Do you want to influence at Amazon? We have the career for you!

Amazon's Employee Services Technology (ES Tech) team is seeking an outstanding ETL/Data Engineer to join our BI team to build out the BI platform with all of the data ingestion mechanisms required for the initiative. Our platform delivers business intelligence to a diverse, global community of internal customers from one of the worlds largest and most complex financial data sets. Amazon has culture of data-driven decision-making, and demands business intelligence that is timely, accurate, and actionable.

You will be responsible for designing and implementing solutions using third-party technology and Amazon cloud technologies. A successful candidate knows and loves working with business intelligence ETL tools, is comfortable accessing and working with big data from multiple sources, and passionately partners with the business to identify strategic opportunities and deliver results. You should have an internal drive to answer why? questions, excellent analytical abilities, strong technical skills, as well as superior written and verbal communication skills. S/he would be a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail), and enjoy working in a fast-paced dynamic environment.

Responsibilities include:
· Drive the collection of new data and the refinement of existing data sources to continually improve data quality
· Support data analysts and product managers by turning business requirements into functional specifications and then executing ETL delivery
· Lead the technical lifecycle of data presentation from data sourcing to transforming into user-facing metrics





Basic Qualifications

· Bachelors or Masters Degree in Computer Science, Systems Analysis, or related field
· 3+ years experience in data modeling, ETL development, and Data Warehousing
· 1+ years experience with BI/DW/ETL projects.
· Knowledge of AWS product suite including S3, Redshift, Dynamo DB and RDS.
· Experience in scripts like Python, Java, javascript etc.
· Technical guru; SQL expert.
· Experience with Linux, UNIX, UNIX tools
· Experience writing software to automate manual workflows
· Good instincts; you know what it means to be a subject matter expert and how to be a team player



Preferred Qualifications


Strong background in data relationships, modeling, and mining.
Mulesoft experience a plus.




Amazon is an Equal Opportunity Employer",4.3,"Amazon
4.3",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart"
Data Analyst,-1,"Responsibilites :
Backgrounds in technology, information management, relational database design and development, business intelligence, data mining or statistics.
Solid understand of data analysis techniques or processes will help reduce the need for you to learn every data analysis tool in the market
Experinece in importing, cleaning, transforming, validating or modeling data with the purpose of understanding or making conclusions from the data for decision making purposes.
Experinece in Performing audit on data and resolve business related issues for customer base
Experinece in Performing data analysis and facilitate in delivery to all end users.
Explorering sift through mountains of data to discover the data you actually need

Send us the Resume at info@zettamine.com",3.8,"ZettaMine
3.8",Hyderabad,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Big Data Engineer,-1,"Data Engineer

About Print Analytics

As part of the HP Inc. R&D Centre, Print Analytics Team work closely with Print GBU of HP Inc. across multiple domains. We deploy data products and analytics assets, provide data-driven actionable insights to influence business decisions.

Within Print Analytics, Supplies Analytics Team seeks to deploy data products through designing table structures and data flows, automating repetitive data tasks, building and maintaining data dictionaries, finding/resolving data anomalies and data errors. This would, in turn, result in delivering complex analysis and improving intelligence.

Business Environment

Supplies Analytics Team strategically partners with Big Data Business Transformation organization to deploy data products and deliver analytics to help them discover new opportunities and solve their business challenges in a data driven manner.

Role Description:

In order to deploy data products, we are looking for a high caliber and detail-oriented Data Engineer who can work in collaboration with cross-functional, cross-regional teams to establish and improve data pipelines. She / He will also be responsible for designing table structures and data flows, automating repetitive data tasks, building and maintaining data dictionaries, finding/resolving data anomalies and data errors. This would, in turn, enable downstream data analyses and AI/ML models.

The analyst would act as an informed team member who can help bridge technical data requirements.

Responsibilities:
Establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data platform, repositories or models for structured/unstructured data.
Analyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.
Writes and executes complete testing plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs, and creates solutions for issues with code and integration into data system architecture.
Collaborates and communicates with project team regarding project progress and issue resolution.
Works with the data engineering team for all phases of larger and more-complex development projects and engages with external users on business and technical requirements.
Collaborates with peers, engineers, data scientists and project team.
Typically interacts with high-level Individual Contributors, Managers and Program Teams on a daily/weekly basis.
Defines and leads portions of project requirements for data exchanges and business requirements with externals and internal teams
Creates plans, data collection and analysis procedures and works with data insight visualization teams for assigned projects.
Collaborates with internal and external partners to perform experiments and validations in accordance with overall plan.
Collaborates with SMEs to develop procedures for collecting, recording, analyzing, and communicating data for review and feedback.
Education and Experience Required:
Bachelor's or Master's degree in Computer Science, Information Systems, Engineering or equivalent.
4-6 years experience in a data analyst or data engineering type role.
Knowledge & Skills:
Using data engineering tools, languages, frameworks to mine, cleanse and explore data.
Fluent in relational based systems and writing complex SQL.
Fluent in programming and automating repetitive tasks preferably using VBA and Python
Fluent in complex, distributed and massively parallel systems.
Strong analytical and problem-solving skills with ability to represent complex algorithms in software.
Designing data systems/solutions to manage complex data.
Strong understanding of database technologies and management systems.
Strong understanding of cloud-based systems/services, including the AWS environment.
Database architecture testing methodology, including execution of test plans, debugging, and testing scripts and tools.
Ability to effectively communicate product architectures, design proposals and negotiate options at management levels.
Using scientific design and data collection methodologies, tools and analysis packages to collect, validate, and analyze research data.
Excellent written and verbal communication skills
Strong interpersonal skills and ability to work in a collaborative environment",4.1,"HP Inc.
4.1",Bengaluru,"Palo Alto, CA",10000+ employees,1939,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Science Trainer,-1,"Should have a strong knowledge on Machine Learning, Deep Learning, R Programming; Python,Statistics,Hadoop etc
Understanding and assessing individual (or) group training requirements.
Execute workshops to create awareness of the latest technologies.
Up to date knowledge of IT skills and software packages.
Designing the Course modules appropriate to the skills needed.
Helping IT Professionals in updating their skills with latest technologies.
Evaluating each and every Individual progress and outcomes.

Job Types: Full-time, Part-time

Salary: ₹300,000.00 - ₹500,000.00 per year

Experience:
total work: 5 years (Preferred)
Training: 5 years (Preferred)
Education:
Bachelor's (Preferred)
Location:
Ameerpet, Hyderabad, Telangana (Preferred)
Work Remotely:
Temporarily due to COVID-19",3.7,"Naresh I Technologies
3.7",Telangana,"Hyderābād, India",51 to 200 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1
Research Scientist,-1,"Role Purpose:

To perform the formulation/AI
product chemistry studies and work, as discussed with the Team Leader
T&E, to agreed timelines.
Ensure HSEQ as per site policy
and local Regulation requirements
Maintain Laboratory and
equipment as per GLP requirements.
Support the Study
Director to GLP studies and documentation
Update GLP data in team space
Accountabilities:

Excellent experimental skills i.e., perform and
document analytical and product chemistry work as per GLP
Minimum of 2-4 years’ experience with good technical
knowledge of LC and/or GC, preferably both, in an industrial setup.
Knowledge of method development/Validation of
Chromatographic methods
Good hands on experience on spectroscopic techniques
viz. LCMS, GCMS, NMR etc. with at least 3 years practical experience.
Able to plan and organize his/her work to achieve a
high level of productivity and to meet important deadlines
Maintain Laboratories and assigned Equipment used for
GLP studies and document as per the GLP requirements
Contribute to a product chemistry group and conduct,
under the direction of a study director, studies that fully meet world-wide
regulatory requirements to facilitate registration.
Characterize analytical references and certified
substances to meet development and production schedule requirements
Good understanding of GLP, SOPs and knowledge of
formulation/A.I. Product Chemistry
Ensure HSE and waste disposal as per the site policy
Communicate results and
programs effectively with staff, peers, and customers
Ensure compliance with all company HS&E policies
and GLP. Train junior scientist to enable safe and competent performance.
Knowledge, Skills and
Experience:
PhD degree in Chemistry preferable in analytical or
allied Science, area from the reputed Universities with strong academic records
and good communication skills and sound in instrumentations. with >2 years
of industrial experience preferable worked in GLP facility
Or
Master degree in Chemistry preferable analytical or
allied Science, area from the reputed Universities with strong academic records
and good communication skills with >3 years of industrial experience.
Experience Analytical Chemist with sound GLP experience is
desirable,
Excellent experimental skills
Able to plan and organize work to achieve a high level
of productivity and to meet important deadlines.
IT literate relevant to work
Sound understanding of GLP and knowledge of
formulation/AI Product Chemistry
Good knowledge of written English
Team player, flexible and with people skill
Behaviors:

Team-Oriented
Demonstrates
personal commitment to the team
Values
and uses individual differences and talents
Results-Oriented
Works
tenaciously to deliver agreed goals
Self-disciplined
to achieve results through effective prioritisation and timely delivery
Communicative
Ensures
structure and clarity in both verbal and written messages
Provides
timely communications and feedback to stakeholders",4.0,"Syngenta
4.0",India,"Basel, Switzerland",10000+ employees,2000,Company - Public,Chemical Manufacturing,Manufacturing,₹500+ billion (INR),-1
Data Engineer/Python Spark Developer,-1,"The Applications Development Intermediate Programmer Analyst is an intermediate level position responsible for participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to contribute to applications systems analysis and programming activities. Responsibilities: Utilize knowledge of applications development procedures and concepts, and basic knowledge of other technical areas to identify and define necessary system enhancements, including using script tools and analyzing/interpreting code Consult with users, clients, and other technology groups on issues, and recommend programming solutions, install, and support customer exposure systems Apply fundamental knowledge of programming languages for design specifications. Analyze applications to identify vulnerabilities and security issues, as well as conduct testing and debugging Serve as advisor or coach to new or lower level analysts Identify problems, analyze information, and make evaluative judgements to recommend and implement solutions Resolve issues by identifying and selecting solutions through the applications of acquired technical experience and guided by precedents Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency. Qualifications: 2-5 years of relevant experience in the Financial Service industry Intermediate level experience in Applications Development role Consistently demonstrates clear and concise written and verbal communication Demonstrated problem-solving and decision-making skills Ability to work under pressure and manage deadlines or unexpected changes in expectations or requirements Education: Bachelors degree/University degree or equivalent experience This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - IN ------------------------------------------------------ Time Type :Full time ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.7,"Citi
3.7",Pune,"New York, NY",10000+ employees,1812,Company - Public,Investment Banking & Asset Management,Finance,₹500+ billion (INR),-1
Python for Data Science-Developer,-1,"Pune, India
BE / BTech
1405960
Job Description
Key skills required for the job are: n Python for Data Science-L2, (Mandatory) .As a Senior Developer, you are responsible for development, support, maintenance and implementation of a complex project module. You should have good experience in application of standard software development principles. You should be able to work as an independent team member, capable of applying judgment to plan and execute your tasks. You should have in-depth knowledge of at least one development technology/ programming language. You should be able to respond to technical queries / requests from team members and customers. You should be able to coach, guide and mentor junior members in the team. Minimum work experience: 3 - 5 YEARS

Roles and Responsibilities
Mandatory Skills: Python for Data Science-L2
Experience Range: 3-5 YEARS
We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law. Any complaints or concerns regarding the recruitment, application or hiring process should be directed to our Ombuds group www.wiproombuds.com. Any US applicant can also call our hotline at 1-866-921-6714. Applicants outside the US can request the applicable hotline number via email via the Ombuds group.

Wipro does not charge any fee at any stage of the recruitment process and has not authorized agencies/partners to collect any fee for recruitment. If you encounter any suspicious mail, advertisements or persons who offer jobs at Wipro, please do let us know by contacting us on helpdesk.recruitment@wipro.com",3.6,"Wipro LTD
3.6",Pune,"Bengaluru, India",10000+ employees,1945,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Cognizant Technology Solutions, Tata Consultancy Services, Accenture"
Data Engineering,-1,"Data Engineer

Job Purpose :
Analyzing, designing, developing and managing the infrastructure and the data that feeds Data Science models.
The Data Engineer is expected to be in charge of the whole lifecycle of the datasets, including updates, backups,
synchronization, and policy access.

Job Responsibilities :
Managing the lifecycle (from data collection to archive) of ML/DL datasets and ensure their
usability for Nielsen’s Data Scientists.
Design, build and integrate data from various sources.
Design ETL pipelines with scripted components.
Optimize data workflows, choosing the most cost-efficient approach.
Automate the management of recurrent task in the pipeline.
Perform feasibility studies/analysis with a critical point of view.
Support and maintain (troubleshoot issues with data and applications).
Develop technical documentation for applications, including diagrams and manuals.
Work on many different software challenges always ensuring a combination of simplicity and
maintainability within the code.
Contribute to architectural designs of large complexity and size, potentially involving several distinct
software components.
Working closely with data scientists and a variety of end-users (across different cultures) to ensure
technical compatibility and user satisfaction.
Work as a member of a team, encouraging team building, motivation and cultivate effective team
relations.

Role Requirements :
E=essential, P=preferred.

E - Bachelor's degree in computer engineering.
P - Master’s degree in data engineering or related.
E - Demonstrated experience and knowledge in Big Data and NoSQL databases.
E - Demonstrated experience and knowledge in Object-Oriented Programming.
E - Demonstrated experience and knowledge in distributed systems.
E - Proficient in programming languages: Python.
E - Experience designing and implementing data warehouses.
E - Experience developing ETL pipelines.
E - Experience working with distributed storage systems in the cloud (Azure, GCP or AWS).
P - Experience managing deep learning datasets.
P - Experience managing Cassandra.
P - Experience working with Spark.
P - Experience implementing CICD pipelines for automation.
E - Experience in the use of collaborative developing tools such as Git, Confluence, Jira, etc.
E - Problem-solving capabilities.
E - Strong ability to analyze and synthesize. (Good analytical and logical thinking capability)
E - Proactive attitude, resolutive, used to work in a team and manage deadlines.
E - Ability to learn quickly.
E - Agile methodologies development (SCRUM/KANBAN).
E - Ability to keep fluid communication written and oral in English, both written and spoken.
Experience level: Minimal work experience of 3-4 years with evidence.

To apply for this job please send your resume to connect@blackstraw.ai

Location :
Blackstraw.ai , Chennai, 4th floor, Tower C, Ratha Tek Meadows Rd, Elcot Sez, Sholinganallur, Chennai, Tamil Nadu 600119, India",4.6,"Blackstraw
4.6",Chennai,"Tampa, FL",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
Sr. Big Data Engineer - Cloudera/ Hortonworks,-1,"Location : Visakhapatnam

Experience : 5-6 years

Notice Period : 30 days

Roles and Responsibilities :
Design & implement new components and various emerging technologies in Hadoop Eco System, and successful execution of various projects.
Integrate external data sources and create data lake/data mart.
Integrate machine learning models on real-time input data stream.
Collaborate with various cross-functional teams: infrastructure, network, database.
Work with various teams to set up new Hadoop users, security and platform governance which should be pci-dss complaint.
Create and executive capacity planning strategy process for the Hadoop platform.
Monitor job performances, file system/disk-space management, cluster & database connectivity, log files, management of backup/security and troubleshooting various user issues.
Design, implement, test and document performance benchmarking strategy for the platform as well for each use cases.
Drive customer communication during critical events and participate/lead various operational improvement initiatives.
Responsible for setup, administration, and monitoring, tuning, optimizing, governing Large Scale
Hadoop Cluster and Hadoop components: On-Premise/Cloud to meet high availability/uptime requirements.? - 2-4 years relevant experience in BIG DATA.
Exposure to Cloudera/Hortonworks production implementations.
Knowledge of Linux and shell scripting is a must.
Sound knowledge on Python or Scala.
Sound knowledge on Spark, HDFS/HIVE/HBASE
Thorough understanding of Hadoop, Spark, and ecosystem components.
Must be proficient with data ingestion tools like sqoop, flume, talend, and Kafka.
Candidates having knowledge on Machine Learning using Spark will be given preference.
Knowledge of Spark & Hadoop is a must.
Knowledge of AWS and Google Cloud Platform and their various components is preferable.",4.7,"innData Analytics
4.7",Visakhapatnam,"Visakhapatnam, India",1 to 50 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"3+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, data warehousing, and building ETL pipelines
Experience in SQL
- 5+ years of experience with and detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures.
- 4+ years of Big data(Hadoop) experience including one programming language JAVA/PYTHON/SCALA
3+ years of experience in architecting data warehouse solutions and integrating technical components
4+ years of experience with relational and star schema data modeling concepts
Experience in MPP systems such as Redshift, Netezza or Teradata.
-Experience in any big data technologies - Hadoop Eco Systems, EMR
3+ years of working with very large data warehousing environment
Demonstrated knowledge and experience in capacity planning for hardware and storage needs
The Finance Automation team at Amazon is looking for a Data Engineer to play a key role in building their industry leading Financial Data Warehouses. If you have experience in building and maintaining very large data warehouses with high transaction volumes then we need you!!!

The Data Engineer should be an expert familiar with all of the new age data engineering technologies (e.g. Distributed computing, MPP systems, Cloud, NoSQL databases, Data Models and atleast one programming language-JAVA/PYTHON/SCALA). The ideal candidate will be responsible for developing overall architecture and high level design. The candidate must have extensive experience with Star Schemas, Dimensional Models, Datamarts in Traditional Data Warehouses as well as in Big Data / Advanced Analytics domains. The individual is expected to bring a methodology and lead the framework development for the next generation data warehouse by designing an efficient, flexible, extensible, and scalable design and mappings and also will be working extensively on building big data environment.

Excellent written and verbal communication skills are required as the candidate will work very closely with a diverse team. The candidate will also lead a small technical teams or participate in close customer interactions while having an influencing role, and be accountable for deliverable's. Ability to create and manage work plans, timelines and accommodate multiple priorities is required.

Job Responsibilities
Tableau Skill is mandatory.
Applies broad knowledge of technology options, technology platforms, design techniques and approaches across the data warehouse life cycle phases to design an integrated, quality solution to address the business requirements
Meets and collaborates with business users on requirements, objectives and measures.
Designs the technology infrastructure across all technical environments
Ensures completeness and compatibility of the technical infrastructure to support system performance, availability and architecture requirements
Designs and plans for the integration for all data engineering components
Supervises the technical implementation of the data warehouse and oversees hardware/ software configuration
Provides input and recommendations on technical issues to the project manager
Reviews technical work of other team members
Reviews and participate in testing of the data design, tool design, data extracts/transforms, networks and hardware selections
Develops the implementation and operation support plans
Experience in PYTHON, BIG DATA and AWS.
Knowledge of Reporting tools such as OBIEE is preferred
Excellent communication skills, both written and verbal
Strong ability to interact, communicate, present and influence within multiple levels of the organization",-1,ADCI HYD 13 SEZ,Hyderabad,-1,-1,-1,-1,-1,-1,-1,-1
Data Management - Digital Expert,-1,"A candidate for this position must have had at least 3 years of working experience working with business analysis/informatics and business outcomes research within a fast-paced and complex business setting, preferably working as support data scientist junior support personnel.

The candidate will also have experience working in probability and statistics, time-series analysis, or econometrics as well as experience in the use of machine learning methods, for example, linear regression, correlation, statistical significance, and so forth. A candidate for this position will also require strong programming skills and experience working with tools such as SAS, R Programming, Open Source, visualizations, and so forth.

A suitable candidate will also have had experience as well as in-depth knowledge of the Python programming language, SAS Enterprise Miner and substantial knowledge of big data platforms such as Aster and Hadoop.

Communication skills for the Data Scientist, both in written and verbal form are a must have. The Data Scientist will be required to explain advanced statistical content to senior data scientists and relevant stakeholders.

Therefore, he must have the ability to translate and tailor this technical content into business applicable material with clear recommendations and insights relevant to the audience at hand.

These reports and presentations will not only be translations of technical analyses into business applicable material, the reports have to be simple, concise, understandable and convincing, which will require exceptionally good communication skills on the Data Scientist’s part.

A candidate for this position must be technologically adept, demonstrate exceptionally good computer skills, and demonstrate a passion for research, statistics, and data analysis as well as a demonstrated ability and passion for designing and implementing successful data analysis solutions within a business.

The candidate must have a strong understanding of data-mining techniques and an ability to apply these techniques in practical real-world business issues. The Data Scientist will demonstrate an ability to consider data, identify patterns, issues, or data analysis needs for the business. The candidate must also have skills in the workings of SQL and scripting languages such as Python and Perl as well as familiarity with statistical analysis, data visualization, and data cleansing tools and techniques.

about you

Excellent customer service skills
Good leadership skills
Ability to build relationships with peers ,stakeholders and the management
Excellent interpersonal skills
Good time management, organizational and communication skills
Ability to work under pressure and deal with multiple tasks concurrently
Proactive, self-motivated
Problem solving skills
Matrix Management
Excellent knowledge of Service Management tools / processes

additional information

Degree / Diploma Holders with good Telecom / and IT infrastructure (Sever / Cloud / Security etc)
CCNA / ITIL Preferred
Excellent verbal & written communication skills in English
5 – 7 years of work experience, at least 3 years in telecom domain
At least 3 years of hands on experience in Data Science
Hands on experience on Power BI or Tableu Application

department

Customer Services & Operations

contract

Regular",3.9,"Orange
3.9",Mumbai,"Paris, France",10000+ employees,1988,Company - Private,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Vodafone, Deutsche Telekom, Telefónica"
CSII - Item and inventory - Senior Data Scientist,-1,"Our Company

We help people around the world save money and live better -- anytime and anywhere -- in retail stores, online and through their mobile devices. Each week, more than 220 million customers and members visit our 11,096 stores under 69 banners in 27 countries and e-commerce websites in 10 countries. With last fiscal revenues of approximately $486 billion, Walmart employs 2.2 million employees worldwide.

@ Walmart Labs in Chennai, we use technology for the charter of building brand new platforms and services on the latest technology stack to support both our stores and e-commerce businesses worldwide.

Our Team:

CSII Team is responsible for building data driven highly optimized supply chain suite of products to manage entire gamut of supply chain lifecycle for our retail and ecommerce lines of business. With our rapidly increasing footfalls in stores and exponential growth in online orders; this all has to be done to scale millions of owned and marketplace SKUs complete inbound and outbound fulfilment lifecycles.

Teams mission - Enable customers to receive their orders when and where they want in an innovative and cost effective way for Walmart derives from Walmarts mission statement - Save Money. Live Better complementing our organizations philosophy to deliver low prices every day, on everything.

How we achieve this, comes down to the team of smartest technologists from India focused on the entire suite of supply chain management products for the Walmart Supply Chain at a massive scale. From forecasting & replenishing inventory for millions of items worth billions of dollars, sourcing of millions of orders, to route optimization & last mile delivery to Warehouse Management Systems to most advanced grocery & order management systems; technology is the backbone behind the entire platform enabling the massive cloud-scale supply chain from India.

With over 4,000 associates in Silicon Valley, San Diego, Portland, Brazil, United Kingdom and India, were bringing together some of the best professionals from around the world. If youre inspired by the opportunity to solve complex problems at scale and make a difference for our customers and members, join us.

Your Opportunity

Data Science

This position Data Science , will be on the Walmart Labs Supply Chain team, focused on building Walmart's best in class Supply Chain. At Walmart Labs, you will Work with small teams of talented analyst to build a best-in-class supply chain at Walmart. Be given the freedom to try new things and prove the value of your own ideas and innovations and own them all the way to production Identify and facilitate the removal of team impediments and escalate as appropriate Foster a motivating culture of openness, collaboration, and continuous improvement Ensure business needs are being met using Data Science best practices Participate in internal hackathons and innovation challenges!.

Your Responsibility

· Develop interactive statistical models using the latest frameworks.

· Develop Machine learning modelling leveraging existing frameworks and customizing to problem.

· Find workable solution in case of data inconsistency and inconclusive data

· Drive projects with minimal guidance. Provide thought leadership by researching best practices and conducting experiments

· Evaluate various analytical/statistical methods and procedures and provide recommendation of relevance, applicability, efficiency of those to Walmart Catalog teams

· Work with cross functional group consisting of Engineering, Product, Program managers to drive data based decisions

Your Qualifications

· Bachelors degree in computer science or related discipline with 8+ years experience (5+ Relevant)

· Practical experience with SAS, ETL, data processing, database programming and data analytics

· Proficient is Sql and no-sql languages, R, Python

· Worked on gathering data from Cassandra, Kafka, MongoDBs. Work with big data on GCP and Azure.

· Advanced statistical modelling skills

· Handled multi-million records of data. Troubleshooting and fixing data issue

· Data Visualization in any BI tools like Tableau, PowerBI, etc.,

· Collected, analyzed, and reported data to meet customer needs.

· Understanding and application of statistical concepts to solve business problems",3.3,"Walmart
3.3",Chennai,"Bentonville, AR",1001 to 5000 employees,1962,Company - Public,"Department, Clothing, & Shoe Shops",Retail,₹500+ billion (INR),"Target, Costco Wholesale, Amazon"
Data Analyst,-1,"Netomi is a Y-Combinator and VC-backed Artificial Intelligence company that sits at the intersection of two rapidly developing fields: AI and messaging. We do not sell an abstract, futuristic technology - we sell a solution that a large number of Fortune 500 companies are using today to drive engagement and sales across the entire customer journey. By leveraging deep reinforcement learning and our continuously learning neural network, our customers are able to successfully meet their objectives of generating social engagement, driving commerce and providing customer service. We're building the future of how technology and people work together to create frictionless experiences for customers.

Want to have a direct impact in solving the top challenges businesses face today? Join us!

Job Description:

We are looking for a Data Analyst who can help us dig into raw data, analyse it and draw conclusions that help in making business decisions.
Responsibilities
Business Analysis to understand the client's business and work with Data Analysts to define the Deep Learning (DL) model
Quality Assurance of Deep Learning models
Analyze the conversation quality in chatbots
Leverage multiple crowdsourcing strategies to collect training and test data for DL models and help with cleansing, filtering and massaging those data
Providing a high level of data quality awareness across multiple teams
Evaluate and identify where enhancements of data to maintained higher quality data
Detailed testing feedback preparation to help the team to improve the models.
Monitor and improve the Data Quality Assurance process that can meet/exceed the current standards and procedures
Learn and/or leverage the required software tools and technology

Requirements
0-1 years experience in related field
Bachelors degree from a Tier I/Tier II college
Knowledge of any one foreign language - French, Spanish or Russian
Excellent written and verbal communication skills
An eye for detail and accuracy",4.8,"Netomi
4.8",Gurgaon,"San Francisco, CA",51 to 200 employees,2015,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"HP is the world’s leading personal systems and printing company, we create technology that makes life better for everyone, everywhere. Our innovation springs from a team of individuals, each collaborating and contributing their own perspectives, knowledge, and experience to advance the way the world works and lives.

We are looking for visionaries, like you, who are ready to make a purposeful impact on the way the world works.

At HP, the future is yours to create!

We are Pricing Analytics Team; our main objective is to help the business to decide optimal price for the HP products in a scientific way through statistical and predictive analysis.

If you are our Data Engineer in India, you will get an opportunity to work on below.

Designs and establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data pipelines, repositories or models for structured data.
Analyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.
Writes and executes complete pipeline plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs and creates solutions for issues with data sources and integration into data system architecture.
Collaborates and communicates with project team regarding project progress and issue resolution. Represents the data engineering team for all phases of larger and more-complex development projects. Provides guidance and mentoring to less experienced staff members.

Are you a high-performer? We are looking for an individual with.

Well versed knowledge on SQL servers and database solutions.
Python programming language to create efficient data flow
Various operating systems like Linux, windows, Unix which will enable data interconnection Data warehousing and ETL tools Good to have.
Knowledge on R and visualization tools such as Power BI / Tableau/ R Shiny Data architecture skills to create effective data flow Team player to interact and understand the data based on data scientists and analysts
#LI-Post",3.3,"HP
3.3",Bengaluru,"Houston, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1
